{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Fake_Reviews_Bert_Downsampled_512.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "621f5003c5f44eb08c0c4a27dd316b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b1bc5eb01be44a8ca3d58f17c86736f5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_43cc940616fa4d35844d8b721522aeef",
              "IPY_MODEL_24d053d374e949688d5db7770771e396"
            ]
          }
        },
        "b1bc5eb01be44a8ca3d58f17c86736f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43cc940616fa4d35844d8b721522aeef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a3a9677fc48048f98dc0d6ffba32fb51",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9eb09889587b4302b7dd1cae9211e296"
          }
        },
        "24d053d374e949688d5db7770771e396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2a722e18c0b34aa49c8b9c0b84f7a352",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 873kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_98e8f164d9f542a8a49c078e4cc7e7c1"
          }
        },
        "a3a9677fc48048f98dc0d6ffba32fb51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9eb09889587b4302b7dd1cae9211e296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a722e18c0b34aa49c8b9c0b84f7a352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "98e8f164d9f542a8a49c078e4cc7e7c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7982dd13d724592bb480d1407e1b396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cec9eb609b6a438da8d9e47fdb8c93f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3e7776b26b134f538a70ca19a1410103",
              "IPY_MODEL_448f301ad0954d5581b2396c845db405"
            ]
          }
        },
        "cec9eb609b6a438da8d9e47fdb8c93f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e7776b26b134f538a70ca19a1410103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_93d75db7bdfd46b79e5b0f782abd2cb1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_284cf875f53840de9f29c8486eeb7066"
          }
        },
        "448f301ad0954d5581b2396c845db405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d663cc94ad1a4e42b4fd1aa36ab08fde",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:10&lt;00:00, 41.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3640e7cd939645118b0c78602513095c"
          }
        },
        "93d75db7bdfd46b79e5b0f782abd2cb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "284cf875f53840de9f29c8486eeb7066": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d663cc94ad1a4e42b4fd1aa36ab08fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3640e7cd939645118b0c78602513095c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a15229eccf374a4fb2f9062cb77c25ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_04f4a168ed80426fb301cf7ce687f8d1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d9106493e9fa44c79103977a97fd57ed",
              "IPY_MODEL_5de95874dbc34484bf9239edc6a1fdc5"
            ]
          }
        },
        "04f4a168ed80426fb301cf7ce687f8d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9106493e9fa44c79103977a97fd57ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e9c5ad16749b478e8a161a007d3676ae",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d70dbcf61ac446bb1fe96c8f06c8b4f"
          }
        },
        "5de95874dbc34484bf9239edc6a1fdc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb0d3a09f9844ee38d6d3aa8f519c1c4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 70.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b71ebd95b60f40388c6af9bb77ead339"
          }
        },
        "e9c5ad16749b478e8a161a007d3676ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d70dbcf61ac446bb1fe96c8f06c8b4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb0d3a09f9844ee38d6d3aa8f519c1c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b71ebd95b60f40388c6af9bb77ead339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ilanagweinstein/Machine-Learning-Project/blob/master/Fake_Reviews_Bert_Downsampled_512.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwujU93ZUC2d",
        "colab_type": "text"
      },
      "source": [
        "## Kaggle Sentiment Analysis on Movie Reviews ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIVMY4-BdK-b",
        "colab_type": "text"
      },
      "source": [
        "**Loading transformers, data and initializing GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNdugWnaLapH",
        "colab_type": "code",
        "outputId": "969e3d88-3fcd-4fcc-c7fd-201e9954c690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/97/7db72a0beef1825f82188a4b923e62a146271ac2ced7928baa4d47ef2467/transformers-2.9.1-py3-none-any.whl (641kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 4.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 58.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/88/49e772d686088e1278766ad68a463513642a2a877487decbd691dec02955/sentencepiece-0.1.90-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 49.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 58.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=8207bb6b998907cfcbf2cc75352d5906542cbecd9bfbd7792d6deb161b857508\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.90 tokenizers-0.7.0 transformers-2.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcnIFcqkLapN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebz8IXtKLuU8",
        "colab_type": "code",
        "outputId": "14acb4b5-890d-4b85-d965-2e3c559bc54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "  raise SystemError('GPU device not found')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMwqMWdgbZ0W",
        "colab_type": "code",
        "outputId": "2c04fb45-757d-45fc-a557-433136fb65cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch# If there's a GPU available...\n",
        "if torch.cuda.is_available():  # Tell PyTorch to use the GPU. \n",
        "  device = torch.device(\"cuda\") \n",
        "  print('There are %d GPU(s) available.' % torch.cuda.device_count()) \n",
        "  print('We will use the GPU:', torch.cuda.get_device_name(0))# If not...\n",
        "else:\n",
        "  print('No GPU available, using the CPU instead.')\n",
        "  device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoF8f73IeOdR",
        "colab_type": "code",
        "outputId": "936ad345-dba2-4607-cd49-7ad08889c074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=fdf46230fdc1bc9ea0b5085c417b60e3890b9f65532529212b716bfbbf4550b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLnGt1Ypfe30",
        "colab_type": "code",
        "outputId": "e20f41ed-e0ce-497c-c6b6-d203a84cd757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!wget 'https://worksheets.codalab.org/rest/bundles/0x7b873062afd04a7f82a7a49940ee7737/contents/blob/' -O train.csv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-19 14:42:33--  https://worksheets.codalab.org/rest/bundles/0x7b873062afd04a7f82a7a49940ee7737/contents/blob/\n",
            "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.71.231.153\n",
            "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.71.231.153|:443... ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHp2bc5Jq3L9",
        "colab_type": "code",
        "outputId": "6b4b0b0c-254b-4692-8c58-9ca9fc28d40c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!wget 'https://worksheets.codalab.org/rest/bundles/0xa63401efaa6d44e39ed6ed9fe7e08cd2/contents/blob/' -O dev.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-19 03:19:38--  https://worksheets.codalab.org/rest/bundles/0xa63401efaa6d44e39ed6ed9fe7e08cd2/contents/blob/\n",
            "Resolving worksheets.codalab.org (worksheets.codalab.org)... 40.71.231.153\n",
            "Connecting to worksheets.codalab.org (worksheets.codalab.org)|40.71.231.153|:443... ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsT-2TG5eDzs",
        "colab_type": "code",
        "outputId": "ce21ebe1-53c7-4bf3-cc59-0cf53106f91c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykZkUaurLapR",
        "colab_type": "code",
        "outputId": "436d5eff-b52c-4c00-eb90-6e6275b67943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# train = pd.DataFrame(pd.read_csv('train.csv', sep=','))\n",
        "# test = pd.DataFrame(pd.read_csv('dev.csv', sep=','))\n",
        "\n",
        "train = pd.DataFrame(pd.read_csv('/drive/My Drive/train.csv', sep=','))\n",
        "test = pd.DataFrame(pd.read_csv('/drive/My Drive/dev.csv', sep=','))\n",
        "\n",
        "print('Number of training sentences: {:,}\\n'.format(train.shape[0]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 250,874\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IqNPn8tLapX",
        "colab_type": "code",
        "outputId": "dfd941bd-5a61-4840-d027-d92116e35778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ex_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>prod_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>label</th>\n",
              "      <th>date</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>923</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-12-08</td>\n",
              "      <td>The food at snack is a selection of popular Gr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>924</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2013-05-16</td>\n",
              "      <td>This little place in Soho is wonderful. I had ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>925</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2013-07-01</td>\n",
              "      <td>ordered lunch for 15 from Snack last Friday.  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>926</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-07-28</td>\n",
              "      <td>This is a beautiful quaint little restaurant o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>927</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-11-01</td>\n",
              "      <td>Snack is great place for a  casual sit down lu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ex_id  ...                                             review\n",
              "0      0  ...  The food at snack is a selection of popular Gr...\n",
              "1      1  ...  This little place in Soho is wonderful. I had ...\n",
              "2      2  ...  ordered lunch for 15 from Snack last Friday.  ...\n",
              "3      3  ...  This is a beautiful quaint little restaurant o...\n",
              "4      4  ...  Snack is great place for a  casual sit down lu...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFfZyAYMLapa",
        "colab_type": "code",
        "outputId": "9b54593f-cba5-4d3d-b55f-f3cc550407c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ex_id</th>\n",
              "      <th>user_id</th>\n",
              "      <th>prod_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>label</th>\n",
              "      <th>date</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>934</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-01-20</td>\n",
              "      <td>all around good place, cozy, I came in and did...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17</td>\n",
              "      <td>940</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2014-09-16</td>\n",
              "      <td>For lunch, my friend and I had: -Lamb sandwich...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20</td>\n",
              "      <td>943</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2014-05-24</td>\n",
              "      <td>Some good Big Greek cooking!! Came to City on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>953</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2013-10-17</td>\n",
              "      <td>So... as you may notice from some of my other ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43</td>\n",
              "      <td>966</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-12-19</td>\n",
              "      <td>I don't understand the whole \"You can't order ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ex_id  ...                                             review\n",
              "0     11  ...  all around good place, cozy, I came in and did...\n",
              "1     17  ...  For lunch, my friend and I had: -Lamb sandwich...\n",
              "2     20  ...  Some good Big Greek cooking!! Came to City on ...\n",
              "3     30  ...  So... as you may notice from some of my other ...\n",
              "4     43  ...  I don't understand the whole \"You can't order ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy8YUGnydeEJ",
        "colab_type": "text"
      },
      "source": [
        "**Analysis of data can be found in Cadent_Sentiment_Analysis_Basic**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4xnNHAwLaqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train['review']\n",
        "y_train = train['label']\n",
        "\n",
        "X_test = test['review']\n",
        "y_test = test['label']\n",
        "\n",
        "train_texts, train_labels = X_train, y_train\n",
        "val_texts, val_labels = X_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR3FWXqW9aKe",
        "colab_type": "code",
        "outputId": "eb7cbd6d-537e-469d-ebb8-57945431401a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# concatenate our training data back together\n",
        "X = pd.concat([X_train, y_train], axis=1)\n",
        "\n",
        "# separate minority and majority classes\n",
        "genuine = X[X.label==0]\n",
        "fake = X[X.label==1]\n",
        "\n",
        "# downsample majority\n",
        "genuine_downsampled = resample(genuine,\n",
        "                                replace = False, # sample without replacement\n",
        "                                n_samples = len(fake), # match minority n\n",
        "                                random_state = 27) # reproducible results\n",
        "\n",
        "# combine minority and downsampled majority\n",
        "downsampled = pd.concat([genuine_downsampled, fake], ignore_index = True)\n",
        "downsampled.shape\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51638, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cClDhmDoJoiD",
        "colab_type": "code",
        "outputId": "330b5d0b-2903-4fc1-d7ca-44d55396dd82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "downsampled.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What a great place! A variety of low-key Itali...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Once upon a time, I was determined to make Emp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Amazing staff, awesome pancakes over all great...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I really liked this place! I went for dinner w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Closed for remodeling. Wish i would have known...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  What a great place! A variety of low-key Itali...      0\n",
              "1  Once upon a time, I was determined to make Emp...      0\n",
              "2  Amazing staff, awesome pancakes over all great...      0\n",
              "3  I really liked this place! I went for dinner w...      0\n",
              "4  Closed for remodeling. Wish i would have known...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8WZIwwK-ZOo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_texts = downsampled['review']\n",
        "train_labels = downsampled['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t6S3JouBeso",
        "colab_type": "code",
        "outputId": "cc0d4726-a1f2-44c9-c28a-58e2b9e43711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "downsampled[downsampled['label'] == 0].shape[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25819"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcOMZ8IuBqA5",
        "colab_type": "code",
        "outputId": "216fe891-c035-4513-b42d-a2ea1501ebf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "downsampled[downsampled['label'] == 1].shape[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25819"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4dDsykFeLkg",
        "colab_type": "text"
      },
      "source": [
        "**Data Pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avew8uWPnv8C",
        "colab_type": "code",
        "outputId": "4780ef79-e039-48e7-f6c1-a54836adbdce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "621f5003c5f44eb08c0c4a27dd316b35",
            "b1bc5eb01be44a8ca3d58f17c86736f5",
            "43cc940616fa4d35844d8b721522aeef",
            "24d053d374e949688d5db7770771e396",
            "a3a9677fc48048f98dc0d6ffba32fb51",
            "9eb09889587b4302b7dd1cae9211e296",
            "2a722e18c0b34aa49c8b9c0b84f7a352",
            "98e8f164d9f542a8a49c078e4cc7e7c1"
          ]
        }
      },
      "source": [
        "#The following code was adapted from this Bert-fine-tuning example by Chris McCormick and Nick Ryan\n",
        "#Link: https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "#The same tutorial has been helpful for a current Fake Claim detection project I have been working on at NYU.\n",
        "\n",
        "#BERT tokenizer\n",
        "from transformers import BertTokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "621f5003c5f44eb08c0c4a27dd316b35",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHtdYGTnoR3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_mask(texts):\n",
        "  # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "  input_ids = []# For every sentence...\n",
        "  attention_masks = []\n",
        "\n",
        "  for text in texts:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    \n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        text,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences. Max BERT can do is 512.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])# Print sentence 0, now as a list of IDs.\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "  \n",
        "    # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  \n",
        "  #print out example\n",
        "  print('Original: ', texts[0])\n",
        "  print('Token IDs:', input_ids[0])\n",
        "  print('Attention Masks:', attention_masks[0])\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMk6Y1I1rMpA",
        "colab_type": "code",
        "outputId": "b5cf9994-c809-4186-b1cb-0b0ac9cc9cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Train data: tokenize, pad, mask and convert to tensors\n",
        "train_inputs, train_masks = tokenize_mask(train_texts)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "\n",
        "#Val data: tokenize, pad, mask and convert to tensors\n",
        "val_inputs, val_masks = tokenize_mask(val_texts)\n",
        "val_labels = torch.tensor(val_labels)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  What a great place! A variety of low-key Italian restaurants interspersed in a large Italian marketplace. We ate at the fish restaurant and everything was delicious. Later I picked up a small apple tart and panna cotta from the dessert counter. However, the restaurant staff are pretty obnoxious and rude as many of them are transplants who have some Italian background and have no idea of American customer service. However our waiter wasn't Italian so he was great but then again I don't blame the staff for being rude and dismissive as the clientele seems to cater to equally rude, entitled, poser elitists like the table of three women who threw a hissy fit when our food arrived earlier than theirs. Another patron started pouting when she got carded. Just go for the food and selection and it will be fine.\n",
            "Token IDs: tensor([  101,  2054,  1037,  2307,  2173,   999,  1037,  3528,  1997,  2659,\n",
            "         1011,  3145,  3059,  7884, 25338,  1999,  1037,  2312,  3059, 18086,\n",
            "         1012,  2057,  8823,  2012,  1996,  3869,  4825,  1998,  2673,  2001,\n",
            "        12090,  1012,  2101,  1045,  3856,  2039,  1037,  2235,  6207, 16985,\n",
            "         2102,  1998,  6090,  2532, 26046,  2696,  2013,  1996, 18064,  4675,\n",
            "         1012,  2174,  1010,  1996,  4825,  3095,  2024,  3492, 27885,  3630,\n",
            "        25171,  1998, 12726,  2004,  2116,  1997,  2068,  2024, 22291,  2015,\n",
            "         2040,  2031,  2070,  3059,  4281,  1998,  2031,  2053,  2801,  1997,\n",
            "         2137,  8013,  2326,  1012,  2174,  2256, 15610,  2347,  1005,  1056,\n",
            "         3059,  2061,  2002,  2001,  2307,  2021,  2059,  2153,  1045,  2123,\n",
            "         1005,  1056,  7499,  1996,  3095,  2005,  2108, 12726,  1998, 19776,\n",
            "         3512,  2004,  1996,  7396, 12260,  3849,  2000, 23488,  2000,  8053,\n",
            "        12726,  1010,  4709,  1010, 13382,  2099, 12005, 16774,  2015,  2066,\n",
            "         1996,  2795,  1997,  2093,  2308,  2040,  4711,  1037, 19074,  2100,\n",
            "         4906,  2043,  2256,  2833,  3369,  3041,  2084, 17156,  1012,  2178,\n",
            "         9161,  2318, 13433, 20807,  2043,  2016,  2288,  4003,  2098,  1012,\n",
            "         2074,  2175,  2005,  1996,  2833,  1998,  4989,  1998,  2009,  2097,\n",
            "         2022,  2986,  1012,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "Attention Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n",
            "Original:  all around good place, cozy, I came in and didn't have a huge appetite but just stuck to the appetizers...which my friend and I did the combo platter of and we were more than full with it.\n",
            "Token IDs: tensor([  101,  2035,  2105,  2204,  2173,  1010, 26931,  1010,  1045,  2234,\n",
            "         1999,  1998,  2134,  1005,  1056,  2031,  1037,  4121, 18923,  2021,\n",
            "         2074,  5881,  2000,  1996, 10439, 20624, 16750,  1012,  1012,  1012,\n",
            "         2029,  2026,  2767,  1998,  1045,  2106,  1996, 25025, 28005,  2121,\n",
            "         1997,  1998,  2057,  2020,  2062,  2084,  2440,  2007,  2009,  1012,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "Attention Masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MYOWL6XegkW",
        "colab_type": "text"
      },
      "source": [
        "**Pre-trained Model and Training Set-up**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSfzPkYxsaiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler# The DataLoader needs to know our batch size for training\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)# Create the DataLoader for our validation set.\n",
        "\n",
        "# Create the DataLoader for validation set without labels.\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAROsdsUtWcw",
        "colab_type": "code",
        "outputId": "5560b61f-f4ed-4435-a5f4-bb93266fba07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f7982dd13d724592bb480d1407e1b396",
            "cec9eb609b6a438da8d9e47fdb8c93f4",
            "3e7776b26b134f538a70ca19a1410103",
            "448f301ad0954d5581b2396c845db405",
            "93d75db7bdfd46b79e5b0f782abd2cb1",
            "284cf875f53840de9f29c8486eeb7066",
            "d663cc94ad1a4e42b4fd1aa36ab08fde",
            "3640e7cd939645118b0c78602513095c",
            "a15229eccf374a4fb2f9062cb77c25ab",
            "04f4a168ed80426fb301cf7ce687f8d1",
            "d9106493e9fa44c79103977a97fd57ed",
            "5de95874dbc34484bf9239edc6a1fdc5",
            "e9c5ad16749b478e8a161a007d3676ae",
            "7d70dbcf61ac446bb1fe96c8f06c8b4f",
            "bb0d3a09f9844ee38d6d3aa8f519c1c4",
            "b71ebd95b60f40388c6af9bb77ead339"
          ]
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        " \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        " num_labels = 2, # The number of output labels for multi-class classification. \n",
        " output_attentions = False, # Whether the model returns attentions weights.\n",
        " output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")# Tell pytorch to run this model on the GPU.\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7982dd13d724592bb480d1407e1b396",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a15229eccf374a4fb2f9062cb77c25ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMLOMxE3e4eo",
        "colab_type": "text"
      },
      "source": [
        "model.cuda() output removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGtw1ayevvg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "optimizer = AdamW(model.parameters(),\n",
        " lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        " eps = 1e-8 # args.adam_epsilon - default is 1e-8.\n",
        " )\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        " num_warmup_steps = 0, # Default value in run_glue.py\n",
        " num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNYYeNFywR8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg8vSTuT7d0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK1LwK5GfAEq",
        "colab_type": "text"
      },
      "source": [
        "#Training#"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1l0NZC3yWSr",
        "colab_type": "code",
        "outputId": "9cd1a263-b00c-48ef-bf02-f8a7f73db12d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "  \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in val_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(val_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "    #save model for epoch\n",
        "\n",
        "    import os\n",
        "\n",
        "    output_dir = './model_save2/epoch_{}'.format(epoch_i)\n",
        "\n",
        "    # Create output directory if needed\n",
        "    if not os.path.exists(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "\n",
        "    print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "    # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "    # They can then be reloaded using `from_pretrained()`\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "    model_to_save.save_pretrained(output_dir)\n",
        "    tokenizer.save_pretrained(output_dir)\n",
        "    \n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  3,228.    Elapsed: 0:00:33.\n",
            "  Batch    80  of  3,228.    Elapsed: 0:01:07.\n",
            "  Batch   120  of  3,228.    Elapsed: 0:01:40.\n",
            "  Batch   160  of  3,228.    Elapsed: 0:02:13.\n",
            "  Batch   200  of  3,228.    Elapsed: 0:02:46.\n",
            "  Batch   240  of  3,228.    Elapsed: 0:03:19.\n",
            "  Batch   280  of  3,228.    Elapsed: 0:03:52.\n",
            "  Batch   320  of  3,228.    Elapsed: 0:04:25.\n",
            "  Batch   360  of  3,228.    Elapsed: 0:04:58.\n",
            "  Batch   400  of  3,228.    Elapsed: 0:05:31.\n",
            "  Batch   440  of  3,228.    Elapsed: 0:06:04.\n",
            "  Batch   480  of  3,228.    Elapsed: 0:06:38.\n",
            "  Batch   520  of  3,228.    Elapsed: 0:07:11.\n",
            "  Batch   560  of  3,228.    Elapsed: 0:07:44.\n",
            "  Batch   600  of  3,228.    Elapsed: 0:08:17.\n",
            "  Batch   640  of  3,228.    Elapsed: 0:08:50.\n",
            "  Batch   680  of  3,228.    Elapsed: 0:09:23.\n",
            "  Batch   720  of  3,228.    Elapsed: 0:09:56.\n",
            "  Batch   760  of  3,228.    Elapsed: 0:10:29.\n",
            "  Batch   800  of  3,228.    Elapsed: 0:11:03.\n",
            "  Batch   840  of  3,228.    Elapsed: 0:11:36.\n",
            "  Batch   880  of  3,228.    Elapsed: 0:12:09.\n",
            "  Batch   920  of  3,228.    Elapsed: 0:12:42.\n",
            "  Batch   960  of  3,228.    Elapsed: 0:13:15.\n",
            "  Batch 1,000  of  3,228.    Elapsed: 0:13:48.\n",
            "  Batch 1,040  of  3,228.    Elapsed: 0:14:21.\n",
            "  Batch 1,080  of  3,228.    Elapsed: 0:14:54.\n",
            "  Batch 1,120  of  3,228.    Elapsed: 0:15:28.\n",
            "  Batch 1,160  of  3,228.    Elapsed: 0:16:01.\n",
            "  Batch 1,200  of  3,228.    Elapsed: 0:16:34.\n",
            "  Batch 1,240  of  3,228.    Elapsed: 0:17:07.\n",
            "  Batch 1,280  of  3,228.    Elapsed: 0:17:40.\n",
            "  Batch 1,320  of  3,228.    Elapsed: 0:18:13.\n",
            "  Batch 1,360  of  3,228.    Elapsed: 0:18:46.\n",
            "  Batch 1,400  of  3,228.    Elapsed: 0:19:20.\n",
            "  Batch 1,440  of  3,228.    Elapsed: 0:19:53.\n",
            "  Batch 1,480  of  3,228.    Elapsed: 0:20:26.\n",
            "  Batch 1,520  of  3,228.    Elapsed: 0:20:59.\n",
            "  Batch 1,560  of  3,228.    Elapsed: 0:21:32.\n",
            "  Batch 1,600  of  3,228.    Elapsed: 0:22:05.\n",
            "  Batch 1,640  of  3,228.    Elapsed: 0:22:38.\n",
            "  Batch 1,680  of  3,228.    Elapsed: 0:23:12.\n",
            "  Batch 1,720  of  3,228.    Elapsed: 0:23:45.\n",
            "  Batch 1,760  of  3,228.    Elapsed: 0:24:18.\n",
            "  Batch 1,800  of  3,228.    Elapsed: 0:24:51.\n",
            "  Batch 1,840  of  3,228.    Elapsed: 0:25:24.\n",
            "  Batch 1,880  of  3,228.    Elapsed: 0:25:57.\n",
            "  Batch 1,920  of  3,228.    Elapsed: 0:26:31.\n",
            "  Batch 1,960  of  3,228.    Elapsed: 0:27:04.\n",
            "  Batch 2,000  of  3,228.    Elapsed: 0:27:37.\n",
            "  Batch 2,040  of  3,228.    Elapsed: 0:28:10.\n",
            "  Batch 2,080  of  3,228.    Elapsed: 0:28:43.\n",
            "  Batch 2,120  of  3,228.    Elapsed: 0:29:16.\n",
            "  Batch 2,160  of  3,228.    Elapsed: 0:29:49.\n",
            "  Batch 2,200  of  3,228.    Elapsed: 0:30:23.\n",
            "  Batch 2,240  of  3,228.    Elapsed: 0:30:56.\n",
            "  Batch 2,280  of  3,228.    Elapsed: 0:31:29.\n",
            "  Batch 2,320  of  3,228.    Elapsed: 0:32:02.\n",
            "  Batch 2,360  of  3,228.    Elapsed: 0:32:35.\n",
            "  Batch 2,400  of  3,228.    Elapsed: 0:33:08.\n",
            "  Batch 2,440  of  3,228.    Elapsed: 0:33:42.\n",
            "  Batch 2,480  of  3,228.    Elapsed: 0:34:15.\n",
            "  Batch 2,520  of  3,228.    Elapsed: 0:34:48.\n",
            "  Batch 2,560  of  3,228.    Elapsed: 0:35:21.\n",
            "  Batch 2,600  of  3,228.    Elapsed: 0:35:54.\n",
            "  Batch 2,640  of  3,228.    Elapsed: 0:36:27.\n",
            "  Batch 2,680  of  3,228.    Elapsed: 0:37:01.\n",
            "  Batch 2,720  of  3,228.    Elapsed: 0:37:34.\n",
            "  Batch 2,760  of  3,228.    Elapsed: 0:38:07.\n",
            "  Batch 2,800  of  3,228.    Elapsed: 0:38:40.\n",
            "  Batch 2,840  of  3,228.    Elapsed: 0:39:13.\n",
            "  Batch 2,880  of  3,228.    Elapsed: 0:39:46.\n",
            "  Batch 2,920  of  3,228.    Elapsed: 0:40:20.\n",
            "  Batch 2,960  of  3,228.    Elapsed: 0:40:53.\n",
            "  Batch 3,000  of  3,228.    Elapsed: 0:41:26.\n",
            "  Batch 3,040  of  3,228.    Elapsed: 0:41:59.\n",
            "  Batch 3,080  of  3,228.    Elapsed: 0:42:32.\n",
            "  Batch 3,120  of  3,228.    Elapsed: 0:43:05.\n",
            "  Batch 3,160  of  3,228.    Elapsed: 0:43:39.\n",
            "  Batch 3,200  of  3,228.    Elapsed: 0:44:12.\n",
            "\n",
            "  Average training loss: 0.61\n",
            "  Training epcoh took: 0:44:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation Loss: 0.60\n",
            "  Validation took: 0:10:02\n",
            "Saving model to ./model_save2/epoch_0\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  3,228.    Elapsed: 0:00:33.\n",
            "  Batch    80  of  3,228.    Elapsed: 0:01:06.\n",
            "  Batch   120  of  3,228.    Elapsed: 0:01:40.\n",
            "  Batch   160  of  3,228.    Elapsed: 0:02:13.\n",
            "  Batch   200  of  3,228.    Elapsed: 0:02:46.\n",
            "  Batch   240  of  3,228.    Elapsed: 0:03:19.\n",
            "  Batch   280  of  3,228.    Elapsed: 0:03:53.\n",
            "  Batch   320  of  3,228.    Elapsed: 0:04:26.\n",
            "  Batch   360  of  3,228.    Elapsed: 0:04:59.\n",
            "  Batch   400  of  3,228.    Elapsed: 0:05:32.\n",
            "  Batch   440  of  3,228.    Elapsed: 0:06:05.\n",
            "  Batch   480  of  3,228.    Elapsed: 0:06:39.\n",
            "  Batch   520  of  3,228.    Elapsed: 0:07:12.\n",
            "  Batch   560  of  3,228.    Elapsed: 0:07:45.\n",
            "  Batch   600  of  3,228.    Elapsed: 0:08:18.\n",
            "  Batch   640  of  3,228.    Elapsed: 0:08:51.\n",
            "  Batch   680  of  3,228.    Elapsed: 0:09:24.\n",
            "  Batch   720  of  3,228.    Elapsed: 0:09:58.\n",
            "  Batch   760  of  3,228.    Elapsed: 0:10:31.\n",
            "  Batch   800  of  3,228.    Elapsed: 0:11:04.\n",
            "  Batch   840  of  3,228.    Elapsed: 0:11:37.\n",
            "  Batch   880  of  3,228.    Elapsed: 0:12:10.\n",
            "  Batch   920  of  3,228.    Elapsed: 0:12:44.\n",
            "  Batch   960  of  3,228.    Elapsed: 0:13:17.\n",
            "  Batch 1,000  of  3,228.    Elapsed: 0:13:50.\n",
            "  Batch 1,040  of  3,228.    Elapsed: 0:14:23.\n",
            "  Batch 1,080  of  3,228.    Elapsed: 0:14:56.\n",
            "  Batch 1,120  of  3,228.    Elapsed: 0:15:29.\n",
            "  Batch 1,160  of  3,228.    Elapsed: 0:16:03.\n",
            "  Batch 1,200  of  3,228.    Elapsed: 0:16:36.\n",
            "  Batch 1,240  of  3,228.    Elapsed: 0:17:09.\n",
            "  Batch 1,280  of  3,228.    Elapsed: 0:17:42.\n",
            "  Batch 1,320  of  3,228.    Elapsed: 0:18:15.\n",
            "  Batch 1,360  of  3,228.    Elapsed: 0:18:48.\n",
            "  Batch 1,400  of  3,228.    Elapsed: 0:19:22.\n",
            "  Batch 1,440  of  3,228.    Elapsed: 0:19:55.\n",
            "  Batch 1,480  of  3,228.    Elapsed: 0:20:28.\n",
            "  Batch 1,520  of  3,228.    Elapsed: 0:21:01.\n",
            "  Batch 1,560  of  3,228.    Elapsed: 0:21:34.\n",
            "  Batch 1,600  of  3,228.    Elapsed: 0:22:08.\n",
            "  Batch 1,640  of  3,228.    Elapsed: 0:22:41.\n",
            "  Batch 1,680  of  3,228.    Elapsed: 0:23:14.\n",
            "  Batch 1,720  of  3,228.    Elapsed: 0:23:47.\n",
            "  Batch 1,760  of  3,228.    Elapsed: 0:24:20.\n",
            "  Batch 1,800  of  3,228.    Elapsed: 0:24:53.\n",
            "  Batch 1,840  of  3,228.    Elapsed: 0:25:27.\n",
            "  Batch 1,880  of  3,228.    Elapsed: 0:26:00.\n",
            "  Batch 1,920  of  3,228.    Elapsed: 0:26:33.\n",
            "  Batch 1,960  of  3,228.    Elapsed: 0:27:06.\n",
            "  Batch 2,000  of  3,228.    Elapsed: 0:27:39.\n",
            "  Batch 2,040  of  3,228.    Elapsed: 0:28:12.\n",
            "  Batch 2,080  of  3,228.    Elapsed: 0:28:46.\n",
            "  Batch 2,120  of  3,228.    Elapsed: 0:29:19.\n",
            "  Batch 2,160  of  3,228.    Elapsed: 0:29:52.\n",
            "  Batch 2,200  of  3,228.    Elapsed: 0:30:25.\n",
            "  Batch 2,240  of  3,228.    Elapsed: 0:30:58.\n",
            "  Batch 2,280  of  3,228.    Elapsed: 0:31:31.\n",
            "  Batch 2,320  of  3,228.    Elapsed: 0:32:05.\n",
            "  Batch 2,360  of  3,228.    Elapsed: 0:32:38.\n",
            "  Batch 2,400  of  3,228.    Elapsed: 0:33:11.\n",
            "  Batch 2,440  of  3,228.    Elapsed: 0:33:44.\n",
            "  Batch 2,480  of  3,228.    Elapsed: 0:34:17.\n",
            "  Batch 2,520  of  3,228.    Elapsed: 0:34:51.\n",
            "  Batch 2,560  of  3,228.    Elapsed: 0:35:24.\n",
            "  Batch 2,600  of  3,228.    Elapsed: 0:35:57.\n",
            "  Batch 2,640  of  3,228.    Elapsed: 0:36:30.\n",
            "  Batch 2,680  of  3,228.    Elapsed: 0:37:03.\n",
            "  Batch 2,720  of  3,228.    Elapsed: 0:37:36.\n",
            "  Batch 2,760  of  3,228.    Elapsed: 0:38:10.\n",
            "  Batch 2,800  of  3,228.    Elapsed: 0:38:43.\n",
            "  Batch 2,840  of  3,228.    Elapsed: 0:39:16.\n",
            "  Batch 2,880  of  3,228.    Elapsed: 0:39:49.\n",
            "  Batch 2,920  of  3,228.    Elapsed: 0:40:22.\n",
            "  Batch 2,960  of  3,228.    Elapsed: 0:40:56.\n",
            "  Batch 3,000  of  3,228.    Elapsed: 0:41:29.\n",
            "  Batch 3,040  of  3,228.    Elapsed: 0:42:02.\n",
            "  Batch 3,080  of  3,228.    Elapsed: 0:42:35.\n",
            "  Batch 3,120  of  3,228.    Elapsed: 0:43:08.\n",
            "  Batch 3,160  of  3,228.    Elapsed: 0:43:41.\n",
            "  Batch 3,200  of  3,228.    Elapsed: 0:44:15.\n",
            "\n",
            "  Average training loss: 0.54\n",
            "  Training epcoh took: 0:44:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "  Validation Loss: 0.59\n",
            "  Validation took: 0:10:02\n",
            "Saving model to ./model_save2/epoch_1\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of  3,228.    Elapsed: 0:00:33.\n",
            "  Batch    80  of  3,228.    Elapsed: 0:01:06.\n",
            "  Batch   120  of  3,228.    Elapsed: 0:01:40.\n",
            "  Batch   160  of  3,228.    Elapsed: 0:02:13.\n",
            "  Batch   200  of  3,228.    Elapsed: 0:02:46.\n",
            "  Batch   240  of  3,228.    Elapsed: 0:03:19.\n",
            "  Batch   280  of  3,228.    Elapsed: 0:03:52.\n",
            "  Batch   320  of  3,228.    Elapsed: 0:04:25.\n",
            "  Batch   360  of  3,228.    Elapsed: 0:04:59.\n",
            "  Batch   400  of  3,228.    Elapsed: 0:05:32.\n",
            "  Batch   440  of  3,228.    Elapsed: 0:06:05.\n",
            "  Batch   480  of  3,228.    Elapsed: 0:06:38.\n",
            "  Batch   520  of  3,228.    Elapsed: 0:07:11.\n",
            "  Batch   560  of  3,228.    Elapsed: 0:07:45.\n",
            "  Batch   600  of  3,228.    Elapsed: 0:08:18.\n",
            "  Batch   640  of  3,228.    Elapsed: 0:08:51.\n",
            "  Batch   680  of  3,228.    Elapsed: 0:09:24.\n",
            "  Batch   720  of  3,228.    Elapsed: 0:09:57.\n",
            "  Batch   760  of  3,228.    Elapsed: 0:10:31.\n",
            "  Batch   800  of  3,228.    Elapsed: 0:11:04.\n",
            "  Batch   840  of  3,228.    Elapsed: 0:11:37.\n",
            "  Batch   880  of  3,228.    Elapsed: 0:12:10.\n",
            "  Batch   920  of  3,228.    Elapsed: 0:12:43.\n",
            "  Batch   960  of  3,228.    Elapsed: 0:13:16.\n",
            "  Batch 1,000  of  3,228.    Elapsed: 0:13:50.\n",
            "  Batch 1,040  of  3,228.    Elapsed: 0:14:23.\n",
            "  Batch 1,080  of  3,228.    Elapsed: 0:14:56.\n",
            "  Batch 1,120  of  3,228.    Elapsed: 0:15:29.\n",
            "  Batch 1,160  of  3,228.    Elapsed: 0:16:02.\n",
            "  Batch 1,200  of  3,228.    Elapsed: 0:16:36.\n",
            "  Batch 1,240  of  3,228.    Elapsed: 0:17:09.\n",
            "  Batch 1,280  of  3,228.    Elapsed: 0:17:42.\n",
            "  Batch 1,320  of  3,228.    Elapsed: 0:18:15.\n",
            "  Batch 1,360  of  3,228.    Elapsed: 0:18:48.\n",
            "  Batch 1,400  of  3,228.    Elapsed: 0:19:21.\n",
            "  Batch 1,440  of  3,228.    Elapsed: 0:19:55.\n",
            "  Batch 1,480  of  3,228.    Elapsed: 0:20:28.\n",
            "  Batch 1,520  of  3,228.    Elapsed: 0:21:01.\n",
            "  Batch 1,560  of  3,228.    Elapsed: 0:21:34.\n",
            "  Batch 1,600  of  3,228.    Elapsed: 0:22:07.\n",
            "  Batch 1,640  of  3,228.    Elapsed: 0:22:41.\n",
            "  Batch 1,680  of  3,228.    Elapsed: 0:23:14.\n",
            "  Batch 1,720  of  3,228.    Elapsed: 0:23:47.\n",
            "  Batch 1,760  of  3,228.    Elapsed: 0:24:20.\n",
            "  Batch 1,800  of  3,228.    Elapsed: 0:24:53.\n",
            "  Batch 1,840  of  3,228.    Elapsed: 0:25:27.\n",
            "  Batch 1,880  of  3,228.    Elapsed: 0:26:00.\n",
            "  Batch 1,920  of  3,228.    Elapsed: 0:26:33.\n",
            "  Batch 1,960  of  3,228.    Elapsed: 0:27:06.\n",
            "  Batch 2,000  of  3,228.    Elapsed: 0:27:39.\n",
            "  Batch 2,040  of  3,228.    Elapsed: 0:28:12.\n",
            "  Batch 2,080  of  3,228.    Elapsed: 0:28:46.\n",
            "  Batch 2,120  of  3,228.    Elapsed: 0:29:19.\n",
            "  Batch 2,160  of  3,228.    Elapsed: 0:29:52.\n",
            "  Batch 2,200  of  3,228.    Elapsed: 0:30:25.\n",
            "  Batch 2,240  of  3,228.    Elapsed: 0:30:58.\n",
            "  Batch 2,280  of  3,228.    Elapsed: 0:31:31.\n",
            "  Batch 2,320  of  3,228.    Elapsed: 0:32:05.\n",
            "  Batch 2,360  of  3,228.    Elapsed: 0:32:38.\n",
            "  Batch 2,400  of  3,228.    Elapsed: 0:33:11.\n",
            "  Batch 2,440  of  3,228.    Elapsed: 0:33:44.\n",
            "  Batch 2,480  of  3,228.    Elapsed: 0:34:17.\n",
            "  Batch 2,520  of  3,228.    Elapsed: 0:34:50.\n",
            "  Batch 2,560  of  3,228.    Elapsed: 0:35:24.\n",
            "  Batch 2,600  of  3,228.    Elapsed: 0:35:57.\n",
            "  Batch 2,640  of  3,228.    Elapsed: 0:36:30.\n",
            "  Batch 2,680  of  3,228.    Elapsed: 0:37:03.\n",
            "  Batch 2,720  of  3,228.    Elapsed: 0:37:36.\n",
            "  Batch 2,760  of  3,228.    Elapsed: 0:38:10.\n",
            "  Batch 2,800  of  3,228.    Elapsed: 0:38:43.\n",
            "  Batch 2,840  of  3,228.    Elapsed: 0:39:16.\n",
            "  Batch 2,880  of  3,228.    Elapsed: 0:39:49.\n",
            "  Batch 2,920  of  3,228.    Elapsed: 0:40:22.\n",
            "  Batch 2,960  of  3,228.    Elapsed: 0:40:55.\n",
            "  Batch 3,000  of  3,228.    Elapsed: 0:41:29.\n",
            "  Batch 3,040  of  3,228.    Elapsed: 0:42:02.\n",
            "  Batch 3,080  of  3,228.    Elapsed: 0:42:35.\n",
            "  Batch 3,120  of  3,228.    Elapsed: 0:43:08.\n",
            "  Batch 3,160  of  3,228.    Elapsed: 0:43:41.\n",
            "  Batch 3,200  of  3,228.    Elapsed: 0:44:14.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:44:37\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation Loss: 0.68\n",
            "  Validation took: 0:10:02\n",
            "Saving model to ./model_save2/epoch_2\n",
            "\n",
            "Training complete!\n",
            "Total training took 2:43:59 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpiQ1LZ3rsdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r ./model_save2/ \"/drive/My Drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8vT9lN_VOjk",
        "colab_type": "code",
        "outputId": "9ba14649-760d-48b2-f566-c74914b9013b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.61</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0:44:34</td>\n",
              "      <td>0:10:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.54</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0:44:37</td>\n",
              "      <td>0:10:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.43</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0:44:37</td>\n",
              "      <td>0:10:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.61         0.60           0.62       0:44:34         0:10:02\n",
              "2               0.54         0.59           0.67       0:44:37         0:10:02\n",
              "3               0.43         0.68           0.65       0:44:37         0:10:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFOYhwOLVWmm",
        "colab_type": "code",
        "outputId": "bcc94d41-8b98-4a01-de37-8aea97f211ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "#We do not have validation labels t\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvUAAAGaCAYAAACPCLyfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3xUVf4//tf0mfSQ3gMBkkAKJZRAQguBUEQFIkVFWT9Y1u6qq7vud939re7KugKi6yo2RBRFpAkETGihSIAgoYROQkImhfSeKff3R8xASAIZyORmktfz8fChc+eWd0YOec2555wrEQRBABERERERWS2p2AUQEREREdHdYagnIiIiIrJyDPVERERERFaOoZ6IiIiIyMox1BMRERERWTmGeiIiIiIiK8dQT0TUQ+Tm5iI4OBjLly+/43O89tprCA4O7sCqiIioI8jFLoCIqKcyJxynpKTA19fXgtVYl+DgYIwbNw4ff/yx2KUQEXUJEj58iohIHBs3bmz2+ujRo/juu+8wZ84cDB06tNl78fHxsLGxuavrCYKAhoYGyGQyyOV31qej0+lgNBqhUqnuqpa7xVBPRNQce+qJiERy7733NnttMBjw3XffYdCgQS3eu1lVVRXs7OzMup5EIrnrMK5QKO7qeCIisgyOqSci6uImTJiAhx9+GKdPn8Zjjz2GoUOHYsaMGQAaw/2SJUuQmJiIESNGICwsDPHx8Xj33XdRW1vb7Dytjam/cduuXbswa9YshIeHIyYmBu+88w70en2zc7Q2pr5pW2VlJf76178iOjoa4eHhmDt3Lo4fP97i5yktLcXrr7+OESNGYPDgwViwYAFOnz6Nhx9+GBMmTOioj830873yyisYNWoUwsLCMHHiRLz33nstPpuysjK8/fbbmDhxIsLDwzFixAjMnDkTn376abP9NmzYgNmzZyMqKgqDBg1CXFwc/vCHP6CkpKRD6yYiMhd76omIrEBeXh4eeeQRJCQkYNKkSaipqQEAFBQU4IcffsCkSZMwffp0yOVypKWl4dNPP0VmZiY+++yzdp1/z549+OabbzB37lzMmjULKSkp+Pzzz+Ho6Ignn3yyXed47LHH0KtXLzz99NMoKyvDF198gccffxwpKSmmuwoNDQ1YuHAhMjMzMXPmTISHh+Ps2bNYuHAhHB0d7+zDacPVq1eRmJiIyspKzJ8/HwEBAUhLS8PHH3+M9PR0fPnll6ZhSM8//zyOHDmCuXPnIjg4GHV1dbh48SLS0tLwf//3fwAaA/0f//hHREVF4bnnnoNarYZWq8WePXtQXFyMXr16dWj9RETmYKgnIrICubm5+Mc//oHExMRm2/38/LB79+5mw2IefPBBLF26FB999BEyMjIQERFx2/NfuHABP/30k2ky7rx583DPPffg66+/bneoHzBgAN58803T66CgILzwwgv46aefMHfuXADA2rVrkZmZiRdeeAFPPfWUad/+/fvj73//O3x8fNp1rfZ47733UFJSgk8++QRjx44F0PjZvPPOO/j888+xfv16U+j/5ZdfMG/ePPzlL39p83zJycmwtbXFypUrm81JeP755zusZiKiO8XhN0REVsDJyQkzZ85ssV2pVJoCvV6vR3l5OUpKSjBq1CgAaHX4S2vi4uKara4jkUgwYsQIFBUVobq6ul3nePTRR5u9HjlyJAAgOzvbtG3Xrl2QyWRYsGBBs30TExNhb2/fruu0h9FoxM6dOzFgwABToG/yxBNPQCqVIjk5GQCgUqmgVCqRkZGB3NzcNs9pb2+Puro67N69G1xjgoi6GvbUExFZAT8/P8hkslbfW716NdasWYMLFy7AaDQ2e6+8vLzd57+Zk5MTgMbx5ra2tmafw9nZ2XR8k9zcXLi7u7c4n1KphK+vLyoqKtpV7+2UlJSgpqYGffv2bfGek5MT3NzckJOTY7r2n/70J7z11luIi4tD3759MXLkSEycOBHR0dGm45544gkcPnwYTz/9NJycnDB8+HCMGTMGU6ZMMXvSMhFRR2OoJyKyAhqNptXtX3zxBf71r38hJiYGCxYsgLu7OxQKBQoKCvDaa6+1u0e5rS8MAO76HNbQqz1v3jzExcVhz549SEtLw/bt2/H1119j6tSpWLJkCQAgMDAQW7duxcGDB3Hw4EGkpaXhjTfewPvvv4/Vq1fD399f5J+CiHoyhnoiIiu2ceNG+Pj4YMWKFZBKr4+o3Lt3r4hVtc3HxwcHDx5EdXV1s956nU6H3NxcODg4dMh1evXqBVtbW1y4cKHFe+Xl5SgqKkJoaGiz7e7u7khMTERiYiIMBgNeffVV/PTTT1i4cKFpXoJSqcTYsWNNQ3r27NmDxx9/HF988QX++te/dkjtRER3gmPqiYismFQqhUQiadYbrtfrsWLFChGratuECRNgMBjw1VdfNdv+/fffo7KyssOuI5VKMX78eJw+fbrFF5xPPvkERqMREydOBADU1ta2WOJSJpOZlu5sGsLU2rKVAwYMaLYPEZFY2FNPRGTFEhIS8J///AeLFi1CfHw8qqqq8NNPP93xE2MtLTExEWvWrMHSpUtx5coV05KWSUlJCAgIaLEu/q1kZ2fjv//9b6vvPfroo3jppZdw4MABPP3005g/fz78/f1x5MgRbN26FcOGDcP9998PAMjKysJDDz2E+Ph49OvXDw4ODrh06RK+/fZb+Pr6IioqCkDjkp329vaIioqCl5cXKioqsH79ekgkkts+LIyIyNK65t/6RETULo899hgEQcAPP/yAt956C25ubpgyZQpmzZqFqVOnil1eC0qlEitXrsTixYuRkpKCbdu2ISIiAl9++SX+/Oc/o66urt3nunz5MpYtW9bqe4mJifDx8cH333+P999/H5s2bUJlZSU8PDzwxBNP4KmnnjJ98fH09MSsWbNw6NAhJCcno6GhAR4eHkhMTMSiRYtM8xnmzZuHbdu24bvvvkN5eTmcnJwQGhqKN954w7TSDxGRWCSCNcxgIiKibs1gMGDkyJGIiIho9wOziIjoOo6pJyKiTtVab/yaNWtQUVGB0aNHi1AREZH14/AbIiLqVG+88QYaGhowePBgKJVKHDt2DD/99BMCAgLwwAMPiF0eEZFV4vAbIiLqVBs2bMDq1auRlZWFmpoauLi4YOzYsXj++efh6uoqdnlERFaJoZ6IiIiIyMpxTD0RERERkZVjqCciIiIisnKcKGum0tJqGI0dO2LJxcUOxcVVHXpOImrE9kVkOWxfRJYhlUrg7Gxr1jEM9WYyGoUOD/VN5yUiy2D7IrIcti+iroHDb4iIiIiIrBxDPRERERGRlWOoJyIiIiKycgz1RERERERWjqGeiIiIiMjKcfUbIiIiog5QW1uNqqpyGAw6sUuhLkwmU8DOzhEajXlLVt4OQz0RERHRXdLpGlBZWQonJ1coFCpIJBKxS6IuSBAE6HT1KCu7BrlcAYVC2WHn5vAbIiIiortUWVkGOztHKJVqBnpqk0QigVKphq2tI6qqyjr03Az1RERERHdJr2+ASqURuwyyEmq1BjpdQ4eek8NviIiIyCxp+enYdDEJZfVlcFI5YUZQAoZ7DhG7LFEZjQZIpTKxyyArIZXKYDQaOvScDPVERETUbmn56fjmzDrojI2TQUvry/DNmXUA0OODPYfdUHtZ4s8Kh98QERFRu226mGQK9E10Rh02XUwSqSIiAhjqiYiIqJ0KqgtRWt/65L62thPdzjPPPI5nnnm804/tbjj8hoiIiG7papUW27N2Ir0wo819nFVOnVgRdYaYmKh27bd27SZ4eXlbuBq6HYZ6IiIiatWVilwkZaXg+LVTUMmUiA8YB2eVE3688FOzITgKqQIzghJErJQs4S9/+Xuz199//y0KCrR49tmXmm13cnK+q+ssWfKhKMd2Nwz1RERE1Myl8mwkZaXgVPEZaOQaTA2ciHF+MbBV2AAA1HIVV7/pASZPntrs9e7dKSgvL2ux/WZ1dXVQq9Xtvo5Cobij+u722O6GoZ6IiIggCALOl11CUlYKzpZegJ3CFjP6JGCMbzQ08ubrrw/3HILhnkPg5maPoqJKkSqmruCZZx5HVVUVXn31T1i+fAnOnj2DBx9cgMceewKpqbuxadN6nDt3FhUV5XBzc8fUqffg4YcXQiaTNTsHAHzwwScAgPT0I3juuSfx1luLcfnyJWzYsA4VFeUID4/EK6/8Cb6+fh1yLACsW/c91qxZjeLiawgKCsIzz7yIFSs+anZOa8FQT0RE1IMJgoAzJeexLSsZF8uzYK+0w/19pyHWJxoqWcc9wp7Md/BUPn7ccxHFFfVwcVBh5tggRA/0FLusFsrKSvHqqy9i0qQEJCRMg4dHY41bt/4EjcYGc+Y8CBsbDY4ePYJPP/0fqqur8fTTz9/2vCtXfgapVIb58xegsrIC3367Cn/72xtYsWJlhxy7fv0PWLJkMQYNGoI5c+ZBq9Xi9ddfhr29Pdzc3O/8AxEJQz0REVEPJAgCThZnYltWCrIrcuCkckRi/3sxyms4lDIOaRDbwVP5WLntDBr0RgBAcUU9Vm47AwBdLthfu1aE1177C6ZPv7fZ9jff/AdUquvDcO67bzb+/e+3sX79Wixa9BSUylt/adTr9fj885WQyxvjqoODI5YtexeXLl1Anz597+pYnU6HTz/9CAMHhmPp0v+a9uvbtx/eeutNhnoiIiLq2oyCEb8WnURSVgquVmnhou6F+cGzMMJrKORSxoKOtv+EFvsytGYfdzGvHHqD0Gxbg96IL7ZmYu+veWafLybCC6PDvcw+rj3UajUSEqa12H5joK+pqUZDgw6RkYOxceOPyM7OQr9+/W953mnTZpjCNgBERg4CAOTlXb1tqL/dsWfOnEZ5eTl+//v7m+0XH5+A999/75bn7qrYeomIiHoAg9GAo4XHsT1rJ/JrCuFu44oFoXMQ5TEIMqns9iegTnVzoL/ddjG5ubk3C8ZNLl26iBUrPkJ6+mFUV1c3e6+6uuq2520axtPE3t4BAFBZeft5HLc7Nj+/8YvWzWPs5XI5vLws8+XH0hjqiYiIujGD0YBD+enYkb0TRbXF8Lb1xO8Gzsdg9whIJXwGpaWNDr+zHvJX/rsfxRX1Lba7OKjwxwe71kpDN/bIN6msrMSzzz4OGxs7PPbYk/Dx8YVSqcS5c2fw0UfLYTQab3teaRtfNgXh9l9s7uZYa8VQT0RE1A3pjHr8oj2MHdm7UVJXCj97HywKX4AI1wEM81Zg5tigZmPqAUApl2Lm2CARq2q/Y8eOory8HG+99W8MGnT9S4hWa/7QIUvw9Gz8opWbm4PIyMGm7Xq9HlqtFkFBtx7e0xUx1BMREXUjDYYG7M9Lw8/Zu1HeUIHeDv6Y0/8+DHQJgUQiEbs8aqemybDWsPpNa6TSxi+ON/aM63Q6rF+/VqySmgkJGQBHR0ds2rQekydPNQ0f+vnnJFRWVohc3Z1hqCciIuoG6vR1SL36C1Ku7EWlrgr9nPpgwYA5CHbuyzBvpaIHelpNiL9ZeHgE7O0d8NZbb2L27DmQSCTYvn0rusroF4VCgd/97nEsWfJvvPDC7zF+fBy0Wi22bdsMHx9fq2wzDPVERERWrEZXiz25+7ErZx+q9TUI7dUfCYFx6OvUW+zSqAdzdHTC4sVL8MEHS7FixUewt3fApElTEBU1HC+99IzY5QEAZs2aA0EQsGbNanz44TIEBfXDv/71HpYufRdKpUrs8swmEbrzjAELKC6ugtHYsR8Zn8hHZDlsX9RdVTVUY1dOKnbnHkCdoQ7hrqFICIxDoIN/p9XA9nVdfn42PD0DxC6D7pLRaMT06fEYO3Y8/vjHNyx6rVv9mZFKJXBxsTPrfOypJyIisiLl9ZVIydmD1Ku/QGfQYZBbGCYHxsHP3lvs0oisSn19PVSq5j3ySUlbUFFRjsGDh4pU1Z1jqCciIrICpXVlSL6yB/vzDkFvNCDKYxAmB06Al62H2KURWaWMjF/x0UfLMW7cBDg4OOLcuTPYsmUT+vQJwvjxE8Uuz2wM9URERF3YtdoS/Jy9C79oj8AIASM8h2JSwDi427iJXRqRVfP29oGrqxt++OE7VFSUw8HBEQkJ0/Dkk89AoVCIXZ7ZGOqJiIi6oMKaImzP2oW0gnRIIcFI72GY5D8OLppeYpdG1C34+Phi8eIlYpfRYRjqiYiIupC8qnxsz96JowXHIZfKMNZnFCYGjIWTylHs0oioC2OoJyIi6gJyKq8iKSsFvxadhFKmxET/sZjgHwsHpb3YpRGRFWCoJyIiEtHl8itIykrByeJMaORqTAmMwzi/GNgpbMUujYisCEM9ERGRCM6XXkJSVgrOlJ6HrdwG9/SZjDE+o2Cj0IhdGhFZIYZ6IiKiTiIIAs6WXsC2rGRcKLsMe4Ud7guailifaKjl1vcESyLqOhjqiYiILEwQBJwqPoNtWSnIqrgCJ5UjZvebgdHeI6CUWd/SeUTU9TDUExERWYhRMCKj6BSSslKQU5UHF7Uz5gbPxEivKCik/BVMRB1HKnYBRERE3Y1RMOJI/jG8nbYEK06uQr2hAQ+FPoC/jnwVsT4jGeipR9q6dTNiYqKg1eaZts2efQ/eeuvNOzr2bqWnH0FMTBTS04902DnFxL9ViIiIOojBaEBawTHsyNqJwtpr8LT1wMIB8zDEIxJSCfvRyLq8+uqLSE8/jM2bf4ZG0/oE7pdeeganTp3Apk07oFJ1zXkhycnbUVJSjAcemC92KRbFUE9ERHSXdEY9ftEewc/Zu1BcVwpfO2/8X9jDiHQbyDBPVis+fjIOHEjFvn17EB+f0OL90tISHD16GJMmTbnjQP/NN+sglVq2jaSk7MD58+dahPpBg4YgJWU/FIruMa9F1FDf0NCAZcuWYePGjaioqEBISAhefPFFREdHt+v4zZs3Y+XKlbhw4QKUSiX69++PV199FREREQCA3NxcxMXFtXrsihUrMGbMmA77WYiIqOdpMOhwIC8NP1/ZjbL6cgQ4+CGx/70IcwmFRCIRuzyiuxIbOw4ajQ2Sk7e3Gup37kyGwWDApEkt32svpVJ5NyXeFalU2mXvLtwJUUP9a6+9hh07dmDBggUICAjA+vXrsWjRIqxatQqDBw++5bFLlizBp59+ihkzZmDOnDmoqanBmTNnUFRU1GLfGTNmICYmptm2kJCQDv1ZiIio56jT12Nf3i9IvrIHlQ1VCHLsjYdCExHi3I9hnroNtVqN2Nix2LUrGRUVFXBwcGj2fnLydri4uMDPLwDvvvsvHD2ahoKCAqjVagwZEoWnn34eXl7et7zG7Nn3YPDgofjzn980bbt06SKWLv03Tp48AUdHR9x770y4urq1ODY1dTc2bVqPc+fOoqKiHG5u7pg69R48/PBCyGQyAMAzzzyOX39NBwDExEQBADw9vfDDD5uRnn4Ezz33JN5//38YMiTKdN6UlB34+usvkZ2dBRsbW4weHYunnnoOTk5Opn2eeeZxVFVV4f/9v7/jvfcWIzPzFOztHZCYOBcPPviIeR90BxEt1GdkZGDLli14/fXX8eijjwIA7rvvPkyfPh3vvvsuVq9e3eax6enp+Pjjj7F8+XLEx8ff9loDBw7Evffe21GlExFRD1Wrr8We3APYmZOKal0NQpz7IWHgBPRzDhK7NOqG0vLTseliEkrry+CscsKMoAQM9xzSqTXExydgx45t2L07BTNm3G/anp+vxcmTGZg9ey4yM0/h5MkMTJw4GW5u7tBq87Bhwzo8++wT+PrrtVCr1e2+XnHxNTz33JMwGo146KFHoFZrsGnT+lZ71Ldu/QkajQ3mzHkQNjYaHD16BJ9++j9UV1fj6aefBwA88sjvUFtbi4ICLZ599iUAgEZj0+b1t27djLff/hsGDgzHU089h8LCAqxb9x0yM09hxYqvmtVRUVGOP/zhOYwfH4e4uEnYtSsZH320HH369EV09Oh2/8wdRbRQn5SUBIVCgcTERNM2lUqF2bNnY8mSJSgsLIS7u3urx3711VcIDw9HfHw8jEYjamtrYWt768dp19TUQC6Xi3qbh4iIrFO1rga7clKxO3c/avV1CHMJweTAOPRxDBC7NOqm0vLT8c2ZddAZdQCA0voyfHNmHQB0arAfNmwEnJyckZy8vVmoT07eDkEQEB8/GUFBfTF+/MRmx40ePQZPPrkQu3enICFhWruvt3r1SpSXl+HTT1chOLhxVMWUKdMxb979LfZ9881/QKW6/oXhvvtm49//fhvr16/FokVPQalUYtiwkfjxx7UoLy/D5MlTb3ltvV6Pjz5ajr59+2P58o9NmTE4OARvvvlnbN68HrNnzzXtX1hYgL/+9R+moUnTp9+L2bOnY8uWjT0r1GdmZqJ3794twnhERAQEQUBmZmabof7gwYOYNm0a3nvvPaxatQo1NTXw8fHBCy+8gBkzZrTYf9myZfjnP/8JiUSCyMhIvPzyyxg2bJhFfi4iIuo+KhuqkHJlL/ZePYB6QwMi3cKQEDgB/va+YpdGVuKQ9igOag+bfdzl8ivQC/pm23RGHVZn/oADeWlmny/aaxhGeA01+zi5XI4JEyZiw4Z1uHbtGlxdXQEAyck74OvrhwEDwprtr9frUV1dBV9fP9jZ2ePcuTNmhfqDB/cjPDzSFOgBwNnZGfHxU7B+/dpm+94Y6GtqqtHQoENk5GBs3PgjsrOz0K9ff7N+1jNnTqO0tMT0haDJhAnx+PDDZThwYH+zUG9nZ4eJEyebXisUCoSGDkRe3lWzrttRRAv1RUVF8PDwaLHdza1xzFRhYWGrx5WXl6OsrAxbtmyBTCbDyy+/DCcnJ6xevRqvvPIKNBqNaUiOVCpFTEwM4uPj4e7ujuzsbHz22WdYuHAhvvzyS0RFRbV6DSIi6tnK6suRfGUP9l09BL1RjyHuEUgIjIO3nafYpVEPcXOgv912S4qPT8CPP67Fzp078MAD85GVdRkXLpzDwoWLAAD19XVYtepLbN26GUVFhRAEwXRsVVWVWdcqKMhHeHhki+3+/i3vil26dBErVnyE9PTDqK6ubvZedbV51wUahxS1di2pVApfXz8UFGibbXd392gxh8be3gEXL14w+9odQbRQX1dX1+oSQk1jlerr61s9rqamBgBQVlaG77//HpGRjf/j4+PjER8fjw8//NAU6r29vfHZZ581O37q1KmYNm0a3n33XaxZs8bsul1c7Mw+pj3c3Owtcl4iYvui9iuqLsbGzB3YefkAjIIRsQHDcX/oZHg7MMy3he2rUWGhFHJ5y6UZR/sNw2g/80cHvL73HyipK2uxvZfaCS8P//0d1XinBg8eDG9vHyQnb8f8+Q8hJWU7AGDKlKmQy6V45513sWXLJsyZMx/h4RGwtbWDRCLBX/7yOgCYPheptDEAy2TNPyuJRNLstVQqafFZ3nxsZWUlnn32Cdja2uLxx5+Cj48vlEoVzp7NxIcfvg+J5Pp1m4L3zeeUyaTNznn9dcvr33wOiUQCmUzW6n6CILT6Z+FmUqm0Q9uPaKFerVZDp9O12N4U5ttaYqhpu6+vrynQA41LIk2ePBlfffUVqqur2xxj7+HhgWnTpuH7779HbW1tmw9TaEtxcRWMRuH2O5rBzc0eRUWVHXpOImrE9kXtUVhzDTuyd+FQ/lFIIMFIryhMChgHV40LUA/+GWoD29d1RqMRer2xw853T5+EZmPqAUAhVeCePgkdep32ioubhFWrvkBWVjZ+/nk7goND4e3tB73eiF27kpGQMA1PP/2Caf/6+npUVVVCEARTvU35yWBo/lnduI+HhyeuXLnS4mfMyspqduzhw4dRXl6Gt95ajEGDrs8xyM3NbXGNphsHN5/TYDA229fNrXEEyeXLWQgPv74KoyAIyMm5gt69g244pwBBaHnOprsU7fl/ZDQa22w/UqnE7I5k0Z6I4ebm1uoQm6YlKdsaT+/k5ASlUmka03UjV1dXCIJw21s9Xl5eMBqNqKiouIPKiYiou8ivLsCXp77F33/5N44UHEOsTzT+Fv1HzA+Z1RjoiUQy3HMI5ofMgrOqcRlFZ5UT5ofM6vTVb5pMmjQFAPDBB0uQm5vTbG16qVTWYv91676DwWAw+zrR0aNx4sRxnD17xrSttLQUP/+8rdl+TQ+sunGoj06nazHuHgA0Gk27hgGFhAyAs3MvbNjwQ7OO5127UlBUVIhRozp/8qs5ROupDwkJwapVq1r0qh8/ftz0fmukUilCQ0NRUFDQ4r38/HzIZDI4Ojre8to5OTnt2o+IiLqn3Mo8JGWl4Neik1BI5ZjgH4s4v7FwVHEoCXUdwz2HiBbib9a7dx/07dsf+/bthVQqRVzc9Qmio0bFYPv2rbC1tUNgYG+cOnUCR46k3VHOmj//EWzfvhUvvfQ0Zs+eC5VKjU2b1sPDwwtVVedN+4WHR8De3gFvvfUmZs+eA4lEgu3bt0JoZTBFcHAIduzYhuXL30NIyABoNDaIiWn5AFK5XI6nnnoWb7/9Nzz77BOYOHESCgsL8MMP36FPnyDcc0/LFXi6EtF66hMSEqDT6bB27fVvVA0NDfjxxx8xZMgQ0yTavLw8XLx4scWxWq0W+/fvN22rqqrCtm3bMHjwYNN6qCUlJS2um52djS1btiAqKsqsdVOJiMj6ZVfk4H8ZX+Kfh5cis+QcJgWMx/836k+Y2Xc6Az3RbTT1zg8ePLTZiInnn38ZkydPxc8/b8MHHyzFtWvXsHTph7dcD74trq6ueP/9j9G7dxBWrfoSa9d+i4SEqUhMnNtsP0dHJyxevAQuLq5YseIjfPvt14iKGoHf//65Fue8995ZmDx5CrZu/Ql/+9sbWLr0321ef+rUe/Dmm2+hvr4OH364DFu3bkZ8fAKWLftfl3/6rEQQWvtO0zmef/55pKSk4JFHHoG/vz/Wr1+PkydPYuXKlRg6tHHZpYcffhhpaWk4e/as6bja2lrMnDkTBQUFePTRR+Hg4IB169bh8uXLzY59/fXXkZOTg5EjR8Ld3R1XrlzBmjVroNfrsXr1agwcONDsmjmmnsi6sH0RAFwou4ykrBRklpyDjVyD8X4xGOc7GjYK80MHXcf2dV1+fjY8PfncAmq/W/2ZuezzE9UAACAASURBVJMx9aINvwGAxYsXY+nSpdi4cSPKy8sRHByMTz75xBTK26LRaPDVV19h8eLF+Prrr1FXV4eBAwfiiy++aHbs6NGjsWbNGnz99deorKyEg4MDRo8ejWeeeQb9+vWz9I9HREQiEgQB50ovYltWMs6XXYKdwhb3Bk3BGJ9oqOW8U0tE3YuoPfXWiD31RNaF7avnEQQBp0vOYtvlFFyuyIaj0h4TA8ZhtPcIqGR8qnhHYvu6jj31ZK5u1VNPRETUUYyCESeunUZSVgquVF6Fs8oJc/rfj2ivKChkLZ+LQkTUnTDUExGRVTMKRhwrzEBS1k7kVefDVeOCB0NmY7jnEMil/DVHRD0D/7YjIiKrZDAacKTgV2zP3omCmiJ42LjjkQFzMdQ9ErJW1s0mIurOGOqJiMiq6I16HNIexY7sXbhWVwIfOy88FvYQBrmFQSoRbaVmIiJRMdQTEZFV0Bl0OKA9jJ+zd6O0vgz+9r54ot89CHMNZZgnoh6PoZ6IiLq0ekMD9l39BclX9qCioRJ9HAMxP2QWQnv1h0QiEbs8IhNBEPhnktrFEotPMtQTEVGXVKuvw97cA9iZk4oqXTX6O/fFwoHz0M8piMGJuhyZTA6drgFKZdd+6ih1DTpdA2Syjo3hDPVERNSl1OhqsCtnH3bl7ketvhYDXIIxJTAOfRwDxS6NqE12dk4oKyuCk5MbFAolv3hSqwRBgE7XgLKyItjbO3fouRnqiYioS6hsqMLOnFTszT2AOkM9Il0HYnLgBAQ4+IldGtFtaTS2AIDy8mswGPQiV0NdmUwmh729s+nPTEdhqCciIlGV11cg+coe7Lv6C3RGPQa7hyMhMA4+dl5il0ZkFo3GtsODGlF7MdQTEZEoSupK8XP2HhzQpsEoGBHlMQiTAybA09Zd7NKIiKwOQz0REXWqa7XF2J61C4fyjwIARngOxaSA8XCzcRG5MiIi68VQT0REnSK/uhDbs3fiSMGvkEqkGO09HPEB49BL3bGTxYiIeiKGeiIisqirVVokZaXgWOEJyKVyjPMdjTj/MXBSOYpdGhFRt8FQT0REFnGlIhfbslKQce0UVDIl4gPGYYJfLOyVdmKXRkTU7TDUExFRh7pUno1tWck4XXwWGrkGUwMnYpxfDGwVNmKXRkTUbTHUExHRXRMEAefLLmFbVgrOlV6AncIWM/okYIxvNDRyjdjlERF1ewz1RER0xwRBQGbJOSRlpeBieRbslXa4v+80xPpEQyVTil0eEVGPwVBPRERmEwQBJ66dRlLWTmRX5sBJ5YjE/vdilNdwKGUKscsjIupxGOqJiKjdjIIRvxadRFJWCq5WaeGi7oX5wbMwwmso5FL+SiEiEgv/BiYiotsyGA04Wngc27N2Ir+mEO42rlgQOgdRHoMgk8rELo+IqMdjqCciojbpjXqk5R/DjuydKKothretJ343cD4Gu0dAKpGKXR4REf2GoZ6IiFrQGXQ4qD2CHdm7UFpfBj97HywKX4AI1wEM80REXRBDPRERmTQYGrAv7xCSs/egvKECvR38MTf4fgx0CYFEIhG7PCIiagNDPRERoU5fh71XDyLlyl5U6arRz6kPFgyYg2DnvgzzRERWgKGeiKgHq9HVYk/ufuzK2YdqfQ1Ce/VHQmAc+jr1Frs0IiIyA0M9EVEPVNVQjV05qdidewB1hjqEu4YiITAOgQ7+YpdGRER3gKGeiKgHKa+vRErOHqRe/QU6gw6D3MIwOTAOfvbeYpdGRER3gaGeiKgHKK0rw89X9uBA3iHojQZEeQzC5MAJ8LL1ELs0IiLqAAz1RETd2LXaEuzI3oVftEcgQMAIz6GYFDAO7jZuYpdGREQdiKGeiKgbKqgpwo6sXUgrSIcUEkR7D8Mk/3Fw0fQSuzQiIrIAhnoiom4kryof27N34mjBccilMoz1GYWJAWPhpHIUuzQiIrIghnoiom4gp/IqkrJS8GvRSShlSkz0H4sJ/rFwUNqLXRoREXUChnoRHTyVjx/3XERJRT16Oagwc2wQogd6il0WEVmRy+VXkJSVjJPFZ6CRqzElMA7j/GJgp7AVuzQiIupEDPUiOXgqHyu3nUGD3ggAKK6ox8ptZwCAwZ6Ibut86SUkZaXgTOl52MptcE+fyRjjMwo2Co3YpRERkQgY6kXy456LpkDfpEFvxI97LjLUE1GrBEHAmdLz2HY5BRfLL8NeYYf7gqYi1icaarlK7PKIiEhEDPUiKa6ob3O7IAiQSCSdXBERdVWCIOBkcSaSsnYiq+IKnFSOmN1vBkZ7j4BSphC7PCIi6gIY6kXi4qBqM9j/acUhxEZ4YXSYJxzt2PtG1FMZBSOOF51CUlYKcqvy4KJ2xtzgmRjpFQWFlH99ExHRdRJBEASxi7AmxcVVMBrv/iO7eUw9ACjlUkSHeUJ7rRrncsshlUgQEeSC2AgvhAe5QC6T3vV1iXoaNzd7FBVVil2GWYyCEekFx5GUvRPa6gK4a1wxKXAChnsMhkwqE7s8IhNrbF9E1kAqlcDFxc6sY9jVI5KmcfNtrX6TX1KD1Iw8HDiRj18vXIOjrRKjwjwRG+kNz142YpZORBZiMBqQVnAMO7J2orD2GjxtPbBwwDwM8YiEVMIv9URE1Db21Jupo3rqb3Srng6D0YiMi8VIPa5FxsViGAUB/XwdERvhjWEh7lAp2WtHdCvW0JOoM+rxi/YIfs7eheK6UvjaeSMhMA6RbgMZ5qlLs4b2RWSN7qSnnqHeTJ0d6m9UVlWPAyfzkZqhRUFJDdRKGYaHeiA20gt9vBw4uZaoFV05dDQYdNifdwjJV/agrL4cAQ5+mBIYhzCXULZnsgpduX0RWTOG+k4gZqhvIggCzueWIzUjD4fPFKJBZ4SPqy1iI7wQHeYJextlh9ZHZM26Yuio09cj9epBpOTsRWVDFYIce2NK7ziEOPdjmCer0hXbF1F3wFDfCbpCqL9Rbb0eaZkFSM3Q4lJeBWRSCQb3c0VspDcGBvaCVMqAQD1bVwodtfpa7Mk9gJ05qajW1SDEuR8SAiegn3OQ2KUR3ZGu1L6IuhNOlO2BNCo5xg7ywdhBPsgtqsK+DC0OnMzHkbNF6OWgwugwL8REeMHNiU+ZJBJLla4au3P2YXfuftTq6xDmEoLJgXHo4xggdmlERNRNsKfeTB3ZU5+Wn45NF5NQVl8GJ5UTZgQlYLjnkLs+r95gxK/nr2FvRh5OXSqBACA0wBmxEV4YGuwGhZyTa6nnELMnsbKhCilX9mLv1QOoNzQg0i0MCYET4G/vK0o9RB2NPfVElmF1w28aGhqwbNkybNy4ERUVFQgJCcGLL76I6Ojodh2/efNmrFy5EhcuXIBSqUT//v3x6quvIiIiwrSP0WjEZ599hm+//RZFRUUIDAzEU089halTp95RzR0V6tPy0/HNmXXQGXWmbQqpAvNDZnVIsG9SUlGHfSe02JehxbXyOtio5Bg50AOxEd4I8LTvsOsQdVVihI6y+nIkZ+/BvrxD0Bv1GOIegYTAOHjbeXZqHUSWxlBPZBlWN/zmtddew44dO7BgwQIEBARg/fr1WLRoEVatWoXBgwff8tglS5bg008/xYwZMzBnzhzU1NTgzJkzKCoqarHfJ598gjlz5iAsLAwpKSl48cUXIZVKkZCQYMkf75Y2XUxqFugBQGfUYf2FLejr1BsauQZqmequJ831clBjxujemD4qEGeyS5GaocXe41rsTL8Kfw87xEZ4Y+RAD9iq+ah5ortVXFuKHVd24Ze8wzBCwDCPwZgcMB4etu5il0ZERN2caD31GRkZSExMxOuvv45HH30UAFBfX4/p06fD3d0dq1evbvPY9PR0zJ8/H8uXL0d8fHyb+xUUFCAuLg7z5s3Dn//8ZwCNK8c89NBD0Gq1SE5OhlRq3hrQHdVT//TOV2+7jwQS2Mg10MjVsFFooJE3/mMjV0Oj0Pz2nqbFPk3bFVJ5q18Kqmp1OHS6AKnH83ClsAoKuRRD+7shNsILwQHOkHL1DepGOqMnsbDmGrZn70RafjokkGCkVxQmBYyDq8bFotclEht76oksw6p66pOSkqBQKJCYmGjaplKpMHv2bCxZsgSFhYVwd2+9d+urr75CeHg44uPjYTQaUVtbC1tb2xb7JScnQ6fTYf78+aZtEokE8+bNwx/+8AdkZGRg0KBBHf/DtYOzygml9WUtttspbHFv0BTU6GtRq69Dja4WtfrGf2r0tSivqUStrvG/b+7pv5lcImsW/jVydeN/KzSwcdJgdJwGg2tkuJxbg+NZZ3Bo8zn0srHFyGBfjAkLgJtTy8+UiK7TVhdge9ZOHCn4FXKpDLE+0Yj3HwtntZPYpRERUQ8jWqjPzMxE7969W4TxiIgICIKAzMzMNkP9wYMHMW3aNLz33ntYtWoVampq4OPjgxdeeAEzZsxodg07Ozv07t27xTUA4PTp06KF+hlBCa2OqZ/V7552j6nXGfWo09ehRl/bIvzX6up++2JQe/0Lgr4WxbUljfvra2EUjI0nkgEIAtQAagDsbAB2pgMSQQ6NTA0HtS1sb7xToPjtbkErr5u+QKjlKj4Jk7qtnMo8bM9Kwa9FJ6GQyjHBPxZxfmPhqOI8FSIiEodoob6oqAgeHh4ttru5uQEACgsLWz2uvLwcZWVl2LJlC2QyGV5++WU4OTlh9erVeOWVV6DRaExDcoqKiuDq6mr2NTpDU3C/m9VvFFI5FEo72CvNuz0DNA5DajDqGkO/rin016BWX4fCigqczStCdlEJKox1qFUa4OBQD7WmDnoUoEZfizp9HQS0PQxJAgnUclXzuwQKG9Pdgubbbx5GZAOlVMGH8FCXk1VxBUlZKThxLRNqmQqTAsZjgl8s7JS8q0VEROISLdTX1dVBoWg5OVOlUgFoHF/fmpqaGgBAWVkZvv/+e0RGRgIA4uPjER8fjw8//NAU6uvq6qBUtny66u2ucSvmjm+6lWluYzEtfGyHna+jGYwCjp0txM9p2UhLz4feICDY3xn3jfDH6EgvSGVGVOtqUN1Qg2pdbeO/f/vvGl0Nqht+26arQY2uFiUNJaipqkW1rgZ1+lt/9jKJFDZKG9gqNLBV2sBWYQMbpQZ2Cpsbtt/wnkIDO+X19xQyTvyl69zc7q4H/UzRBaw7vRXH8zNhq7TBA2HTkdBvHMM8Ee6+fRFRxxAt1KvVauh0LceENwXtpuB9s6btvr6+pkAPAEqlEpMnT8ZXX32F6upq2NraQq1Wo6Ghwexr3EpXe6KspQW42uD/pobigXFBOHgyH6kZWnyw9jg+2XACw0LcERvhjX6+jrCVOAEqNP7TDgajwTQk6MYhQk3zBUyvf7uTUFlbjYLK4sa7Cbpa6AXDLc+vkMpvuBug+e1ugPr65OLfXjfdITDtq2jch0OHuo87bV+CIOBs6QUkZaXgfNkl03yXMT7RUMvVqC03ohZds90SdZau/PuLyJpZ1URZNze3Voe/NC1J2dZ4eicnJyiVylaH1bi6ukIQBFRVVcHW1hZubm44cuSI2deglhxslJg83B+ThvnhUl4FUjPycCizEPtP5MOzlw1iI7wwKswTjnbtS/UyqQx2Sts77unUGXQ3fCGou2EYUePrxvBf99s8gzpUNlSioKbI9No0n6ANapnqFuH/5tWH1Dfs2zFLkZJ4BEHAqeIzSMraicsV2XBU2mNWv3sw2nsEVLKWd/6IiIi6AtFCfUhICFatWmXqVW9y/Phx0/utkUqlCA0NRUFBQYv38vPzIZPJ4OjoCAAIDQ3F2rVrcfny5WaTZZuuERoa2mE/T08hkUgQ5OOIIB9HzI3rh8NnCpGaocXa3Rexbs8lRPZ1QWyEN8KDekFm5nKh5lDIFHCUKeCocjD7WEEQUG+oN90puD7JuO6GuwTNJxuX1JUiV5eHWn0d6gx1tzz/jUuR3ir8m+YXNHtt0+ZSpGRZRsGIjGunkZSVgpzKq3BWOWFO//sR7RXF4VxERNTliRbqExIS8Pnnn2Pt2rWmdeobGhrw448/YsiQIaZJtHl5eaitrUVQUFCzY9955x3s378fo0ePBgBUVVVh27ZtGDx4MNRqNQAgLi4O//znP/HNN980W6d+zZo18Pb2bjZ8h8ynVsoRG+GN2AhvaIursS9Di/0n83Hs/DU42ikxOswLsRFe8OhlI3apzUgkEqjlaqjlajjD/KUHjYLx+tCg1lYa0l2/e3DHS5G2Ev6vf0FQN39GgaL5a5lUdqcfTY9kFIw4VpiBpKydyKvOh6vGBQ+GzMZwzyGQS0V9Ph8REVG7ifbwKQB4/vnnkZKSgkceeQT+/v5Yv349Tp48iZUrV2Lo0KEAgIcffhhpaWk4e/as6bja2lrMnDkTBQUFePTRR+Hg4IB169bh8uXLzY4FgMWLF+Pzzz/HAw88gPDwcCQnJ2P37t1YsmQJpk6danbNPW1Mvbn0BiNOXCxGaoYWGReLYRQE9PdzQmyEF6KC3aFSMnCaliLV1bQI/01fEEx3C5rmHdww1+B2Q4eUMuX1OwU3zBewuSH8N905aP5Qs+65FGlb7ctgNOBIwa/Ynr0TBTVF8LBxR0LgBAx1j+QXI6J26k6/v4i6kjsZUy9qqK+vr8fSpUuxefNmlJeXIzg4GC+99BJGjRpl2qe1UA80jotfvHgx9uzZg7q6OgwcOBAvvfQShg0b1mw/o9GIFStW4LvvvkNhYSF69+6NJ554AtOnT7+jmhnq26+0sh4HTmqxL0OLgtJaqJUyjBjggdgIb/T2sucQkztwq6VIbwz/ta3OM7jDpUhb3CWwaXUpUo1cA5VM2eX+v97cvvRGPQ5pj2J79i4U15XAx84LCYFxGOQW1u2+0BBZWnf9/UUkNqsL9daIod58giDgXE4ZUjO0OHKmEA16I3zdbBET4Y3ogR6wt+Hkw85iFIyoN9Sj5uYhQjeF/+vbbxhmpK9FvaHlalI3kkqkLe8S/PZwsqYvA6b5BQqbFvMMFB043CUtP73ZcyCm9o5Hg7EBP2fvRll9OfztfTElMA5hrqEM80R3qLv//iISC0N9J2Covzs1dXqkZRYgNSMPl7WVkMskGNTPDWMivDAgsBek0q7Vy0vNtXcp0hpdzQ3zDppWI2rfUqQ3Dhlqmi/Q1sPKbtxPI1Obhs2k5ae3eGJzkz6OgZgSGIfQXv273F0FImvTk35/EXUmhvpOwFDfcXILq7A3Iw+/nCpAVa0OvRxUiAn3Qky4F1ydNGKXRxZg7lKkNfob5x20fynSioYKGFrZ115hh3/G/IVhnqiD9NTfX0SWxlDfCRjqO55Ob8SvF64h9XgeTl0uAQCEBjojNsIbQ/q7QiHnpEVq/1KkNbpaHMo/2uZ5PpywuBOrJureevrvLyJLsaqHTxE1UcilGBbijmEh7igur8P+E1qkZmjx8aZTsFXLMXKgJ2IjvODvwUeR92TmLEV6rvQiSuvLWmx3Vpm/hCkREZE1YE+9mdhT3zmMgoDM7FKkHs9D+rki6A0CAjztMSbCCyMGeMBGzYcBUdtaG1OvkCowP2QWhnsOEbEyou6Fv7+ILIPDbzoBQ33nq6rV4ZdT+UjN0CKnsAoKuRRRwW6IifBGsL8TpBwfTa24efWbGUEJDPREHYy/v4gsg6G+EzDUi0cQBGQXVCL1uBa/nC5Abb0ebk5qxER4IybcC872KrFLpC6I7YvIcti+iCyDob4TMNR3DfU6A9LPFiE1Iw9nrpRBIgHC+7ggNsILkX1dIZdx3XFqxPZFZDlsX0SWwYmy1GOoFDJEh3kiOswThaU1SM3QYv8JLT5cXwx7GwVGhXkiNsIb3q62YpdKREREZHHsqTcTe+q7LoPRiFOXS5B6XItfL1yDwSggyMcBsRHeGBbiDo2K32F7IrYvIsth+yKyDA6/6QQM9dahoroBB07mIzUjD9riGqgUMgwLdceYCG8E+Tjw4UM9CNsXkeWwfRFZBkN9J2Coty6CIOBiXgVSj+chLbMQ9ToDvFxsEBPhhVFhXnC0VYpdIlkY2xeR5bB9EVkGQ30nYKi3XnUNehzOLERqhhYXrpZDJpUgIsgFsZHeCO/TCzIpJ9d2R2xfRJbD9kVkGZwoS3QLaqUcsZHeiI30Rt61auzL0OLASS2Onb8GJzslRod7ISbCCx7ONmKXSkRERGQW9tSbiT313YveYMTxC8VIzcjDiUvFEAQg2M8JsZFeGBrsDpVCJnaJdJfYvogsh+2LyDI4/KYTMNR3X6WV9dh/Qot9GVoUltVCo5JhxABPxEZ4IdDTnpNrrRTbF5HlsH0RWQZDfSdgqO/+BEHAuZwy7D2uxdGzhWjQG+HrZofYSC9ED/SEnUYhdolkBrYvIsth+yKyDIb6TsBQ37PU1OlxKLMAqcfzkJVfCblMgiH93RAb4Y3QQGdI2Xvf5bF9EVkO2xeRZXCiLFEHs1HLMX6wD8YP9sGVgkrsy9Di4Kl8pGUWwsVBZZpc6+qoEbtUIiIi6sHYU28m9tSTTm/AsfPXkHo8D6ezSgEAAwKdERvpjcH93KCQc2nMroTti8hy2L6ILIM99USdQCGXYXioB4aHeuBaeS32ZWix/4QW/9t4CrZqOaIHeiI20ht+7uY1RiIiIqI7xZ56M7GnnlpjNAo4nV2C1ONaHDtfBL1BQKCnPWIjvTEi1AM2an5/FgvbF5HlsH0RWQYnynYChnq6napaHQ6ezEdqRh5yi6qhlEsxNNgdYyK90N/PiUtjdjK2LyLLYfsisgwOvyHqAuw0CsQP88PEKF9k5VciNUOLQ6fzcfBUPtydNYiN8MKoMC8426vELpWIiIi6CfbUm4k99XQn6nUGHD1biNTjWpzNKYNEAoT3cUFshDci+7pALuPkWkth+yKyHLYvIstgTz1RF6VSyDAqrLGHvqC0BvsytNh3QouM9SfgYKPAqDAvxEZ6wcvFVuxSiYiIyAqxp95M7KmnjmIwGnHiUglSj+ch42IxDEYBfX0cERvhhWGh7lAr+Z27I7B9EVkO2xeRZXCibCdgqCdLKK9uwIGTWqQe1yK/pAYqpQzDQ9wRG+mNIG8HTq69C2xfRJbD9kVkGQz1nYChnixJEARcuFqO1ONaHD5TiHqdAV4uNoiN8MaoME842CrFLtHqsH0RWQ7bF5FliBbq9Xo9UlJSUF5ejvHjx8PNze1uT9llMdRTZ6mt1+PwmUKkZuTh4tUKyKQSDOrrithIL4T1doFUyt779mD7IrIcti8iy+iUibKLFy/GoUOHsG7dOgCNPYsLFy7EkSNHIAgCnJyc8P3338Pf39/cUxPRDTQqOcZEemNMpDeuXqvGvow8HDiZj6PniuBsr8LocE/ERHjD3UkjdqlEREQkMrPX0UtNTUVUVJTp9c6dO3H48GE89thj+M9//gMA+OSTTzquQiKCj6st5kzoh/88PRpP3x8GP3c7bDmYjdf+dxCLv0nHwZP5aNAZxC6TiIiIRGJ2T31+fj4CAgJMr3ft2gVfX1+8/PLLAIDz589j8+bNHVchEZnIZY1Ppx0a7I6SijrsP5mPfRl5WPHTaXz9sxwjB3ggNtILAR72nFxLRETUg5gd6nU6HeTy64cdOnQIo0aNMr328/NDUVFRx1RHRG3q5aDGPaMCMS06AGevlCE1Iw/7Tmix69hV+LnbITbCCyMHesJOoxC7VCIiIrIws4ffeHp64tixYwAae+VzcnIwbNgw0/vFxcWwsbHpuAqJ6JakEglCA5zx+D0DseSZ0XhoUn9IJRJ8k3weL32wH//beBKnskpg5EJXRERE3ZbZPfXTpk3Df//7X5SUlOD8+fOws7PD2LFjTe9nZmZykiyRSGzUCkwY4osJQ3xxpaASqce1+OV0PtIyC+HqqEZMuBdGh3vBxVEtdqlERETUgcwO9U888QS0Wi1SUlJgZ2eHd955Bw4ODgCAyspK7Ny5E48++mhH10lEZvL3sMeDk+zxwIQgHD1XhNTjWmzYdxkb913GwN69EBvpjUF9XaGQm33DjoiIiLqYDn34lNFoRHV1NdRqNRSK7jmOl+vUkzW7VlaLfSe02HdCi5KKethpFBg50ANjIrzh627eerjWgu2LyHLYvogsQ/QnyjY0NECp7N5PvGSop+7AaBRwOqsEezO0OHauCAajgN5e9oiN8MbwUA/YqM2+iddlsX0RWQ7bF5FldEqo37NnDzIyMvDss8+atq1evRr/+c9/UFdXhylTpuBf//oXe+rNwL8USUyVNQ04eKoAqRl5uFpUDaVciqgQd8RGeKG/n5PVL43J9kVkOWxfRJbRKU+U/eyzz+Di4mJ6ffHiRbz99tvw8/ODr68vtm7divDwcI6rJ7IS9jZKTBrmh/goX1zWViI1Iw+HThfgwMl8eDhrEBPROLnWyU4ldqlERETUBrND/aVLl5qtdrN161aoVCr88MMPsLOzwx/+8Ads2LCBoZ7IykgkEvTxdkAfbwfMndAPR84WIvV4HtbtuYT1ey8jIsgFsRFeCA9ygVzGybVERERdidmhvry8HM7OzqbXBw4cwMiRI2Fn13iLYPjw4dizZ0/HVUhEnU6llGH0b8tf5pfUYF+GFvtPaPHrhWtwsFViVJgnYiO84OViK3apREREhDsI9c7OzsjLywMAVFVV4cSJE3jppZdM7+v1ehgMho6rkIhE5dnLBrPHBeH+Mb1x4mIJUjPysCMtB0mHrqCvryNiI7wwPMQDKqVM7FKJiIh6LLND/aBBg7BmzRr07dsXe/fuhcFgwJgxY0zvZ2dnw93dvUOLJCLxyaRSDOrnikH9XFFeVY8DJ/OxN0OLL7aewTfJ5zEi1B2xEd7o4+1g9ZNriYiIrI3Zof65557DggUL8MILLwAA7r//fvTt2xcAIAgCkpOTMWLEiI6tkoi6FEc7FaaMDEDCCH+czy1HakYefjldgL3HtfB2tUVshBeiwzzhYNO9l7glIiLqKu5onfqysjKkJ4aOEAAAIABJREFUp6fD3t4ew4YNM20vLy/Hhg0bMGLECISEhHRooV0Fl7Qkal1tvR5pmQVIzdDiUl4FZFIJBvVzRWyEN8J694JUKk7vPdsXkeWwfRFZhugPnzJXQ0MDli1bho0bN6KiogIhISF48cUXER0dfcvjli9fjg8++KDFdldXV+zfv7/ZtuDg4FbP8eabb2LevHlm18xQT3R7V4uqkJqhxYGT+aiq1cHZXoXR4V6IifCCu5OmU2th+yKyHLYvIsvolHXqm1y5cgUpKSnIyckBAPj5+SEuLg7+/v7tPsdrr72GHTt2YMGCBQgICMD69euxaNEirFq1CoMHD77t8X//+9+hVqtNr2/87xvFxMRgxowZzbZFRka2u04iMo+Pmx3mxvXD7HFB+PX8NezNyMOWA1n46UAWQgOcEfv/t3fncVmV+f/H3/fNKioKeIO4IKgsioAImuaSu2SYVu77kmOjzbR8m2+L06Y1NmlNM5aVS6WOWxouWeNuZam4oKLiilgSKiiKArIo9++PfvGNQUUMPNzwej4ePh7d17nOud/Hx+PEx4vruk6ot1oFWOTowOJaAADKwl0V9e+9957mzJlTbJeb6dOna8KECXrqqadKvEZ8fLy++uorvfjii4V72vfr10/R0dGaMWOGFi1aVOI1HnzwQbm6upbYr3Hjxurbt2+J/QCULXu7X95OGxnkqfQrOfr+4Fl9H39Ws79MkIuTvdoGe6ljaD01qlvT6KgAANi0Uhf1K1as0EcffaTw8HA9/vjj8vf3lySdOHFC8+bN00cffaSGDRvq0Ucfve111q1bJwcHBw0YMKCwzcnJSf3799c//vEPpaamlriLjtVqVWZmpqpXr17ibhs5OTkymUxycuKtmIAR3F2d9XB7P0Xf76ujP17Stviz+u7AWW2J+1k+njXUMaye2gZ7qbqzg9FRAQCwOaUu6hcvXqywsDAtXLhQ9vb/d7qPj48eeOABDRs2TP/+979LLOqPHDkiPz8/Va9e9OU1oaGhslqtOnLkSIlFfefOnZWdna3q1aurV69eev7551W7du1i/VasWKGFCxfKarUqICBAf/7zn9WjR49S3DWAsmI2mdTc113Nfd2VlZOvnYfPa1t8ihZtPK5lW04qItCijqHeCmrkJjNbYwIAcEdKXdQnJibq2WefLVLQF17M3l69e/fWu+++W+J10tLS5OXlVazdYrFIklJTU295rqurq0aMGKGwsDA5ODho586dWrZsmRISErR8+XI5Ov7fNnrh4eHq3bu3GjRooLNnz2rBggV68skn9c477yg6OvpObrmI0i5auFMWC9MPUPVYJPk2dNfgqGZKTL6sjbt+0jdxyYpNOC8vdxd1b+OjbpE+srj9vsW1PF9A+eH5AiqGUhf1Dg4Oys7OvuXxrKwsOTiU/OvznJycm/b7dXpMbm7uLc8dNWpUkc9RUVHy9/fXlClTtGrVKg0cOLDw2NKlS4v0feSRRxQdHa3p06froYceKvVLctj9Bigfrk52eqyjn/q09VHc8TRtiz+rReuOavG6owpu7K5OofXU0r+O7O3MpbouzxdQfni+gPJxN7vflO6no6SQkBAtW7ZMFy5cKHbs4sWL+vzzz+9oZxlnZ2fl5+cXa/+1mC/t3PchQ4aoWrVq2rFjx237ubi4aPDgwTp37pxOnTpVqu8AUP4cHezUNriu/jIkXG890U4P3e+rn9OyNGvVIT37/g9auvmEfk7LNDomAAAVSqlH6idOnKjRo0erd+/eeuyxxwrfJnvy5EnFxMQoKytLM2bMKPE6FovlplNs0tLSJKnE+fT/zWw2y8vLSxkZGSX29fb2lqQ76gvAOJ61q+nRTo3Vr4OfDiWla1t8ijbvTdaG3Wfk5+2qjmHeuq+Zl6o53fXuvAAAVAql/knYunVrzZw5U1OnTtWnn35a5Fi9evX097//XZGRkSVeJygoSAsXLlRWVlaRxbIHDhwoPF4a+fn5Onv2rFq0aFFi31/31nd3dy/VdwAwhtlsUmgTD4U28dCV7DztPHRO2+LPasG6Y1q6+YRaB3qqY1g9+TeoVeopdQAAVAZ3NbzVtWtXde7cWYcOHVJycrKkX14+FRwcrM8//1y9e/fW119/fdtrREVF6ZNPPtHy5csL96nPy8tTTEyMWrVqVbiINiUlRdeuXVOTJk0Kz01PTy9WkM+bN0+5ubnq2LHjbftdunRJixcvVoMGDeTr63s3tw/AQK4ujurZxkc9WjfUqbNXtO3AWcUeOa8fDp2Tl7uLOoZ6q32Lukr48ZJivk1U+pVcubs66dEHmqhdcF2j4wMAUC7u+nfWZrNZoaGhCg0NLdJ+6dIlJSUllXh+WFiYoqKiNGPGDKWlpcnHx0crV65USkqKpk2bVtjv+eef165du3Ts2LHCti5duqh3794KCAiQo6OjYmNjtX79ekVERBTZ0WbRokXavHmzOnfurHr16un8+fNatmyZ0tPT9cEHH9ztrQOoAEwmk5rUq6Um9WppSDd/7T6aqm3xKVrxTaJWfJMok0my/v817Rev5Gr+f45KEoU9AKBSMnQi6ttvv6333ntPq1evVkZGhgIDAzV79mxFRETc9rw+ffooLi5O69atU35+vurXr6+JEydqwoQJRbbaDA8PV1xcnJYvX66MjAy5uLioZcuWmjBhQonfAcB2ODnaqUOotzqEeuvsxSxNnb9HOXlF33idd71AMd8mUtQDAColk9VqLdP9GT/88EP961//0pEjR8ryshUGW1oCFd/Yt7bc8tgnL3S9h0mAyo2fX0D5uCdbWgJARefhevMtcU2StsQll/k/zAEAMBpFPYBK59EHmsjRvuj/3hzszfL2cNG/NxzXmwv36sdzjC4CACqPO5pT/99bV95OXFzcXYcBgLLw67z5/979pm1zL+1MOK9lm09oyvzd6hHZUH07+LHPPQDA5t3RnPrS7hlvMpmYU18KzEkEys/Nnq+snHx98U2ivtmfIreaThraPUCtAuqwxz1QSvz8AsrH3cypv6PhqQULFtxVIACoiKo7O2hkVJDuD/HWgnXH9MHKgwpr4qFhPQNUp1Y1o+MBAFBqZb77TWXHSD1gW0p6vq7fKNCmPcla9f0pSVLfDn7qEdlQ9nYsOQJKws8voHyU20g9AFRW9nZmRd3no9ZBnlq08biWb03UjkPnNLJXkJo2qGV0PAAA7ghDUQAgyaOWs/7cP1R/ejRE2bnX9bd/79Vn/zmqzGv5RkcDAKBEjNQDwG+EB1jUzNdNq79P0sbdydp3Ik2DujZVu+C6LKQFAFRYjNQDwH9xdrTXoK7+emV0pCy1q2nu2iOavmSfzl7MMjoaAAA3RVEPALfg41VTL42I0IhegfrxfKZe/WSXVm07pfzrN4yOBgBAEUy/AYDbMJtM6hJeX60CLFq2+YTW/HBaOxPOa0TPQAX7uRsdDwAASYzUA8AdqVXdUX94OFj/M7ilTJLeWbZfH685rIzMXKOjAQBAUQ8ApRHs664p49ro4fa+2nssVS/NidXWuGQV8MoPAICBKOoBoJQc7O3Ur2NjvT62jXzr1tTCDcf1t4V79dN5XsIDADAGRT0A3CVvj+p6bnBLjY9urrTL1zTlsz1auvmEcvKuGx0NAFDFsFAWAH4Hk8mkdi3qKrSph1Z8k6gNu89o99FUDesRoFYBFqPjAQCqCEbqAaAMVHd20KioIL00PELVne31fsxB/WtFvC5kXDM6GgCgCqCoB4Ay1LRBLb0yurUGdmmqhB/T9de5sVoX+5Ou3ygwOhoAoBJj+g0AlDF7O7Oi7vNRZJBFizee0OdbT2r7obMaGRWkpvVrGR0PAFAJMVIPAOWkTq1q+tNjIXry0RBl5VzX3xbu1fx1R5WVk290NABAJcNIPQCUI5PJpFYBFjX3ddOqbUnatCdZ+46naVBXf7UN9pLJZDI6IgCgEmCkHgDuAWdHew3u5q9XRkfKo1Y1zVmboBlL9+tcerbR0QAAlQBFPQDcQz5eNTV5RIRG9AzQ6XNX9cq8WK3adkr5128YHQ0AYMOYfgMA95jZbFKXVg3UKsCipVtOas0PpxWbcF7DewUq2Nfd6HgAABvESD0AGKRWDSdNeDhY/zOopayS3lm6X7PXHFZGVp7R0QAANoaiHgAMFuznrqnj2ujh9r7acyxVL83eqa37flaB1Wp0NACAjaCoB4AKwMHeTv06NtbrY9uokVcNLVx/TNMW7tVP568aHQ0AYAMo6gGgAvH2qK6/DAnX49HNlHr5mqZ8tkfLtpxQTt51o6MBACowFsoCQAVjMpl0fwtvhTapoxXfJGr9rjPafTRVw7oHKDzAYnQ8AEAFxEg9AFRQNao5aPSDQXpxeCtVc7LXzJiDmvlFvC5m5BgdDQBQwVDUA0AF59+gtl4d3VoDOjfR4aR0TZ67U+tif9L1GwVGRwMAVBAU9QBgA+ztzHqwbSO98fh9aubjps+3ntSUz/Yo8ecMo6MBACoAinoAsCF1alfTn/uHatIjIcrKydffFu7VgnVHlZWTb3Q0AICBWCgLADbGZDIpItCi5r5uWv19kjbuOaO442ka1M1fbZt7yWQyGR0RAHCPMVIPADaqmpO9Bnfz1yujWsujlrPmfJmgGUv361x6ttHRAAD3GEU9ANi4RnVravKISA3vGaDT567olXmxWv19kvKv3zA6GgDgHmH6DQBUAmazSV1bNVCrAIuWbj6h1d8naWfCeY3sGaBmvu5GxwMAlDNG6gGgEqldw0lP9G2hZweFyVpg1fSl+zXny8PKyMozOhoAoBxR1ANAJdTCz0NTxrVR9P2+2nUkVZNn79Q3+39WgdVqdDQAQDmgqAeASsrRwU6PdmqsKePayMerhhasO6Zp/96rM6mZRkcDAJQxinoAqOS8ParrL0PCNe6hZjqffk2vf7pbn285qdw8FtICQGXBQlkAqAJMJpPah3grrGkdrfjmpNbt+km7j57X0B4BCve3GB0PAPA7MVIPAFVIjWoOGv1gM704vJWcnew184uDmvlFvNKv5BgdDQDwO1DUA0AV5N+gtl4d3Vr9OzfR4aR0TZ4Tq/W7ftKNggKjowEA7gJFPQBUUfZ2ZvVu20hvPH6fAn1qa9mWk5ry2R4lpmQYHQ0AUEqGFvV5eXmaPn26OnTooNDQUA0cOFA7duwo8byZM2cqMDCw2J/27dvftP/y5cv14IMPKiQkRL169dKiRYvK+lYAwGbVqV1NT/UP1aRHWijzWr7+tmCvFqw/puycfKOjAQDukKELZV944QVt2LBBI0eOVKNGjbRy5UqNHz9eCxcuVHh4eInnT5kyRc7OzoWff/vfv1q6dKleffVVRUVFacyYMdqzZ4+mTJmi3NxcjR07tkzvBwBslclkUkSgp5r7umvVtiRt2ntGccfTNLhbU93XzEsmk8noiACA2zBZrca8iSQ+Pl4DBgzQiy++qNGjR0uScnNzFR0dLU9Pz9uOps+cOVPvv/++du/eLVdX11v2y8nJ0QMPPKCIiAjNmjWrsP25557Tli1b9O2336pmzZqlyn3xYqYKCsr2r8xiqam0tKtlek0Av+D5ujs/nruq+euO6vS5qwr2ddPwnoHycncxOhYqGJ4voHyYzSZ5eNQo3TnllKVE69atk4ODgwYMGFDY5uTkpP79+2vv3r1KTU0t8RpWq1WZmZm61b9LYmNjdfnyZQ0dOrRI+7Bhw5SVlaXvvvvu990EAFRSjerW1F9HRmpYjwCdOntFL8/bpTXfJyn/OgtpAaAiMqyoP3LkiPz8/FS9evUi7aGhobJarTpy5EiJ1+jcubMiIiIUERGhF198UZcvXy5yPCEhQZLUokWLIu3BwcEym82FxwEAxZnNJnWLaKA3Hm+rVgF1tOr7JL3yyS4dOZ1udDQAwH8xbE59WlqavLy8irVbLL+8BOV2I/Wurq4aMWKEwsLC5ODgoJ07d2rZsmVKSEjQ8uXL5ejoWPgdjo6Oql27dpHzf227k98GAEBV51bTSU/0baEOIRe1cMMxTV+6X+2CvTSoq79cqzsaHQ8AIAOL+pycHDk4OBRrd3JykvTL/PpbGTVqVJHPUVFR8vf315QpU7Rq1SoNHDjwtt/x6/fc7jtupbTzm+6UxVK6uf0A7hzPV9noYqmp+1s11PJNx/XF1hM6eCpdo6Obq0ebRjKbWUhbVfF8ARWDYUW9s7Oz8vOLb5f2a6H9a3F/p4YMGaLp06drx44dhUW9s7Oz8vLybto/Nze31N8hsVAWsDU8X2WvV2QDhfi6aeH6Y3p/+QGt235aI3sFqoFn+Qx6oOLi+QLKh00tlLVYLDed/pKWliZJ8vT0LNX1zGazvLy8lJHxfy9NsVgsys/PLzbXPi8vT5cvXy71dwAAflGvTnX979BwjXuomc6lZ+u1T3fr860nlZt3w+hoAFAlGVbUBwUFKSkpSVlZWUXaDxw4UHi8NPLz83X27Fm5ubkVtjVr1kySdOjQoSJ9Dx06pIKCgsLjAIDSM5lMah/irb/9oa3ah9TVutif9Ne5O7X/xAWjowFAlWNYUR8VFaX8/HwtX768sC0vL08xMTFq1apV4SLalJQUJSYmFjk3Pb34zgvz5s1Tbm6uOnbsWNjWtm1b1a5dW4sXLy7Sd8mSJXJxcVGnTp3K8pYAoEqqUc1BY3o30wvDWsnJ0V7/+iJe78ccVPqVHKOjAUCVYdic+rCwMEVFRWnGjBlKS0uTj4+PVq5cqZSUFE2bNq2w3/PPP69du3bp2LFjhW1dunRR7969FRAQIEdHR8XGxmr9+vWKiIhQdHR0YT9nZ2f9+c9/1pQpU/TUU0+pQ4cO2rNnj9asWaPnnnvuti+uAgCUTkDD2nptTGut3/WTvvzhtCbPTdcjHfzULbKB7MyGjSEBQJVgWFEvSW+//bbee+89rV69WhkZGQoMDNTs2bMVERFx2/P69OmjuLg4rVu3Tvn5+apfv74mTpyoCRMmyN6+6C0NGzZMDg4O+uSTT7R582Z5e3tr8uTJGjlyZHneGgBUSfZ2Zj3Uzldtmnlp0cbjWrrlpLYfOqeRUUFqXI+BFAAoLybrrV7Hipti9xvAtvB8GcdqtWrvsTQt3nRcGZl56hxeX4890Fguzjffahi2h+cLKB93s/uNoSP1AIDKy2QyKTLIU8F+7lq57ZQ2701W3PE0De7mrzbNPGUysbc9AJQVJjkCAMpVNSd7De0eoJdHRcqtppM+XnNY7y7br/OXso2OBgCVBkU9AOCe8K3rqr+OjNSwHgFKTLmil+fu0pofkpR/vcDoaABg85h+AwC4Z8xmk7pFNFCrAIuWbj6hVduStPPweY3oFahmjdxKvgAA4KYYqQcA3HNuNZ30x34t9MzAMF2/UaDpS/Zp7toEXcnOMzoaANgkinoAgGFCGnto6uP36aF2jRSbcF6TZ+/UdwdSVMDGbABQKhT1AABDOTnY6bEHmui1sW1U31JDn/3nqN5aFKfktEyjowGAzaCoBwBUCPXrVNfzQ8M1tncznbuYrdc/3a3lW08qN++G0dEAoMJjoSwAoMIwmUzqEOqtsKYeWv5Nov4T+5N2HUnV8J4BCmtax+h4AFBhMVIPAKhwaro4amzvZnp+aLgcHcz654p4fRBzUOlXcoyOBgAVEkU9AKDCCvRx0+tj2+ixBxor/tRFTZ4bqw27z+hGAXvbA8BvUdQDACo0ezuzHmrnq6mP36eABrW1dPMJTZ2/R6dSrhgdDQAqDIp6AIBN8KxdTU8PCNXEfi10JStPby7Yo39vOKbsnOtGRwMAw7FQFgBgM0wmkyKDPBXs566Y705pS1yy9h5L05Du/mod5CmTyWR0RAAwBCP1AACbU83JXsN6BOivIyNVu6aTPlp9WO9+fkCpl7KNjgYAhqCoBwDYLD9vV708MlJDu/sr8ecMvTxvl778IUn511lIC6BqYfoNAMCmmc0mdY9sqIhATy3ZfEIrtyVpZ8J5jegZqKBGbkbHA4B7gpF6AECl4FbTSRP7tdDTA0KVf71Aby/Zp3lrE3QlO8/oaABQ7ijqAQCVSmiTOpr6+H16qF0j7Uw4r8mzd+q7AykqsFqNjgYA5YaiHgBQ6Tg52OmxB5rotTGtVb9OdX32n6P6+6I4/ZyWaXQ0ACgXFPUAgEqrvqWG/ndYK43pHaSzF7P12qe7teKbROXm3zA6GgCUKRbKAgAqNbPJpI6h9dSyaR19vvWkvt75o3YdOa9hPQIU1rSO0fEAoEwwUg8AqBJqujhq3EPN9fzQcDnYm/XPFfH6YOVBpV/JMToaAPxuFPUAgCol0MdNr49to0c7NVZ84kVNnhurjbvP6EYBe9sDsF0U9QCAKsfezqzo+301dVwb+devpSWbT+iN+XuVdPaK0dEA4K5Q1AMAqixPNxc9MzBMT/QN1uWsXL0xf48WbTiu7JzrRkcDgFJhoSwAoEozmUxq08xLLfw8tPK7U9oSl6w9x1M1pJu/Wgd5ymQyGR0RAErESD0AAJJcnO01rGeA/joqUrWrO+mj1Yf1j+UHlHop2+hoAFAiinoAAH7Dz9tVL4+K1JDu/jqZnKGX5+3Sl9tP6/oNFtICqLiYfgMAwH8xm03qEdlQkYGeWrzpuFZ+d0o7D5/TyF6BCvRxMzoeABTDSD0AALfgVtNJkx4J0VP9Q5V/vUB/X7xP875K0NXsPKOjAUARjNQDAFCCsKZ1FNTITV/+cFrrd/2k/ScuaGCXpmof6i0zC2kBVACM1AMAcAecHOzUv3MTvTamterVqa5P/3NUby+K089pmUZHAwCKegAASqO+pYaeH9ZKYx4M0s8XsvTap7u14ptE5ebfMDoagCqM6TcAAJSS2WRSx7B6CvOvo+VbTurrnT9q15HzGt4zUKFNPIyOB6AKYqQeAIC75OriqHHRzfW/Q8LlYG/We8sPaNbKg7p0NdfoaACqGIp6AAB+p6BGbnptTBs90qmxDiRe1OQ5O7VxzxkVFFiNjgagiqCoBwCgDDjYm9Xnfl9NHddGTerX0pJNJzR1wR4lnb1idDQAVQBFPQAAZcjTzUXPDgzTE32Ddflqrt6Yv0eLNhxXds51o6MBqMRYKAsAQBkzmUxq08xLLfw8FPNdorbEJWvP8VQN7R6gyECLTOxtD6CMMVIPAEA5cXG21/CegfrrqEjVqu6oD1cd0nvL45V6+ZrR0QBUMhT1AACUMz9vV708KlJDuvnrePJlvTw3Vmu3n9b1GwVGRwNQSTD9BgCAe8DObFaP1g0VEWjRks0nFPPdKe04fE4jewUq0MfN6HgAbBwj9QAA3EPurs6a9EiInuofqrz8Av198T598tURXc3OMzoaABvGSD0AAAYIa1pHQT5uWrM9SRt2ndH+kxc0oEsTdQjxZiEtgFJjpB4AAIM4OdppQOemenV0a9X1cNGnXx/V3xfv088XsoyOBsDGGFrU5+Xlafr06erQoYNCQ0M1cOBA7dixo9TXGT9+vAIDA/Xmm28WOxYYGHjTP0uWLCmLWwAA4Hdr4FlDLwxrpdEPBunntEy99skuffFtonLzbxgdDYCNMHT6zQsvvKANGzZo5MiRatSokVauXKnx48dr4cKFCg8Pv6NrfPPNN9qzZ89t+3To0EEPP/xwkbawsLC7zg0AQFkzm0zqFFZPLf3raPmWk/pqx4+KTTivEb0CFdLYw+h4ACo4w4r6+Ph4ffXVV3rxxRc1evRoSVK/fv0UHR2tGTNmaNGiRSVeIy8vT9OmTdO4ceM0c+bMW/Zr3Lix+vbtW1bRAQAoN64ujhoX3VztQ7y1YP0x/ePzA4oM8tSQbv5yq+lkdDwAFZRh02/WrVsnBwcHDRgwoLDNyclJ/fv31969e5WamlriNRYsWKCcnByNGzeuxL45OTnKzc39XZkBALhXghq56fWxbfRIRz/tP3FBk+fs1KY9Z1RQYDU6GoAKyLCi/siRI/Lz81P16tWLtIeGhspqterIkSO3PT8tLU2zZs3SM888o2rVqt2274oVK9SyZUuFhoaqT58+2rhx4+/ODwBAeXOwN6tPez9NfbyNmtRz1eJNJzR1wR6dPnfF6GgAKhjDivq0tDR5enoWa7dYLJJU4kj9u+++Kz8/vxKn1YSHh+uZZ57RrFmz9MorrygvL09PPvmk1q5de/fhAQC4h7zcXPTsoJaa8HCwLl3N1dT5e7R443Fdy71udDQAFYRhc+pzcnLk4OBQrN3J6Zf5grebKhMfH69Vq1Zp4cKFJe7lu3Tp0iKfH3nkEUVHR2v69Ol66KGHSr0XsIdHjVL1v1MWS81yuS4Ani9UHtGerurcppEWfp2g/+w4rbgTF/SHfiG6P9S4ve15voCKwbCi3tnZWfn5+cXafy3mfy3u/5vVatWbb76pnj17KjIystTf6+LiosGDB+udd97RqVOn1KRJk1Kdf/FiZpnPZ7RYaiot7WqZXhPAL3i+UBn179RYrZrW0YJ1R/XWgt0Kaeyh4T0DZKl9++moZY3nCygfZrOp1APJhk2/sVgsN51ik5aWJkk3nZojSRs3blR8fLyGDBmi5OTkwj+SlJmZqeTkZOXk5Nz2u729vSVJGRkZv+cWAAAwTON6rnp5dKQGd22q42cu6+W5sfpqx2ldv1FgdDQABjBspD4oKEgLFy5UVlZWkcWyBw4cKDx+MykpKSooKNCoUaOKHYuJiVFMTIzmzJmjTp063fK7z5w5I0lyd3f/PbcAAICh7Mxm9Wzjo8ggTy3ZdEJffHtKOw//srd9QMPaRscDcA8ZVtRHRUXpk08+0fLlywv3qc/Ly1NMTIxatWolLy8vSb8U8deuXSucJtO1a1c1aNCg2PUmTZqkLl26qH///goODpYkpaenFyvcL126pMWLF6tBgwby9fUtvxsEAOAecXd11qRHQ7T/5AUt2nBMby2KU4dQbw3s0lQ1qhVfvwag8jGsqA8LC1NUVJRmzJihtLQvWALzAAANKElEQVQ0+fj4aOXKlUpJSdG0adMK+z3//PPatWuXjh07Jkny8fGRj4/PTa/ZsGFDde/evfDzokWLtHnzZnXu3Fn16tXT+fPntWzZMqWnp+uDDz4o3xsEAOAea9m0jpr5uGnND0nasPuM9p+4oIFdmqp9SF3DFtICuDcMK+ol6e2339Z7772n1atXKyMjQ4GBgZo9e7YiIiLK5Prh4eGKi4vT8uXLlZGRIRcXF7Vs2VITJkwos+8AAKAicXK004AuTdUuuK4WrD+mT74+ou8PntXIXoGqV6d6yRcAYJNMVquVV9OVArvfALaF5wtVWYHVqm0HUrTim0Tl5N3Qg219FN3OV44OdmVyfZ4voHzcze43ho7UAwCA8mM2mfRAy/oK97do2ZaTWrv9R8UmnNeInoFq0djD6HgAypBhW1oCAIB7w7W6o8b3aa6/DAmX2WzWu58f0IerDuly5q1f9AjAtlDUAwBQRTRr5KYpY9uoX0c/7TtxQZPn7NTmvcllPq0UwL1HUQ8AQBXiYG/Ww+39NHVcG/l5u2rRxuN6Y8Ee/XiOufGALaOoBwCgCvJyd9H/DGqpPzzcXOlXczVl/m4t3nRc13KvGx0NwF1goSwAAFWUyWRS2+Z1FdrYQ198e0qb9yRr77E0Denmr4hAC3vbAzaEkXoAAKo4F2cHjegVqJdGRqhGNQfNWnVI/1wRrwuXrxkdDcAdoqgHAACSpCb1aumV0ZEa3LWpjv10WX+dG6uvd/6o6zcKjI4GoARMvwEAAIXszGb1bOOjyCBPLdp4XCu+SdSOQ+c0olegAhrWNjoegFvgjbKlxBtlAdvC8wX8PvtOpGnxxuO6eCVXHUO9NaBLUx08dVEx3yYq/Uqu3F2d9OgDTdQuuK7RUYFKgzfKAgCAMhXub1GzRm5a88Npbdh1RruOnNf1Aqtu3PhlgOvilVzN/89RSaKwBwzEnHoAAHBbzo72GtilqV4d01o3flPQ/yrveoFivk00KB0AiaIeAADcoYaeNXT9xs2noF68knuP0wD4LYp6AABwxzxcnUrVDuDeoKgHAAB37NEHmsjRvmj54Ghv1qMPNDEoEQCJhbIAAKAUfl0My+43QMVCUQ8AAEqlXXBdtQuuy5axQAXC9BsAAADAxlHUAwAAADaOoh4AAACwcRT1AAAAgI2jqAcAAABsHEU9AAAAYOMo6gEAAAAbR1EPAAAA2DiKegAAAMDG8UbZUjKbTTZ1XQA8X0B54vkCyt7dPFcmq9VqLYcsAAAAAO4Rpt8AAAAANo6iHgAAALBxFPUAAACAjaOoBwAAAGwcRT0AAABg4yjqAQAAABtHUQ8AAADYOIp6AAAAwMZR1AMAAAA2jqIeAAAAsHH2RgeoqlJTU7VgwQIdOHBAhw4dUnZ2thYsWKD77rvP6GiATYuPj9fKlSsVGxurlJQU1a5dW+Hh4Xr66afVqFEjo+MBNu3gwYP66KOPlJCQoIsXL6pmzZoKCgrSpEmT1KpVK6PjAZXOnDlzNGPGDAUFBWn16tW37UtRb5CkpCTNmTNHjRo1UmBgoPbt22d0JKBSmDt3ruLi4hQVFaXAwEClpaVp0aJF6tevn1asWKEmTZoYHRGwWWfOnNGNGzc0YMAAWSwWXb16VV9++aWGDx+uOXPmqH379kZHBCqNtLQ0ffjhh3Jxcbmj/iar1Wot50y4iczMTOXn58vNzU2bNm3SpEmTGKkHykBcXJxatGghR0fHwrbTp0+rT58+euihh/TWW28ZmA6ofK5du6bu3burRYsW+vjjj42OA1QaL7zwglJSUmS1WnXlypUSR+qZU2+QGjVqyM3NzegYQKXTqlWrIgW9JPn6+srf31+JiYkGpQIqr2rVqsnd3V1XrlwxOgpQacTHx2vNmjV68cUX7/gcinoAlZ7VatWFCxf4hzRQRjIzM5Wenq5Tp07p3Xff1fHjx9WuXTujYwGVgtVq1dSpU9WvXz81a9bsjs9jTj2ASm/NmjU6f/68nnnmGaOjAJXCSy+9pPXr10uSHBwcNHjwYD3xxBMGpwIqh1WrVunkyZP64IMPSnUeRT2ASi0xMVFTpkxRRESE+vbta3QcoFKYNGmSBg0apHPnzmn16tXKy8tTfn5+salvAEonMzNT77zzjv7whz/I09OzVOcy/QZApZWWlqYJEyaoVq1a+uc//ymzmf/lAWUhMDBQ7du312OPPaZ58+bp8OHDpZr7C+DmPvzwQzk4OGjMmDGlPpefcAAqpatXr2r8+PG6evWq5s6dK4vFYnQkoFJycHBQt27dtGHDBuXk5BgdB7BZqampmj9/voYOHaoLFy4oOTlZycnJys3NVX5+vpKTk5WRkXHL85l+A6DSyc3N1RNPPKHTp0/rs88+U+PGjY2OBFRqOTk5slqtysrKkrOzs9FxAJt08eJF5efna8aMGZoxY0ax4926ddP48eP13HPP3fR8inoAlcqNGzf09NNPa//+/Zo1a5ZatmxpdCSg0khPT5e7u3uRtszMTK1fv17e3t7y8PAwKBlg+xo0aHDTxbHvvfeesrOz9dJLL8nX1/eW51PUG2jWrFmSVLh39urVq7V37165urpq+PDhRkYDbNZbb72lLVu2qEuXLrp8+XKRl3VUr15d3bt3NzAdYNuefvppOTk5KTw8XBaLRWfPnlVMTIzOnTund9991+h4gE2rWbPmTX9GzZ8/X3Z2diX+/OKNsgYKDAy8aXv9+vW1ZcuWe5wGqBxGjBihXbt23fQYzxbw+6xYsUKrV6/WyZMndeXKFdWsWVMtW7bU2LFj1aZNG6PjAZXSiBEj7uiNshT1AAAAgI1j9xsAAADAxlHUAwAAADaOoh4AAACwcRT1AAAAgI2jqAcAAABsHEU9AAAAYOMo6gEAAAAbR1EPAKjwRowYoa5duxodAwAqLHujAwAAjBEbG6uRI0fe8ridnZ0SEhLuYSIAwN2iqAeAKi46OlqdOnUq1m4288tcALAVFPUAUMU1b95cffv2NToGAOB3YBgGAHBbycnJCgwM1MyZM7V27Vr16dNHISEh6ty5s2bOnKnr168XO+fo0aOaNGmS7rvvPoWEhKh3796aM2eObty4UaxvWlqa3njjDXXr1k0tWrRQu3btNGbMGP3www/F+p4/f17PPvusWrdurbCwMI0bN05JSUnlct8AYEsYqQeAKu7atWtKT08v1u7o6KgaNWoUft6yZYvOnDmjYcOGqU6dOtqyZYvef/99paSkaNq0aYX9Dh48qBEjRsje3r6w79atWzVjxgwdPXpU77zzTmHf5ORkDRkyRBcvXlTfvn3VokULXbt2TQcOHND27dvVvn37wr7Z2dkaPny4wsLC9Mwzzyg5OVkLFizQxIkTtXbtWtnZ2ZXT3xAAVHwU9QBQxc2cOVMzZ84s1t65c2d9/PHHhZ+PHj2qFStWKDg4WJI0fPhwPfnkk4qJidGgQYPUsmVLSdKbb76pvLw8LV26VEFBQYV9n376aa1du1b9+/dXu3btJEmvv/66UlNTNXfuXHXs2LHI9xcUFBT5fOnSJY0bN07jx48vbHN3d9f06dO1ffv2YucDQFVCUQ8AVdygQYMUFRVVrN3d3b3I5/vvv7+woJckk8mkxx9/XJs2bdLGjRvVsmVLXbx4Ufv27VOPHj0KC/pf+/7xj3/UunXrtHHjRrVr106XL1/Wtm3b1LFjx5sW5P+9UNdsNhfbradt27aSpB9//JGiHkCVRlEPAFVco0aNdP/995fYr0mTJsXamjZtKkk6c+aMpF+m0/y2/bcaN24ss9lc2Penn36S1WpV8+bN7yinp6ennJycirTVrl1bknT58uU7ugYAVFYslAUA2ITbzZm3Wq33MAkAVDwU9QCAO5KYmFis7eTJk5Kkhg0bSpIaNGhQpP23Tp06pYKCgsK+Pj4+MplMOnLkSHlFBoAqg6IeAHBHtm/frsOHDxd+tlqtmjt3riSpe/fukiQPDw+Fh4dr69atOn78eJG+s2fPliT16NFD0i9TZzp16qTvvvtO27dvL/Z9jL4DwJ1jTj0AVHEJCQlavXr1TY/9WqxLUlBQkEaNGqVhw4bJYrFo8+bN2r59u/r27avw8PDCfpMnT9aIESM0bNgwDR06VBaLRVu3btX333+v6Ojowp1vJOnll19WQkKCxo8fr379+ik4OFi5ubk6cOCA6tevr7/85S/ld+MAUIlQ1ANAFbd27VqtXbv2psc2bNhQOJe9a9eu8vPz08cff6ykpCR5eHho4sSJmjhxYpFzQkJCtHTpUv3rX//SkiVLlJ2drYYNG+q5557T2LFji/Rt2LChvvjiC33wwQf67rvvtHr1arm6uiooKEiDBg0qnxsGgErIZOX3mwCA20hOTla3bt305JNP6k9/+pPRcQAAN8GcegAAAMDGUdQDAAAANo6iHgAAALBxzKkHAAAAbBwj9QAAAICNo6gHAAAAbBxFPQAAAGDjKOoBAAAAG0dRDwAAANg4inoAAADAxv0/skod09VhBLoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60uJ0z5X_ybO",
        "colab_type": "code",
        "outputId": "82ecfba7-d8ed-436d-c4a5-d20c07b44d3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(val_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Predict \n",
        "for batch in val_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 35,918 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCIW87IFZKp8",
        "colab_type": "code",
        "outputId": "58282d24-97a4-49d6-af8e-75230fafdb56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import itertools\n",
        "y_pred = []\n",
        "for i in range(len(predictions)):\n",
        "  \n",
        "  # The predictions for this batch are a 5-column ndarray with a row for each batch (32). \n",
        "  #Pick the label with the highest value and consider the index = class\n",
        "  pred_labels_i = list(np.argmax(predictions[i], axis=1))\n",
        "  y_pred.append(pred_labels_i)\n",
        "\n",
        "y_pred = list(itertools.chain.from_iterable(y_pred))\n",
        "true_labels = list(itertools.chain.from_iterable(true_labels))\n",
        "y_pred[0:5]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 1, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFk0A1t8Gbbz",
        "colab_type": "code",
        "outputId": "151aa236-d09c-4d4b-e2b3-94c4dfb800c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "true_labels[0:5]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL3E5firGuka",
        "colab_type": "code",
        "outputId": "3ff70a8f-7547-420c-ceaf-ea03d1bde94a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "f1_score(true_labels,y_pred, average='micro')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6549640848599588"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnUhLvNcJK7I",
        "colab_type": "code",
        "outputId": "6fc473ec-8548-445e-cbf6-1ad9b9aa0fb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Combine the results across all batches. \n",
        "# flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "# flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_predictions = y_pred\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "# flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "flat_true_labels = true_labels\n",
        "\n",
        "# Calculate the MCC\n",
        "# mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "f1_weighted = f1_score(flat_true_labels, flat_predictions,average='weighted')\n",
        "f1_micro = f1_score(flat_true_labels, flat_predictions,average='micro')\n",
        "f1_macro = f1_score(flat_true_labels, flat_predictions,average='macro')\n",
        "acc = accuracy_score(flat_true_labels, flat_predictions)\n",
        "fpr, tpr, thresholds = roc_curve(flat_true_labels, flat_predictions)\n",
        "auc_score = auc(fpr, tpr)\n",
        "ap = average_precision_score(flat_true_labels, flat_predictions)\n",
        "\n",
        "\n",
        "# print('Total MCC: %.3f' % mcc)\n",
        "print()\n",
        "print('Total f1_weighted: %.3f' % f1_weighted)\n",
        "print('Total f1_micro: %.3f' % f1_micro)\n",
        "print('Total f1_macro: %.3f' % f1_macro)\n",
        "print('Total acc: %.3f' % acc)\n",
        "print('AUC: %.3f' % auc_score)\n",
        "print('AP: %.3f' % ap)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total f1_weighted: 0.723\n",
            "Total f1_micro: 0.655\n",
            "Total f1_macro: 0.534\n",
            "Total acc: 0.655\n",
            "AUC: 0.681\n",
            "AP: 0.162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TN_ZmY2sSl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_dir_0  = './model_save1/epoch_0'\n",
        "output_dir_1  = './model_save1/epoch_1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRHg2uEVvCuD",
        "colab_type": "text"
      },
      "source": [
        "EPOCH 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRnr_EOrrwzQ",
        "colab_type": "code",
        "outputId": "ba856418-2d58-4903-e2a2-3e236a7b6941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = model.from_pretrained(output_dir_1)\n",
        "# tokenizer = tokenizer.from_pretrained(output_dir_1)\n",
        "\n",
        "# # Copy the model to the GPU.\n",
        "# model.to(device)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, pretrained_config_archive_map, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresolved_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-d37ad69fdd1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load a trained model and vocabulary that you have fine-tuned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# tokenizer = tokenizer.from_pretrained(output_dir_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# # Copy the model to the GPU.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m             )\n\u001b[1;32m    548\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, pretrained_config_archive_map, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m                     )\n\u001b[1;32m    271\u001b[0m                 )\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load './model_save1/epoch_1'. Make sure that:\n\n- './model_save1/epoch_1' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or './model_save1/epoch_1' is the correct path to a directory containing a 'config.json' file\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okutIz06smPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(val_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Predict \n",
        "for batch in val_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sg6qDaYu2Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "y_pred = []\n",
        "for i in range(len(predictions)):\n",
        "  \n",
        "  # The predictions for this batch are a 5-column ndarray with a row for each batch (32). \n",
        "  #Pick the label with the highest value and consider the index = class\n",
        "  pred_labels_i = list(np.argmax(predictions[i], axis=1))\n",
        "  y_pred.append(pred_labels_i)\n",
        "\n",
        "y_pred = list(itertools.chain.from_iterable(y_pred))\n",
        "true_labels = list(itertools.chain.from_iterable(true_labels))\n",
        "y_pred[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDtuLKRLvdKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_labels[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIxhTCZIu-uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_predictions = y_pred\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "# flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "flat_true_labels = true_labels\n",
        "\n",
        "# Calculate the MCC\n",
        "# mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "f1_weighted = f1_score(flat_true_labels, flat_predictions,average='weighted')\n",
        "f1_micro = f1_score(flat_true_labels, flat_predictions,average='micro')\n",
        "f1_macro = f1_score(flat_true_labels, flat_predictions,average='macro')\n",
        "acc = accuracy_score(flat_true_labels, flat_predictions)\n",
        "fpr, tpr, thresholds = roc_curve(flat_true_labels, flat_predictions)\n",
        "auc_score = auc(fpr, tpr)\n",
        "ap = average_precision_score(flat_true_labels, flat_predictions)\n",
        "\n",
        "\n",
        "# print('Total MCC: %.3f' % mcc)\n",
        "print()\n",
        "print('Total f1_weighted: %.3f' % f1_weighted)\n",
        "print('Total f1_micro: %.3f' % f1_micro)\n",
        "print('Total f1_macro: %.3f' % f1_macro)\n",
        "print('Total acc: %.3f' % acc)\n",
        "print('AUC: %.3f' % auc_score)\n",
        "print('AP: %.3f' % ap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkRXf6zHvADv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW51Xe-Tw5Jo",
        "colab_type": "text"
      },
      "source": [
        "EPOCH 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKvVHU_Aw50D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = model.from_pretrained(output_dir_0)\n",
        "tokenizer = tokenizer.from_pretrained(output_dir_0)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjFrmBgaw8JD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(val_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# Predict \n",
        "for batch in val_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-e-5xBzxFUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "y_pred = []\n",
        "for i in range(len(predictions)):\n",
        "  \n",
        "  # The predictions for this batch are a 5-column ndarray with a row for each batch (32). \n",
        "  #Pick the label with the highest value and consider the index = class\n",
        "  pred_labels_i = list(np.argmax(predictions[i], axis=1))\n",
        "  y_pred.append(pred_labels_i)\n",
        "\n",
        "y_pred = list(itertools.chain.from_iterable(y_pred))\n",
        "true_labels = list(itertools.chain.from_iterable(true_labels))\n",
        "y_pred[0:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWUxj68AxJiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_predictions = y_pred\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "# flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "flat_true_labels = true_labels\n",
        "\n",
        "# Calculate the MCC\n",
        "# mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "f1_weighted = f1_score(flat_true_labels, flat_predictions,average='weighted')\n",
        "f1_micro = f1_score(flat_true_labels, flat_predictions,average='micro')\n",
        "f1_macro = f1_score(flat_true_labels, flat_predictions,average='macro')\n",
        "acc = accuracy_score(flat_true_labels, flat_predictions)\n",
        "fpr, tpr, thresholds = roc_curve(flat_true_labels, flat_predictions)\n",
        "auc_score = auc(fpr, tpr)\n",
        "ap = average_precision_score(flat_true_labels, flat_predictions)\n",
        "\n",
        "\n",
        "# print('Total MCC: %.3f' % mcc)\n",
        "print()\n",
        "print('Total f1_weighted: %.3f' % f1_weighted)\n",
        "print('Total f1_micro: %.3f' % f1_micro)\n",
        "print('Total f1_macro: %.3f' % f1_macro)\n",
        "print('Total acc: %.3f' % acc)\n",
        "print('AUC: %.3f' % auc_score)\n",
        "print('AP: %.3f' % ap)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb02FRCrxrlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}