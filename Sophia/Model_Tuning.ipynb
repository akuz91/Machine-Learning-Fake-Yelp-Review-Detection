{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRHmSyHxEIhN"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JM7hDSNClfoK"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(2020)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c8o1FHzD-_y_"
   },
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities \n",
    "def plot_loss(history, label, n):\n",
    "  # Use a log scale to show the wide range of values.\n",
    "    plt.semilogy(history.epoch,  history.history['loss'],\n",
    "               color=colors[n], label='Train '+label)\n",
    "    plt.semilogy(history.epoch,  history.history['val_loss'],\n",
    "          color=colors[n], label='Val '+label,\n",
    "          linestyle=\"--\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend()\n",
    "    \n",
    "def plot_metrics(history):\n",
    "    metrics =  ['loss', 'auc', 'precision', 'recall']\n",
    "    for n, metric in enumerate(metrics):\n",
    "        name = metric.replace(\"_\",\" \").capitalize()\n",
    "        plt.subplot(2,2,n+1)\n",
    "        plt.plot(history.epoch,  history.history[metric], color=colors[0], label='Train')\n",
    "        plt.plot(history.epoch, history.history['val_'+metric],\n",
    "                 color=colors[0], linestyle=\"--\", label='Val')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(name)\n",
    "        plt.legend()\n",
    "\n",
    "def plot_cm(labels, predictions, p=0.5):\n",
    "    cm = confusion_matrix(labels, predictions > p)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "    plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
    "    print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "    print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
    "    print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
    "    print('Total Fraudulent Transactions: ', np.sum(cm[1]))\n",
    "    \n",
    "def plot_roc(name, labels, predictions, **kwargs):\n",
    "    fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
    "\n",
    "    plt.plot(100*fp, 100*tp, label=name+ ' (AUC = %0.3f)' % auc(fp, tp), linewidth=2, **kwargs)\n",
    "    plt.xlabel('False positives [%]')\n",
    "    plt.ylabel('True positives [%]')\n",
    "#     plt.xlim([-0.5,20])\n",
    "#     plt.ylim([80,100.5])\n",
    "    plt.grid(True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "def AUCcalc(y_val_val, y_pred):\n",
    "    fpr, tpr, thresholds = roc_curve(y_val_val, y_pred)\n",
    "    tauc = auc(fpr, tpr)\n",
    "    return tauc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z3iZVjziKHmX"
   },
   "source": [
    "## Data processing and exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_preprocessed_train = pd.DataFrame(pd.read_csv(os.getcwd() + '/' + 'full_preprocessed_train.csv', sep=','))\n",
    "full_preprocessed_val = pd.DataFrame(pd.read_csv(os.getcwd() + '/' + 'full_preprocessed_dev.csv', sep=','))\n",
    "\n",
    "full_preprocessed_train = full_preprocessed_train.replace(np.nan, \" \")\n",
    "full_preprocessed_val = full_preprocessed_val.replace(np.nan, \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_train = pd.DataFrame(pd.read_csv(os.getcwd() + '/' + 'dv_train.csv', sep=',', header=None))\n",
    "doc2vec_val = pd.DataFrame(pd.read_csv(os.getcwd() + '/' + 'dv_val.csv', sep=',', header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_X_training_data = pd.concat([full_preprocessed_train, doc2vec_train], axis=1, sort=False)\n",
    "doc2vec_X_val_data = pd.concat([full_preprocessed_val, doc2vec_val], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWKB_CVZFLpB"
   },
   "source": [
    "### Examine the class label imbalance\n",
    "\n",
    "Let's look at the dataset imbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCJFrtuY2iLF"
   },
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(doc2vec_X_training_data['label'])\n",
    "total = neg + pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6qox6ryyzwdr"
   },
   "source": [
    "### Clean and normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ef42jTuxEjnj"
   },
   "outputs": [],
   "source": [
    "cleaned_train = doc2vec_X_training_data.copy()\n",
    "cleaned_val = doc2vec_X_val_data.copy()\n",
    "\n",
    "# You don't want the `Time` column.\n",
    "cleaned_train = cleaned_train.drop(['date'], axis=1)\n",
    "cleaned_val = cleaned_val.drop(['date'], axis=1)\n",
    "\n",
    "# The `length` column covers a huge range. Convert to log-space.\n",
    "eps=0.001 \n",
    "cleaned_train['length'] = np.log(cleaned_train.pop('length')+eps)\n",
    "cleaned_val['length'] = np.log(cleaned_val.pop('length')+eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't normalize str col\n",
    "cleaned_train = cleaned_train.drop(['review'], axis = 1)\n",
    "cleaned_val = cleaned_val.drop(['review'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xfxhKg7Yr1-b"
   },
   "outputs": [],
   "source": [
    "train_df = cleaned_train.copy()\n",
    "val_df = cleaned_val.copy()\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('label'))\n",
    "val_labels = np.array(val_df.pop('label'))\n",
    "# test_labels = np.array(test_df.pop('Class'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "# test_features = np.array(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8a_Z_kBmr7Oh"
   },
   "source": [
    "Normalize the input features using the sklearn StandardScaler.\n",
    "This will set the mean to 0 and standard deviation to 1.\n",
    "\n",
    "Note: The `StandardScaler` is only fit using the `train_features` to be sure the model is not peeking at the validation or test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IO-qEUmJ5JQg"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "# test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "# test_features = np.clip(test_features, -5, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFK1u4JX16D8"
   },
   "source": [
    "## Define the model and metrics\n",
    "\n",
    "Define a function that creates a simple neural network with a densly connected hidden layer, a [dropout](https://developers.google.com/machine-learning/glossary/#dropout_regularization) layer to reduce overfitting, and an output sigmoid layer that returns the probability of a transaction being fraudulent: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JQDzUqT3UYG"
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "def make_model(metrics = METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    # Sequential groups a linear stack of layers into a tf.keras.Model.\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(16, activation='relu', input_shape=(train_features.shape[-1],)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias),])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouUkwPcGQsy3"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5KWPSjjstUS"
   },
   "outputs": [],
   "source": [
    "initial_bias = np.log([pos/neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50oyu1uss0i-"
   },
   "outputs": [],
   "source": [
    "model = make_model(output_bias = initial_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EJj9ixKVBMT"
   },
   "source": [
    "### Checkpoint the initial weights\n",
    "\n",
    "To make the various training runs more comparable, keep this initial model's weights in a checkpoint file, and load them into each model before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tSUm4yAVIif"
   },
   "outputs": [],
   "source": [
    "initial_weights = os.path.join(tempfile.mkdtemp(),'initial_weights')\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RsA_7SEntRaV"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cveQoiMyGQCo"
   },
   "source": [
    "## Class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ePGp6GUE1WfH"
   },
   "source": [
    "### Calculate class weights\n",
    "\n",
    "The goal is to identify fradulent transactions, but you don't have very many of those positive samples to work with, so you would want to have the classifier heavily weight the few examples that are available. You can do this by passing Keras weights for each class through a parameter. These will cause the model to \"pay more attention\" to examples from an under-represented class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjGWErngGny7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 0.56\n",
      "Weight for class 1: 4.86\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mk1OOE2ZSHzy"
   },
   "source": [
    "### Train a model with class weights\n",
    "\n",
    "Now try re-training and evaluating the model with class weights to see how that affects the predictions.\n",
    "\n",
    "Note: Using `class_weights` changes the range of the loss. This may affect the stability of the training depending on the optimizer. Optimizers whose step size is dependent on the magnitude of the gradient, like `optimizers.SGD`, may fail. The optimizer used here, `optimizers.Adam`, is unaffected by the scaling change. Also note that because of the weighting, the total losses are not comparable between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UJ589fn8ST3x",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "123/123 [==============================] - 2s 16ms/step - loss: 0.9820 - tp: 7457.0000 - fp: 37391.0000 - tn: 187664.0000 - fn: 18362.0000 - accuracy: 0.7778 - precision: 0.1663 - recall: 0.2888 - auc: 0.6175 - val_loss: 0.4373 - val_tp: 1241.0000 - val_fp: 4987.0000 - val_tn: 27283.0000 - val_fn: 2407.0000 - val_accuracy: 0.7941 - val_precision: 0.1993 - val_recall: 0.3402 - val_auc: 0.6792\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.7732 - tp: 10568.0000 - fp: 51691.0000 - tn: 173364.0000 - fn: 15251.0000 - accuracy: 0.7332 - precision: 0.1697 - recall: 0.4093 - auc: 0.6482 - val_loss: 0.4480 - val_tp: 1436.0000 - val_fp: 5350.0000 - val_tn: 26920.0000 - val_fn: 2212.0000 - val_accuracy: 0.7895 - val_precision: 0.2116 - val_recall: 0.3936 - val_auc: 0.7141\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.7122 - tp: 11984.0000 - fp: 55571.0000 - tn: 169484.0000 - fn: 13835.0000 - accuracy: 0.7233 - precision: 0.1774 - recall: 0.4642 - auc: 0.6736 - val_loss: 0.4542 - val_tp: 1615.0000 - val_fp: 5930.0000 - val_tn: 26340.0000 - val_fn: 2033.0000 - val_accuracy: 0.7783 - val_precision: 0.2140 - val_recall: 0.4427 - val_auc: 0.7306\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6854 - tp: 12700.0000 - fp: 57489.0000 - tn: 167566.0000 - fn: 13119.0000 - accuracy: 0.7186 - precision: 0.1809 - recall: 0.4919 - auc: 0.6882 - val_loss: 0.4479 - val_tp: 1624.0000 - val_fp: 5662.0000 - val_tn: 26608.0000 - val_fn: 2024.0000 - val_accuracy: 0.7860 - val_precision: 0.2229 - val_recall: 0.4452 - val_auc: 0.7396\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6641 - tp: 13539.0000 - fp: 59232.0000 - tn: 165823.0000 - fn: 12280.0000 - accuracy: 0.7149 - precision: 0.1860 - recall: 0.5244 - auc: 0.7008 - val_loss: 0.4463 - val_tp: 1637.0000 - val_fp: 5636.0000 - val_tn: 26634.0000 - val_fn: 2011.0000 - val_accuracy: 0.7871 - val_precision: 0.2251 - val_recall: 0.4487 - val_auc: 0.7440\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6515 - tp: 13990.0000 - fp: 60177.0000 - tn: 164878.0000 - fn: 11829.0000 - accuracy: 0.7130 - precision: 0.1886 - recall: 0.5418 - auc: 0.7087 - val_loss: 0.4416 - val_tp: 1597.0000 - val_fp: 5389.0000 - val_tn: 26881.0000 - val_fn: 2051.0000 - val_accuracy: 0.7929 - val_precision: 0.2286 - val_recall: 0.4378 - val_auc: 0.7468\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.6406 - tp: 14432.0000 - fp: 61170.0000 - tn: 163885.0000 - fn: 11387.0000 - accuracy: 0.7108 - precision: 0.1909 - recall: 0.5590 - auc: 0.7147 - val_loss: 0.4461 - val_tp: 1662.0000 - val_fp: 5559.0000 - val_tn: 26711.0000 - val_fn: 1986.0000 - val_accuracy: 0.7899 - val_precision: 0.2302 - val_recall: 0.4556 - val_auc: 0.7489\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6306 - tp: 14962.0000 - fp: 64006.0000 - tn: 161049.0000 - fn: 10857.0000 - accuracy: 0.7016 - precision: 0.1895 - recall: 0.5795 - auc: 0.7192 - val_loss: 0.4337 - val_tp: 1456.0000 - val_fp: 4718.0000 - val_tn: 27552.0000 - val_fn: 2192.0000 - val_accuracy: 0.8076 - val_precision: 0.2358 - val_recall: 0.3991 - val_auc: 0.7502\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6254 - tp: 15113.0000 - fp: 63835.0000 - tn: 161220.0000 - fn: 10706.0000 - accuracy: 0.7029 - precision: 0.1914 - recall: 0.5853 - auc: 0.7221 - val_loss: 0.4478 - val_tp: 1652.0000 - val_fp: 5567.0000 - val_tn: 26703.0000 - val_fn: 1996.0000 - val_accuracy: 0.7894 - val_precision: 0.2288 - val_recall: 0.4529 - val_auc: 0.7507\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6199 - tp: 15474.0000 - fp: 65188.0000 - tn: 159867.0000 - fn: 10345.0000 - accuracy: 0.6989 - precision: 0.1918 - recall: 0.5993 - auc: 0.7258 - val_loss: 0.4472 - val_tp: 1630.0000 - val_fp: 5461.0000 - val_tn: 26809.0000 - val_fn: 2018.0000 - val_accuracy: 0.7918 - val_precision: 0.2299 - val_recall: 0.4468 - val_auc: 0.7513\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.6147 - tp: 15695.0000 - fp: 66228.0000 - tn: 158827.0000 - fn: 10124.0000 - accuracy: 0.6957 - precision: 0.1916 - recall: 0.6079 - auc: 0.7287 - val_loss: 0.4463 - val_tp: 1611.0000 - val_fp: 5435.0000 - val_tn: 26835.0000 - val_fn: 2037.0000 - val_accuracy: 0.7920 - val_precision: 0.2286 - val_recall: 0.4416 - val_auc: 0.7513\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 1s 11ms/step - loss: 0.6113 - tp: 15951.0000 - fp: 66803.0000 - tn: 158252.0000 - fn: 9868.0000 - accuracy: 0.6944 - precision: 0.1928 - recall: 0.6178 - auc: 0.7306 - val_loss: 0.4427 - val_tp: 1581.0000 - val_fp: 5222.0000 - val_tn: 27048.0000 - val_fn: 2067.0000 - val_accuracy: 0.7971 - val_precision: 0.2324 - val_recall: 0.4334 - val_auc: 0.7518\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.6083 - tp: 16101.0000 - fp: 67248.0000 - tn: 157807.0000 - fn: 9718.0000 - accuracy: 0.6932 - precision: 0.1932 - recall: 0.6236 - auc: 0.7329 - val_loss: 0.4419 - val_tp: 1600.0000 - val_fp: 5313.0000 - val_tn: 26957.0000 - val_fn: 2048.0000 - val_accuracy: 0.7951 - val_precision: 0.2314 - val_recall: 0.4386 - val_auc: 0.7516\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.6068 - tp: 16296.0000 - fp: 68106.0000 - tn: 156949.0000 - fn: 9523.0000 - accuracy: 0.6906 - precision: 0.1931 - recall: 0.6312 - auc: 0.7336 - val_loss: 0.4321 - val_tp: 1420.0000 - val_fp: 4448.0000 - val_tn: 27822.0000 - val_fn: 2228.0000 - val_accuracy: 0.8141 - val_precision: 0.2420 - val_recall: 0.3893 - val_auc: 0.7528\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 2s 13ms/step - loss: 0.6034 - tp: 16467.0000 - fp: 68583.0000 - tn: 156472.0000 - fn: 9352.0000 - accuracy: 0.6893 - precision: 0.1936 - recall: 0.6378 - auc: 0.7362 - val_loss: 0.4370 - val_tp: 1518.0000 - val_fp: 4938.0000 - val_tn: 27332.0000 - val_fn: 2130.0000 - val_accuracy: 0.8032 - val_precision: 0.2351 - val_recall: 0.4161 - val_auc: 0.7530\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.6007 - tp: 16679.0000 - fp: 69459.0000 - tn: 155596.0000 - fn: 9140.0000 - accuracy: 0.6867 - precision: 0.1936 - recall: 0.6460 - auc: 0.7383 - val_loss: 0.4381 - val_tp: 1548.0000 - val_fp: 5088.0000 - val_tn: 27182.0000 - val_fn: 2100.0000 - val_accuracy: 0.7999 - val_precision: 0.2333 - val_recall: 0.4243 - val_auc: 0.7522\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.5999 - tp: 16717.0000 - fp: 69778.0000 - tn: 155277.0000 - fn: 9102.0000 - accuracy: 0.6856 - precision: 0.1933 - recall: 0.6475 - auc: 0.7384 - val_loss: 0.4492 - val_tp: 1651.0000 - val_fp: 5594.0000 - val_tn: 26676.0000 - val_fn: 1997.0000 - val_accuracy: 0.7887 - val_precision: 0.2279 - val_recall: 0.4526 - val_auc: 0.7521\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.5967 - tp: 16962.0000 - fp: 70571.0000 - tn: 154484.0000 - fn: 8857.0000 - accuracy: 0.6834 - precision: 0.1938 - recall: 0.6570 - auc: 0.7411 - val_loss: 0.4339 - val_tp: 1367.0000 - val_fp: 4269.0000 - val_tn: 28001.0000 - val_fn: 2281.0000 - val_accuracy: 0.8176 - val_precision: 0.2425 - val_recall: 0.3747 - val_auc: 0.7525\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.5950 - tp: 17217.0000 - fp: 71171.0000 - tn: 153884.0000 - fn: 8602.0000 - accuracy: 0.6820 - precision: 0.1948 - recall: 0.6668 - auc: 0.7422 - val_loss: 0.4345 - val_tp: 1435.0000 - val_fp: 4556.0000 - val_tn: 27714.0000 - val_fn: 2213.0000 - val_accuracy: 0.8115 - val_precision: 0.2395 - val_recall: 0.3934 - val_auc: 0.7520\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.5946 - tp: 17259.0000 - fp: 71535.0000 - tn: 153520.0000 - fn: 8560.0000 - accuracy: 0.6807 - precision: 0.1944 - recall: 0.6685 - auc: 0.7430 - val_loss: 0.4356 - val_tp: 1441.0000 - val_fp: 4559.0000 - val_tn: 27711.0000 - val_fn: 2207.0000 - val_accuracy: 0.8116 - val_precision: 0.2402 - val_recall: 0.3950 - val_auc: 0.7525\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 9ms/step - loss: 0.5927 - tp: 17514.0000 - fp: 72635.0000 - tn: 152420.0000 - fn: 8305.0000 - accuracy: 0.6774 - precision: 0.1943 - recall: 0.6783 - auc: 0.7443 - val_loss: 0.4314 - val_tp: 1325.0000 - val_fp: 4101.0000 - val_tn: 28169.0000 - val_fn: 2323.0000 - val_accuracy: 0.8211 - val_precision: 0.2442 - val_recall: 0.3632 - val_auc: 0.7522\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.5924 - tp: 17479.0000 - fp: 72393.0000 - tn: 152662.0000 - fn: 8340.0000 - accuracy: 0.6782 - precision: 0.1945 - recall: 0.6770 - auc: 0.7444 - val_loss: 0.4321 - val_tp: 1356.0000 - val_fp: 4216.0000 - val_tn: 28054.0000 - val_fn: 2292.0000 - val_accuracy: 0.8188 - val_precision: 0.2434 - val_recall: 0.3717 - val_auc: 0.7523\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 1s 11ms/step - loss: 0.5905 - tp: 17714.0000 - fp: 73434.0000 - tn: 151621.0000 - fn: 8105.0000 - accuracy: 0.6750 - precision: 0.1943 - recall: 0.6861 - auc: 0.7462 - val_loss: 0.4341 - val_tp: 1358.0000 - val_fp: 4203.0000 - val_tn: 28067.0000 - val_fn: 2290.0000 - val_accuracy: 0.8192 - val_precision: 0.2442 - val_recall: 0.3723 - val_auc: 0.7521\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.5884 - tp: 17909.0000 - fp: 73818.0000 - tn: 151237.0000 - fn: 7910.0000 - accuracy: 0.6742 - precision: 0.1952 - recall: 0.6936 - auc: 0.7491 - val_loss: 0.4308 - val_tp: 1249.0000 - val_fp: 3780.0000 - val_tn: 28490.0000 - val_fn: 2399.0000 - val_accuracy: 0.8280 - val_precision: 0.2484 - val_recall: 0.3424 - val_auc: 0.7515\n",
      "Epoch 25/100\n",
      "120/123 [============================>.] - ETA: 0s - loss: 0.5894 - tp: 17626.0000 - fp: 72809.0000 - tn: 147627.0000 - fn: 7698.0000 - accuracy: 0.6724 - precision: 0.1949 - recall: 0.6960 - auc: 0.7477Restoring model weights from the end of the best epoch.\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.5894 - tp: 17941.0000 - fp: 74269.0000 - tn: 150786.0000 - fn: 7878.0000 - accuracy: 0.6726 - precision: 0.1946 - recall: 0.6949 - auc: 0.7474 - val_loss: 0.4262 - val_tp: 1185.0000 - val_fp: 3479.0000 - val_tn: 28791.0000 - val_fn: 2463.0000 - val_accuracy: 0.8346 - val_precision: 0.2541 - val_recall: 0.3248 - val_auc: 0.7509\n",
      "Epoch 00025: early stopping\n"
     ]
    }
   ],
   "source": [
    "weighted_model = make_model()\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks = [early_stopping],\n",
    "    validation_data=(val_features, val_labels),\n",
    "    # The class weights go here\n",
    "    class_weight=class_weight) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R0ynYRO0G3Lx"
   },
   "source": [
    "### Check training history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REy6WClTZIwQ"
   },
   "source": [
    "### Evaluate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nifqscPGw-5w"
   },
   "outputs": [],
   "source": [
    "train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "val_predictions_weighted = weighted_model.predict(val_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hXDAwyr0HYdX"
   },
   "source": [
    "### Plot the ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hzScIVZS1Xm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x142d8ccc0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc(\"Train Weighted\", train_labels, train_predictions_weighted, color=colors[1])\n",
    "plot_roc(\"Validation Weighted\", val_labels, val_predictions_weighted, color=colors[1], linestyle='--')\n",
    "\n",
    "\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision Report:\n",
      "Validation Weighted:  0.23499379006955262\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Precision Report:\")\n",
    "print(\"Validation Weighted: \", average_precision_score(val_labels, val_predictions_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:\n",
      "Validation Weighted:  0.7529670459704031\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC:\")\n",
    "print(\"Validation Weighted: \", AUCcalc(val_labels, val_predictions_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(metrics = METRICS, lr = 1e-3, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    # Sequential groups a linear stack of layers into a tf.keras.Model.\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(16, activation='relu', input_shape=(train_features.shape[-1],)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias),])\n",
    "\n",
    "    model.compile(\n",
    "      optimizer=keras.optimizers.Adam(lr=lr),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=0,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = [2000, 10000]\n",
    "# EPOCHS = [100, 250, 500]\n",
    "# lr  = [0.001, 0.01, 0.1, 1.0]\n",
    "BATCH_SIZE = [2000, 10000]\n",
    "EPOCHS = [100]\n",
    "lr  = list(np.unique(np.concatenate((10.**np.arange(-6,1,1), np.arange(1,3,.3)))) )\n",
    "\n",
    "every_cart = list(product(BATCH_SIZE, EPOCHS, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "126/126 [==============================] - 3s 22ms/step - loss: 0.9826 - tp: 8691.0000 - fp: 41089.0000 - tn: 216236.0000 - fn: 20776.0000 - accuracy: 0.7843 - precision: 0.1746 - recall: 0.2949 - auc: 0.6251 - val_loss: 0.4462 - val_tp: 1318.0000 - val_fp: 5458.0000 - val_tn: 26812.0000 - val_fn: 2330.0000 - val_accuracy: 0.7832 - val_precision: 0.1945 - val_recall: 0.3613 - val_auc: 0.6804\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7743 - tp: 10480.0000 - fp: 51748.0000 - tn: 173307.0000 - fn: 15339.0000 - accuracy: 0.7326 - precision: 0.1684 - recall: 0.4059 - auc: 0.6474 - val_loss: 0.4519 - val_tp: 1472.0000 - val_fp: 5606.0000 - val_tn: 26664.0000 - val_fn: 2176.0000 - val_accuracy: 0.7833 - val_precision: 0.2080 - val_recall: 0.4035 - val_auc: 0.7141\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7087 - tp: 12100.0000 - fp: 55788.0000 - tn: 169267.0000 - fn: 13719.0000 - accuracy: 0.7229 - precision: 0.1782 - recall: 0.4686 - auc: 0.6760 - val_loss: 0.4529 - val_tp: 1603.0000 - val_fp: 5822.0000 - val_tn: 26448.0000 - val_fn: 2045.0000 - val_accuracy: 0.7810 - val_precision: 0.2159 - val_recall: 0.4394 - val_auc: 0.7321\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6810 - tp: 12981.0000 - fp: 57520.0000 - tn: 167535.0000 - fn: 12838.0000 - accuracy: 0.7195 - precision: 0.1841 - recall: 0.5028 - auc: 0.6915 - val_loss: 0.4493 - val_tp: 1656.0000 - val_fp: 5734.0000 - val_tn: 26536.0000 - val_fn: 1992.0000 - val_accuracy: 0.7849 - val_precision: 0.2241 - val_recall: 0.4539 - val_auc: 0.7397\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.6624 - tp: 13641.0000 - fp: 59262.0000 - tn: 165793.0000 - fn: 12178.0000 - accuracy: 0.7152 - precision: 0.1871 - recall: 0.5283 - auc: 0.7021 - val_loss: 0.4463 - val_tp: 1619.0000 - val_fp: 5558.0000 - val_tn: 26712.0000 - val_fn: 2029.0000 - val_accuracy: 0.7888 - val_precision: 0.2256 - val_recall: 0.4438 - val_auc: 0.7442\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.6496 - tp: 14038.0000 - fp: 60122.0000 - tn: 164933.0000 - fn: 11781.0000 - accuracy: 0.7134 - precision: 0.1893 - recall: 0.5437 - auc: 0.7092 - val_loss: 0.4403 - val_tp: 1599.0000 - val_fp: 5413.0000 - val_tn: 26857.0000 - val_fn: 2049.0000 - val_accuracy: 0.7922 - val_precision: 0.2280 - val_recall: 0.4383 - val_auc: 0.7470\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.6397 - tp: 14474.0000 - fp: 61228.0000 - tn: 163827.0000 - fn: 11345.0000 - accuracy: 0.7107 - precision: 0.1912 - recall: 0.5606 - auc: 0.7159 - val_loss: 0.4453 - val_tp: 1663.0000 - val_fp: 5677.0000 - val_tn: 26593.0000 - val_fn: 1985.0000 - val_accuracy: 0.7867 - val_precision: 0.2266 - val_recall: 0.4559 - val_auc: 0.7479\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6306 - tp: 14830.0000 - fp: 62504.0000 - tn: 162551.0000 - fn: 10989.0000 - accuracy: 0.7071 - precision: 0.1918 - recall: 0.5744 - auc: 0.7207 - val_loss: 0.4479 - val_tp: 1647.0000 - val_fp: 5549.0000 - val_tn: 26721.0000 - val_fn: 2001.0000 - val_accuracy: 0.7898 - val_precision: 0.2289 - val_recall: 0.4515 - val_auc: 0.7505\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.6245 - tp: 15150.0000 - fp: 63896.0000 - tn: 161159.0000 - fn: 10669.0000 - accuracy: 0.7028 - precision: 0.1917 - recall: 0.5868 - auc: 0.7230 - val_loss: 0.4429 - val_tp: 1563.0000 - val_fp: 5116.0000 - val_tn: 27154.0000 - val_fn: 2085.0000 - val_accuracy: 0.7995 - val_precision: 0.2340 - val_recall: 0.4285 - val_auc: 0.7506\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.6182 - tp: 15522.0000 - fp: 65018.0000 - tn: 160037.0000 - fn: 10297.0000 - accuracy: 0.6998 - precision: 0.1927 - recall: 0.6012 - auc: 0.7273 - val_loss: 0.4412 - val_tp: 1557.0000 - val_fp: 5109.0000 - val_tn: 27161.0000 - val_fn: 2091.0000 - val_accuracy: 0.7995 - val_precision: 0.2336 - val_recall: 0.4268 - val_auc: 0.7519\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.6141 - tp: 15853.0000 - fp: 66101.0000 - tn: 158954.0000 - fn: 9966.0000 - accuracy: 0.6968 - precision: 0.1934 - recall: 0.6140 - auc: 0.7294 - val_loss: 0.4503 - val_tp: 1683.0000 - val_fp: 5759.0000 - val_tn: 26511.0000 - val_fn: 1965.0000 - val_accuracy: 0.7850 - val_precision: 0.2261 - val_recall: 0.4613 - val_auc: 0.7510\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6102 - tp: 16057.0000 - fp: 66869.0000 - tn: 158186.0000 - fn: 9762.0000 - accuracy: 0.6945 - precision: 0.1936 - recall: 0.6219 - auc: 0.7314 - val_loss: 0.4436 - val_tp: 1591.0000 - val_fp: 5230.0000 - val_tn: 27040.0000 - val_fn: 2057.0000 - val_accuracy: 0.7971 - val_precision: 0.2333 - val_recall: 0.4361 - val_auc: 0.7521\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6087 - tp: 16148.0000 - fp: 67599.0000 - tn: 157456.0000 - fn: 9671.0000 - accuracy: 0.6920 - precision: 0.1928 - recall: 0.6254 - auc: 0.7320 - val_loss: 0.4373 - val_tp: 1493.0000 - val_fp: 4811.0000 - val_tn: 27459.0000 - val_fn: 2155.0000 - val_accuracy: 0.8061 - val_precision: 0.2368 - val_recall: 0.4093 - val_auc: 0.7530\n",
      "Epoch 14/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6056 - tp: 16353.0000 - fp: 68289.0000 - tn: 156766.0000 - fn: 9466.0000 - accuracy: 0.6901 - precision: 0.1932 - recall: 0.6334 - auc: 0.7343 - val_loss: 0.4439 - val_tp: 1577.0000 - val_fp: 5177.0000 - val_tn: 27093.0000 - val_fn: 2071.0000 - val_accuracy: 0.7982 - val_precision: 0.2335 - val_recall: 0.4323 - val_auc: 0.7529\n",
      "Epoch 15/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6030 - tp: 16581.0000 - fp: 69100.0000 - tn: 155955.0000 - fn: 9238.0000 - accuracy: 0.6877 - precision: 0.1935 - recall: 0.6422 - auc: 0.7361 - val_loss: 0.4386 - val_tp: 1518.0000 - val_fp: 4964.0000 - val_tn: 27306.0000 - val_fn: 2130.0000 - val_accuracy: 0.8025 - val_precision: 0.2342 - val_recall: 0.4161 - val_auc: 0.7528\n",
      "Epoch 16/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6005 - tp: 16631.0000 - fp: 69422.0000 - tn: 155633.0000 - fn: 9188.0000 - accuracy: 0.6867 - precision: 0.1933 - recall: 0.6441 - auc: 0.7379 - val_loss: 0.4372 - val_tp: 1531.0000 - val_fp: 4981.0000 - val_tn: 27289.0000 - val_fn: 2117.0000 - val_accuracy: 0.8024 - val_precision: 0.2351 - val_recall: 0.4197 - val_auc: 0.7519\n",
      "Epoch 17/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.5998 - tp: 16741.0000 - fp: 70040.0000 - tn: 155015.0000 - fn: 9078.0000 - accuracy: 0.6846 - precision: 0.1929 - recall: 0.6484 - auc: 0.7383 - val_loss: 0.4401 - val_tp: 1514.0000 - val_fp: 4855.0000 - val_tn: 27415.0000 - val_fn: 2134.0000 - val_accuracy: 0.8054 - val_precision: 0.2377 - val_recall: 0.4150 - val_auc: 0.7531\n",
      "Epoch 18/100\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.5960 - tp: 17111.0000 - fp: 70546.0000 - tn: 154509.0000 - fn: 8708.0000 - accuracy: 0.6841 - precision: 0.1952 - recall: 0.6627 - auc: 0.7420 - val_loss: 0.4392 - val_tp: 1507.0000 - val_fp: 4858.0000 - val_tn: 27412.0000 - val_fn: 2141.0000 - val_accuracy: 0.8051 - val_precision: 0.2368 - val_recall: 0.4131 - val_auc: 0.7531\n",
      "Epoch 19/100\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.5937 - tp: 17277.0000 - fp: 71460.0000 - tn: 153595.0000 - fn: 8542.0000 - accuracy: 0.6811 - precision: 0.1947 - recall: 0.6692 - auc: 0.7438 - val_loss: 0.4397 - val_tp: 1523.0000 - val_fp: 5052.0000 - val_tn: 27218.0000 - val_fn: 2125.0000 - val_accuracy: 0.8002 - val_precision: 0.2316 - val_recall: 0.4175 - val_auc: 0.7514\n",
      "Epoch 20/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.5939 - tp: 17276.0000 - fp: 72168.0000 - tn: 152887.0000 - fn: 8543.0000 - accuracy: 0.6783 - precision: 0.1931 - recall: 0.6691 - auc: 0.7428 - val_loss: 0.4327 - val_tp: 1356.0000 - val_fp: 4196.0000 - val_tn: 28074.0000 - val_fn: 2292.0000 - val_accuracy: 0.8194 - val_precision: 0.2442 - val_recall: 0.3717 - val_auc: 0.7530\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5930 - tp: 17451.0000 - fp: 72092.0000 - tn: 152963.0000 - fn: 8368.0000 - accuracy: 0.6793 - precision: 0.1949 - recall: 0.6759 - auc: 0.7440 - val_loss: 0.4370 - val_tp: 1386.0000 - val_fp: 4359.0000 - val_tn: 27911.0000 - val_fn: 2262.0000 - val_accuracy: 0.8157 - val_precision: 0.2413 - val_recall: 0.3799 - val_auc: 0.7528\n",
      "Epoch 22/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.5921 - tp: 17675.0000 - fp: 72963.0000 - tn: 152092.0000 - fn: 8144.0000 - accuracy: 0.6767 - precision: 0.1950 - recall: 0.6846 - auc: 0.7453 - val_loss: 0.4375 - val_tp: 1429.0000 - val_fp: 4574.0000 - val_tn: 27696.0000 - val_fn: 2219.0000 - val_accuracy: 0.8109 - val_precision: 0.2380 - val_recall: 0.3917 - val_auc: 0.7519\n",
      "Epoch 23/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5903 - tp: 17682.0000 - fp: 73409.0000 - tn: 151646.0000 - fn: 8137.0000 - accuracy: 0.6750 - precision: 0.1941 - recall: 0.6848 - auc: 0.7464 - val_loss: 0.4387 - val_tp: 1411.0000 - val_fp: 4430.0000 - val_tn: 27840.0000 - val_fn: 2237.0000 - val_accuracy: 0.8144 - val_precision: 0.2416 - val_recall: 0.3868 - val_auc: 0.7515\n",
      "Epoch 24/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5877 - tp: 18072.0000 - fp: 74444.0000 - tn: 150611.0000 - fn: 7747.0000 - accuracy: 0.6724 - precision: 0.1953 - recall: 0.6999 - auc: 0.7491 - val_loss: 0.4333 - val_tp: 1340.0000 - val_fp: 4182.0000 - val_tn: 28088.0000 - val_fn: 2308.0000 - val_accuracy: 0.8193 - val_precision: 0.2427 - val_recall: 0.3673 - val_auc: 0.7502\n",
      "Epoch 25/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5881 - tp: 18060.0000 - fp: 74563.0000 - tn: 150492.0000 - fn: 7759.0000 - accuracy: 0.6719 - precision: 0.1950 - recall: 0.6995 - auc: 0.7487 - val_loss: 0.4334 - val_tp: 1273.0000 - val_fp: 3862.0000 - val_tn: 28408.0000 - val_fn: 2375.0000 - val_accuracy: 0.8264 - val_precision: 0.2479 - val_recall: 0.3490 - val_auc: 0.7511\n",
      "Epoch 26/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5880 - tp: 18101.0000 - fp: 75001.0000 - tn: 150054.0000 - fn: 7718.0000 - accuracy: 0.6703 - precision: 0.1944 - recall: 0.7011 - auc: 0.7490 - val_loss: 0.4351 - val_tp: 1270.0000 - val_fp: 3822.0000 - val_tn: 28448.0000 - val_fn: 2378.0000 - val_accuracy: 0.8274 - val_precision: 0.2494 - val_recall: 0.3481 - val_auc: 0.7516\n",
      "Epoch 27/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5875 - tp: 18106.0000 - fp: 74937.0000 - tn: 150118.0000 - fn: 7713.0000 - accuracy: 0.6706 - precision: 0.1946 - recall: 0.7013 - auc: 0.7497 - val_loss: 0.4359 - val_tp: 1297.0000 - val_fp: 4012.0000 - val_tn: 28258.0000 - val_fn: 2351.0000 - val_accuracy: 0.8228 - val_precision: 0.2443 - val_recall: 0.3555 - val_auc: 0.7500\n",
      "Epoch 28/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5869 - tp: 18365.0000 - fp: 75696.0000 - tn: 149359.0000 - fn: 7454.0000 - accuracy: 0.6686 - precision: 0.1952 - recall: 0.7113 - auc: 0.7501 - val_loss: 0.4318 - val_tp: 1181.0000 - val_fp: 3505.0000 - val_tn: 28765.0000 - val_fn: 2467.0000 - val_accuracy: 0.8337 - val_precision: 0.2520 - val_recall: 0.3237 - val_auc: 0.7489\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.7189 - tp: 13729.0000 - fp: 60689.0000 - tn: 196636.0000 - fn: 15738.0000 - accuracy: 0.7335 - precision: 0.1845 - recall: 0.4659 - auc: 0.6804 - val_loss: 0.4869 - val_tp: 1961.0000 - val_fp: 7207.0000 - val_tn: 25063.0000 - val_fn: 1687.0000 - val_accuracy: 0.7524 - val_precision: 0.2139 - val_recall: 0.5376 - val_auc: 0.7463\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6118 - tp: 16128.0000 - fp: 68178.0000 - tn: 156877.0000 - fn: 9691.0000 - accuracy: 0.6896 - precision: 0.1913 - recall: 0.6247 - auc: 0.7285 - val_loss: 0.4618 - val_tp: 1727.0000 - val_fp: 5976.0000 - val_tn: 26294.0000 - val_fn: 1921.0000 - val_accuracy: 0.7801 - val_precision: 0.2242 - val_recall: 0.4734 - val_auc: 0.7506\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5998 - tp: 17361.0000 - fp: 73721.0000 - tn: 151334.0000 - fn: 8458.0000 - accuracy: 0.6724 - precision: 0.1906 - recall: 0.6724 - auc: 0.7371 - val_loss: 0.4776 - val_tp: 1837.0000 - val_fp: 6443.0000 - val_tn: 25827.0000 - val_fn: 1811.0000 - val_accuracy: 0.7702 - val_precision: 0.2219 - val_recall: 0.5036 - val_auc: 0.7496\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5952 - tp: 18103.0000 - fp: 77137.0000 - tn: 147918.0000 - fn: 7716.0000 - accuracy: 0.6618 - precision: 0.1901 - recall: 0.7012 - auc: 0.7413 - val_loss: 0.4659 - val_tp: 1821.0000 - val_fp: 6206.0000 - val_tn: 26064.0000 - val_fn: 1827.0000 - val_accuracy: 0.7764 - val_precision: 0.2269 - val_recall: 0.4992 - val_auc: 0.7504\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5921 - tp: 18667.0000 - fp: 78875.0000 - tn: 146180.0000 - fn: 7152.0000 - accuracy: 0.6571 - precision: 0.1914 - recall: 0.7230 - auc: 0.7457 - val_loss: 0.4554 - val_tp: 1622.0000 - val_fp: 5503.0000 - val_tn: 26767.0000 - val_fn: 2026.0000 - val_accuracy: 0.7904 - val_precision: 0.2276 - val_recall: 0.4446 - val_auc: 0.7489\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5899 - tp: 18690.0000 - fp: 78828.0000 - tn: 146227.0000 - fn: 7129.0000 - accuracy: 0.6574 - precision: 0.1917 - recall: 0.7239 - auc: 0.7478 - val_loss: 0.4411 - val_tp: 1360.0000 - val_fp: 4242.0000 - val_tn: 28028.0000 - val_fn: 2288.0000 - val_accuracy: 0.8182 - val_precision: 0.2428 - val_recall: 0.3728 - val_auc: 0.7499\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5888 - tp: 18935.0000 - fp: 79843.0000 - tn: 145212.0000 - fn: 6884.0000 - accuracy: 0.6543 - precision: 0.1917 - recall: 0.7334 - auc: 0.7494 - val_loss: 0.4309 - val_tp: 1273.0000 - val_fp: 3814.0000 - val_tn: 28456.0000 - val_fn: 2375.0000 - val_accuracy: 0.8277 - val_precision: 0.2502 - val_recall: 0.3490 - val_auc: 0.7492\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5888 - tp: 18866.0000 - fp: 78676.0000 - tn: 146379.0000 - fn: 6953.0000 - accuracy: 0.6587 - precision: 0.1934 - recall: 0.7307 - auc: 0.7501 - val_loss: 0.4405 - val_tp: 1252.0000 - val_fp: 3663.0000 - val_tn: 28607.0000 - val_fn: 2396.0000 - val_accuracy: 0.8313 - val_precision: 0.2547 - val_recall: 0.3432 - val_auc: 0.7478\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5878 - tp: 18994.0000 - fp: 79312.0000 - tn: 145743.0000 - fn: 6825.0000 - accuracy: 0.6567 - precision: 0.1932 - recall: 0.7357 - auc: 0.7509 - val_loss: 0.4397 - val_tp: 1163.0000 - val_fp: 3425.0000 - val_tn: 28845.0000 - val_fn: 2485.0000 - val_accuracy: 0.8355 - val_precision: 0.2535 - val_recall: 0.3188 - val_auc: 0.7474\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5850 - tp: 18984.0000 - fp: 78728.0000 - tn: 146327.0000 - fn: 6835.0000 - accuracy: 0.6589 - precision: 0.1943 - recall: 0.7353 - auc: 0.7536 - val_loss: 0.4278 - val_tp: 933.0000 - val_fp: 2534.0000 - val_tn: 29736.0000 - val_fn: 2715.0000 - val_accuracy: 0.8539 - val_precision: 0.2691 - val_recall: 0.2558 - val_auc: 0.7452\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5862 - tp: 19110.0000 - fp: 79063.0000 - tn: 145992.0000 - fn: 6709.0000 - accuracy: 0.6581 - precision: 0.1947 - recall: 0.7402 - auc: 0.7529 - val_loss: 0.4279 - val_tp: 1054.0000 - val_fp: 3051.0000 - val_tn: 29219.0000 - val_fn: 2594.0000 - val_accuracy: 0.8428 - val_precision: 0.2568 - val_recall: 0.2889 - val_auc: 0.7446\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5857 - tp: 19056.0000 - fp: 78612.0000 - tn: 146443.0000 - fn: 6763.0000 - accuracy: 0.6597 - precision: 0.1951 - recall: 0.7381 - auc: 0.7540 - val_loss: 0.4303 - val_tp: 714.0000 - val_fp: 1740.0000 - val_tn: 30530.0000 - val_fn: 2934.0000 - val_accuracy: 0.8699 - val_precision: 0.2910 - val_recall: 0.1957 - val_auc: 0.7457\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 2s 14ms/step - loss: 0.6811 - tp: 16965.0000 - fp: 79743.0000 - tn: 177582.0000 - fn: 12502.0000 - accuracy: 0.6784 - precision: 0.1754 - recall: 0.5757 - auc: 0.6860 - val_loss: 0.6060 - val_tp: 2719.0000 - val_fp: 11739.0000 - val_tn: 20531.0000 - val_fn: 929.0000 - val_accuracy: 0.6473 - val_precision: 0.1881 - val_recall: 0.7453 - val_auc: 0.7489\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6130 - tp: 18093.0000 - fp: 81273.0000 - tn: 143782.0000 - fn: 7726.0000 - accuracy: 0.6452 - precision: 0.1821 - recall: 0.7008 - auc: 0.7257 - val_loss: 0.4945 - val_tp: 1975.0000 - val_fp: 7395.0000 - val_tn: 24875.0000 - val_fn: 1673.0000 - val_accuracy: 0.7475 - val_precision: 0.2108 - val_recall: 0.5414 - val_auc: 0.7409\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6150 - tp: 18088.0000 - fp: 80749.0000 - tn: 144306.0000 - fn: 7731.0000 - accuracy: 0.6473 - precision: 0.1830 - recall: 0.7006 - auc: 0.7263 - val_loss: 0.4726 - val_tp: 1775.0000 - val_fp: 6380.0000 - val_tn: 25890.0000 - val_fn: 1873.0000 - val_accuracy: 0.7702 - val_precision: 0.2177 - val_recall: 0.4866 - val_auc: 0.7411\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6139 - tp: 17751.0000 - fp: 78626.0000 - tn: 146429.0000 - fn: 8068.0000 - accuracy: 0.6544 - precision: 0.1842 - recall: 0.6875 - auc: 0.7281 - val_loss: 0.4696 - val_tp: 1459.0000 - val_fp: 4903.0000 - val_tn: 27367.0000 - val_fn: 2189.0000 - val_accuracy: 0.8026 - val_precision: 0.2293 - val_recall: 0.3999 - val_auc: 0.7360\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6172 - tp: 17474.0000 - fp: 77871.0000 - tn: 147184.0000 - fn: 8345.0000 - accuracy: 0.6563 - precision: 0.1833 - recall: 0.6768 - auc: 0.7251 - val_loss: 0.5163 - val_tp: 1588.0000 - val_fp: 5831.0000 - val_tn: 26439.0000 - val_fn: 2060.0000 - val_accuracy: 0.7803 - val_precision: 0.2140 - val_recall: 0.4353 - val_auc: 0.7321\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6139 - tp: 17791.0000 - fp: 77970.0000 - tn: 147085.0000 - fn: 8028.0000 - accuracy: 0.6572 - precision: 0.1858 - recall: 0.6891 - auc: 0.7290 - val_loss: 0.4847 - val_tp: 1477.0000 - val_fp: 5118.0000 - val_tn: 27152.0000 - val_fn: 2171.0000 - val_accuracy: 0.7971 - val_precision: 0.2240 - val_recall: 0.4049 - val_auc: 0.7332\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6154 - tp: 17534.0000 - fp: 76258.0000 - tn: 148797.0000 - fn: 8285.0000 - accuracy: 0.6630 - precision: 0.1869 - recall: 0.6791 - auc: 0.7277 - val_loss: 0.4544 - val_tp: 597.0000 - val_fp: 1595.0000 - val_tn: 30675.0000 - val_fn: 3051.0000 - val_accuracy: 0.8706 - val_precision: 0.2724 - val_recall: 0.1637 - val_auc: 0.7365\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6181 - tp: 17149.0000 - fp: 73755.0000 - tn: 151300.0000 - fn: 8670.0000 - accuracy: 0.6714 - precision: 0.1886 - recall: 0.6642 - auc: 0.7266 - val_loss: 0.4090 - val_tp: 577.0000 - val_fp: 1520.0000 - val_tn: 30750.0000 - val_fn: 3071.0000 - val_accuracy: 0.8722 - val_precision: 0.2752 - val_recall: 0.1582 - val_auc: 0.7325\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6214 - tp: 16889.0000 - fp: 72408.0000 - tn: 152647.0000 - fn: 8930.0000 - accuracy: 0.6758 - precision: 0.1891 - recall: 0.6541 - auc: 0.7239 - val_loss: 0.4682 - val_tp: 1250.0000 - val_fp: 4035.0000 - val_tn: 28235.0000 - val_fn: 2398.0000 - val_accuracy: 0.8209 - val_precision: 0.2365 - val_recall: 0.3427 - val_auc: 0.7325\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6164 - tp: 16882.0000 - fp: 71918.0000 - tn: 153137.0000 - fn: 8937.0000 - accuracy: 0.6777 - precision: 0.1901 - recall: 0.6539 - auc: 0.7277 - val_loss: 0.4650 - val_tp: 452.0000 - val_fp: 1423.0000 - val_tn: 30847.0000 - val_fn: 3196.0000 - val_accuracy: 0.8714 - val_precision: 0.2411 - val_recall: 0.1239 - val_auc: 0.7192\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6175 - tp: 16806.0000 - fp: 70615.0000 - tn: 154440.0000 - fn: 9013.0000 - accuracy: 0.6826 - precision: 0.1922 - recall: 0.6509 - auc: 0.7286 - val_loss: 0.4689 - val_tp: 665.0000 - val_fp: 1766.0000 - val_tn: 30504.0000 - val_fn: 2983.0000 - val_accuracy: 0.8678 - val_precision: 0.2735 - val_recall: 0.1823 - val_auc: 0.7295\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 4.7321 - tp: 21218.0000 - fp: 136996.0000 - tn: 120329.0000 - fn: 8249.0000 - accuracy: 0.4936 - precision: 0.1341 - recall: 0.7201 - auc: 0.5981 - val_loss: 0.7360 - val_tp: 3296.0000 - val_fp: 20832.0000 - val_tn: 11438.0000 - val_fn: 352.0000 - val_accuracy: 0.4102 - val_precision: 0.1366 - val_recall: 0.9035 - val_auc: 0.6238\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7052 - tp: 23119.0000 - fp: 154748.0000 - tn: 70307.0000 - fn: 2700.0000 - accuracy: 0.3724 - precision: 0.1300 - recall: 0.8954 - auc: 0.6091 - val_loss: 0.5782 - val_tp: 3138.0000 - val_fp: 17868.0000 - val_tn: 14402.0000 - val_fn: 510.0000 - val_accuracy: 0.4883 - val_precision: 0.1494 - val_recall: 0.8602 - val_auc: 0.6698\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6757 - tp: 23611.0000 - fp: 157479.0000 - tn: 67576.0000 - fn: 2208.0000 - accuracy: 0.3635 - precision: 0.1304 - recall: 0.9145 - auc: 0.6146 - val_loss: 0.5534 - val_tp: 3016.0000 - val_fp: 16386.0000 - val_tn: 15884.0000 - val_fn: 632.0000 - val_accuracy: 0.5262 - val_precision: 0.1554 - val_recall: 0.8268 - val_auc: 0.6905\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6689 - tp: 23281.0000 - fp: 153709.0000 - tn: 71346.0000 - fn: 2538.0000 - accuracy: 0.3772 - precision: 0.1315 - recall: 0.9017 - auc: 0.6171 - val_loss: 0.7328 - val_tp: 3425.0000 - val_fp: 23716.0000 - val_tn: 8554.0000 - val_fn: 223.0000 - val_accuracy: 0.3335 - val_precision: 0.1262 - val_recall: 0.9389 - val_auc: 0.6136\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6814 - tp: 23510.0000 - fp: 157561.0000 - tn: 67494.0000 - fn: 2309.0000 - accuracy: 0.3627 - precision: 0.1298 - recall: 0.9106 - auc: 0.6096 - val_loss: 0.5289 - val_tp: 2861.0000 - val_fp: 15264.0000 - val_tn: 17006.0000 - val_fn: 787.0000 - val_accuracy: 0.5531 - val_precision: 0.1578 - val_recall: 0.7843 - val_auc: 0.6854\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7094 - tp: 21490.0000 - fp: 146820.0000 - tn: 78235.0000 - fn: 4329.0000 - accuracy: 0.3975 - precision: 0.1277 - recall: 0.8323 - auc: 0.6010 - val_loss: 0.5852 - val_tp: 2936.0000 - val_fp: 17486.0000 - val_tn: 14784.0000 - val_fn: 712.0000 - val_accuracy: 0.4933 - val_precision: 0.1438 - val_recall: 0.8048 - val_auc: 0.6487\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7790 - tp: 22148.0000 - fp: 159374.0000 - tn: 65681.0000 - fn: 3671.0000 - accuracy: 0.3501 - precision: 0.1220 - recall: 0.8578 - auc: 0.5791 - val_loss: 0.5913 - val_tp: 3126.0000 - val_fp: 19616.0000 - val_tn: 12654.0000 - val_fn: 522.0000 - val_accuracy: 0.4393 - val_precision: 0.1375 - val_recall: 0.8569 - val_auc: 0.6365\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7762 - tp: 23439.0000 - fp: 171310.0000 - tn: 53745.0000 - fn: 2380.0000 - accuracy: 0.3077 - precision: 0.1204 - recall: 0.9078 - auc: 0.5704 - val_loss: 0.6829 - val_tp: 3436.0000 - val_fp: 24132.0000 - val_tn: 8138.0000 - val_fn: 212.0000 - val_accuracy: 0.3222 - val_precision: 0.1246 - val_recall: 0.9419 - val_auc: 0.5986\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7223 - tp: 20965.0000 - fp: 158774.0000 - tn: 66281.0000 - fn: 4854.0000 - accuracy: 0.3478 - precision: 0.1166 - recall: 0.8120 - auc: 0.5624 - val_loss: 0.6254 - val_tp: 185.0000 - val_fp: 1311.0000 - val_tn: 30959.0000 - val_fn: 3463.0000 - val_accuracy: 0.8671 - val_precision: 0.1237 - val_recall: 0.0507 - val_auc: 0.5931\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7081 - tp: 21042.0000 - fp: 161253.0000 - tn: 63802.0000 - fn: 4777.0000 - accuracy: 0.3382 - precision: 0.1154 - recall: 0.8150 - auc: 0.5609 - val_loss: 0.6909 - val_tp: 3374.0000 - val_fp: 24071.0000 - val_tn: 8199.0000 - val_fn: 274.0000 - val_accuracy: 0.3222 - val_precision: 0.1229 - val_recall: 0.9249 - val_auc: 0.5914\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7158 - tp: 20263.0000 - fp: 162515.0000 - tn: 62540.0000 - fn: 5556.0000 - accuracy: 0.3301 - precision: 0.1109 - recall: 0.7848 - auc: 0.5369 - val_loss: 0.6189 - val_tp: 44.0000 - val_fp: 98.0000 - val_tn: 32172.0000 - val_fn: 3604.0000 - val_accuracy: 0.8969 - val_precision: 0.3099 - val_recall: 0.0121 - val_auc: 0.5614\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7475 - tp: 15805.0000 - fp: 128027.0000 - tn: 97028.0000 - fn: 10014.0000 - accuracy: 0.4498 - precision: 0.1099 - recall: 0.6121 - auc: 0.5335 - val_loss: 2.2797 - val_tp: 268.0000 - val_fp: 4185.0000 - val_tn: 28085.0000 - val_fn: 3380.0000 - val_accuracy: 0.7894 - val_precision: 0.0602 - val_recall: 0.0735 - val_auc: 0.5008\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.0603 - tp: 17370.0000 - fp: 139842.0000 - tn: 85213.0000 - fn: 8449.0000 - accuracy: 0.4089 - precision: 0.1105 - recall: 0.6728 - auc: 0.5375 - val_loss: 0.7195 - val_tp: 3528.0000 - val_fp: 26944.0000 - val_tn: 5326.0000 - val_fn: 120.0000 - val_accuracy: 0.2465 - val_precision: 0.1158 - val_recall: 0.9671 - val_auc: 0.5658\n",
      "Epoch 1/250\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.9811 - tp: 11089.0000 - fp: 64352.0000 - tn: 192973.0000 - fn: 18378.0000 - accuracy: 0.7115 - precision: 0.1470 - recall: 0.3763 - auc: 0.6107 - val_loss: 0.4465 - val_tp: 1303.0000 - val_fp: 5409.0000 - val_tn: 26861.0000 - val_fn: 2345.0000 - val_accuracy: 0.7841 - val_precision: 0.1941 - val_recall: 0.3572 - val_auc: 0.6791\n",
      "Epoch 2/250\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7729 - tp: 10545.0000 - fp: 51863.0000 - tn: 173192.0000 - fn: 15274.0000 - accuracy: 0.7324 - precision: 0.1690 - recall: 0.4084 - auc: 0.6497 - val_loss: 0.4508 - val_tp: 1467.0000 - val_fp: 5603.0000 - val_tn: 26667.0000 - val_fn: 2181.0000 - val_accuracy: 0.7833 - val_precision: 0.2075 - val_recall: 0.4021 - val_auc: 0.7140\n",
      "Epoch 3/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7130 - tp: 11888.0000 - fp: 55574.0000 - tn: 169481.0000 - fn: 13931.0000 - accuracy: 0.7229 - precision: 0.1762 - recall: 0.4604 - auc: 0.6728 - val_loss: 0.4480 - val_tp: 1565.0000 - val_fp: 5611.0000 - val_tn: 26659.0000 - val_fn: 2083.0000 - val_accuracy: 0.7858 - val_precision: 0.2181 - val_recall: 0.4290 - val_auc: 0.7316\n",
      "Epoch 4/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6809 - tp: 12911.0000 - fp: 57736.0000 - tn: 167319.0000 - fn: 12908.0000 - accuracy: 0.7184 - precision: 0.1828 - recall: 0.5001 - auc: 0.6911 - val_loss: 0.4526 - val_tp: 1671.0000 - val_fp: 5815.0000 - val_tn: 26455.0000 - val_fn: 1977.0000 - val_accuracy: 0.7831 - val_precision: 0.2232 - val_recall: 0.4581 - val_auc: 0.7398\n",
      "Epoch 5/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6627 - tp: 13578.0000 - fp: 58720.0000 - tn: 166335.0000 - fn: 12241.0000 - accuracy: 0.7171 - precision: 0.1878 - recall: 0.5259 - auc: 0.7018 - val_loss: 0.4420 - val_tp: 1558.0000 - val_fp: 5274.0000 - val_tn: 26996.0000 - val_fn: 2090.0000 - val_accuracy: 0.7950 - val_precision: 0.2280 - val_recall: 0.4271 - val_auc: 0.7454\n",
      "Epoch 6/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6515 - tp: 13930.0000 - fp: 60028.0000 - tn: 165027.0000 - fn: 11889.0000 - accuracy: 0.7133 - precision: 0.1884 - recall: 0.5395 - auc: 0.7086 - val_loss: 0.4432 - val_tp: 1621.0000 - val_fp: 5437.0000 - val_tn: 26833.0000 - val_fn: 2027.0000 - val_accuracy: 0.7922 - val_precision: 0.2297 - val_recall: 0.4444 - val_auc: 0.7471\n",
      "Epoch 7/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6411 - tp: 14425.0000 - fp: 61649.0000 - tn: 163406.0000 - fn: 11394.0000 - accuracy: 0.7088 - precision: 0.1896 - recall: 0.5587 - auc: 0.7141 - val_loss: 0.4399 - val_tp: 1563.0000 - val_fp: 5132.0000 - val_tn: 27138.0000 - val_fn: 2085.0000 - val_accuracy: 0.7991 - val_precision: 0.2335 - val_recall: 0.4285 - val_auc: 0.7491\n",
      "Epoch 8/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6316 - tp: 14858.0000 - fp: 63278.0000 - tn: 161777.0000 - fn: 10961.0000 - accuracy: 0.7041 - precision: 0.1902 - recall: 0.5755 - auc: 0.7187 - val_loss: 0.4437 - val_tp: 1614.0000 - val_fp: 5432.0000 - val_tn: 26838.0000 - val_fn: 2034.0000 - val_accuracy: 0.7921 - val_precision: 0.2291 - val_recall: 0.4424 - val_auc: 0.7501\n",
      "Epoch 9/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6256 - tp: 15077.0000 - fp: 64127.0000 - tn: 160928.0000 - fn: 10742.0000 - accuracy: 0.7016 - precision: 0.1904 - recall: 0.5839 - auc: 0.7216 - val_loss: 0.4474 - val_tp: 1661.0000 - val_fp: 5577.0000 - val_tn: 26693.0000 - val_fn: 1987.0000 - val_accuracy: 0.7894 - val_precision: 0.2295 - val_recall: 0.4553 - val_auc: 0.7508\n",
      "Epoch 10/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6193 - tp: 15437.0000 - fp: 65308.0000 - tn: 159747.0000 - fn: 10382.0000 - accuracy: 0.6983 - precision: 0.1912 - recall: 0.5979 - auc: 0.7260 - val_loss: 0.4392 - val_tp: 1544.0000 - val_fp: 5021.0000 - val_tn: 27249.0000 - val_fn: 2104.0000 - val_accuracy: 0.8016 - val_precision: 0.2352 - val_recall: 0.4232 - val_auc: 0.7512\n",
      "Epoch 11/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6139 - tp: 15864.0000 - fp: 66276.0000 - tn: 158779.0000 - fn: 9955.0000 - accuracy: 0.6961 - precision: 0.1931 - recall: 0.6144 - auc: 0.7294 - val_loss: 0.4444 - val_tp: 1632.0000 - val_fp: 5366.0000 - val_tn: 26904.0000 - val_fn: 2016.0000 - val_accuracy: 0.7945 - val_precision: 0.2332 - val_recall: 0.4474 - val_auc: 0.7516\n",
      "Epoch 12/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6105 - tp: 16061.0000 - fp: 67280.0000 - tn: 157775.0000 - fn: 9758.0000 - accuracy: 0.6929 - precision: 0.1927 - recall: 0.6221 - auc: 0.7313 - val_loss: 0.4387 - val_tp: 1542.0000 - val_fp: 5005.0000 - val_tn: 27265.0000 - val_fn: 2106.0000 - val_accuracy: 0.8020 - val_precision: 0.2355 - val_recall: 0.4227 - val_auc: 0.7517\n",
      "Epoch 13/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6071 - tp: 16153.0000 - fp: 67370.0000 - tn: 157685.0000 - fn: 9666.0000 - accuracy: 0.6929 - precision: 0.1934 - recall: 0.6256 - auc: 0.7335 - val_loss: 0.4410 - val_tp: 1553.0000 - val_fp: 5111.0000 - val_tn: 27159.0000 - val_fn: 2095.0000 - val_accuracy: 0.7994 - val_precision: 0.2330 - val_recall: 0.4257 - val_auc: 0.7525\n",
      "Epoch 14/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6053 - tp: 16388.0000 - fp: 68677.0000 - tn: 156378.0000 - fn: 9431.0000 - accuracy: 0.6887 - precision: 0.1927 - recall: 0.6347 - auc: 0.7348 - val_loss: 0.4348 - val_tp: 1498.0000 - val_fp: 4817.0000 - val_tn: 27453.0000 - val_fn: 2150.0000 - val_accuracy: 0.8060 - val_precision: 0.2372 - val_recall: 0.4106 - val_auc: 0.7523\n",
      "Epoch 15/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6033 - tp: 16523.0000 - fp: 68915.0000 - tn: 156140.0000 - fn: 9296.0000 - accuracy: 0.6882 - precision: 0.1934 - recall: 0.6400 - auc: 0.7357 - val_loss: 0.4356 - val_tp: 1482.0000 - val_fp: 4757.0000 - val_tn: 27513.0000 - val_fn: 2166.0000 - val_accuracy: 0.8073 - val_precision: 0.2375 - val_recall: 0.4062 - val_auc: 0.7528\n",
      "Epoch 16/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5997 - tp: 16665.0000 - fp: 69231.0000 - tn: 155824.0000 - fn: 9154.0000 - accuracy: 0.6876 - precision: 0.1940 - recall: 0.6455 - auc: 0.7387 - val_loss: 0.4369 - val_tp: 1445.0000 - val_fp: 4548.0000 - val_tn: 27722.0000 - val_fn: 2203.0000 - val_accuracy: 0.8120 - val_precision: 0.2411 - val_recall: 0.3961 - val_auc: 0.7526\n",
      "Epoch 17/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5981 - tp: 16879.0000 - fp: 70328.0000 - tn: 154727.0000 - fn: 8940.0000 - accuracy: 0.6840 - precision: 0.1936 - recall: 0.6537 - auc: 0.7401 - val_loss: 0.4426 - val_tp: 1551.0000 - val_fp: 5093.0000 - val_tn: 27177.0000 - val_fn: 2097.0000 - val_accuracy: 0.7998 - val_precision: 0.2334 - val_recall: 0.4252 - val_auc: 0.7530\n",
      "Epoch 18/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5976 - tp: 16970.0000 - fp: 71166.0000 - tn: 153889.0000 - fn: 8849.0000 - accuracy: 0.6811 - precision: 0.1925 - recall: 0.6573 - auc: 0.7398 - val_loss: 0.4334 - val_tp: 1437.0000 - val_fp: 4531.0000 - val_tn: 27739.0000 - val_fn: 2211.0000 - val_accuracy: 0.8123 - val_precision: 0.2408 - val_recall: 0.3939 - val_auc: 0.7525\n",
      "Epoch 19/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5948 - tp: 17234.0000 - fp: 71451.0000 - tn: 153604.0000 - fn: 8585.0000 - accuracy: 0.6810 - precision: 0.1943 - recall: 0.6675 - auc: 0.7431 - val_loss: 0.4342 - val_tp: 1401.0000 - val_fp: 4359.0000 - val_tn: 27911.0000 - val_fn: 2247.0000 - val_accuracy: 0.8161 - val_precision: 0.2432 - val_recall: 0.3840 - val_auc: 0.7531\n",
      "Epoch 20/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5947 - tp: 17233.0000 - fp: 71575.0000 - tn: 153480.0000 - fn: 8586.0000 - accuracy: 0.6805 - precision: 0.1940 - recall: 0.6675 - auc: 0.7424 - val_loss: 0.4395 - val_tp: 1468.0000 - val_fp: 4700.0000 - val_tn: 27570.0000 - val_fn: 2180.0000 - val_accuracy: 0.8085 - val_precision: 0.2380 - val_recall: 0.4024 - val_auc: 0.7525\n",
      "Epoch 21/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5938 - tp: 17453.0000 - fp: 72757.0000 - tn: 152298.0000 - fn: 8366.0000 - accuracy: 0.6766 - precision: 0.1935 - recall: 0.6760 - auc: 0.7432 - val_loss: 0.4409 - val_tp: 1502.0000 - val_fp: 4813.0000 - val_tn: 27457.0000 - val_fn: 2146.0000 - val_accuracy: 0.8063 - val_precision: 0.2378 - val_recall: 0.4117 - val_auc: 0.7519\n",
      "Epoch 22/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5903 - tp: 17685.0000 - fp: 73053.0000 - tn: 152002.0000 - fn: 8134.0000 - accuracy: 0.6764 - precision: 0.1949 - recall: 0.6850 - auc: 0.7468 - val_loss: 0.4323 - val_tp: 1337.0000 - val_fp: 4093.0000 - val_tn: 28177.0000 - val_fn: 2311.0000 - val_accuracy: 0.8217 - val_precision: 0.2462 - val_recall: 0.3665 - val_auc: 0.7523\n",
      "Epoch 23/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5904 - tp: 17764.0000 - fp: 73386.0000 - tn: 151669.0000 - fn: 8055.0000 - accuracy: 0.6754 - precision: 0.1949 - recall: 0.6880 - auc: 0.7466 - val_loss: 0.4351 - val_tp: 1373.0000 - val_fp: 4312.0000 - val_tn: 27958.0000 - val_fn: 2275.0000 - val_accuracy: 0.8166 - val_precision: 0.2415 - val_recall: 0.3764 - val_auc: 0.7509\n",
      "Epoch 24/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5886 - tp: 17899.0000 - fp: 74178.0000 - tn: 150877.0000 - fn: 7920.0000 - accuracy: 0.6728 - precision: 0.1944 - recall: 0.6932 - auc: 0.7481 - val_loss: 0.4316 - val_tp: 1274.0000 - val_fp: 3929.0000 - val_tn: 28341.0000 - val_fn: 2374.0000 - val_accuracy: 0.8245 - val_precision: 0.2449 - val_recall: 0.3492 - val_auc: 0.7514\n",
      "Epoch 25/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5881 - tp: 18041.0000 - fp: 74515.0000 - tn: 150540.0000 - fn: 7778.0000 - accuracy: 0.6720 - precision: 0.1949 - recall: 0.6987 - auc: 0.7487 - val_loss: 0.4296 - val_tp: 1181.0000 - val_fp: 3511.0000 - val_tn: 28759.0000 - val_fn: 2467.0000 - val_accuracy: 0.8336 - val_precision: 0.2517 - val_recall: 0.3237 - val_auc: 0.7505\n",
      "Epoch 26/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5878 - tp: 18108.0000 - fp: 74489.0000 - tn: 150566.0000 - fn: 7711.0000 - accuracy: 0.6723 - precision: 0.1956 - recall: 0.7013 - auc: 0.7493 - val_loss: 0.4340 - val_tp: 1258.0000 - val_fp: 3875.0000 - val_tn: 28395.0000 - val_fn: 2390.0000 - val_accuracy: 0.8256 - val_precision: 0.2451 - val_recall: 0.3448 - val_auc: 0.7498\n",
      "Epoch 27/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5868 - tp: 18277.0000 - fp: 75464.0000 - tn: 149591.0000 - fn: 7542.0000 - accuracy: 0.6691 - precision: 0.1950 - recall: 0.7079 - auc: 0.7502 - val_loss: 0.4280 - val_tp: 1149.0000 - val_fp: 3364.0000 - val_tn: 28906.0000 - val_fn: 2499.0000 - val_accuracy: 0.8368 - val_precision: 0.2546 - val_recall: 0.3150 - val_auc: 0.7499\n",
      "Epoch 28/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5852 - tp: 18418.0000 - fp: 75794.0000 - tn: 149261.0000 - fn: 7401.0000 - accuracy: 0.6684 - precision: 0.1955 - recall: 0.7134 - auc: 0.7519 - val_loss: 0.4335 - val_tp: 1205.0000 - val_fp: 3645.0000 - val_tn: 28625.0000 - val_fn: 2443.0000 - val_accuracy: 0.8305 - val_precision: 0.2485 - val_recall: 0.3303 - val_auc: 0.7481\n",
      "Epoch 29/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5857 - tp: 18412.0000 - fp: 76056.0000 - tn: 148999.0000 - fn: 7407.0000 - accuracy: 0.6673 - precision: 0.1949 - recall: 0.7131 - auc: 0.7515 - val_loss: 0.4292 - val_tp: 1075.0000 - val_fp: 3110.0000 - val_tn: 29160.0000 - val_fn: 2573.0000 - val_accuracy: 0.8418 - val_precision: 0.2569 - val_recall: 0.2947 - val_auc: 0.7488\n",
      "Epoch 1/250\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.7118 - tp: 13961.0000 - fp: 61428.0000 - tn: 195897.0000 - fn: 15506.0000 - accuracy: 0.7317 - precision: 0.1852 - recall: 0.4738 - auc: 0.6837 - val_loss: 0.4474 - val_tp: 1493.0000 - val_fp: 4896.0000 - val_tn: 27374.0000 - val_fn: 2155.0000 - val_accuracy: 0.8037 - val_precision: 0.2337 - val_recall: 0.4093 - val_auc: 0.7484\n",
      "Epoch 2/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6130 - tp: 16002.0000 - fp: 67961.0000 - tn: 157094.0000 - fn: 9817.0000 - accuracy: 0.6900 - precision: 0.1906 - recall: 0.6198 - auc: 0.7277 - val_loss: 0.4693 - val_tp: 1798.0000 - val_fp: 6212.0000 - val_tn: 26058.0000 - val_fn: 1850.0000 - val_accuracy: 0.7755 - val_precision: 0.2245 - val_recall: 0.4929 - val_auc: 0.7506\n",
      "Epoch 3/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5990 - tp: 17495.0000 - fp: 73840.0000 - tn: 151215.0000 - fn: 8324.0000 - accuracy: 0.6725 - precision: 0.1915 - recall: 0.6776 - auc: 0.7379 - val_loss: 0.4766 - val_tp: 1863.0000 - val_fp: 6658.0000 - val_tn: 25612.0000 - val_fn: 1785.0000 - val_accuracy: 0.7649 - val_precision: 0.2186 - val_recall: 0.5107 - val_auc: 0.7482\n",
      "Epoch 4/250\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5950 - tp: 18202.0000 - fp: 76690.0000 - tn: 148365.0000 - fn: 7617.0000 - accuracy: 0.6639 - precision: 0.1918 - recall: 0.7050 - auc: 0.7425 - val_loss: 0.4598 - val_tp: 1634.0000 - val_fp: 5392.0000 - val_tn: 26878.0000 - val_fn: 2014.0000 - val_accuracy: 0.7938 - val_precision: 0.2326 - val_recall: 0.4479 - val_auc: 0.7520\n",
      "Epoch 5/250\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.5910 - tp: 18655.0000 - fp: 78200.0000 - tn: 146855.0000 - fn: 7164.0000 - accuracy: 0.6597 - precision: 0.1926 - recall: 0.7225 - auc: 0.7465 - val_loss: 0.4618 - val_tp: 1715.0000 - val_fp: 5843.0000 - val_tn: 26427.0000 - val_fn: 1933.0000 - val_accuracy: 0.7835 - val_precision: 0.2269 - val_recall: 0.4701 - val_auc: 0.7513\n",
      "Epoch 6/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5897 - tp: 18752.0000 - fp: 78953.0000 - tn: 146102.0000 - fn: 7067.0000 - accuracy: 0.6571 - precision: 0.1919 - recall: 0.7263 - auc: 0.7485 - val_loss: 0.4628 - val_tp: 1686.0000 - val_fp: 5615.0000 - val_tn: 26655.0000 - val_fn: 1962.0000 - val_accuracy: 0.7890 - val_precision: 0.2309 - val_recall: 0.4622 - val_auc: 0.7512\n",
      "Epoch 7/250\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5895 - tp: 18821.0000 - fp: 78966.0000 - tn: 146089.0000 - fn: 6998.0000 - accuracy: 0.6573 - precision: 0.1925 - recall: 0.7290 - auc: 0.7490 - val_loss: 0.4576 - val_tp: 1550.0000 - val_fp: 5097.0000 - val_tn: 27173.0000 - val_fn: 2098.0000 - val_accuracy: 0.7997 - val_precision: 0.2332 - val_recall: 0.4249 - val_auc: 0.7489\n",
      "Epoch 8/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 10ms/step - loss: 0.5882 - tp: 19029.0000 - fp: 79724.0000 - tn: 145331.0000 - fn: 6790.0000 - accuracy: 0.6551 - precision: 0.1927 - recall: 0.7370 - auc: 0.7505 - val_loss: 0.4394 - val_tp: 802.0000 - val_fp: 2021.0000 - val_tn: 30249.0000 - val_fn: 2846.0000 - val_accuracy: 0.8645 - val_precision: 0.2841 - val_recall: 0.2198 - val_auc: 0.7465\n",
      "Epoch 9/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5873 - tp: 18964.0000 - fp: 78281.0000 - tn: 146774.0000 - fn: 6855.0000 - accuracy: 0.6606 - precision: 0.1950 - recall: 0.7345 - auc: 0.7521 - val_loss: 0.4355 - val_tp: 1191.0000 - val_fp: 3555.0000 - val_tn: 28715.0000 - val_fn: 2457.0000 - val_accuracy: 0.8326 - val_precision: 0.2509 - val_recall: 0.3265 - val_auc: 0.7478\n",
      "Epoch 10/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5867 - tp: 18986.0000 - fp: 78648.0000 - tn: 146407.0000 - fn: 6833.0000 - accuracy: 0.6593 - precision: 0.1945 - recall: 0.7353 - auc: 0.7526 - val_loss: 0.4452 - val_tp: 1134.0000 - val_fp: 3320.0000 - val_tn: 28950.0000 - val_fn: 2514.0000 - val_accuracy: 0.8376 - val_precision: 0.2546 - val_recall: 0.3109 - val_auc: 0.7471\n",
      "Epoch 11/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5871 - tp: 19027.0000 - fp: 78004.0000 - tn: 147051.0000 - fn: 6792.0000 - accuracy: 0.6620 - precision: 0.1961 - recall: 0.7369 - auc: 0.7527 - val_loss: 0.4261 - val_tp: 1029.0000 - val_fp: 2929.0000 - val_tn: 29341.0000 - val_fn: 2619.0000 - val_accuracy: 0.8455 - val_precision: 0.2600 - val_recall: 0.2821 - val_auc: 0.7474\n",
      "Epoch 12/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5849 - tp: 19153.0000 - fp: 78948.0000 - tn: 146107.0000 - fn: 6666.0000 - accuracy: 0.6587 - precision: 0.1952 - recall: 0.7418 - auc: 0.7548 - val_loss: 0.4392 - val_tp: 580.0000 - val_fp: 1272.0000 - val_tn: 30998.0000 - val_fn: 3068.0000 - val_accuracy: 0.8792 - val_precision: 0.3132 - val_recall: 0.1590 - val_auc: 0.7475\n",
      "Epoch 13/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5848 - tp: 18969.0000 - fp: 78089.0000 - tn: 146966.0000 - fn: 6850.0000 - accuracy: 0.6614 - precision: 0.1954 - recall: 0.7347 - auc: 0.7543 - val_loss: 0.4249 - val_tp: 998.0000 - val_fp: 2991.0000 - val_tn: 29279.0000 - val_fn: 2650.0000 - val_accuracy: 0.8429 - val_precision: 0.2502 - val_recall: 0.2736 - val_auc: 0.7420\n",
      "Epoch 14/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5854 - tp: 18938.0000 - fp: 77791.0000 - tn: 147264.0000 - fn: 6881.0000 - accuracy: 0.6625 - precision: 0.1958 - recall: 0.7335 - auc: 0.7541 - val_loss: 0.4185 - val_tp: 385.0000 - val_fp: 778.0000 - val_tn: 31492.0000 - val_fn: 3263.0000 - val_accuracy: 0.8875 - val_precision: 0.3310 - val_recall: 0.1055 - val_auc: 0.7411\n",
      "Epoch 1/250\n",
      "126/126 [==============================] - 2s 17ms/step - loss: 0.6923 - tp: 16476.0000 - fp: 79873.0000 - tn: 177452.0000 - fn: 12991.0000 - accuracy: 0.6762 - precision: 0.1710 - recall: 0.5591 - auc: 0.6786 - val_loss: 0.5968 - val_tp: 2721.0000 - val_fp: 12002.0000 - val_tn: 20268.0000 - val_fn: 927.0000 - val_accuracy: 0.6400 - val_precision: 0.1848 - val_recall: 0.7459 - val_auc: 0.7426\n",
      "Epoch 2/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6120 - tp: 18234.0000 - fp: 83130.0000 - tn: 141925.0000 - fn: 7585.0000 - accuracy: 0.6384 - precision: 0.1799 - recall: 0.7062 - auc: 0.7256 - val_loss: 0.5344 - val_tp: 2218.0000 - val_fp: 8560.0000 - val_tn: 23710.0000 - val_fn: 1430.0000 - val_accuracy: 0.7219 - val_precision: 0.2058 - val_recall: 0.6080 - val_auc: 0.7455\n",
      "Epoch 3/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6124 - tp: 17942.0000 - fp: 80128.0000 - tn: 144927.0000 - fn: 7877.0000 - accuracy: 0.6492 - precision: 0.1830 - recall: 0.6949 - auc: 0.7271 - val_loss: 0.4889 - val_tp: 1763.0000 - val_fp: 6421.0000 - val_tn: 25849.0000 - val_fn: 1885.0000 - val_accuracy: 0.7688 - val_precision: 0.2154 - val_recall: 0.4833 - val_auc: 0.7408\n",
      "Epoch 4/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6129 - tp: 17868.0000 - fp: 78579.0000 - tn: 146476.0000 - fn: 7951.0000 - accuracy: 0.6551 - precision: 0.1853 - recall: 0.6920 - auc: 0.7295 - val_loss: 0.4544 - val_tp: 1561.0000 - val_fp: 5274.0000 - val_tn: 26996.0000 - val_fn: 2087.0000 - val_accuracy: 0.7951 - val_precision: 0.2284 - val_recall: 0.4279 - val_auc: 0.7418\n",
      "Epoch 5/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6161 - tp: 17338.0000 - fp: 75963.0000 - tn: 149092.0000 - fn: 8481.0000 - accuracy: 0.6634 - precision: 0.1858 - recall: 0.6715 - auc: 0.7259 - val_loss: 0.5427 - val_tp: 2146.0000 - val_fp: 8744.0000 - val_tn: 23526.0000 - val_fn: 1502.0000 - val_accuracy: 0.7147 - val_precision: 0.1971 - val_recall: 0.5883 - val_auc: 0.7348\n",
      "Epoch 6/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6199 - tp: 17336.0000 - fp: 76248.0000 - tn: 148807.0000 - fn: 8483.0000 - accuracy: 0.6623 - precision: 0.1852 - recall: 0.6714 - auc: 0.7241 - val_loss: 0.4832 - val_tp: 1913.0000 - val_fp: 7366.0000 - val_tn: 24904.0000 - val_fn: 1735.0000 - val_accuracy: 0.7466 - val_precision: 0.2062 - val_recall: 0.5244 - val_auc: 0.7343\n",
      "Epoch 7/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6184 - tp: 17118.0000 - fp: 74929.0000 - tn: 150126.0000 - fn: 8701.0000 - accuracy: 0.6666 - precision: 0.1860 - recall: 0.6630 - auc: 0.7251 - val_loss: 0.4742 - val_tp: 1567.0000 - val_fp: 5231.0000 - val_tn: 27039.0000 - val_fn: 2081.0000 - val_accuracy: 0.7964 - val_precision: 0.2305 - val_recall: 0.4296 - val_auc: 0.7369\n",
      "Epoch 8/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6200 - tp: 16549.0000 - fp: 70421.0000 - tn: 154634.0000 - fn: 9270.0000 - accuracy: 0.6823 - precision: 0.1903 - recall: 0.6410 - auc: 0.7242 - val_loss: 0.4810 - val_tp: 1501.0000 - val_fp: 5136.0000 - val_tn: 27134.0000 - val_fn: 2147.0000 - val_accuracy: 0.7972 - val_precision: 0.2262 - val_recall: 0.4115 - val_auc: 0.7369\n",
      "Epoch 9/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6170 - tp: 16892.0000 - fp: 71694.0000 - tn: 153361.0000 - fn: 8927.0000 - accuracy: 0.6786 - precision: 0.1907 - recall: 0.6542 - auc: 0.7278 - val_loss: 0.5096 - val_tp: 979.0000 - val_fp: 4219.0000 - val_tn: 28051.0000 - val_fn: 2669.0000 - val_accuracy: 0.8082 - val_precision: 0.1883 - val_recall: 0.2684 - val_auc: 0.7048\n",
      "Epoch 10/250\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6168 - tp: 16851.0000 - fp: 71040.0000 - tn: 154015.0000 - fn: 8968.0000 - accuracy: 0.6811 - precision: 0.1917 - recall: 0.6527 - auc: 0.7285 - val_loss: 0.4606 - val_tp: 1142.0000 - val_fp: 3506.0000 - val_tn: 28764.0000 - val_fn: 2506.0000 - val_accuracy: 0.8326 - val_precision: 0.2457 - val_recall: 0.3130 - val_auc: 0.7356\n",
      "Epoch 11/250\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6204 - tp: 16308.0000 - fp: 68614.0000 - tn: 156441.0000 - fn: 9511.0000 - accuracy: 0.6886 - precision: 0.1920 - recall: 0.6316 - auc: 0.7247 - val_loss: 0.4908 - val_tp: 1358.0000 - val_fp: 4554.0000 - val_tn: 27716.0000 - val_fn: 2290.0000 - val_accuracy: 0.8095 - val_precision: 0.2297 - val_recall: 0.3723 - val_auc: 0.7367\n",
      "Epoch 12/250\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6190 - tp: 16371.0000 - fp: 68365.0000 - tn: 156690.0000 - fn: 9448.0000 - accuracy: 0.6898 - precision: 0.1932 - recall: 0.6341 - auc: 0.7263 - val_loss: 0.4545 - val_tp: 681.0000 - val_fp: 1869.0000 - val_tn: 30401.0000 - val_fn: 2967.0000 - val_accuracy: 0.8654 - val_precision: 0.2671 - val_recall: 0.1867 - val_auc: 0.7319\n",
      "Epoch 1/250\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 4.7881 - tp: 20726.0000 - fp: 135892.0000 - tn: 121433.0000 - fn: 8741.0000 - accuracy: 0.4957 - precision: 0.1323 - recall: 0.7034 - auc: 0.5952 - val_loss: 0.6559 - val_tp: 3276.0000 - val_fp: 20658.0000 - val_tn: 11612.0000 - val_fn: 372.0000 - val_accuracy: 0.4145 - val_precision: 0.1369 - val_recall: 0.8980 - val_auc: 0.6112\n",
      "Epoch 2/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7155 - tp: 23188.0000 - fp: 154957.0000 - tn: 70098.0000 - fn: 2631.0000 - accuracy: 0.3718 - precision: 0.1302 - recall: 0.8981 - auc: 0.6051 - val_loss: 0.5779 - val_tp: 3135.0000 - val_fp: 18328.0000 - val_tn: 13942.0000 - val_fn: 513.0000 - val_accuracy: 0.4754 - val_precision: 0.1461 - val_recall: 0.8594 - val_auc: 0.6654\n",
      "Epoch 3/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6796 - tp: 23598.0000 - fp: 159733.0000 - tn: 65322.0000 - fn: 2221.0000 - accuracy: 0.3544 - precision: 0.1287 - recall: 0.9140 - auc: 0.6073 - val_loss: 0.6793 - val_tp: 3288.0000 - val_fp: 20579.0000 - val_tn: 11691.0000 - val_fn: 360.0000 - val_accuracy: 0.4170 - val_precision: 0.1378 - val_recall: 0.9013 - val_auc: 0.6734\n",
      "Epoch 4/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6729 - tp: 23864.0000 - fp: 159392.0000 - tn: 65663.0000 - fn: 1955.0000 - accuracy: 0.3569 - precision: 0.1302 - recall: 0.9243 - auc: 0.6108 - val_loss: 0.5886 - val_tp: 3182.0000 - val_fp: 18423.0000 - val_tn: 13847.0000 - val_fn: 466.0000 - val_accuracy: 0.4741 - val_precision: 0.1473 - val_recall: 0.8723 - val_auc: 0.6828\n",
      "Epoch 5/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7049 - tp: 23433.0000 - fp: 160498.0000 - tn: 64557.0000 - fn: 2386.0000 - accuracy: 0.3507 - precision: 0.1274 - recall: 0.9076 - auc: 0.5974 - val_loss: 0.5909 - val_tp: 3156.0000 - val_fp: 19150.0000 - val_tn: 13120.0000 - val_fn: 492.0000 - val_accuracy: 0.4531 - val_precision: 0.1415 - val_recall: 0.8651 - val_auc: 0.6573\n",
      "Epoch 6/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6936 - tp: 22914.0000 - fp: 159709.0000 - tn: 65346.0000 - fn: 2905.0000 - accuracy: 0.3518 - precision: 0.1255 - recall: 0.8875 - auc: 0.5923 - val_loss: 0.6680 - val_tp: 3253.0000 - val_fp: 20555.0000 - val_tn: 11715.0000 - val_fn: 395.0000 - val_accuracy: 0.4167 - val_precision: 0.1366 - val_recall: 0.8917 - val_auc: 0.6525\n",
      "Epoch 7/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6872 - tp: 23329.0000 - fp: 163730.0000 - tn: 61325.0000 - fn: 2490.0000 - accuracy: 0.3374 - precision: 0.1247 - recall: 0.9036 - auc: 0.5916 - val_loss: 0.6356 - val_tp: 3260.0000 - val_fp: 21095.0000 - val_tn: 11175.0000 - val_fn: 388.0000 - val_accuracy: 0.4019 - val_precision: 0.1339 - val_recall: 0.8936 - val_auc: 0.6275\n",
      "Epoch 8/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7004 - tp: 22588.0000 - fp: 158478.0000 - tn: 66577.0000 - fn: 3231.0000 - accuracy: 0.3554 - precision: 0.1248 - recall: 0.8749 - auc: 0.5922 - val_loss: 0.5988 - val_tp: 3149.0000 - val_fp: 19716.0000 - val_tn: 12554.0000 - val_fn: 499.0000 - val_accuracy: 0.4372 - val_precision: 0.1377 - val_recall: 0.8632 - val_auc: 0.6506\n",
      "Epoch 9/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6956 - tp: 22429.0000 - fp: 160904.0000 - tn: 64151.0000 - fn: 3390.0000 - accuracy: 0.3451 - precision: 0.1223 - recall: 0.8687 - auc: 0.5837 - val_loss: 0.6199 - val_tp: 3230.0000 - val_fp: 20665.0000 - val_tn: 11605.0000 - val_fn: 418.0000 - val_accuracy: 0.4130 - val_precision: 0.1352 - val_recall: 0.8854 - val_auc: 0.6243\n",
      "Epoch 10/250\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7702 - tp: 21264.0000 - fp: 157245.0000 - tn: 67810.0000 - fn: 4555.0000 - accuracy: 0.3551 - precision: 0.1191 - recall: 0.8236 - auc: 0.5674 - val_loss: 0.6668 - val_tp: 3172.0000 - val_fp: 20852.0000 - val_tn: 11418.0000 - val_fn: 476.0000 - val_accuracy: 0.4062 - val_precision: 0.1320 - val_recall: 0.8695 - val_auc: 0.6091\n",
      "Epoch 11/250\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 3.0438 - tp: 20128.0000 - fp: 152564.0000 - tn: 72491.0000 - fn: 5691.0000 - accuracy: 0.3692 - precision: 0.1166 - recall: 0.7796 - auc: 0.5557 - val_loss: 1.7766 - val_tp: 3292.0000 - val_fp: 25230.0000 - val_tn: 7040.0000 - val_fn: 356.0000 - val_accuracy: 0.2877 - val_precision: 0.1154 - val_recall: 0.9024 - val_auc: 0.5317\n",
      "Epoch 12/250\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.1761 - tp: 16421.0000 - fp: 134062.0000 - tn: 90993.0000 - fn: 9398.0000 - accuracy: 0.4282 - precision: 0.1091 - recall: 0.6360 - auc: 0.5285 - val_loss: 0.7131 - val_tp: 3597.0000 - val_fp: 29782.0000 - val_tn: 2488.0000 - val_fn: 51.0000 - val_accuracy: 0.1694 - val_precision: 0.1078 - val_recall: 0.9860 - val_auc: 0.5330\n",
      "Epoch 13/250\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7170 - tp: 14637.0000 - fp: 124610.0000 - tn: 100445.0000 - fn: 11182.0000 - accuracy: 0.4587 - precision: 0.1051 - recall: 0.5669 - auc: 0.5100 - val_loss: 0.5775 - val_tp: 2.0000 - val_fp: 21.0000 - val_tn: 32249.0000 - val_fn: 3646.0000 - val_accuracy: 0.8979 - val_precision: 0.0870 - val_recall: 5.4825e-04 - val_auc: 0.5411\n",
      "Epoch 14/250\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7046 - tp: 13967.0000 - fp: 119163.0000 - tn: 105892.0000 - fn: 11852.0000 - accuracy: 0.4778 - precision: 0.1049 - recall: 0.5410 - auc: 0.5099 - val_loss: 0.6602 - val_tp: 3609.0000 - val_fp: 29583.0000 - val_tn: 2687.0000 - val_fn: 39.0000 - val_accuracy: 0.1753 - val_precision: 0.1087 - val_recall: 0.9893 - val_auc: 0.5336\n",
      "Epoch 1/500\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 0.9827 - tp: 11077.0000 - fp: 66660.0000 - tn: 190665.0000 - fn: 18390.0000 - accuracy: 0.7034 - precision: 0.1425 - recall: 0.3759 - auc: 0.6069 - val_loss: 0.4430 - val_tp: 1302.0000 - val_fp: 5322.0000 - val_tn: 26948.0000 - val_fn: 2346.0000 - val_accuracy: 0.7865 - val_precision: 0.1966 - val_recall: 0.3569 - val_auc: 0.6808\n",
      "Epoch 2/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7725 - tp: 10583.0000 - fp: 51670.0000 - tn: 173385.0000 - fn: 15236.0000 - accuracy: 0.7333 - precision: 0.1700 - recall: 0.4099 - auc: 0.6496 - val_loss: 0.4490 - val_tp: 1456.0000 - val_fp: 5467.0000 - val_tn: 26803.0000 - val_fn: 2192.0000 - val_accuracy: 0.7868 - val_precision: 0.2103 - val_recall: 0.3991 - val_auc: 0.7150\n",
      "Epoch 3/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7101 - tp: 12041.0000 - fp: 55943.0000 - tn: 169112.0000 - fn: 13778.0000 - accuracy: 0.7221 - precision: 0.1771 - recall: 0.4664 - auc: 0.6744 - val_loss: 0.4483 - val_tp: 1554.0000 - val_fp: 5612.0000 - val_tn: 26658.0000 - val_fn: 2094.0000 - val_accuracy: 0.7855 - val_precision: 0.2169 - val_recall: 0.4260 - val_auc: 0.7319\n",
      "Epoch 4/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6807 - tp: 12954.0000 - fp: 57128.0000 - tn: 167927.0000 - fn: 12865.0000 - accuracy: 0.7210 - precision: 0.1848 - recall: 0.5017 - auc: 0.6917 - val_loss: 0.4421 - val_tp: 1550.0000 - val_fp: 5376.0000 - val_tn: 26894.0000 - val_fn: 2098.0000 - val_accuracy: 0.7919 - val_precision: 0.2238 - val_recall: 0.4249 - val_auc: 0.7404\n",
      "Epoch 5/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6618 - tp: 13598.0000 - fp: 59159.0000 - tn: 165896.0000 - fn: 12221.0000 - accuracy: 0.7155 - precision: 0.1869 - recall: 0.5267 - auc: 0.7025 - val_loss: 0.4405 - val_tp: 1535.0000 - val_fp: 5191.0000 - val_tn: 27079.0000 - val_fn: 2113.0000 - val_accuracy: 0.7966 - val_precision: 0.2282 - val_recall: 0.4208 - val_auc: 0.7450\n",
      "Epoch 6/500\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6524 - tp: 13947.0000 - fp: 60155.0000 - tn: 164900.0000 - fn: 11872.0000 - accuracy: 0.7129 - precision: 0.1882 - recall: 0.5402 - auc: 0.7072 - val_loss: 0.4353 - val_tp: 1499.0000 - val_fp: 4913.0000 - val_tn: 27357.0000 - val_fn: 2149.0000 - val_accuracy: 0.8034 - val_precision: 0.2338 - val_recall: 0.4109 - val_auc: 0.7480\n",
      "Epoch 7/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6396 - tp: 14421.0000 - fp: 61184.0000 - tn: 163871.0000 - fn: 11398.0000 - accuracy: 0.7107 - precision: 0.1907 - recall: 0.5585 - auc: 0.7158 - val_loss: 0.4482 - val_tp: 1677.0000 - val_fp: 5658.0000 - val_tn: 26612.0000 - val_fn: 1971.0000 - val_accuracy: 0.7876 - val_precision: 0.2286 - val_recall: 0.4597 - val_auc: 0.7492\n",
      "Epoch 8/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6302 - tp: 15110.0000 - fp: 63807.0000 - tn: 161248.0000 - fn: 10709.0000 - accuracy: 0.7030 - precision: 0.1915 - recall: 0.5852 - auc: 0.7195 - val_loss: 0.4420 - val_tp: 1604.0000 - val_fp: 5354.0000 - val_tn: 26916.0000 - val_fn: 2044.0000 - val_accuracy: 0.7940 - val_precision: 0.2305 - val_recall: 0.4397 - val_auc: 0.7499\n",
      "Epoch 9/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6251 - tp: 15236.0000 - fp: 64686.0000 - tn: 160369.0000 - fn: 10583.0000 - accuracy: 0.7000 - precision: 0.1906 - recall: 0.5901 - auc: 0.7218 - val_loss: 0.4510 - val_tp: 1679.0000 - val_fp: 5710.0000 - val_tn: 26560.0000 - val_fn: 1969.0000 - val_accuracy: 0.7862 - val_precision: 0.2272 - val_recall: 0.4603 - val_auc: 0.7506\n",
      "Epoch 10/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6183 - tp: 15575.0000 - fp: 65531.0000 - tn: 159524.0000 - fn: 10244.0000 - accuracy: 0.6980 - precision: 0.1920 - recall: 0.6032 - auc: 0.7261 - val_loss: 0.4459 - val_tp: 1613.0000 - val_fp: 5383.0000 - val_tn: 26887.0000 - val_fn: 2035.0000 - val_accuracy: 0.7935 - val_precision: 0.2306 - val_recall: 0.4422 - val_auc: 0.7516\n",
      "Epoch 11/500\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6117 - tp: 15960.0000 - fp: 66270.0000 - tn: 158785.0000 - fn: 9859.0000 - accuracy: 0.6965 - precision: 0.1941 - recall: 0.6181 - auc: 0.7312 - val_loss: 0.4444 - val_tp: 1598.0000 - val_fp: 5312.0000 - val_tn: 26958.0000 - val_fn: 2050.0000 - val_accuracy: 0.7950 - val_precision: 0.2313 - val_recall: 0.4380 - val_auc: 0.7523\n",
      "Epoch 12/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6112 - tp: 15959.0000 - fp: 66810.0000 - tn: 158245.0000 - fn: 9860.0000 - accuracy: 0.6944 - precision: 0.1928 - recall: 0.6181 - auc: 0.7313 - val_loss: 0.4432 - val_tp: 1597.0000 - val_fp: 5301.0000 - val_tn: 26969.0000 - val_fn: 2051.0000 - val_accuracy: 0.7953 - val_precision: 0.2315 - val_recall: 0.4378 - val_auc: 0.7519\n",
      "Epoch 13/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6088 - tp: 16074.0000 - fp: 67394.0000 - tn: 157661.0000 - fn: 9745.0000 - accuracy: 0.6925 - precision: 0.1926 - recall: 0.6226 - auc: 0.7321 - val_loss: 0.4358 - val_tp: 1522.0000 - val_fp: 4927.0000 - val_tn: 27343.0000 - val_fn: 2126.0000 - val_accuracy: 0.8036 - val_precision: 0.2360 - val_recall: 0.4172 - val_auc: 0.7527\n",
      "Epoch 14/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6047 - tp: 16341.0000 - fp: 68297.0000 - tn: 156758.0000 - fn: 9478.0000 - accuracy: 0.6900 - precision: 0.1931 - recall: 0.6329 - auc: 0.7351 - val_loss: 0.4398 - val_tp: 1567.0000 - val_fp: 5129.0000 - val_tn: 27141.0000 - val_fn: 2081.0000 - val_accuracy: 0.7993 - val_precision: 0.2340 - val_recall: 0.4296 - val_auc: 0.7531\n",
      "Epoch 15/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6022 - tp: 16544.0000 - fp: 68704.0000 - tn: 156351.0000 - fn: 9275.0000 - accuracy: 0.6892 - precision: 0.1941 - recall: 0.6408 - auc: 0.7373 - val_loss: 0.4388 - val_tp: 1555.0000 - val_fp: 5130.0000 - val_tn: 27140.0000 - val_fn: 2093.0000 - val_accuracy: 0.7989 - val_precision: 0.2326 - val_recall: 0.4263 - val_auc: 0.7528\n",
      "Epoch 16/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6008 - tp: 16733.0000 - fp: 69284.0000 - tn: 155771.0000 - fn: 9086.0000 - accuracy: 0.6876 - precision: 0.1945 - recall: 0.6481 - auc: 0.7382 - val_loss: 0.4389 - val_tp: 1522.0000 - val_fp: 4915.0000 - val_tn: 27355.0000 - val_fn: 2126.0000 - val_accuracy: 0.8040 - val_precision: 0.2364 - val_recall: 0.4172 - val_auc: 0.7533\n",
      "Epoch 17/500\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.5975 - tp: 16893.0000 - fp: 70328.0000 - tn: 154727.0000 - fn: 8926.0000 - accuracy: 0.6841 - precision: 0.1937 - recall: 0.6543 - auc: 0.7403 - val_loss: 0.4448 - val_tp: 1585.0000 - val_fp: 5308.0000 - val_tn: 26962.0000 - val_fn: 2063.0000 - val_accuracy: 0.7948 - val_precision: 0.2299 - val_recall: 0.4345 - val_auc: 0.7522\n",
      "Epoch 18/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5989 - tp: 16895.0000 - fp: 71007.0000 - tn: 154048.0000 - fn: 8924.0000 - accuracy: 0.6814 - precision: 0.1922 - recall: 0.6544 - auc: 0.7386 - val_loss: 0.4312 - val_tp: 1329.0000 - val_fp: 4139.0000 - val_tn: 28131.0000 - val_fn: 2319.0000 - val_accuracy: 0.8202 - val_precision: 0.2431 - val_recall: 0.3643 - val_auc: 0.7533\n",
      "Epoch 19/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5957 - tp: 17114.0000 - fp: 71173.0000 - tn: 153882.0000 - fn: 8705.0000 - accuracy: 0.6816 - precision: 0.1938 - recall: 0.6628 - auc: 0.7413 - val_loss: 0.4365 - val_tp: 1453.0000 - val_fp: 4599.0000 - val_tn: 27671.0000 - val_fn: 2195.0000 - val_accuracy: 0.8108 - val_precision: 0.2401 - val_recall: 0.3983 - val_auc: 0.7535\n",
      "Epoch 20/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5933 - tp: 17340.0000 - fp: 72029.0000 - tn: 153026.0000 - fn: 8479.0000 - accuracy: 0.6791 - precision: 0.1940 - recall: 0.6716 - auc: 0.7437 - val_loss: 0.4405 - val_tp: 1514.0000 - val_fp: 4899.0000 - val_tn: 27371.0000 - val_fn: 2134.0000 - val_accuracy: 0.8042 - val_precision: 0.2361 - val_recall: 0.4150 - val_auc: 0.7531\n",
      "Epoch 21/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5923 - tp: 17528.0000 - fp: 72475.0000 - tn: 152580.0000 - fn: 8291.0000 - accuracy: 0.6781 - precision: 0.1947 - recall: 0.6789 - auc: 0.7450 - val_loss: 0.4340 - val_tp: 1348.0000 - val_fp: 4183.0000 - val_tn: 28087.0000 - val_fn: 2300.0000 - val_accuracy: 0.8195 - val_precision: 0.2437 - val_recall: 0.3695 - val_auc: 0.7528\n",
      "Epoch 22/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5917 - tp: 17579.0000 - fp: 73432.0000 - tn: 151623.0000 - fn: 8240.0000 - accuracy: 0.6745 - precision: 0.1932 - recall: 0.6809 - auc: 0.7444 - val_loss: 0.4366 - val_tp: 1414.0000 - val_fp: 4427.0000 - val_tn: 27843.0000 - val_fn: 2234.0000 - val_accuracy: 0.8145 - val_precision: 0.2421 - val_recall: 0.3876 - val_auc: 0.7527\n",
      "Epoch 23/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5902 - tp: 17784.0000 - fp: 73976.0000 - tn: 151079.0000 - fn: 8035.0000 - accuracy: 0.6731 - precision: 0.1938 - recall: 0.6888 - auc: 0.7465 - val_loss: 0.4335 - val_tp: 1382.0000 - val_fp: 4313.0000 - val_tn: 27957.0000 - val_fn: 2266.0000 - val_accuracy: 0.8168 - val_precision: 0.2427 - val_recall: 0.3788 - val_auc: 0.7514\n",
      "Epoch 24/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5881 - tp: 17905.0000 - fp: 73990.0000 - tn: 151065.0000 - fn: 7914.0000 - accuracy: 0.6735 - precision: 0.1948 - recall: 0.6935 - auc: 0.7483 - val_loss: 0.4288 - val_tp: 1255.0000 - val_fp: 3831.0000 - val_tn: 28439.0000 - val_fn: 2393.0000 - val_accuracy: 0.8267 - val_precision: 0.2468 - val_recall: 0.3440 - val_auc: 0.7517\n",
      "Epoch 25/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5884 - tp: 18029.0000 - fp: 74442.0000 - tn: 150613.0000 - fn: 7790.0000 - accuracy: 0.6722 - precision: 0.1950 - recall: 0.6983 - auc: 0.7482 - val_loss: 0.4296 - val_tp: 1255.0000 - val_fp: 3786.0000 - val_tn: 28484.0000 - val_fn: 2393.0000 - val_accuracy: 0.8280 - val_precision: 0.2490 - val_recall: 0.3440 - val_auc: 0.7510\n",
      "Epoch 26/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5869 - tp: 18208.0000 - fp: 74968.0000 - tn: 150087.0000 - fn: 7611.0000 - accuracy: 0.6708 - precision: 0.1954 - recall: 0.7052 - auc: 0.7502 - val_loss: 0.4316 - val_tp: 1237.0000 - val_fp: 3728.0000 - val_tn: 28542.0000 - val_fn: 2411.0000 - val_accuracy: 0.8291 - val_precision: 0.2491 - val_recall: 0.3391 - val_auc: 0.7505\n",
      "Epoch 27/500\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5859 - tp: 18330.0000 - fp: 75488.0000 - tn: 149567.0000 - fn: 7489.0000 - accuracy: 0.6692 - precision: 0.1954 - recall: 0.7099 - auc: 0.7512 - val_loss: 0.4344 - val_tp: 1291.0000 - val_fp: 3944.0000 - val_tn: 28326.0000 - val_fn: 2357.0000 - val_accuracy: 0.8246 - val_precision: 0.2466 - val_recall: 0.3539 - val_auc: 0.7499\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5854 - tp: 18430.0000 - fp: 76100.0000 - tn: 148955.0000 - fn: 7389.0000 - accuracy: 0.6672 - precision: 0.1950 - recall: 0.7138 - auc: 0.7519 - val_loss: 0.4270 - val_tp: 1116.0000 - val_fp: 3232.0000 - val_tn: 29038.0000 - val_fn: 2532.0000 - val_accuracy: 0.8395 - val_precision: 0.2567 - val_recall: 0.3059 - val_auc: 0.7494\n",
      "Epoch 29/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5848 - tp: 18493.0000 - fp: 75875.0000 - tn: 149180.0000 - fn: 7326.0000 - accuracy: 0.6684 - precision: 0.1960 - recall: 0.7163 - auc: 0.7525 - val_loss: 0.4277 - val_tp: 1060.0000 - val_fp: 2990.0000 - val_tn: 29280.0000 - val_fn: 2588.0000 - val_accuracy: 0.8447 - val_precision: 0.2617 - val_recall: 0.2906 - val_auc: 0.7482\n",
      "Epoch 1/500\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.7148 - tp: 13881.0000 - fp: 61646.0000 - tn: 195679.0000 - fn: 15586.0000 - accuracy: 0.7307 - precision: 0.1838 - recall: 0.4711 - auc: 0.6801 - val_loss: 0.4744 - val_tp: 1844.0000 - val_fp: 6648.0000 - val_tn: 25622.0000 - val_fn: 1804.0000 - val_accuracy: 0.7647 - val_precision: 0.2171 - val_recall: 0.5055 - val_auc: 0.7453\n",
      "Epoch 2/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6125 - tp: 16070.0000 - fp: 67893.0000 - tn: 157162.0000 - fn: 9749.0000 - accuracy: 0.6905 - precision: 0.1914 - recall: 0.6224 - auc: 0.7278 - val_loss: 0.4596 - val_tp: 1683.0000 - val_fp: 5686.0000 - val_tn: 26584.0000 - val_fn: 1965.0000 - val_accuracy: 0.7870 - val_precision: 0.2284 - val_recall: 0.4613 - val_auc: 0.7514\n",
      "Epoch 3/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5992 - tp: 17333.0000 - fp: 73356.0000 - tn: 151699.0000 - fn: 8486.0000 - accuracy: 0.6738 - precision: 0.1911 - recall: 0.6713 - auc: 0.7376 - val_loss: 0.4624 - val_tp: 1718.0000 - val_fp: 5715.0000 - val_tn: 26555.0000 - val_fn: 1930.0000 - val_accuracy: 0.7872 - val_precision: 0.2311 - val_recall: 0.4709 - val_auc: 0.7527\n",
      "Epoch 4/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5944 - tp: 18184.0000 - fp: 77294.0000 - tn: 147761.0000 - fn: 7635.0000 - accuracy: 0.6615 - precision: 0.1905 - recall: 0.7043 - auc: 0.7427 - val_loss: 0.4778 - val_tp: 1925.0000 - val_fp: 6858.0000 - val_tn: 25412.0000 - val_fn: 1723.0000 - val_accuracy: 0.7611 - val_precision: 0.2192 - val_recall: 0.5277 - val_auc: 0.7500\n",
      "Epoch 5/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5919 - tp: 18559.0000 - fp: 78510.0000 - tn: 146545.0000 - fn: 7260.0000 - accuracy: 0.6581 - precision: 0.1912 - recall: 0.7188 - auc: 0.7452 - val_loss: 0.4875 - val_tp: 1961.0000 - val_fp: 7013.0000 - val_tn: 25257.0000 - val_fn: 1687.0000 - val_accuracy: 0.7578 - val_precision: 0.2185 - val_recall: 0.5376 - val_auc: 0.7525\n",
      "Epoch 6/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5904 - tp: 18913.0000 - fp: 79932.0000 - tn: 145123.0000 - fn: 6906.0000 - accuracy: 0.6539 - precision: 0.1913 - recall: 0.7325 - auc: 0.7478 - val_loss: 0.4575 - val_tp: 1359.0000 - val_fp: 4242.0000 - val_tn: 28028.0000 - val_fn: 2289.0000 - val_accuracy: 0.8182 - val_precision: 0.2426 - val_recall: 0.3725 - val_auc: 0.7491\n",
      "Epoch 7/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5897 - tp: 18785.0000 - fp: 78675.0000 - tn: 146380.0000 - fn: 7034.0000 - accuracy: 0.6584 - precision: 0.1927 - recall: 0.7276 - auc: 0.7492 - val_loss: 0.4607 - val_tp: 1618.0000 - val_fp: 5355.0000 - val_tn: 26915.0000 - val_fn: 2030.0000 - val_accuracy: 0.7944 - val_precision: 0.2320 - val_recall: 0.4435 - val_auc: 0.7500\n",
      "Epoch 8/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5873 - tp: 18995.0000 - fp: 79048.0000 - tn: 146007.0000 - fn: 6824.0000 - accuracy: 0.6577 - precision: 0.1937 - recall: 0.7357 - auc: 0.7515 - val_loss: 0.4607 - val_tp: 1492.0000 - val_fp: 4807.0000 - val_tn: 27463.0000 - val_fn: 2156.0000 - val_accuracy: 0.8061 - val_precision: 0.2369 - val_recall: 0.4090 - val_auc: 0.7480\n",
      "Epoch 9/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5865 - tp: 18987.0000 - fp: 78718.0000 - tn: 146337.0000 - fn: 6832.0000 - accuracy: 0.6590 - precision: 0.1943 - recall: 0.7354 - auc: 0.7521 - val_loss: 0.4429 - val_tp: 1171.0000 - val_fp: 3531.0000 - val_tn: 28739.0000 - val_fn: 2477.0000 - val_accuracy: 0.8327 - val_precision: 0.2490 - val_recall: 0.3210 - val_auc: 0.7471\n",
      "Epoch 10/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5874 - tp: 19008.0000 - fp: 79297.0000 - tn: 145758.0000 - fn: 6811.0000 - accuracy: 0.6568 - precision: 0.1934 - recall: 0.7362 - auc: 0.7519 - val_loss: 0.4521 - val_tp: 925.0000 - val_fp: 2470.0000 - val_tn: 29800.0000 - val_fn: 2723.0000 - val_accuracy: 0.8554 - val_precision: 0.2725 - val_recall: 0.2536 - val_auc: 0.7482\n",
      "Epoch 11/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5866 - tp: 18995.0000 - fp: 78534.0000 - tn: 146521.0000 - fn: 6824.0000 - accuracy: 0.6598 - precision: 0.1948 - recall: 0.7357 - auc: 0.7527 - val_loss: 0.4412 - val_tp: 1157.0000 - val_fp: 3438.0000 - val_tn: 28832.0000 - val_fn: 2491.0000 - val_accuracy: 0.8349 - val_precision: 0.2518 - val_recall: 0.3172 - val_auc: 0.7457\n",
      "Epoch 12/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5862 - tp: 18882.0000 - fp: 78054.0000 - tn: 147001.0000 - fn: 6937.0000 - accuracy: 0.6612 - precision: 0.1948 - recall: 0.7313 - auc: 0.7530 - val_loss: 0.4254 - val_tp: 765.0000 - val_fp: 1935.0000 - val_tn: 30335.0000 - val_fn: 2883.0000 - val_accuracy: 0.8659 - val_precision: 0.2833 - val_recall: 0.2097 - val_auc: 0.7452\n",
      "Epoch 13/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5850 - tp: 19078.0000 - fp: 78933.0000 - tn: 146122.0000 - fn: 6741.0000 - accuracy: 0.6585 - precision: 0.1947 - recall: 0.7389 - auc: 0.7541 - val_loss: 0.4336 - val_tp: 638.0000 - val_fp: 1547.0000 - val_tn: 30723.0000 - val_fn: 3010.0000 - val_accuracy: 0.8731 - val_precision: 0.2920 - val_recall: 0.1749 - val_auc: 0.7430\n",
      "Epoch 1/500\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.6938 - tp: 16255.0000 - fp: 77479.0000 - tn: 179846.0000 - fn: 13212.0000 - accuracy: 0.6838 - precision: 0.1734 - recall: 0.5516 - auc: 0.6784 - val_loss: 0.5299 - val_tp: 2235.0000 - val_fp: 8842.0000 - val_tn: 23428.0000 - val_fn: 1413.0000 - val_accuracy: 0.7145 - val_precision: 0.2018 - val_recall: 0.6127 - val_auc: 0.7431\n",
      "Epoch 2/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6115 - tp: 18247.0000 - fp: 82262.0000 - tn: 142793.0000 - fn: 7572.0000 - accuracy: 0.6419 - precision: 0.1815 - recall: 0.7067 - auc: 0.7270 - val_loss: 0.4651 - val_tp: 1310.0000 - val_fp: 4493.0000 - val_tn: 27777.0000 - val_fn: 2338.0000 - val_accuracy: 0.8098 - val_precision: 0.2257 - val_recall: 0.3591 - val_auc: 0.7369\n",
      "Epoch 3/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6134 - tp: 18024.0000 - fp: 80643.0000 - tn: 144412.0000 - fn: 7795.0000 - accuracy: 0.6475 - precision: 0.1827 - recall: 0.6981 - auc: 0.7274 - val_loss: 0.4799 - val_tp: 1656.0000 - val_fp: 6110.0000 - val_tn: 26160.0000 - val_fn: 1992.0000 - val_accuracy: 0.7744 - val_precision: 0.2132 - val_recall: 0.4539 - val_auc: 0.7320\n",
      "Epoch 4/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6174 - tp: 18204.0000 - fp: 83278.0000 - tn: 141777.0000 - fn: 7615.0000 - accuracy: 0.6377 - precision: 0.1794 - recall: 0.7051 - auc: 0.7240 - val_loss: 0.4775 - val_tp: 1644.0000 - val_fp: 5866.0000 - val_tn: 26404.0000 - val_fn: 2004.0000 - val_accuracy: 0.7809 - val_precision: 0.2189 - val_recall: 0.4507 - val_auc: 0.7384\n",
      "Epoch 5/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6142 - tp: 17959.0000 - fp: 79175.0000 - tn: 145880.0000 - fn: 7860.0000 - accuracy: 0.6531 - precision: 0.1849 - recall: 0.6956 - auc: 0.7289 - val_loss: 0.4603 - val_tp: 1666.0000 - val_fp: 5780.0000 - val_tn: 26490.0000 - val_fn: 1982.0000 - val_accuracy: 0.7839 - val_precision: 0.2237 - val_recall: 0.4567 - val_auc: 0.7400\n",
      "Epoch 6/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6144 - tp: 17764.0000 - fp: 78377.0000 - tn: 146678.0000 - fn: 8055.0000 - accuracy: 0.6555 - precision: 0.1848 - recall: 0.6880 - auc: 0.7268 - val_loss: 0.4704 - val_tp: 1370.0000 - val_fp: 4524.0000 - val_tn: 27746.0000 - val_fn: 2278.0000 - val_accuracy: 0.8106 - val_precision: 0.2324 - val_recall: 0.3755 - val_auc: 0.7354\n",
      "Epoch 7/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6210 - tp: 17398.0000 - fp: 78520.0000 - tn: 146535.0000 - fn: 8421.0000 - accuracy: 0.6534 - precision: 0.1814 - recall: 0.6738 - auc: 0.7210 - val_loss: 0.4914 - val_tp: 1800.0000 - val_fp: 6710.0000 - val_tn: 25560.0000 - val_fn: 1848.0000 - val_accuracy: 0.7617 - val_precision: 0.2115 - val_recall: 0.4934 - val_auc: 0.7363\n",
      "Epoch 8/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6179 - tp: 17351.0000 - fp: 76493.0000 - tn: 148562.0000 - fn: 8468.0000 - accuracy: 0.6613 - precision: 0.1849 - recall: 0.6720 - auc: 0.7250 - val_loss: 0.4617 - val_tp: 1139.0000 - val_fp: 3563.0000 - val_tn: 28707.0000 - val_fn: 2509.0000 - val_accuracy: 0.8309 - val_precision: 0.2422 - val_recall: 0.3122 - val_auc: 0.7362\n",
      "Epoch 9/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6188 - tp: 17175.0000 - fp: 73518.0000 - tn: 151537.0000 - fn: 8644.0000 - accuracy: 0.6725 - precision: 0.1894 - recall: 0.6652 - auc: 0.7273 - val_loss: 0.4656 - val_tp: 834.0000 - val_fp: 2510.0000 - val_tn: 29760.0000 - val_fn: 2814.0000 - val_accuracy: 0.8518 - val_precision: 0.2494 - val_recall: 0.2286 - val_auc: 0.7309\n",
      "Epoch 10/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6170 - tp: 17064.0000 - fp: 72653.0000 - tn: 152402.0000 - fn: 8755.0000 - accuracy: 0.6755 - precision: 0.1902 - recall: 0.6609 - auc: 0.7284 - val_loss: 0.4623 - val_tp: 1040.0000 - val_fp: 3081.0000 - val_tn: 29189.0000 - val_fn: 2608.0000 - val_accuracy: 0.8416 - val_precision: 0.2524 - val_recall: 0.2851 - val_auc: 0.7366\n",
      "Epoch 11/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6191 - tp: 16599.0000 - fp: 70006.0000 - tn: 155049.0000 - fn: 9220.0000 - accuracy: 0.6842 - precision: 0.1917 - recall: 0.6429 - auc: 0.7259 - val_loss: 0.5129 - val_tp: 1421.0000 - val_fp: 4770.0000 - val_tn: 27500.0000 - val_fn: 2227.0000 - val_accuracy: 0.8052 - val_precision: 0.2295 - val_recall: 0.3895 - val_auc: 0.7345\n",
      "Epoch 1/500\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 4.9040 - tp: 21712.0000 - fp: 138997.0000 - tn: 118328.0000 - fn: 7755.0000 - accuracy: 0.4883 - precision: 0.1351 - recall: 0.7368 - auc: 0.6024 - val_loss: 0.5471 - val_tp: 2661.0000 - val_fp: 14583.0000 - val_tn: 17687.0000 - val_fn: 987.0000 - val_accuracy: 0.5665 - val_precision: 0.1543 - val_recall: 0.7294 - val_auc: 0.6605\n",
      "Epoch 2/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7163 - tp: 23480.0000 - fp: 159459.0000 - tn: 65596.0000 - fn: 2339.0000 - accuracy: 0.3551 - precision: 0.1283 - recall: 0.9094 - auc: 0.6015 - val_loss: 0.6172 - val_tp: 3237.0000 - val_fp: 20300.0000 - val_tn: 11970.0000 - val_fn: 411.0000 - val_accuracy: 0.4234 - val_precision: 0.1375 - val_recall: 0.8873 - val_auc: 0.6248\n",
      "Epoch 3/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6749 - tp: 24168.0000 - fp: 164257.0000 - tn: 60798.0000 - fn: 1651.0000 - accuracy: 0.3387 - precision: 0.1283 - recall: 0.9361 - auc: 0.6070 - val_loss: 0.6432 - val_tp: 3259.0000 - val_fp: 20032.0000 - val_tn: 12238.0000 - val_fn: 389.0000 - val_accuracy: 0.4315 - val_precision: 0.1399 - val_recall: 0.8934 - val_auc: 0.6685\n",
      "Epoch 4/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6703 - tp: 23453.0000 - fp: 155323.0000 - tn: 69732.0000 - fn: 2366.0000 - accuracy: 0.3714 - precision: 0.1312 - recall: 0.9084 - auc: 0.6162 - val_loss: 0.6349 - val_tp: 3200.0000 - val_fp: 18733.0000 - val_tn: 13537.0000 - val_fn: 448.0000 - val_accuracy: 0.4660 - val_precision: 0.1459 - val_recall: 0.8772 - val_auc: 0.6669\n",
      "Epoch 5/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6777 - tp: 23251.0000 - fp: 155476.0000 - tn: 69579.0000 - fn: 2568.0000 - accuracy: 0.3700 - precision: 0.1301 - recall: 0.9005 - auc: 0.6136 - val_loss: 0.6561 - val_tp: 3247.0000 - val_fp: 20178.0000 - val_tn: 12092.0000 - val_fn: 401.0000 - val_accuracy: 0.4271 - val_precision: 0.1386 - val_recall: 0.8901 - val_auc: 0.6546\n",
      "Epoch 6/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6800 - tp: 23867.0000 - fp: 160214.0000 - tn: 64841.0000 - fn: 1952.0000 - accuracy: 0.3536 - precision: 0.1297 - recall: 0.9244 - auc: 0.6102 - val_loss: 0.5719 - val_tp: 3002.0000 - val_fp: 17669.0000 - val_tn: 14601.0000 - val_fn: 646.0000 - val_accuracy: 0.4901 - val_precision: 0.1452 - val_recall: 0.8229 - val_auc: 0.6686\n",
      "Epoch 7/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6993 - tp: 22676.0000 - fp: 156944.0000 - tn: 68111.0000 - fn: 3143.0000 - accuracy: 0.3619 - precision: 0.1262 - recall: 0.8783 - auc: 0.5945 - val_loss: 0.6587 - val_tp: 3211.0000 - val_fp: 19626.0000 - val_tn: 12644.0000 - val_fn: 437.0000 - val_accuracy: 0.4414 - val_precision: 0.1406 - val_recall: 0.8802 - val_auc: 0.6576\n",
      "Epoch 8/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6852 - tp: 23069.0000 - fp: 162252.0000 - tn: 62803.0000 - fn: 2750.0000 - accuracy: 0.3423 - precision: 0.1245 - recall: 0.8935 - auc: 0.5894 - val_loss: 0.6058 - val_tp: 3068.0000 - val_fp: 19522.0000 - val_tn: 12748.0000 - val_fn: 580.0000 - val_accuracy: 0.4403 - val_precision: 0.1358 - val_recall: 0.8410 - val_auc: 0.6226\n",
      "Epoch 9/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7145 - tp: 21067.0000 - fp: 149945.0000 - tn: 75110.0000 - fn: 4752.0000 - accuracy: 0.3834 - precision: 0.1232 - recall: 0.8159 - auc: 0.5848 - val_loss: 0.6557 - val_tp: 3333.0000 - val_fp: 21661.0000 - val_tn: 10609.0000 - val_fn: 315.0000 - val_accuracy: 0.3882 - val_precision: 0.1334 - val_recall: 0.9137 - val_auc: 0.6437\n",
      "Epoch 10/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7600 - tp: 20388.0000 - fp: 153150.0000 - tn: 71905.0000 - fn: 5431.0000 - accuracy: 0.3679 - precision: 0.1175 - recall: 0.7897 - auc: 0.5627 - val_loss: 0.6174 - val_tp: 3062.0000 - val_fp: 21226.0000 - val_tn: 11044.0000 - val_fn: 586.0000 - val_accuracy: 0.3927 - val_precision: 0.1261 - val_recall: 0.8394 - val_auc: 0.6040\n",
      "Epoch 11/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7595 - tp: 19428.0000 - fp: 152625.0000 - tn: 72430.0000 - fn: 6391.0000 - accuracy: 0.3662 - precision: 0.1129 - recall: 0.7525 - auc: 0.5469 - val_loss: 0.6081 - val_tp: 3386.0000 - val_fp: 23384.0000 - val_tn: 8886.0000 - val_fn: 262.0000 - val_accuracy: 0.3417 - val_precision: 0.1265 - val_recall: 0.9282 - val_auc: 0.6158\n",
      "Epoch 12/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 2.7461 - tp: 16387.0000 - fp: 129087.0000 - tn: 95968.0000 - fn: 9432.0000 - accuracy: 0.4479 - precision: 0.1126 - recall: 0.6347 - auc: 0.5434 - val_loss: 0.8205 - val_tp: 3480.0000 - val_fp: 27027.0000 - val_tn: 5243.0000 - val_fn: 168.0000 - val_accuracy: 0.2429 - val_precision: 0.1141 - val_recall: 0.9539 - val_auc: 0.5544\n",
      "Epoch 13/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.8126 - tp: 15066.0000 - fp: 127823.0000 - tn: 97232.0000 - fn: 10753.0000 - accuracy: 0.4476 - precision: 0.1054 - recall: 0.5835 - auc: 0.5139 - val_loss: 0.7565 - val_tp: 3488.0000 - val_fp: 26738.0000 - val_tn: 5532.0000 - val_fn: 160.0000 - val_accuracy: 0.2511 - val_precision: 0.1154 - val_recall: 0.9561 - val_auc: 0.5795\n",
      "Epoch 14/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.3845 - tp: 14588.0000 - fp: 121038.0000 - tn: 104017.0000 - fn: 11231.0000 - accuracy: 0.4728 - precision: 0.1076 - recall: 0.5650 - auc: 0.5243 - val_loss: 0.6508 - val_tp: 47.0000 - val_fp: 247.0000 - val_tn: 32023.0000 - val_fn: 3601.0000 - val_accuracy: 0.8929 - val_precision: 0.1599 - val_recall: 0.0129 - val_auc: 0.5295\n",
      "Epoch 15/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7019 - tp: 14284.0000 - fp: 119346.0000 - tn: 105709.0000 - fn: 11535.0000 - accuracy: 0.4783 - precision: 0.1069 - recall: 0.5532 - auc: 0.5197 - val_loss: 0.6400 - val_tp: 29.0000 - val_fp: 88.0000 - val_tn: 32182.0000 - val_fn: 3619.0000 - val_accuracy: 0.8968 - val_precision: 0.2479 - val_recall: 0.0079 - val_auc: 0.5309\n",
      "Epoch 16/500\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7267 - tp: 14443.0000 - fp: 122910.0000 - tn: 102145.0000 - fn: 11376.0000 - accuracy: 0.4647 - precision: 0.1052 - recall: 0.5594 - auc: 0.5156 - val_loss: 0.6837 - val_tp: 3601.0000 - val_fp: 30158.0000 - val_tn: 2112.0000 - val_fn: 47.0000 - val_accuracy: 0.1591 - val_precision: 0.1067 - val_recall: 0.9871 - val_auc: 0.5274\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 1.2268 - tp: 6361.0000 - fp: 43463.0000 - tn: 213862.0000 - fn: 23106.0000 - accuracy: 0.7679 - precision: 0.1277 - recall: 0.2159 - auc: 0.5844 - val_loss: 0.4012 - val_tp: 861.0000 - val_fp: 3539.0000 - val_tn: 28731.0000 - val_fn: 2787.0000 - val_accuracy: 0.8239 - val_precision: 0.1957 - val_recall: 0.2360 - val_auc: 0.6445\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.9987 - tp: 7865.0000 - fp: 38785.0000 - tn: 186270.0000 - fn: 17954.0000 - accuracy: 0.7738 - precision: 0.1686 - recall: 0.3046 - auc: 0.6217 - val_loss: 0.4549 - val_tp: 1282.0000 - val_fp: 5842.0000 - val_tn: 26428.0000 - val_fn: 2366.0000 - val_accuracy: 0.7715 - val_precision: 0.1800 - val_recall: 0.3514 - val_auc: 0.6564\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.9098 - tp: 8858.0000 - fp: 44540.0000 - tn: 180515.0000 - fn: 16961.0000 - accuracy: 0.7549 - precision: 0.1659 - recall: 0.3431 - auc: 0.6282 - val_loss: 0.4435 - val_tp: 1281.0000 - val_fp: 5457.0000 - val_tn: 26813.0000 - val_fn: 2367.0000 - val_accuracy: 0.7822 - val_precision: 0.1901 - val_recall: 0.3512 - val_auc: 0.6668\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.8493 - tp: 9177.0000 - fp: 46841.0000 - tn: 178214.0000 - fn: 16642.0000 - accuracy: 0.7470 - precision: 0.1638 - recall: 0.3554 - auc: 0.6301 - val_loss: 0.4458 - val_tp: 1310.0000 - val_fp: 5421.0000 - val_tn: 26849.0000 - val_fn: 2338.0000 - val_accuracy: 0.7840 - val_precision: 0.1946 - val_recall: 0.3591 - val_auc: 0.6765\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.8144 - tp: 9661.0000 - fp: 49261.0000 - tn: 175794.0000 - fn: 16158.0000 - accuracy: 0.7392 - precision: 0.1640 - recall: 0.3742 - auc: 0.6348 - val_loss: 0.4449 - val_tp: 1339.0000 - val_fp: 5347.0000 - val_tn: 26923.0000 - val_fn: 2309.0000 - val_accuracy: 0.7868 - val_precision: 0.2003 - val_recall: 0.3671 - val_auc: 0.6868\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.7857 - tp: 10081.0000 - fp: 49800.0000 - tn: 175255.0000 - fn: 15738.0000 - accuracy: 0.7388 - precision: 0.1684 - recall: 0.3904 - auc: 0.6445 - val_loss: 0.4451 - val_tp: 1365.0000 - val_fp: 5321.0000 - val_tn: 26949.0000 - val_fn: 2283.0000 - val_accuracy: 0.7883 - val_precision: 0.2042 - val_recall: 0.3742 - val_auc: 0.6960\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7659 - tp: 10396.0000 - fp: 50611.0000 - tn: 174444.0000 - fn: 15423.0000 - accuracy: 0.7368 - precision: 0.1704 - recall: 0.4026 - auc: 0.6507 - val_loss: 0.4446 - val_tp: 1372.0000 - val_fp: 5271.0000 - val_tn: 26999.0000 - val_fn: 2276.0000 - val_accuracy: 0.7899 - val_precision: 0.2065 - val_recall: 0.3761 - val_auc: 0.7038\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7464 - tp: 10973.0000 - fp: 52176.0000 - tn: 172879.0000 - fn: 14846.0000 - accuracy: 0.7328 - precision: 0.1738 - recall: 0.4250 - auc: 0.6592 - val_loss: 0.4460 - val_tp: 1410.0000 - val_fp: 5366.0000 - val_tn: 26904.0000 - val_fn: 2238.0000 - val_accuracy: 0.7883 - val_precision: 0.2081 - val_recall: 0.3865 - val_auc: 0.7106\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7295 - tp: 11352.0000 - fp: 53244.0000 - tn: 171811.0000 - fn: 14467.0000 - accuracy: 0.7301 - precision: 0.1757 - recall: 0.4397 - auc: 0.6650 - val_loss: 0.4559 - val_tp: 1520.0000 - val_fp: 5864.0000 - val_tn: 26406.0000 - val_fn: 2128.0000 - val_accuracy: 0.7775 - val_precision: 0.2059 - val_recall: 0.4167 - val_auc: 0.7157\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7178 - tp: 11684.0000 - fp: 54338.0000 - tn: 170717.0000 - fn: 14135.0000 - accuracy: 0.7271 - precision: 0.1770 - recall: 0.4525 - auc: 0.6714 - val_loss: 0.4515 - val_tp: 1513.0000 - val_fp: 5608.0000 - val_tn: 26662.0000 - val_fn: 2135.0000 - val_accuracy: 0.7844 - val_precision: 0.2125 - val_recall: 0.4147 - val_auc: 0.7216\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7082 - tp: 11875.0000 - fp: 54690.0000 - tn: 170365.0000 - fn: 13944.0000 - accuracy: 0.7264 - precision: 0.1784 - recall: 0.4599 - auc: 0.6757 - val_loss: 0.4512 - val_tp: 1546.0000 - val_fp: 5712.0000 - val_tn: 26558.0000 - val_fn: 2102.0000 - val_accuracy: 0.7824 - val_precision: 0.2130 - val_recall: 0.4238 - val_auc: 0.7254\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6999 - tp: 12215.0000 - fp: 55309.0000 - tn: 169746.0000 - fn: 13604.0000 - accuracy: 0.7253 - precision: 0.1809 - recall: 0.4731 - auc: 0.6802 - val_loss: 0.4496 - val_tp: 1546.0000 - val_fp: 5630.0000 - val_tn: 26640.0000 - val_fn: 2102.0000 - val_accuracy: 0.7847 - val_precision: 0.2154 - val_recall: 0.4238 - val_auc: 0.7296\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6945 - tp: 12401.0000 - fp: 55640.0000 - tn: 169415.0000 - fn: 13418.0000 - accuracy: 0.7247 - precision: 0.1823 - recall: 0.4803 - auc: 0.6836 - val_loss: 0.4466 - val_tp: 1543.0000 - val_fp: 5494.0000 - val_tn: 26776.0000 - val_fn: 2105.0000 - val_accuracy: 0.7884 - val_precision: 0.2193 - val_recall: 0.4230 - val_auc: 0.7328\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6877 - tp: 12560.0000 - fp: 55864.0000 - tn: 169191.0000 - fn: 13259.0000 - accuracy: 0.7245 - precision: 0.1836 - recall: 0.4865 - auc: 0.6883 - val_loss: 0.4448 - val_tp: 1549.0000 - val_fp: 5476.0000 - val_tn: 26794.0000 - val_fn: 2099.0000 - val_accuracy: 0.7891 - val_precision: 0.2205 - val_recall: 0.4246 - val_auc: 0.7352\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6792 - tp: 12788.0000 - fp: 56570.0000 - tn: 168485.0000 - fn: 13031.0000 - accuracy: 0.7226 - precision: 0.1844 - recall: 0.4953 - auc: 0.6933 - val_loss: 0.4462 - val_tp: 1557.0000 - val_fp: 5482.0000 - val_tn: 26788.0000 - val_fn: 2091.0000 - val_accuracy: 0.7892 - val_precision: 0.2212 - val_recall: 0.4268 - val_auc: 0.7375\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6758 - tp: 13033.0000 - fp: 57745.0000 - tn: 167310.0000 - fn: 12786.0000 - accuracy: 0.7189 - precision: 0.1841 - recall: 0.5048 - auc: 0.6945 - val_loss: 0.4453 - val_tp: 1581.0000 - val_fp: 5520.0000 - val_tn: 26750.0000 - val_fn: 2067.0000 - val_accuracy: 0.7888 - val_precision: 0.2226 - val_recall: 0.4334 - val_auc: 0.7391\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6698 - tp: 13112.0000 - fp: 57045.0000 - tn: 168010.0000 - fn: 12707.0000 - accuracy: 0.7220 - precision: 0.1869 - recall: 0.5078 - auc: 0.6992 - val_loss: 0.4440 - val_tp: 1587.0000 - val_fp: 5476.0000 - val_tn: 26794.0000 - val_fn: 2061.0000 - val_accuracy: 0.7902 - val_precision: 0.2247 - val_recall: 0.4350 - val_auc: 0.7411\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6676 - tp: 13379.0000 - fp: 58272.0000 - tn: 166783.0000 - fn: 12440.0000 - accuracy: 0.7181 - precision: 0.1867 - recall: 0.5182 - auc: 0.7004 - val_loss: 0.4416 - val_tp: 1588.0000 - val_fp: 5418.0000 - val_tn: 26852.0000 - val_fn: 2060.0000 - val_accuracy: 0.7918 - val_precision: 0.2267 - val_recall: 0.4353 - val_auc: 0.7424\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6624 - tp: 13428.0000 - fp: 58075.0000 - tn: 166980.0000 - fn: 12391.0000 - accuracy: 0.7191 - precision: 0.1878 - recall: 0.5201 - auc: 0.7033 - val_loss: 0.4448 - val_tp: 1630.0000 - val_fp: 5609.0000 - val_tn: 26661.0000 - val_fn: 2018.0000 - val_accuracy: 0.7877 - val_precision: 0.2252 - val_recall: 0.4468 - val_auc: 0.7438\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6579 - tp: 13707.0000 - fp: 58755.0000 - tn: 166300.0000 - fn: 12112.0000 - accuracy: 0.7175 - precision: 0.1892 - recall: 0.5309 - auc: 0.7070 - val_loss: 0.4413 - val_tp: 1603.0000 - val_fp: 5399.0000 - val_tn: 26871.0000 - val_fn: 2045.0000 - val_accuracy: 0.7928 - val_precision: 0.2289 - val_recall: 0.4394 - val_auc: 0.7452\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6584 - tp: 13647.0000 - fp: 58792.0000 - tn: 166263.0000 - fn: 12172.0000 - accuracy: 0.7171 - precision: 0.1884 - recall: 0.5286 - auc: 0.7059 - val_loss: 0.4394 - val_tp: 1598.0000 - val_fp: 5419.0000 - val_tn: 26851.0000 - val_fn: 2050.0000 - val_accuracy: 0.7921 - val_precision: 0.2277 - val_recall: 0.4380 - val_auc: 0.7461\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6536 - tp: 13708.0000 - fp: 58261.0000 - tn: 166794.0000 - fn: 12111.0000 - accuracy: 0.7195 - precision: 0.1905 - recall: 0.5309 - auc: 0.7096 - val_loss: 0.4420 - val_tp: 1635.0000 - val_fp: 5563.0000 - val_tn: 26707.0000 - val_fn: 2013.0000 - val_accuracy: 0.7891 - val_precision: 0.2271 - val_recall: 0.4482 - val_auc: 0.7467\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6492 - tp: 14092.0000 - fp: 59758.0000 - tn: 165297.0000 - fn: 11727.0000 - accuracy: 0.7151 - precision: 0.1908 - recall: 0.5458 - auc: 0.7127 - val_loss: 0.4419 - val_tp: 1655.0000 - val_fp: 5603.0000 - val_tn: 26667.0000 - val_fn: 1993.0000 - val_accuracy: 0.7885 - val_precision: 0.2280 - val_recall: 0.4537 - val_auc: 0.7476\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6502 - tp: 14048.0000 - fp: 59778.0000 - tn: 165277.0000 - fn: 11771.0000 - accuracy: 0.7148 - precision: 0.1903 - recall: 0.5441 - auc: 0.7111 - val_loss: 0.4397 - val_tp: 1645.0000 - val_fp: 5542.0000 - val_tn: 26728.0000 - val_fn: 2003.0000 - val_accuracy: 0.7899 - val_precision: 0.2289 - val_recall: 0.4509 - val_auc: 0.7481\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6456 - tp: 14090.0000 - fp: 59475.0000 - tn: 165580.0000 - fn: 11729.0000 - accuracy: 0.7162 - precision: 0.1915 - recall: 0.5457 - auc: 0.7145 - val_loss: 0.4393 - val_tp: 1641.0000 - val_fp: 5498.0000 - val_tn: 26772.0000 - val_fn: 2007.0000 - val_accuracy: 0.7911 - val_precision: 0.2299 - val_recall: 0.4498 - val_auc: 0.7490\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6440 - tp: 14186.0000 - fp: 60292.0000 - tn: 164763.0000 - fn: 11633.0000 - accuracy: 0.7133 - precision: 0.1905 - recall: 0.5494 - auc: 0.7150 - val_loss: 0.4368 - val_tp: 1612.0000 - val_fp: 5352.0000 - val_tn: 26918.0000 - val_fn: 2036.0000 - val_accuracy: 0.7943 - val_precision: 0.2315 - val_recall: 0.4419 - val_auc: 0.7496\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6397 - tp: 14299.0000 - fp: 60248.0000 - tn: 164807.0000 - fn: 11520.0000 - accuracy: 0.7139 - precision: 0.1918 - recall: 0.5538 - auc: 0.7183 - val_loss: 0.4371 - val_tp: 1602.0000 - val_fp: 5341.0000 - val_tn: 26929.0000 - val_fn: 2046.0000 - val_accuracy: 0.7943 - val_precision: 0.2307 - val_recall: 0.4391 - val_auc: 0.7501\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6361 - tp: 14587.0000 - fp: 60550.0000 - tn: 164505.0000 - fn: 11232.0000 - accuracy: 0.7139 - precision: 0.1941 - recall: 0.5650 - auc: 0.7207 - val_loss: 0.4355 - val_tp: 1589.0000 - val_fp: 5248.0000 - val_tn: 27022.0000 - val_fn: 2059.0000 - val_accuracy: 0.7966 - val_precision: 0.2324 - val_recall: 0.4356 - val_auc: 0.7505\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6374 - tp: 14541.0000 - fp: 61305.0000 - tn: 163750.0000 - fn: 11278.0000 - accuracy: 0.7107 - precision: 0.1917 - recall: 0.5632 - auc: 0.7188 - val_loss: 0.4352 - val_tp: 1603.0000 - val_fp: 5277.0000 - val_tn: 26993.0000 - val_fn: 2045.0000 - val_accuracy: 0.7961 - val_precision: 0.2330 - val_recall: 0.4394 - val_auc: 0.7508\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6339 - tp: 14567.0000 - fp: 61077.0000 - tn: 163978.0000 - fn: 11252.0000 - accuracy: 0.7117 - precision: 0.1926 - recall: 0.5642 - auc: 0.7212 - val_loss: 0.4350 - val_tp: 1603.0000 - val_fp: 5292.0000 - val_tn: 26978.0000 - val_fn: 2045.0000 - val_accuracy: 0.7957 - val_precision: 0.2325 - val_recall: 0.4394 - val_auc: 0.7509\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6350 - tp: 14565.0000 - fp: 61316.0000 - tn: 163739.0000 - fn: 11254.0000 - accuracy: 0.7107 - precision: 0.1919 - recall: 0.5641 - auc: 0.7198 - val_loss: 0.4339 - val_tp: 1591.0000 - val_fp: 5195.0000 - val_tn: 27075.0000 - val_fn: 2057.0000 - val_accuracy: 0.7981 - val_precision: 0.2345 - val_recall: 0.4361 - val_auc: 0.7514\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6325 - tp: 14637.0000 - fp: 61306.0000 - tn: 163749.0000 - fn: 11182.0000 - accuracy: 0.7111 - precision: 0.1927 - recall: 0.5669 - auc: 0.7215 - val_loss: 0.4338 - val_tp: 1588.0000 - val_fp: 5175.0000 - val_tn: 27095.0000 - val_fn: 2060.0000 - val_accuracy: 0.7986 - val_precision: 0.2348 - val_recall: 0.4353 - val_auc: 0.7515\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6294 - tp: 14862.0000 - fp: 61674.0000 - tn: 163381.0000 - fn: 10957.0000 - accuracy: 0.7105 - precision: 0.1942 - recall: 0.5756 - auc: 0.7243 - val_loss: 0.4303 - val_tp: 1546.0000 - val_fp: 4989.0000 - val_tn: 27281.0000 - val_fn: 2102.0000 - val_accuracy: 0.8026 - val_precision: 0.2366 - val_recall: 0.4238 - val_auc: 0.7518\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6319 - tp: 14687.0000 - fp: 61807.0000 - tn: 163248.0000 - fn: 11132.0000 - accuracy: 0.7093 - precision: 0.1920 - recall: 0.5688 - auc: 0.7213 - val_loss: 0.4309 - val_tp: 1534.0000 - val_fp: 4951.0000 - val_tn: 27319.0000 - val_fn: 2114.0000 - val_accuracy: 0.8033 - val_precision: 0.2365 - val_recall: 0.4205 - val_auc: 0.7519\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6282 - tp: 14799.0000 - fp: 61684.0000 - tn: 163371.0000 - fn: 11020.0000 - accuracy: 0.7102 - precision: 0.1935 - recall: 0.5732 - auc: 0.7241 - val_loss: 0.4337 - val_tp: 1591.0000 - val_fp: 5223.0000 - val_tn: 27047.0000 - val_fn: 2057.0000 - val_accuracy: 0.7973 - val_precision: 0.2335 - val_recall: 0.4361 - val_auc: 0.7518\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6279 - tp: 14853.0000 - fp: 62179.0000 - tn: 162876.0000 - fn: 10966.0000 - accuracy: 0.7084 - precision: 0.1928 - recall: 0.5753 - auc: 0.7240 - val_loss: 0.4295 - val_tp: 1528.0000 - val_fp: 4915.0000 - val_tn: 27355.0000 - val_fn: 2120.0000 - val_accuracy: 0.8041 - val_precision: 0.2372 - val_recall: 0.4189 - val_auc: 0.7526\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6264 - tp: 15021.0000 - fp: 62420.0000 - tn: 162635.0000 - fn: 10798.0000 - accuracy: 0.7081 - precision: 0.1940 - recall: 0.5818 - auc: 0.7250 - val_loss: 0.4265 - val_tp: 1473.0000 - val_fp: 4685.0000 - val_tn: 27585.0000 - val_fn: 2175.0000 - val_accuracy: 0.8090 - val_precision: 0.2392 - val_recall: 0.4038 - val_auc: 0.7526\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6245 - tp: 15078.0000 - fp: 62805.0000 - tn: 162250.0000 - fn: 10741.0000 - accuracy: 0.7068 - precision: 0.1936 - recall: 0.5840 - auc: 0.7258 - val_loss: 0.4290 - val_tp: 1522.0000 - val_fp: 4881.0000 - val_tn: 27389.0000 - val_fn: 2126.0000 - val_accuracy: 0.8049 - val_precision: 0.2377 - val_recall: 0.4172 - val_auc: 0.7528\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6252 - tp: 15079.0000 - fp: 63337.0000 - tn: 161718.0000 - fn: 10740.0000 - accuracy: 0.7047 - precision: 0.1923 - recall: 0.5840 - auc: 0.7252 - val_loss: 0.4327 - val_tp: 1560.0000 - val_fp: 5104.0000 - val_tn: 27166.0000 - val_fn: 2088.0000 - val_accuracy: 0.7998 - val_precision: 0.2341 - val_recall: 0.4276 - val_auc: 0.7527\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6242 - tp: 15034.0000 - fp: 63232.0000 - tn: 161823.0000 - fn: 10785.0000 - accuracy: 0.7050 - precision: 0.1921 - recall: 0.5823 - auc: 0.7254 - val_loss: 0.4267 - val_tp: 1497.0000 - val_fp: 4785.0000 - val_tn: 27485.0000 - val_fn: 2151.0000 - val_accuracy: 0.8069 - val_precision: 0.2383 - val_recall: 0.4104 - val_auc: 0.7530\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6209 - tp: 15226.0000 - fp: 63147.0000 - tn: 161908.0000 - fn: 10593.0000 - accuracy: 0.7061 - precision: 0.1943 - recall: 0.5897 - auc: 0.7282 - val_loss: 0.4274 - val_tp: 1496.0000 - val_fp: 4777.0000 - val_tn: 27493.0000 - val_fn: 2152.0000 - val_accuracy: 0.8071 - val_precision: 0.2385 - val_recall: 0.4101 - val_auc: 0.7530\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6190 - tp: 15221.0000 - fp: 63336.0000 - tn: 161719.0000 - fn: 10598.0000 - accuracy: 0.7053 - precision: 0.1938 - recall: 0.5895 - auc: 0.7294 - val_loss: 0.4292 - val_tp: 1517.0000 - val_fp: 4897.0000 - val_tn: 27373.0000 - val_fn: 2131.0000 - val_accuracy: 0.8043 - val_precision: 0.2365 - val_recall: 0.4158 - val_auc: 0.7526\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6199 - tp: 15300.0000 - fp: 63721.0000 - tn: 161334.0000 - fn: 10519.0000 - accuracy: 0.7041 - precision: 0.1936 - recall: 0.5926 - auc: 0.7283 - val_loss: 0.4274 - val_tp: 1493.0000 - val_fp: 4801.0000 - val_tn: 27469.0000 - val_fn: 2155.0000 - val_accuracy: 0.8063 - val_precision: 0.2372 - val_recall: 0.4093 - val_auc: 0.7531\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6167 - tp: 15360.0000 - fp: 63701.0000 - tn: 161354.0000 - fn: 10459.0000 - accuracy: 0.7044 - precision: 0.1943 - recall: 0.5949 - auc: 0.7307 - val_loss: 0.4323 - val_tp: 1569.0000 - val_fp: 5130.0000 - val_tn: 27140.0000 - val_fn: 2079.0000 - val_accuracy: 0.7993 - val_precision: 0.2342 - val_recall: 0.4301 - val_auc: 0.7525\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6150 - tp: 15518.0000 - fp: 63653.0000 - tn: 161402.0000 - fn: 10301.0000 - accuracy: 0.7052 - precision: 0.1960 - recall: 0.6010 - auc: 0.7322 - val_loss: 0.4305 - val_tp: 1517.0000 - val_fp: 4914.0000 - val_tn: 27356.0000 - val_fn: 2131.0000 - val_accuracy: 0.8039 - val_precision: 0.2359 - val_recall: 0.4158 - val_auc: 0.7530\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6146 - tp: 15596.0000 - fp: 64792.0000 - tn: 160263.0000 - fn: 10223.0000 - accuracy: 0.7010 - precision: 0.1940 - recall: 0.6041 - auc: 0.7310 - val_loss: 0.4333 - val_tp: 1546.0000 - val_fp: 5044.0000 - val_tn: 27226.0000 - val_fn: 2102.0000 - val_accuracy: 0.8010 - val_precision: 0.2346 - val_recall: 0.4238 - val_auc: 0.7531\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6124 - tp: 15924.0000 - fp: 66478.0000 - tn: 158577.0000 - fn: 9895.0000 - accuracy: 0.6956 - precision: 0.1932 - recall: 0.6168 - auc: 0.7319 - val_loss: 0.4306 - val_tp: 1489.0000 - val_fp: 4759.0000 - val_tn: 27511.0000 - val_fn: 2159.0000 - val_accuracy: 0.8074 - val_precision: 0.2383 - val_recall: 0.4082 - val_auc: 0.7533\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6107 - tp: 15681.0000 - fp: 65169.0000 - tn: 159886.0000 - fn: 10138.0000 - accuracy: 0.6998 - precision: 0.1940 - recall: 0.6073 - auc: 0.7330 - val_loss: 0.4266 - val_tp: 1431.0000 - val_fp: 4543.0000 - val_tn: 27727.0000 - val_fn: 2217.0000 - val_accuracy: 0.8118 - val_precision: 0.2395 - val_recall: 0.3923 - val_auc: 0.7534\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6110 - tp: 15778.0000 - fp: 65686.0000 - tn: 159369.0000 - fn: 10041.0000 - accuracy: 0.6981 - precision: 0.1937 - recall: 0.6111 - auc: 0.7324 - val_loss: 0.4311 - val_tp: 1476.0000 - val_fp: 4738.0000 - val_tn: 27532.0000 - val_fn: 2172.0000 - val_accuracy: 0.8076 - val_precision: 0.2375 - val_recall: 0.4046 - val_auc: 0.7531\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6102 - tp: 15838.0000 - fp: 65933.0000 - tn: 159122.0000 - fn: 9981.0000 - accuracy: 0.6974 - precision: 0.1937 - recall: 0.6134 - auc: 0.7333 - val_loss: 0.4274 - val_tp: 1427.0000 - val_fp: 4521.0000 - val_tn: 27749.0000 - val_fn: 2221.0000 - val_accuracy: 0.8123 - val_precision: 0.2399 - val_recall: 0.3912 - val_auc: 0.7536\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6101 - tp: 15813.0000 - fp: 65777.0000 - tn: 159278.0000 - fn: 10006.0000 - accuracy: 0.6979 - precision: 0.1938 - recall: 0.6125 - auc: 0.7333 - val_loss: 0.4262 - val_tp: 1402.0000 - val_fp: 4382.0000 - val_tn: 27888.0000 - val_fn: 2246.0000 - val_accuracy: 0.8155 - val_precision: 0.2424 - val_recall: 0.3843 - val_auc: 0.7537\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6092 - tp: 15953.0000 - fp: 66420.0000 - tn: 158635.0000 - fn: 9866.0000 - accuracy: 0.6959 - precision: 0.1937 - recall: 0.6179 - auc: 0.7337 - val_loss: 0.4249 - val_tp: 1406.0000 - val_fp: 4434.0000 - val_tn: 27836.0000 - val_fn: 2242.0000 - val_accuracy: 0.8141 - val_precision: 0.2408 - val_recall: 0.3854 - val_auc: 0.7537\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6082 - tp: 15882.0000 - fp: 65804.0000 - tn: 159251.0000 - fn: 9937.0000 - accuracy: 0.6981 - precision: 0.1944 - recall: 0.6151 - auc: 0.7344 - val_loss: 0.4329 - val_tp: 1519.0000 - val_fp: 4978.0000 - val_tn: 27292.0000 - val_fn: 2129.0000 - val_accuracy: 0.8021 - val_precision: 0.2338 - val_recall: 0.4164 - val_auc: 0.7525\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6059 - tp: 15954.0000 - fp: 65927.0000 - tn: 159128.0000 - fn: 9865.0000 - accuracy: 0.6979 - precision: 0.1948 - recall: 0.6179 - auc: 0.7364 - val_loss: 0.4257 - val_tp: 1404.0000 - val_fp: 4408.0000 - val_tn: 27862.0000 - val_fn: 2244.0000 - val_accuracy: 0.8148 - val_precision: 0.2416 - val_recall: 0.3849 - val_auc: 0.7535\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6078 - tp: 15949.0000 - fp: 66466.0000 - tn: 158589.0000 - fn: 9870.0000 - accuracy: 0.6957 - precision: 0.1935 - recall: 0.6177 - auc: 0.7340 - val_loss: 0.4273 - val_tp: 1413.0000 - val_fp: 4461.0000 - val_tn: 27809.0000 - val_fn: 2235.0000 - val_accuracy: 0.8136 - val_precision: 0.2406 - val_recall: 0.3873 - val_auc: 0.7533\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6075 - tp: 16053.0000 - fp: 66606.0000 - tn: 158449.0000 - fn: 9766.0000 - accuracy: 0.6956 - precision: 0.1942 - recall: 0.6218 - auc: 0.7348 - val_loss: 0.4242 - val_tp: 1395.0000 - val_fp: 4358.0000 - val_tn: 27912.0000 - val_fn: 2253.0000 - val_accuracy: 0.8159 - val_precision: 0.2425 - val_recall: 0.3824 - val_auc: 0.7537\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6059 - tp: 16085.0000 - fp: 66735.0000 - tn: 158320.0000 - fn: 9734.0000 - accuracy: 0.6952 - precision: 0.1942 - recall: 0.6230 - auc: 0.7357 - val_loss: 0.4248 - val_tp: 1374.0000 - val_fp: 4320.0000 - val_tn: 27950.0000 - val_fn: 2274.0000 - val_accuracy: 0.8164 - val_precision: 0.2413 - val_recall: 0.3766 - val_auc: 0.7532\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6056 - tp: 16087.0000 - fp: 66657.0000 - tn: 158398.0000 - fn: 9732.0000 - accuracy: 0.6955 - precision: 0.1944 - recall: 0.6231 - auc: 0.7362 - val_loss: 0.4250 - val_tp: 1407.0000 - val_fp: 4442.0000 - val_tn: 27828.0000 - val_fn: 2241.0000 - val_accuracy: 0.8139 - val_precision: 0.2406 - val_recall: 0.3857 - val_auc: 0.7530\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6055 - tp: 15991.0000 - fp: 66537.0000 - tn: 158518.0000 - fn: 9828.0000 - accuracy: 0.6956 - precision: 0.1938 - recall: 0.6194 - auc: 0.7359 - val_loss: 0.4243 - val_tp: 1382.0000 - val_fp: 4298.0000 - val_tn: 27972.0000 - val_fn: 2266.0000 - val_accuracy: 0.8173 - val_precision: 0.2433 - val_recall: 0.3788 - val_auc: 0.7536\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6051 - tp: 16225.0000 - fp: 67193.0000 - tn: 157862.0000 - fn: 9594.0000 - accuracy: 0.6939 - precision: 0.1945 - recall: 0.6284 - auc: 0.7362 - val_loss: 0.4218 - val_tp: 1352.0000 - val_fp: 4184.0000 - val_tn: 28086.0000 - val_fn: 2296.0000 - val_accuracy: 0.8196 - val_precision: 0.2442 - val_recall: 0.3706 - val_auc: 0.7535\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6039 - tp: 16364.0000 - fp: 68092.0000 - tn: 156963.0000 - fn: 9455.0000 - accuracy: 0.6909 - precision: 0.1938 - recall: 0.6338 - auc: 0.7374 - val_loss: 0.4249 - val_tp: 1404.0000 - val_fp: 4441.0000 - val_tn: 27829.0000 - val_fn: 2244.0000 - val_accuracy: 0.8139 - val_precision: 0.2402 - val_recall: 0.3849 - val_auc: 0.7530\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.9037 - tp: 10748.0000 - fp: 52164.0000 - tn: 205161.0000 - fn: 18719.0000 - accuracy: 0.7528 - precision: 0.1708 - recall: 0.3647 - auc: 0.6337 - val_loss: 0.4735 - val_tp: 1634.0000 - val_fp: 6608.0000 - val_tn: 25662.0000 - val_fn: 2014.0000 - val_accuracy: 0.7600 - val_precision: 0.1983 - val_recall: 0.4479 - val_auc: 0.7110\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6948 - tp: 12436.0000 - fp: 56510.0000 - tn: 168545.0000 - fn: 13383.0000 - accuracy: 0.7214 - precision: 0.1804 - recall: 0.4817 - auc: 0.6809 - val_loss: 0.4679 - val_tp: 1787.0000 - val_fp: 6454.0000 - val_tn: 25816.0000 - val_fn: 1861.0000 - val_accuracy: 0.7685 - val_precision: 0.2168 - val_recall: 0.4899 - val_auc: 0.7391\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6511 - tp: 13896.0000 - fp: 60316.0000 - tn: 164739.0000 - fn: 11923.0000 - accuracy: 0.7121 - precision: 0.1872 - recall: 0.5382 - auc: 0.7065 - val_loss: 0.4521 - val_tp: 1686.0000 - val_fp: 5820.0000 - val_tn: 26450.0000 - val_fn: 1962.0000 - val_accuracy: 0.7833 - val_precision: 0.2246 - val_recall: 0.4622 - val_auc: 0.7466\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6326 - tp: 14790.0000 - fp: 62214.0000 - tn: 162841.0000 - fn: 11029.0000 - accuracy: 0.7080 - precision: 0.1921 - recall: 0.5728 - auc: 0.7186 - val_loss: 0.4425 - val_tp: 1433.0000 - val_fp: 4677.0000 - val_tn: 27593.0000 - val_fn: 2215.0000 - val_accuracy: 0.8081 - val_precision: 0.2345 - val_recall: 0.3928 - val_auc: 0.7487\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6206 - tp: 15341.0000 - fp: 64626.0000 - tn: 160429.0000 - fn: 10478.0000 - accuracy: 0.7006 - precision: 0.1918 - recall: 0.5942 - auc: 0.7251 - val_loss: 0.4564 - val_tp: 1767.0000 - val_fp: 6065.0000 - val_tn: 26205.0000 - val_fn: 1881.0000 - val_accuracy: 0.7788 - val_precision: 0.2256 - val_recall: 0.4844 - val_auc: 0.7509\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6127 - tp: 15745.0000 - fp: 65362.0000 - tn: 159693.0000 - fn: 10074.0000 - accuracy: 0.6993 - precision: 0.1941 - recall: 0.6098 - auc: 0.7303 - val_loss: 0.4695 - val_tp: 1898.0000 - val_fp: 6694.0000 - val_tn: 25576.0000 - val_fn: 1750.0000 - val_accuracy: 0.7649 - val_precision: 0.2209 - val_recall: 0.5203 - val_auc: 0.7509\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6072 - tp: 16226.0000 - fp: 68201.0000 - tn: 156854.0000 - fn: 9593.0000 - accuracy: 0.6899 - precision: 0.1922 - recall: 0.6285 - auc: 0.7333 - val_loss: 0.4481 - val_tp: 1680.0000 - val_fp: 5584.0000 - val_tn: 26686.0000 - val_fn: 1968.0000 - val_accuracy: 0.7897 - val_precision: 0.2313 - val_recall: 0.4605 - val_auc: 0.7517\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6035 - tp: 16472.0000 - fp: 68189.0000 - tn: 156866.0000 - fn: 9347.0000 - accuracy: 0.6909 - precision: 0.1946 - recall: 0.6380 - auc: 0.7368 - val_loss: 0.4474 - val_tp: 1622.0000 - val_fp: 5342.0000 - val_tn: 26928.0000 - val_fn: 2026.0000 - val_accuracy: 0.7949 - val_precision: 0.2329 - val_recall: 0.4446 - val_auc: 0.7533\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6004 - tp: 16822.0000 - fp: 69662.0000 - tn: 155393.0000 - fn: 8997.0000 - accuracy: 0.6865 - precision: 0.1945 - recall: 0.6515 - auc: 0.7386 - val_loss: 0.4522 - val_tp: 1643.0000 - val_fp: 5449.0000 - val_tn: 26821.0000 - val_fn: 2005.0000 - val_accuracy: 0.7925 - val_precision: 0.2317 - val_recall: 0.4504 - val_auc: 0.7531\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5982 - tp: 17053.0000 - fp: 71450.0000 - tn: 153605.0000 - fn: 8766.0000 - accuracy: 0.6803 - precision: 0.1927 - recall: 0.6605 - auc: 0.7402 - val_loss: 0.4459 - val_tp: 1558.0000 - val_fp: 5102.0000 - val_tn: 27168.0000 - val_fn: 2090.0000 - val_accuracy: 0.7998 - val_precision: 0.2339 - val_recall: 0.4271 - val_auc: 0.7518\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5957 - tp: 17272.0000 - fp: 72415.0000 - tn: 152640.0000 - fn: 8547.0000 - accuracy: 0.6773 - precision: 0.1926 - recall: 0.6690 - auc: 0.7416 - val_loss: 0.4393 - val_tp: 1457.0000 - val_fp: 4660.0000 - val_tn: 27610.0000 - val_fn: 2191.0000 - val_accuracy: 0.8093 - val_precision: 0.2382 - val_recall: 0.3994 - val_auc: 0.7533\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5941 - tp: 17555.0000 - fp: 72868.0000 - tn: 152187.0000 - fn: 8264.0000 - accuracy: 0.6766 - precision: 0.1941 - recall: 0.6799 - auc: 0.7434 - val_loss: 0.4490 - val_tp: 1582.0000 - val_fp: 5157.0000 - val_tn: 27113.0000 - val_fn: 2066.0000 - val_accuracy: 0.7989 - val_precision: 0.2348 - val_recall: 0.4337 - val_auc: 0.7528\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5913 - tp: 17981.0000 - fp: 74402.0000 - tn: 150653.0000 - fn: 7838.0000 - accuracy: 0.6722 - precision: 0.1946 - recall: 0.6964 - auc: 0.7464 - val_loss: 0.4465 - val_tp: 1557.0000 - val_fp: 5018.0000 - val_tn: 27252.0000 - val_fn: 2091.0000 - val_accuracy: 0.8021 - val_precision: 0.2368 - val_recall: 0.4268 - val_auc: 0.7535\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5915 - tp: 17880.0000 - fp: 74161.0000 - tn: 150894.0000 - fn: 7939.0000 - accuracy: 0.6727 - precision: 0.1943 - recall: 0.6925 - auc: 0.7456 - val_loss: 0.4525 - val_tp: 1628.0000 - val_fp: 5343.0000 - val_tn: 26927.0000 - val_fn: 2020.0000 - val_accuracy: 0.7950 - val_precision: 0.2335 - val_recall: 0.4463 - val_auc: 0.7517\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5899 - tp: 18069.0000 - fp: 75045.0000 - tn: 150010.0000 - fn: 7750.0000 - accuracy: 0.6700 - precision: 0.1941 - recall: 0.6998 - auc: 0.7476 - val_loss: 0.4464 - val_tp: 1521.0000 - val_fp: 4939.0000 - val_tn: 27331.0000 - val_fn: 2127.0000 - val_accuracy: 0.8033 - val_precision: 0.2354 - val_recall: 0.4169 - val_auc: 0.7514\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5879 - tp: 18491.0000 - fp: 77005.0000 - tn: 148050.0000 - fn: 7328.0000 - accuracy: 0.6638 - precision: 0.1936 - recall: 0.7162 - auc: 0.7492 - val_loss: 0.4518 - val_tp: 1610.0000 - val_fp: 5363.0000 - val_tn: 26907.0000 - val_fn: 2038.0000 - val_accuracy: 0.7939 - val_precision: 0.2309 - val_recall: 0.4413 - val_auc: 0.7492\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5875 - tp: 18404.0000 - fp: 75943.0000 - tn: 149112.0000 - fn: 7415.0000 - accuracy: 0.6677 - precision: 0.1951 - recall: 0.7128 - auc: 0.7502 - val_loss: 0.4441 - val_tp: 1418.0000 - val_fp: 4508.0000 - val_tn: 27762.0000 - val_fn: 2230.0000 - val_accuracy: 0.8124 - val_precision: 0.2393 - val_recall: 0.3887 - val_auc: 0.7504\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5871 - tp: 18531.0000 - fp: 76709.0000 - tn: 148346.0000 - fn: 7288.0000 - accuracy: 0.6652 - precision: 0.1946 - recall: 0.7177 - auc: 0.7504 - val_loss: 0.4355 - val_tp: 1211.0000 - val_fp: 3561.0000 - val_tn: 28709.0000 - val_fn: 2437.0000 - val_accuracy: 0.8330 - val_precision: 0.2538 - val_recall: 0.3320 - val_auc: 0.7502\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5877 - tp: 18710.0000 - fp: 77907.0000 - tn: 147148.0000 - fn: 7109.0000 - accuracy: 0.6611 - precision: 0.1937 - recall: 0.7247 - auc: 0.7500 - val_loss: 0.4360 - val_tp: 1205.0000 - val_fp: 3545.0000 - val_tn: 28725.0000 - val_fn: 2443.0000 - val_accuracy: 0.8333 - val_precision: 0.2537 - val_recall: 0.3303 - val_auc: 0.7509\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5859 - tp: 18751.0000 - fp: 77592.0000 - tn: 147463.0000 - fn: 7068.0000 - accuracy: 0.6625 - precision: 0.1946 - recall: 0.7262 - auc: 0.7522 - val_loss: 0.4386 - val_tp: 1278.0000 - val_fp: 3915.0000 - val_tn: 28355.0000 - val_fn: 2370.0000 - val_accuracy: 0.8250 - val_precision: 0.2461 - val_recall: 0.3503 - val_auc: 0.7498\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5850 - tp: 18806.0000 - fp: 77462.0000 - tn: 147593.0000 - fn: 7013.0000 - accuracy: 0.6633 - precision: 0.1954 - recall: 0.7284 - auc: 0.7532 - val_loss: 0.4330 - val_tp: 967.0000 - val_fp: 2662.0000 - val_tn: 29608.0000 - val_fn: 2681.0000 - val_accuracy: 0.8512 - val_precision: 0.2665 - val_recall: 0.2651 - val_auc: 0.7486\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5864 - tp: 18593.0000 - fp: 76823.0000 - tn: 148232.0000 - fn: 7226.0000 - accuracy: 0.6650 - precision: 0.1949 - recall: 0.7201 - auc: 0.7521 - val_loss: 0.4390 - val_tp: 1198.0000 - val_fp: 3566.0000 - val_tn: 28704.0000 - val_fn: 2450.0000 - val_accuracy: 0.8325 - val_precision: 0.2515 - val_recall: 0.3284 - val_auc: 0.7489\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5850 - tp: 18975.0000 - fp: 78258.0000 - tn: 146797.0000 - fn: 6844.0000 - accuracy: 0.6608 - precision: 0.1951 - recall: 0.7349 - auc: 0.7540 - val_loss: 0.4269 - val_tp: 960.0000 - val_fp: 2607.0000 - val_tn: 29663.0000 - val_fn: 2688.0000 - val_accuracy: 0.8526 - val_precision: 0.2691 - val_recall: 0.2632 - val_auc: 0.7470\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.9980 - tp: 11790.0000 - fp: 67228.0000 - tn: 190097.0000 - fn: 17677.0000 - accuracy: 0.7039 - precision: 0.1492 - recall: 0.4001 - auc: 0.6082 - val_loss: 0.5638 - val_tp: 2254.0000 - val_fp: 10182.0000 - val_tn: 22088.0000 - val_fn: 1394.0000 - val_accuracy: 0.6777 - val_precision: 0.1812 - val_recall: 0.6179 - val_auc: 0.7173\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6318 - tp: 16385.0000 - fp: 76952.0000 - tn: 148103.0000 - fn: 9434.0000 - accuracy: 0.6557 - precision: 0.1755 - recall: 0.6346 - auc: 0.7006 - val_loss: 0.5113 - val_tp: 1883.0000 - val_fp: 6919.0000 - val_tn: 25351.0000 - val_fn: 1765.0000 - val_accuracy: 0.7582 - val_precision: 0.2139 - val_recall: 0.5162 - val_auc: 0.7369\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6112 - tp: 18230.0000 - fp: 82664.0000 - tn: 142391.0000 - fn: 7589.0000 - accuracy: 0.6402 - precision: 0.1807 - recall: 0.7061 - auc: 0.7248 - val_loss: 0.5059 - val_tp: 2113.0000 - val_fp: 7831.0000 - val_tn: 24439.0000 - val_fn: 1535.0000 - val_accuracy: 0.7392 - val_precision: 0.2125 - val_recall: 0.5792 - val_auc: 0.7490\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6021 - tp: 18305.0000 - fp: 80506.0000 - tn: 144549.0000 - fn: 7514.0000 - accuracy: 0.6491 - precision: 0.1853 - recall: 0.7090 - auc: 0.7344 - val_loss: 0.5168 - val_tp: 2252.0000 - val_fp: 8677.0000 - val_tn: 23593.0000 - val_fn: 1396.0000 - val_accuracy: 0.7196 - val_precision: 0.2061 - val_recall: 0.6173 - val_auc: 0.7489\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5970 - tp: 18566.0000 - fp: 80796.0000 - tn: 144259.0000 - fn: 7253.0000 - accuracy: 0.6490 - precision: 0.1869 - recall: 0.7191 - auc: 0.7396 - val_loss: 0.4961 - val_tp: 2103.0000 - val_fp: 7920.0000 - val_tn: 24350.0000 - val_fn: 1545.0000 - val_accuracy: 0.7365 - val_precision: 0.2098 - val_recall: 0.5765 - val_auc: 0.7471\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5948 - tp: 18606.0000 - fp: 80186.0000 - tn: 144869.0000 - fn: 7213.0000 - accuracy: 0.6516 - precision: 0.1883 - recall: 0.7206 - auc: 0.7420 - val_loss: 0.4966 - val_tp: 2125.0000 - val_fp: 7846.0000 - val_tn: 24424.0000 - val_fn: 1523.0000 - val_accuracy: 0.7392 - val_precision: 0.2131 - val_recall: 0.5825 - val_auc: 0.7483\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5938 - tp: 18841.0000 - fp: 80648.0000 - tn: 144407.0000 - fn: 6978.0000 - accuracy: 0.6507 - precision: 0.1894 - recall: 0.7297 - auc: 0.7446 - val_loss: 0.4880 - val_tp: 2095.0000 - val_fp: 7726.0000 - val_tn: 24544.0000 - val_fn: 1553.0000 - val_accuracy: 0.7417 - val_precision: 0.2133 - val_recall: 0.5743 - val_auc: 0.7481\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5939 - tp: 18915.0000 - fp: 80906.0000 - tn: 144149.0000 - fn: 6904.0000 - accuracy: 0.6500 - precision: 0.1895 - recall: 0.7326 - auc: 0.7440 - val_loss: 0.5094 - val_tp: 2148.0000 - val_fp: 8043.0000 - val_tn: 24227.0000 - val_fn: 1500.0000 - val_accuracy: 0.7343 - val_precision: 0.2108 - val_recall: 0.5888 - val_auc: 0.7492\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5920 - tp: 19003.0000 - fp: 80788.0000 - tn: 144267.0000 - fn: 6816.0000 - accuracy: 0.6508 - precision: 0.1904 - recall: 0.7360 - auc: 0.7461 - val_loss: 0.4610 - val_tp: 1862.0000 - val_fp: 6520.0000 - val_tn: 25750.0000 - val_fn: 1786.0000 - val_accuracy: 0.7688 - val_precision: 0.2221 - val_recall: 0.5104 - val_auc: 0.7477\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5926 - tp: 18751.0000 - fp: 79950.0000 - tn: 145105.0000 - fn: 7068.0000 - accuracy: 0.6531 - precision: 0.1900 - recall: 0.7262 - auc: 0.7448 - val_loss: 0.4440 - val_tp: 1398.0000 - val_fp: 4345.0000 - val_tn: 27925.0000 - val_fn: 2250.0000 - val_accuracy: 0.8164 - val_precision: 0.2434 - val_recall: 0.3832 - val_auc: 0.7463\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.5915 - tp: 18781.0000 - fp: 79312.0000 - tn: 145743.0000 - fn: 7038.0000 - accuracy: 0.6558 - precision: 0.1915 - recall: 0.7274 - auc: 0.7473 - val_loss: 0.4905 - val_tp: 1727.0000 - val_fp: 5812.0000 - val_tn: 26458.0000 - val_fn: 1921.0000 - val_accuracy: 0.7847 - val_precision: 0.2291 - val_recall: 0.4734 - val_auc: 0.7509\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5932 - tp: 18746.0000 - fp: 79184.0000 - tn: 145871.0000 - fn: 7073.0000 - accuracy: 0.6562 - precision: 0.1914 - recall: 0.7261 - auc: 0.7460 - val_loss: 0.4791 - val_tp: 1775.0000 - val_fp: 6161.0000 - val_tn: 26109.0000 - val_fn: 1873.0000 - val_accuracy: 0.7763 - val_precision: 0.2237 - val_recall: 0.4866 - val_auc: 0.7492\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5911 - tp: 19059.0000 - fp: 80495.0000 - tn: 144560.0000 - fn: 6760.0000 - accuracy: 0.6522 - precision: 0.1914 - recall: 0.7382 - auc: 0.7482 - val_loss: 0.4821 - val_tp: 1683.0000 - val_fp: 5665.0000 - val_tn: 26605.0000 - val_fn: 1965.0000 - val_accuracy: 0.7876 - val_precision: 0.2290 - val_recall: 0.4613 - val_auc: 0.7488\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.5918 - tp: 18998.0000 - fp: 80158.0000 - tn: 144897.0000 - fn: 6821.0000 - accuracy: 0.6533 - precision: 0.1916 - recall: 0.7358 - auc: 0.7482 - val_loss: 0.4963 - val_tp: 1560.0000 - val_fp: 5207.0000 - val_tn: 27063.0000 - val_fn: 2088.0000 - val_accuracy: 0.7969 - val_precision: 0.2305 - val_recall: 0.4276 - val_auc: 0.7484\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5940 - tp: 18848.0000 - fp: 79878.0000 - tn: 145177.0000 - fn: 6971.0000 - accuracy: 0.6538 - precision: 0.1909 - recall: 0.7300 - auc: 0.7458 - val_loss: 0.4558 - val_tp: 1392.0000 - val_fp: 4444.0000 - val_tn: 27826.0000 - val_fn: 2256.0000 - val_accuracy: 0.8135 - val_precision: 0.2385 - val_recall: 0.3816 - val_auc: 0.7437\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5931 - tp: 18763.0000 - fp: 78752.0000 - tn: 146303.0000 - fn: 7056.0000 - accuracy: 0.6580 - precision: 0.1924 - recall: 0.7267 - auc: 0.7470 - val_loss: 0.4806 - val_tp: 1882.0000 - val_fp: 6729.0000 - val_tn: 25541.0000 - val_fn: 1766.0000 - val_accuracy: 0.7635 - val_precision: 0.2186 - val_recall: 0.5159 - val_auc: 0.7462\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5924 - tp: 18906.0000 - fp: 79370.0000 - tn: 145685.0000 - fn: 6913.0000 - accuracy: 0.6561 - precision: 0.1924 - recall: 0.7323 - auc: 0.7482 - val_loss: 0.4625 - val_tp: 1501.0000 - val_fp: 4840.0000 - val_tn: 27430.0000 - val_fn: 2147.0000 - val_accuracy: 0.8055 - val_precision: 0.2367 - val_recall: 0.4115 - val_auc: 0.7485\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5898 - tp: 18846.0000 - fp: 79155.0000 - tn: 145900.0000 - fn: 6973.0000 - accuracy: 0.6567 - precision: 0.1923 - recall: 0.7299 - auc: 0.7501 - val_loss: 0.4629 - val_tp: 1335.0000 - val_fp: 4113.0000 - val_tn: 28157.0000 - val_fn: 2313.0000 - val_accuracy: 0.8211 - val_precision: 0.2450 - val_recall: 0.3660 - val_auc: 0.7473\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5903 - tp: 18837.0000 - fp: 78412.0000 - tn: 146643.0000 - fn: 6982.0000 - accuracy: 0.6596 - precision: 0.1937 - recall: 0.7296 - auc: 0.7495 - val_loss: 0.4512 - val_tp: 1644.0000 - val_fp: 5524.0000 - val_tn: 26746.0000 - val_fn: 2004.0000 - val_accuracy: 0.7904 - val_precision: 0.2294 - val_recall: 0.4507 - val_auc: 0.7469\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5906 - tp: 18833.0000 - fp: 78871.0000 - tn: 146184.0000 - fn: 6986.0000 - accuracy: 0.6578 - precision: 0.1928 - recall: 0.7294 - auc: 0.7493 - val_loss: 0.4219 - val_tp: 787.0000 - val_fp: 1973.0000 - val_tn: 30297.0000 - val_fn: 2861.0000 - val_accuracy: 0.8654 - val_precision: 0.2851 - val_recall: 0.2157 - val_auc: 0.7460\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5898 - tp: 18926.0000 - fp: 78274.0000 - tn: 146781.0000 - fn: 6893.0000 - accuracy: 0.6605 - precision: 0.1947 - recall: 0.7330 - auc: 0.7506 - val_loss: 0.4328 - val_tp: 883.0000 - val_fp: 2363.0000 - val_tn: 29907.0000 - val_fn: 2765.0000 - val_accuracy: 0.8572 - val_precision: 0.2720 - val_recall: 0.2421 - val_auc: 0.7466\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 18.6534 - tp: 15867.0000 - fp: 105170.0000 - tn: 152155.0000 - fn: 13600.0000 - accuracy: 0.5859 - precision: 0.1311 - recall: 0.5385 - auc: 0.5787 - val_loss: 1.7347 - val_tp: 2402.0000 - val_fp: 13933.0000 - val_tn: 18337.0000 - val_fn: 1246.0000 - val_accuracy: 0.5774 - val_precision: 0.1470 - val_recall: 0.6584 - val_auc: 0.6237\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.5085 - tp: 17105.0000 - fp: 116137.0000 - tn: 108918.0000 - fn: 8714.0000 - accuracy: 0.5023 - precision: 0.1284 - recall: 0.6625 - auc: 0.5940 - val_loss: 0.5924 - val_tp: 2902.0000 - val_fp: 16549.0000 - val_tn: 15721.0000 - val_fn: 746.0000 - val_accuracy: 0.5185 - val_precision: 0.1492 - val_recall: 0.7955 - val_auc: 0.6575\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7218 - tp: 22733.0000 - fp: 151196.0000 - tn: 73859.0000 - fn: 3086.0000 - accuracy: 0.3850 - precision: 0.1307 - recall: 0.8805 - auc: 0.6004 - val_loss: 0.5290 - val_tp: 2431.0000 - val_fp: 12774.0000 - val_tn: 19496.0000 - val_fn: 1217.0000 - val_accuracy: 0.6105 - val_precision: 0.1599 - val_recall: 0.6664 - val_auc: 0.6803\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6882 - tp: 23496.0000 - fp: 152868.0000 - tn: 72187.0000 - fn: 2323.0000 - accuracy: 0.3814 - precision: 0.1332 - recall: 0.9100 - auc: 0.6193 - val_loss: 0.5649 - val_tp: 3018.0000 - val_fp: 17042.0000 - val_tn: 15228.0000 - val_fn: 630.0000 - val_accuracy: 0.5080 - val_precision: 0.1504 - val_recall: 0.8273 - val_auc: 0.6672\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.6904 - tp: 23958.0000 - fp: 157386.0000 - tn: 67669.0000 - fn: 1861.0000 - accuracy: 0.3652 - precision: 0.1321 - recall: 0.9279 - auc: 0.6179 - val_loss: 0.6088 - val_tp: 3286.0000 - val_fp: 19734.0000 - val_tn: 12536.0000 - val_fn: 362.0000 - val_accuracy: 0.4405 - val_precision: 0.1427 - val_recall: 0.9008 - val_auc: 0.6718\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6671 - tp: 24065.0000 - fp: 157736.0000 - tn: 67319.0000 - fn: 1754.0000 - accuracy: 0.3643 - precision: 0.1324 - recall: 0.9321 - auc: 0.6222 - val_loss: 0.6376 - val_tp: 3250.0000 - val_fp: 20325.0000 - val_tn: 11945.0000 - val_fn: 398.0000 - val_accuracy: 0.4230 - val_precision: 0.1379 - val_recall: 0.8909 - val_auc: 0.6442\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6546 - tp: 24116.0000 - fp: 156140.0000 - tn: 68915.0000 - fn: 1703.0000 - accuracy: 0.3708 - precision: 0.1338 - recall: 0.9340 - auc: 0.6330 - val_loss: 0.5385 - val_tp: 3015.0000 - val_fp: 16207.0000 - val_tn: 16063.0000 - val_fn: 633.0000 - val_accuracy: 0.5312 - val_precision: 0.1569 - val_recall: 0.8265 - val_auc: 0.6909\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6498 - tp: 24100.0000 - fp: 155064.0000 - tn: 69991.0000 - fn: 1719.0000 - accuracy: 0.3751 - precision: 0.1345 - recall: 0.9334 - auc: 0.6364 - val_loss: 0.5652 - val_tp: 3107.0000 - val_fp: 17443.0000 - val_tn: 14827.0000 - val_fn: 541.0000 - val_accuracy: 0.4993 - val_precision: 0.1512 - val_recall: 0.8517 - val_auc: 0.6952\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6499 - tp: 24013.0000 - fp: 153610.0000 - tn: 71445.0000 - fn: 1806.0000 - accuracy: 0.3805 - precision: 0.1352 - recall: 0.9301 - auc: 0.6387 - val_loss: 0.5500 - val_tp: 3050.0000 - val_fp: 16352.0000 - val_tn: 15918.0000 - val_fn: 598.0000 - val_accuracy: 0.5281 - val_precision: 0.1572 - val_recall: 0.8361 - val_auc: 0.6993\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6479 - tp: 24019.0000 - fp: 151278.0000 - tn: 73777.0000 - fn: 1800.0000 - accuracy: 0.3898 - precision: 0.1370 - recall: 0.9303 - auc: 0.6455 - val_loss: 0.7558 - val_tp: 3454.0000 - val_fp: 23339.0000 - val_tn: 8931.0000 - val_fn: 194.0000 - val_accuracy: 0.3448 - val_precision: 0.1289 - val_recall: 0.9468 - val_auc: 0.6383\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6549 - tp: 23985.0000 - fp: 152286.0000 - tn: 72769.0000 - fn: 1834.0000 - accuracy: 0.3857 - precision: 0.1361 - recall: 0.9290 - auc: 0.6395 - val_loss: 0.5823 - val_tp: 3145.0000 - val_fp: 17436.0000 - val_tn: 14834.0000 - val_fn: 503.0000 - val_accuracy: 0.5006 - val_precision: 0.1528 - val_recall: 0.8621 - val_auc: 0.7004\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6468 - tp: 24018.0000 - fp: 151067.0000 - tn: 73988.0000 - fn: 1801.0000 - accuracy: 0.3907 - precision: 0.1372 - recall: 0.9302 - auc: 0.6416 - val_loss: 0.5719 - val_tp: 3156.0000 - val_fp: 17522.0000 - val_tn: 14748.0000 - val_fn: 492.0000 - val_accuracy: 0.4985 - val_precision: 0.1526 - val_recall: 0.8651 - val_auc: 0.6915\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6432 - tp: 23938.0000 - fp: 149820.0000 - tn: 75235.0000 - fn: 1881.0000 - accuracy: 0.3953 - precision: 0.1378 - recall: 0.9271 - auc: 0.6495 - val_loss: 0.5650 - val_tp: 3069.0000 - val_fp: 16655.0000 - val_tn: 15615.0000 - val_fn: 579.0000 - val_accuracy: 0.5202 - val_precision: 0.1556 - val_recall: 0.8413 - val_auc: 0.6952\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6421 - tp: 23876.0000 - fp: 148090.0000 - tn: 76965.0000 - fn: 1943.0000 - accuracy: 0.4020 - precision: 0.1388 - recall: 0.9247 - auc: 0.6520 - val_loss: 0.6004 - val_tp: 3154.0000 - val_fp: 17738.0000 - val_tn: 14532.0000 - val_fn: 494.0000 - val_accuracy: 0.4924 - val_precision: 0.1510 - val_recall: 0.8646 - val_auc: 0.6848\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6454 - tp: 23840.0000 - fp: 147947.0000 - tn: 77108.0000 - fn: 1979.0000 - accuracy: 0.4024 - precision: 0.1388 - recall: 0.9234 - auc: 0.6494 - val_loss: 0.5493 - val_tp: 3049.0000 - val_fp: 15986.0000 - val_tn: 16284.0000 - val_fn: 599.0000 - val_accuracy: 0.5383 - val_precision: 0.1602 - val_recall: 0.8358 - val_auc: 0.7017\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6400 - tp: 23763.0000 - fp: 145861.0000 - tn: 79194.0000 - fn: 2056.0000 - accuracy: 0.4104 - precision: 0.1401 - recall: 0.9204 - auc: 0.6550 - val_loss: 0.5768 - val_tp: 3158.0000 - val_fp: 17326.0000 - val_tn: 14944.0000 - val_fn: 490.0000 - val_accuracy: 0.5040 - val_precision: 0.1542 - val_recall: 0.8657 - val_auc: 0.7005\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6414 - tp: 23802.0000 - fp: 147054.0000 - tn: 78001.0000 - fn: 2017.0000 - accuracy: 0.4058 - precision: 0.1393 - recall: 0.9219 - auc: 0.6522 - val_loss: 0.5973 - val_tp: 3216.0000 - val_fp: 18297.0000 - val_tn: 13973.0000 - val_fn: 432.0000 - val_accuracy: 0.4786 - val_precision: 0.1495 - val_recall: 0.8816 - val_auc: 0.6915\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6350 - tp: 23557.0000 - fp: 143693.0000 - tn: 81362.0000 - fn: 2262.0000 - accuracy: 0.4182 - precision: 0.1408 - recall: 0.9124 - auc: 0.6624 - val_loss: 0.5553 - val_tp: 2995.0000 - val_fp: 15757.0000 - val_tn: 16513.0000 - val_fn: 653.0000 - val_accuracy: 0.5431 - val_precision: 0.1597 - val_recall: 0.8210 - val_auc: 0.7076\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6373 - tp: 23615.0000 - fp: 143802.0000 - tn: 81253.0000 - fn: 2204.0000 - accuracy: 0.4180 - precision: 0.1411 - recall: 0.9146 - auc: 0.6593 - val_loss: 0.6400 - val_tp: 3312.0000 - val_fp: 19509.0000 - val_tn: 12761.0000 - val_fn: 336.0000 - val_accuracy: 0.4475 - val_precision: 0.1451 - val_recall: 0.9079 - val_auc: 0.6859\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6400 - tp: 23607.0000 - fp: 145319.0000 - tn: 79736.0000 - fn: 2212.0000 - accuracy: 0.4119 - precision: 0.1397 - recall: 0.9143 - auc: 0.6556 - val_loss: 0.8813 - val_tp: 3419.0000 - val_fp: 24749.0000 - val_tn: 7521.0000 - val_fn: 229.0000 - val_accuracy: 0.3046 - val_precision: 0.1214 - val_recall: 0.9372 - val_auc: 0.5462\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6758 - tp: 23614.0000 - fp: 149241.0000 - tn: 75814.0000 - fn: 2205.0000 - accuracy: 0.3963 - precision: 0.1366 - recall: 0.9146 - auc: 0.6303 - val_loss: 0.6340 - val_tp: 3178.0000 - val_fp: 18854.0000 - val_tn: 13416.0000 - val_fn: 470.0000 - val_accuracy: 0.4620 - val_precision: 0.1442 - val_recall: 0.8712 - val_auc: 0.6804\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6478 - tp: 23827.0000 - fp: 151919.0000 - tn: 73136.0000 - fn: 1992.0000 - accuracy: 0.3865 - precision: 0.1356 - recall: 0.9228 - auc: 0.6384 - val_loss: 0.5781 - val_tp: 3149.0000 - val_fp: 17940.0000 - val_tn: 14330.0000 - val_fn: 499.0000 - val_accuracy: 0.4866 - val_precision: 0.1493 - val_recall: 0.8632 - val_auc: 0.6843\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6408 - tp: 23728.0000 - fp: 147680.0000 - tn: 77375.0000 - fn: 2091.0000 - accuracy: 0.4030 - precision: 0.1384 - recall: 0.9190 - auc: 0.6492 - val_loss: 0.5872 - val_tp: 3108.0000 - val_fp: 17061.0000 - val_tn: 15209.0000 - val_fn: 540.0000 - val_accuracy: 0.5100 - val_precision: 0.1541 - val_recall: 0.8520 - val_auc: 0.7003\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6371 - tp: 23637.0000 - fp: 145529.0000 - tn: 79526.0000 - fn: 2182.0000 - accuracy: 0.4112 - precision: 0.1397 - recall: 0.9155 - auc: 0.6552 - val_loss: 0.5439 - val_tp: 2984.0000 - val_fp: 15835.0000 - val_tn: 16435.0000 - val_fn: 664.0000 - val_accuracy: 0.5406 - val_precision: 0.1586 - val_recall: 0.8180 - val_auc: 0.7019\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6352 - tp: 23522.0000 - fp: 143456.0000 - tn: 81599.0000 - fn: 2297.0000 - accuracy: 0.4190 - precision: 0.1409 - recall: 0.9110 - auc: 0.6597 - val_loss: 0.5697 - val_tp: 3086.0000 - val_fp: 16658.0000 - val_tn: 15612.0000 - val_fn: 562.0000 - val_accuracy: 0.5206 - val_precision: 0.1563 - val_recall: 0.8459 - val_auc: 0.7017\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6347 - tp: 23413.0000 - fp: 141939.0000 - tn: 83116.0000 - fn: 2406.0000 - accuracy: 0.4246 - precision: 0.1416 - recall: 0.9068 - auc: 0.6630 - val_loss: 0.9122 - val_tp: 3582.0000 - val_fp: 29205.0000 - val_tn: 3065.0000 - val_fn: 66.0000 - val_accuracy: 0.1851 - val_precision: 0.1093 - val_recall: 0.9819 - val_auc: 0.4712\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6804 - tp: 23444.0000 - fp: 149306.0000 - tn: 75749.0000 - fn: 2375.0000 - accuracy: 0.3954 - precision: 0.1357 - recall: 0.9080 - auc: 0.6295 - val_loss: 0.5604 - val_tp: 3043.0000 - val_fp: 16684.0000 - val_tn: 15586.0000 - val_fn: 605.0000 - val_accuracy: 0.5187 - val_precision: 0.1543 - val_recall: 0.8342 - val_auc: 0.6885\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6449 - tp: 23479.0000 - fp: 148406.0000 - tn: 76649.0000 - fn: 2340.0000 - accuracy: 0.3991 - precision: 0.1366 - recall: 0.9094 - auc: 0.6434 - val_loss: 0.6167 - val_tp: 3179.0000 - val_fp: 18198.0000 - val_tn: 14072.0000 - val_fn: 469.0000 - val_accuracy: 0.4803 - val_precision: 0.1487 - val_recall: 0.8714 - val_auc: 0.6897\n",
      "Epoch 1/250\n",
      "26/26 [==============================] - 2s 65ms/step - loss: 1.2185 - tp: 6036.0000 - fp: 31623.0000 - tn: 225702.0000 - fn: 23431.0000 - accuracy: 0.8080 - precision: 0.1603 - recall: 0.2048 - auc: 0.6015 - val_loss: 0.4015 - val_tp: 866.0000 - val_fp: 3572.0000 - val_tn: 28698.0000 - val_fn: 2782.0000 - val_accuracy: 0.8231 - val_precision: 0.1951 - val_recall: 0.2374 - val_auc: 0.6450\n",
      "Epoch 2/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.0004 - tp: 7847.0000 - fp: 39115.0000 - tn: 185940.0000 - fn: 17972.0000 - accuracy: 0.7724 - precision: 0.1671 - recall: 0.3039 - auc: 0.6221 - val_loss: 0.4494 - val_tp: 1257.0000 - val_fp: 5660.0000 - val_tn: 26610.0000 - val_fn: 2391.0000 - val_accuracy: 0.7759 - val_precision: 0.1817 - val_recall: 0.3446 - val_auc: 0.6562\n",
      "Epoch 3/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.9072 - tp: 8789.0000 - fp: 43929.0000 - tn: 181126.0000 - fn: 17030.0000 - accuracy: 0.7570 - precision: 0.1667 - recall: 0.3404 - auc: 0.6290 - val_loss: 0.4464 - val_tp: 1295.0000 - val_fp: 5601.0000 - val_tn: 26669.0000 - val_fn: 2353.0000 - val_accuracy: 0.7786 - val_precision: 0.1878 - val_recall: 0.3550 - val_auc: 0.6667\n",
      "Epoch 4/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.8482 - tp: 9244.0000 - fp: 46702.0000 - tn: 178353.0000 - fn: 16575.0000 - accuracy: 0.7478 - precision: 0.1652 - recall: 0.3580 - auc: 0.6310 - val_loss: 0.4467 - val_tp: 1306.0000 - val_fp: 5438.0000 - val_tn: 26832.0000 - val_fn: 2342.0000 - val_accuracy: 0.7834 - val_precision: 0.1937 - val_recall: 0.3580 - val_auc: 0.6766\n",
      "Epoch 5/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.8125 - tp: 9765.0000 - fp: 49089.0000 - tn: 175966.0000 - fn: 16054.0000 - accuracy: 0.7403 - precision: 0.1659 - recall: 0.3782 - auc: 0.6355 - val_loss: 0.4453 - val_tp: 1336.0000 - val_fp: 5351.0000 - val_tn: 26919.0000 - val_fn: 2312.0000 - val_accuracy: 0.7867 - val_precision: 0.1998 - val_recall: 0.3662 - val_auc: 0.6874\n",
      "Epoch 6/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 33ms/step - loss: 0.7875 - tp: 10099.0000 - fp: 49971.0000 - tn: 175084.0000 - fn: 15720.0000 - accuracy: 0.7382 - precision: 0.1681 - recall: 0.3911 - auc: 0.6424 - val_loss: 0.4442 - val_tp: 1353.0000 - val_fp: 5295.0000 - val_tn: 26975.0000 - val_fn: 2295.0000 - val_accuracy: 0.7887 - val_precision: 0.2035 - val_recall: 0.3709 - val_auc: 0.6966\n",
      "Epoch 7/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.7669 - tp: 10391.0000 - fp: 50759.0000 - tn: 174296.0000 - fn: 15428.0000 - accuracy: 0.7362 - precision: 0.1699 - recall: 0.4025 - auc: 0.6502 - val_loss: 0.4448 - val_tp: 1397.0000 - val_fp: 5289.0000 - val_tn: 26981.0000 - val_fn: 2251.0000 - val_accuracy: 0.7901 - val_precision: 0.2089 - val_recall: 0.3829 - val_auc: 0.7049\n",
      "Epoch 8/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.7464 - tp: 10965.0000 - fp: 52279.0000 - tn: 172776.0000 - fn: 14854.0000 - accuracy: 0.7324 - precision: 0.1734 - recall: 0.4247 - auc: 0.6585 - val_loss: 0.4486 - val_tp: 1433.0000 - val_fp: 5406.0000 - val_tn: 26864.0000 - val_fn: 2215.0000 - val_accuracy: 0.7878 - val_precision: 0.2095 - val_recall: 0.3928 - val_auc: 0.7114\n",
      "Epoch 9/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.7352 - tp: 11298.0000 - fp: 54015.0000 - tn: 171040.0000 - fn: 14521.0000 - accuracy: 0.7268 - precision: 0.1730 - recall: 0.4376 - auc: 0.6617 - val_loss: 0.4464 - val_tp: 1438.0000 - val_fp: 5320.0000 - val_tn: 26950.0000 - val_fn: 2210.0000 - val_accuracy: 0.7904 - val_precision: 0.2128 - val_recall: 0.3942 - val_auc: 0.7173\n",
      "Epoch 10/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.7184 - tp: 11606.0000 - fp: 54250.0000 - tn: 170805.0000 - fn: 14213.0000 - accuracy: 0.7271 - precision: 0.1762 - recall: 0.4495 - auc: 0.6704 - val_loss: 0.4510 - val_tp: 1503.0000 - val_fp: 5580.0000 - val_tn: 26690.0000 - val_fn: 2145.0000 - val_accuracy: 0.7849 - val_precision: 0.2122 - val_recall: 0.4120 - val_auc: 0.7219\n",
      "Epoch 11/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.7069 - tp: 11897.0000 - fp: 54267.0000 - tn: 170788.0000 - fn: 13922.0000 - accuracy: 0.7282 - precision: 0.1798 - recall: 0.4608 - auc: 0.6768 - val_loss: 0.4504 - val_tp: 1538.0000 - val_fp: 5641.0000 - val_tn: 26629.0000 - val_fn: 2110.0000 - val_accuracy: 0.7842 - val_precision: 0.2142 - val_recall: 0.4216 - val_auc: 0.7264\n",
      "Epoch 12/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6973 - tp: 12221.0000 - fp: 55052.0000 - tn: 170003.0000 - fn: 13598.0000 - accuracy: 0.7264 - precision: 0.1817 - recall: 0.4733 - auc: 0.6827 - val_loss: 0.4478 - val_tp: 1523.0000 - val_fp: 5483.0000 - val_tn: 26787.0000 - val_fn: 2125.0000 - val_accuracy: 0.7882 - val_precision: 0.2174 - val_recall: 0.4175 - val_auc: 0.7305\n",
      "Epoch 13/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6949 - tp: 12320.0000 - fp: 56028.0000 - tn: 169027.0000 - fn: 13499.0000 - accuracy: 0.7229 - precision: 0.1803 - recall: 0.4772 - auc: 0.6826 - val_loss: 0.4524 - val_tp: 1604.0000 - val_fp: 5794.0000 - val_tn: 26476.0000 - val_fn: 2044.0000 - val_accuracy: 0.7818 - val_precision: 0.2168 - val_recall: 0.4397 - val_auc: 0.7325\n",
      "Epoch 14/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6885 - tp: 12567.0000 - fp: 56423.0000 - tn: 168632.0000 - fn: 13252.0000 - accuracy: 0.7223 - precision: 0.1822 - recall: 0.4867 - auc: 0.6867 - val_loss: 0.4486 - val_tp: 1573.0000 - val_fp: 5619.0000 - val_tn: 26651.0000 - val_fn: 2075.0000 - val_accuracy: 0.7858 - val_precision: 0.2187 - val_recall: 0.4312 - val_auc: 0.7352\n",
      "Epoch 15/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6784 - tp: 12871.0000 - fp: 56766.0000 - tn: 168289.0000 - fn: 12948.0000 - accuracy: 0.7221 - precision: 0.1848 - recall: 0.4985 - auc: 0.6941 - val_loss: 0.4451 - val_tp: 1575.0000 - val_fp: 5506.0000 - val_tn: 26764.0000 - val_fn: 2073.0000 - val_accuracy: 0.7890 - val_precision: 0.2224 - val_recall: 0.4317 - val_auc: 0.7373\n",
      "Epoch 16/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6780 - tp: 12849.0000 - fp: 57380.0000 - tn: 167675.0000 - fn: 12970.0000 - accuracy: 0.7196 - precision: 0.1830 - recall: 0.4977 - auc: 0.6936 - val_loss: 0.4414 - val_tp: 1532.0000 - val_fp: 5320.0000 - val_tn: 26950.0000 - val_fn: 2116.0000 - val_accuracy: 0.7930 - val_precision: 0.2236 - val_recall: 0.4200 - val_auc: 0.7395\n",
      "Epoch 17/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6727 - tp: 13076.0000 - fp: 56894.0000 - tn: 168161.0000 - fn: 12743.0000 - accuracy: 0.7224 - precision: 0.1869 - recall: 0.5064 - auc: 0.6972 - val_loss: 0.4495 - val_tp: 1649.0000 - val_fp: 5788.0000 - val_tn: 26482.0000 - val_fn: 1999.0000 - val_accuracy: 0.7832 - val_precision: 0.2217 - val_recall: 0.4520 - val_auc: 0.7403\n",
      "Epoch 18/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6665 - tp: 13354.0000 - fp: 57584.0000 - tn: 167471.0000 - fn: 12465.0000 - accuracy: 0.7208 - precision: 0.1882 - recall: 0.5172 - auc: 0.7019 - val_loss: 0.4425 - val_tp: 1570.0000 - val_fp: 5467.0000 - val_tn: 26803.0000 - val_fn: 2078.0000 - val_accuracy: 0.7899 - val_precision: 0.2231 - val_recall: 0.4304 - val_auc: 0.7420\n",
      "Epoch 19/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6620 - tp: 13480.0000 - fp: 57868.0000 - tn: 167187.0000 - fn: 12339.0000 - accuracy: 0.7202 - precision: 0.1889 - recall: 0.5221 - auc: 0.7048 - val_loss: 0.4433 - val_tp: 1591.0000 - val_fp: 5501.0000 - val_tn: 26769.0000 - val_fn: 2057.0000 - val_accuracy: 0.7896 - val_precision: 0.2243 - val_recall: 0.4361 - val_auc: 0.7435\n",
      "Epoch 20/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6576 - tp: 13756.0000 - fp: 58884.0000 - tn: 166171.0000 - fn: 12063.0000 - accuracy: 0.7172 - precision: 0.1894 - recall: 0.5328 - auc: 0.7077 - val_loss: 0.4424 - val_tp: 1601.0000 - val_fp: 5503.0000 - val_tn: 26767.0000 - val_fn: 2047.0000 - val_accuracy: 0.7898 - val_precision: 0.2254 - val_recall: 0.4389 - val_auc: 0.7444\n",
      "Epoch 21/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6569 - tp: 13762.0000 - fp: 58586.0000 - tn: 166469.0000 - fn: 12057.0000 - accuracy: 0.7184 - precision: 0.1902 - recall: 0.5330 - auc: 0.7078 - val_loss: 0.4374 - val_tp: 1558.0000 - val_fp: 5251.0000 - val_tn: 27019.0000 - val_fn: 2090.0000 - val_accuracy: 0.7956 - val_precision: 0.2288 - val_recall: 0.4271 - val_auc: 0.7456\n",
      "Epoch 22/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6495 - tp: 13992.0000 - fp: 58965.0000 - tn: 166090.0000 - fn: 11827.0000 - accuracy: 0.7178 - precision: 0.1918 - recall: 0.5419 - auc: 0.7130 - val_loss: 0.4382 - val_tp: 1572.0000 - val_fp: 5316.0000 - val_tn: 26954.0000 - val_fn: 2076.0000 - val_accuracy: 0.7942 - val_precision: 0.2282 - val_recall: 0.4309 - val_auc: 0.7466\n",
      "Epoch 23/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6519 - tp: 13934.0000 - fp: 59216.0000 - tn: 165839.0000 - fn: 11885.0000 - accuracy: 0.7166 - precision: 0.1905 - recall: 0.5397 - auc: 0.7102 - val_loss: 0.4391 - val_tp: 1601.0000 - val_fp: 5454.0000 - val_tn: 26816.0000 - val_fn: 2047.0000 - val_accuracy: 0.7912 - val_precision: 0.2269 - val_recall: 0.4389 - val_auc: 0.7472\n",
      "Epoch 24/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6484 - tp: 14040.0000 - fp: 59506.0000 - tn: 165549.0000 - fn: 11779.0000 - accuracy: 0.7159 - precision: 0.1909 - recall: 0.5438 - auc: 0.7130 - val_loss: 0.4392 - val_tp: 1617.0000 - val_fp: 5444.0000 - val_tn: 26826.0000 - val_fn: 2031.0000 - val_accuracy: 0.7919 - val_precision: 0.2290 - val_recall: 0.4433 - val_auc: 0.7481\n",
      "Epoch 25/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6443 - tp: 14303.0000 - fp: 60229.0000 - tn: 164826.0000 - fn: 11516.0000 - accuracy: 0.7140 - precision: 0.1919 - recall: 0.5540 - auc: 0.7156 - val_loss: 0.4395 - val_tp: 1632.0000 - val_fp: 5491.0000 - val_tn: 26779.0000 - val_fn: 2016.0000 - val_accuracy: 0.7910 - val_precision: 0.2291 - val_recall: 0.4474 - val_auc: 0.7485\n",
      "Epoch 26/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6444 - tp: 14159.0000 - fp: 60383.0000 - tn: 164672.0000 - fn: 11660.0000 - accuracy: 0.7128 - precision: 0.1899 - recall: 0.5484 - auc: 0.7145 - val_loss: 0.4347 - val_tp: 1577.0000 - val_fp: 5212.0000 - val_tn: 27058.0000 - val_fn: 2071.0000 - val_accuracy: 0.7972 - val_precision: 0.2323 - val_recall: 0.4323 - val_auc: 0.7491\n",
      "Epoch 27/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6421 - tp: 14272.0000 - fp: 60222.0000 - tn: 164833.0000 - fn: 11547.0000 - accuracy: 0.7139 - precision: 0.1916 - recall: 0.5528 - auc: 0.7161 - val_loss: 0.4348 - val_tp: 1580.0000 - val_fp: 5209.0000 - val_tn: 27061.0000 - val_fn: 2068.0000 - val_accuracy: 0.7974 - val_precision: 0.2327 - val_recall: 0.4331 - val_auc: 0.7498\n",
      "Epoch 28/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6408 - tp: 14307.0000 - fp: 60753.0000 - tn: 164302.0000 - fn: 11512.0000 - accuracy: 0.7119 - precision: 0.1906 - recall: 0.5541 - auc: 0.7166 - val_loss: 0.4402 - val_tp: 1660.0000 - val_fp: 5533.0000 - val_tn: 26737.0000 - val_fn: 1988.0000 - val_accuracy: 0.7906 - val_precision: 0.2308 - val_recall: 0.4550 - val_auc: 0.7501\n",
      "Epoch 29/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6383 - tp: 14535.0000 - fp: 61821.0000 - tn: 163234.0000 - fn: 11284.0000 - accuracy: 0.7086 - precision: 0.1904 - recall: 0.5630 - auc: 0.7181 - val_loss: 0.4316 - val_tp: 1567.0000 - val_fp: 5065.0000 - val_tn: 27205.0000 - val_fn: 2081.0000 - val_accuracy: 0.8010 - val_precision: 0.2363 - val_recall: 0.4296 - val_auc: 0.7509\n",
      "Epoch 30/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6347 - tp: 14470.0000 - fp: 60446.0000 - tn: 164609.0000 - fn: 11349.0000 - accuracy: 0.7138 - precision: 0.1931 - recall: 0.5604 - auc: 0.7213 - val_loss: 0.4335 - val_tp: 1580.0000 - val_fp: 5183.0000 - val_tn: 27087.0000 - val_fn: 2068.0000 - val_accuracy: 0.7981 - val_precision: 0.2336 - val_recall: 0.4331 - val_auc: 0.7510\n",
      "Epoch 31/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6348 - tp: 14571.0000 - fp: 60937.0000 - tn: 164118.0000 - fn: 11248.0000 - accuracy: 0.7123 - precision: 0.1930 - recall: 0.5644 - auc: 0.7203 - val_loss: 0.4331 - val_tp: 1587.0000 - val_fp: 5221.0000 - val_tn: 27049.0000 - val_fn: 2061.0000 - val_accuracy: 0.7973 - val_precision: 0.2331 - val_recall: 0.4350 - val_auc: 0.7512\n",
      "Epoch 32/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6312 - tp: 14731.0000 - fp: 61728.0000 - tn: 163327.0000 - fn: 11088.0000 - accuracy: 0.7098 - precision: 0.1927 - recall: 0.5705 - auc: 0.7232 - val_loss: 0.4288 - val_tp: 1509.0000 - val_fp: 4847.0000 - val_tn: 27423.0000 - val_fn: 2139.0000 - val_accuracy: 0.8055 - val_precision: 0.2374 - val_recall: 0.4137 - val_auc: 0.7519\n",
      "Epoch 33/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6320 - tp: 14782.0000 - fp: 61700.0000 - tn: 163355.0000 - fn: 11037.0000 - accuracy: 0.7101 - precision: 0.1933 - recall: 0.5725 - auc: 0.7218 - val_loss: 0.4332 - val_tp: 1582.0000 - val_fp: 5168.0000 - val_tn: 27102.0000 - val_fn: 2066.0000 - val_accuracy: 0.7986 - val_precision: 0.2344 - val_recall: 0.4337 - val_auc: 0.7519\n",
      "Epoch 34/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6296 - tp: 14885.0000 - fp: 62062.0000 - tn: 162993.0000 - fn: 10934.0000 - accuracy: 0.7090 - precision: 0.1934 - recall: 0.5765 - auc: 0.7235 - val_loss: 0.4304 - val_tp: 1552.0000 - val_fp: 5031.0000 - val_tn: 27239.0000 - val_fn: 2096.0000 - val_accuracy: 0.8016 - val_precision: 0.2358 - val_recall: 0.4254 - val_auc: 0.7521\n",
      "Epoch 35/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6281 - tp: 14916.0000 - fp: 62028.0000 - tn: 163027.0000 - fn: 10903.0000 - accuracy: 0.7093 - precision: 0.1939 - recall: 0.5777 - auc: 0.7244 - val_loss: 0.4314 - val_tp: 1578.0000 - val_fp: 5157.0000 - val_tn: 27113.0000 - val_fn: 2070.0000 - val_accuracy: 0.7988 - val_precision: 0.2343 - val_recall: 0.4326 - val_auc: 0.7517\n",
      "Epoch 36/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6247 - tp: 15071.0000 - fp: 62832.0000 - tn: 162223.0000 - fn: 10748.0000 - accuracy: 0.7067 - precision: 0.1935 - recall: 0.5837 - auc: 0.7268 - val_loss: 0.4347 - val_tp: 1615.0000 - val_fp: 5318.0000 - val_tn: 26952.0000 - val_fn: 2033.0000 - val_accuracy: 0.7953 - val_precision: 0.2329 - val_recall: 0.4427 - val_auc: 0.7521\n",
      "Epoch 37/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6257 - tp: 14908.0000 - fp: 62724.0000 - tn: 162331.0000 - fn: 10911.0000 - accuracy: 0.7065 - precision: 0.1920 - recall: 0.5774 - auc: 0.7254 - val_loss: 0.4305 - val_tp: 1553.0000 - val_fp: 5080.0000 - val_tn: 27190.0000 - val_fn: 2095.0000 - val_accuracy: 0.8002 - val_precision: 0.2341 - val_recall: 0.4257 - val_auc: 0.7524\n",
      "Epoch 38/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6241 - tp: 15116.0000 - fp: 62732.0000 - tn: 162323.0000 - fn: 10703.0000 - accuracy: 0.7073 - precision: 0.1942 - recall: 0.5855 - auc: 0.7268 - val_loss: 0.4259 - val_tp: 1475.0000 - val_fp: 4729.0000 - val_tn: 27541.0000 - val_fn: 2173.0000 - val_accuracy: 0.8078 - val_precision: 0.2377 - val_recall: 0.4043 - val_auc: 0.7525\n",
      "Epoch 39/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6237 - tp: 15064.0000 - fp: 62579.0000 - tn: 162476.0000 - fn: 10755.0000 - accuracy: 0.7077 - precision: 0.1940 - recall: 0.5834 - auc: 0.7269 - val_loss: 0.4295 - val_tp: 1552.0000 - val_fp: 5036.0000 - val_tn: 27234.0000 - val_fn: 2096.0000 - val_accuracy: 0.8014 - val_precision: 0.2356 - val_recall: 0.4254 - val_auc: 0.7526\n",
      "Epoch 40/250\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.6214 - tp: 15147.0000 - fp: 62821.0000 - tn: 162234.0000 - fn: 10672.0000 - accuracy: 0.7071 - precision: 0.1943 - recall: 0.5867 - auc: 0.7284 - val_loss: 0.4270 - val_tp: 1496.0000 - val_fp: 4786.0000 - val_tn: 27484.0000 - val_fn: 2152.0000 - val_accuracy: 0.8068 - val_precision: 0.2381 - val_recall: 0.4101 - val_auc: 0.7530\n",
      "Epoch 41/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6211 - tp: 15210.0000 - fp: 63050.0000 - tn: 162005.0000 - fn: 10609.0000 - accuracy: 0.7064 - precision: 0.1944 - recall: 0.5891 - auc: 0.7283 - val_loss: 0.4231 - val_tp: 1413.0000 - val_fp: 4463.0000 - val_tn: 27807.0000 - val_fn: 2235.0000 - val_accuracy: 0.8135 - val_precision: 0.2405 - val_recall: 0.3873 - val_auc: 0.7532\n",
      "Epoch 42/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6185 - tp: 15238.0000 - fp: 62988.0000 - tn: 162067.0000 - fn: 10581.0000 - accuracy: 0.7067 - precision: 0.1948 - recall: 0.5902 - auc: 0.7302 - val_loss: 0.4291 - val_tp: 1529.0000 - val_fp: 4956.0000 - val_tn: 27314.0000 - val_fn: 2119.0000 - val_accuracy: 0.8030 - val_precision: 0.2358 - val_recall: 0.4191 - val_auc: 0.7528\n",
      "Epoch 43/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6210 - tp: 15149.0000 - fp: 63510.0000 - tn: 161545.0000 - fn: 10670.0000 - accuracy: 0.7043 - precision: 0.1926 - recall: 0.5867 - auc: 0.7276 - val_loss: 0.4285 - val_tp: 1514.0000 - val_fp: 4883.0000 - val_tn: 27387.0000 - val_fn: 2134.0000 - val_accuracy: 0.8046 - val_precision: 0.2367 - val_recall: 0.4150 - val_auc: 0.7530\n",
      "Epoch 44/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6179 - tp: 15255.0000 - fp: 63429.0000 - tn: 161626.0000 - fn: 10564.0000 - accuracy: 0.7051 - precision: 0.1939 - recall: 0.5908 - auc: 0.7298 - val_loss: 0.4242 - val_tp: 1469.0000 - val_fp: 4589.0000 - val_tn: 27681.0000 - val_fn: 2179.0000 - val_accuracy: 0.8116 - val_precision: 0.2425 - val_recall: 0.4027 - val_auc: 0.7532\n",
      "Epoch 45/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6173 - tp: 15444.0000 - fp: 63887.0000 - tn: 161168.0000 - fn: 10375.0000 - accuracy: 0.7040 - precision: 0.1947 - recall: 0.5982 - auc: 0.7303 - val_loss: 0.4258 - val_tp: 1471.0000 - val_fp: 4655.0000 - val_tn: 27615.0000 - val_fn: 2177.0000 - val_accuracy: 0.8098 - val_precision: 0.2401 - val_recall: 0.4032 - val_auc: 0.7532\n",
      "Epoch 46/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6166 - tp: 15253.0000 - fp: 63110.0000 - tn: 161945.0000 - fn: 10566.0000 - accuracy: 0.7063 - precision: 0.1946 - recall: 0.5908 - auc: 0.7305 - val_loss: 0.4280 - val_tp: 1505.0000 - val_fp: 4850.0000 - val_tn: 27420.0000 - val_fn: 2143.0000 - val_accuracy: 0.8053 - val_precision: 0.2368 - val_recall: 0.4126 - val_auc: 0.7528\n",
      "Epoch 47/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6157 - tp: 15530.0000 - fp: 64518.0000 - tn: 160537.0000 - fn: 10289.0000 - accuracy: 0.7018 - precision: 0.1940 - recall: 0.6015 - auc: 0.7310 - val_loss: 0.4259 - val_tp: 1481.0000 - val_fp: 4736.0000 - val_tn: 27534.0000 - val_fn: 2167.0000 - val_accuracy: 0.8078 - val_precision: 0.2382 - val_recall: 0.4060 - val_auc: 0.7530\n",
      "Epoch 48/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6158 - tp: 15368.0000 - fp: 64049.0000 - tn: 161006.0000 - fn: 10451.0000 - accuracy: 0.7030 - precision: 0.1935 - recall: 0.5952 - auc: 0.7304 - val_loss: 0.4229 - val_tp: 1389.0000 - val_fp: 4365.0000 - val_tn: 27905.0000 - val_fn: 2259.0000 - val_accuracy: 0.8156 - val_precision: 0.2414 - val_recall: 0.3808 - val_auc: 0.7537\n",
      "Epoch 49/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6139 - tp: 15565.0000 - fp: 64518.0000 - tn: 160537.0000 - fn: 10254.0000 - accuracy: 0.7020 - precision: 0.1944 - recall: 0.6029 - auc: 0.7320 - val_loss: 0.4223 - val_tp: 1397.0000 - val_fp: 4367.0000 - val_tn: 27903.0000 - val_fn: 2251.0000 - val_accuracy: 0.8157 - val_precision: 0.2424 - val_recall: 0.3829 - val_auc: 0.7536\n",
      "Epoch 50/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6126 - tp: 15658.0000 - fp: 64983.0000 - tn: 160072.0000 - fn: 10161.0000 - accuracy: 0.7005 - precision: 0.1942 - recall: 0.6065 - auc: 0.7326 - val_loss: 0.4244 - val_tp: 1431.0000 - val_fp: 4543.0000 - val_tn: 27727.0000 - val_fn: 2217.0000 - val_accuracy: 0.8118 - val_precision: 0.2395 - val_recall: 0.3923 - val_auc: 0.7533\n",
      "Epoch 51/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6138 - tp: 15579.0000 - fp: 65025.0000 - tn: 160030.0000 - fn: 10240.0000 - accuracy: 0.7000 - precision: 0.1933 - recall: 0.6034 - auc: 0.7313 - val_loss: 0.4258 - val_tp: 1455.0000 - val_fp: 4612.0000 - val_tn: 27658.0000 - val_fn: 2193.0000 - val_accuracy: 0.8105 - val_precision: 0.2398 - val_recall: 0.3988 - val_auc: 0.7530\n",
      "Epoch 52/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6121 - tp: 15668.0000 - fp: 65264.0000 - tn: 159791.0000 - fn: 10151.0000 - accuracy: 0.6994 - precision: 0.1936 - recall: 0.6068 - auc: 0.7323 - val_loss: 0.4266 - val_tp: 1470.0000 - val_fp: 4689.0000 - val_tn: 27581.0000 - val_fn: 2178.0000 - val_accuracy: 0.8088 - val_precision: 0.2387 - val_recall: 0.4030 - val_auc: 0.7531\n",
      "Epoch 53/250\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6125 - tp: 15584.0000 - fp: 65104.0000 - tn: 159951.0000 - fn: 10235.0000 - accuracy: 0.6997 - precision: 0.1931 - recall: 0.6036 - auc: 0.7318 - val_loss: 0.4218 - val_tp: 1370.0000 - val_fp: 4276.0000 - val_tn: 27994.0000 - val_fn: 2278.0000 - val_accuracy: 0.8175 - val_precision: 0.2426 - val_recall: 0.3755 - val_auc: 0.7538\n",
      "Epoch 54/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6114 - tp: 15692.0000 - fp: 65449.0000 - tn: 159606.0000 - fn: 10127.0000 - accuracy: 0.6987 - precision: 0.1934 - recall: 0.6078 - auc: 0.7325 - val_loss: 0.4202 - val_tp: 1318.0000 - val_fp: 4022.0000 - val_tn: 28248.0000 - val_fn: 2330.0000 - val_accuracy: 0.8232 - val_precision: 0.2468 - val_recall: 0.3613 - val_auc: 0.7540\n",
      "Epoch 55/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6088 - tp: 15855.0000 - fp: 65699.0000 - tn: 159356.0000 - fn: 9964.0000 - accuracy: 0.6984 - precision: 0.1944 - recall: 0.6141 - auc: 0.7347 - val_loss: 0.4206 - val_tp: 1362.0000 - val_fp: 4220.0000 - val_tn: 28050.0000 - val_fn: 2286.0000 - val_accuracy: 0.8189 - val_precision: 0.2440 - val_recall: 0.3734 - val_auc: 0.7541\n",
      "Epoch 56/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6096 - tp: 15811.0000 - fp: 65694.0000 - tn: 159361.0000 - fn: 10008.0000 - accuracy: 0.6982 - precision: 0.1940 - recall: 0.6124 - auc: 0.7337 - val_loss: 0.4198 - val_tp: 1344.0000 - val_fp: 4183.0000 - val_tn: 28087.0000 - val_fn: 2304.0000 - val_accuracy: 0.8194 - val_precision: 0.2432 - val_recall: 0.3684 - val_auc: 0.7537\n",
      "Epoch 57/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6079 - tp: 15752.0000 - fp: 65568.0000 - tn: 159487.0000 - fn: 10067.0000 - accuracy: 0.6985 - precision: 0.1937 - recall: 0.6101 - auc: 0.7351 - val_loss: 0.4206 - val_tp: 1330.0000 - val_fp: 4132.0000 - val_tn: 28138.0000 - val_fn: 2318.0000 - val_accuracy: 0.8204 - val_precision: 0.2435 - val_recall: 0.3646 - val_auc: 0.7537\n",
      "Epoch 58/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6083 - tp: 15837.0000 - fp: 65883.0000 - tn: 159172.0000 - fn: 9982.0000 - accuracy: 0.6976 - precision: 0.1938 - recall: 0.6134 - auc: 0.7346 - val_loss: 0.4225 - val_tp: 1364.0000 - val_fp: 4308.0000 - val_tn: 27962.0000 - val_fn: 2284.0000 - val_accuracy: 0.8165 - val_precision: 0.2405 - val_recall: 0.3739 - val_auc: 0.7533\n",
      "Epoch 59/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6077 - tp: 15982.0000 - fp: 66217.0000 - tn: 158838.0000 - fn: 9837.0000 - accuracy: 0.6968 - precision: 0.1944 - recall: 0.6190 - auc: 0.7351 - val_loss: 0.4179 - val_tp: 1312.0000 - val_fp: 4025.0000 - val_tn: 28245.0000 - val_fn: 2336.0000 - val_accuracy: 0.8229 - val_precision: 0.2458 - val_recall: 0.3596 - val_auc: 0.7537\n",
      "Epoch 60/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6048 - tp: 15936.0000 - fp: 65333.0000 - tn: 159722.0000 - fn: 9883.0000 - accuracy: 0.7002 - precision: 0.1961 - recall: 0.6172 - auc: 0.7374 - val_loss: 0.4201 - val_tp: 1339.0000 - val_fp: 4123.0000 - val_tn: 28147.0000 - val_fn: 2309.0000 - val_accuracy: 0.8209 - val_precision: 0.2451 - val_recall: 0.3671 - val_auc: 0.7538\n",
      "Epoch 61/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6063 - tp: 15961.0000 - fp: 66670.0000 - tn: 158385.0000 - fn: 9858.0000 - accuracy: 0.6950 - precision: 0.1932 - recall: 0.6182 - auc: 0.7358 - val_loss: 0.4139 - val_tp: 1221.0000 - val_fp: 3708.0000 - val_tn: 28562.0000 - val_fn: 2427.0000 - val_accuracy: 0.8292 - val_precision: 0.2477 - val_recall: 0.3347 - val_auc: 0.7538\n",
      "Epoch 62/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6060 - tp: 16001.0000 - fp: 65508.0000 - tn: 159547.0000 - fn: 9818.0000 - accuracy: 0.6997 - precision: 0.1963 - recall: 0.6197 - auc: 0.7363 - val_loss: 0.4213 - val_tp: 1335.0000 - val_fp: 4162.0000 - val_tn: 28108.0000 - val_fn: 2313.0000 - val_accuracy: 0.8197 - val_precision: 0.2429 - val_recall: 0.3660 - val_auc: 0.7540\n",
      "Epoch 63/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6038 - tp: 16165.0000 - fp: 66960.0000 - tn: 158095.0000 - fn: 9654.0000 - accuracy: 0.6946 - precision: 0.1945 - recall: 0.6261 - auc: 0.7378 - val_loss: 0.4212 - val_tp: 1371.0000 - val_fp: 4329.0000 - val_tn: 27941.0000 - val_fn: 2277.0000 - val_accuracy: 0.8161 - val_precision: 0.2405 - val_recall: 0.3758 - val_auc: 0.7530\n",
      "Epoch 64/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6045 - tp: 16076.0000 - fp: 66433.0000 - tn: 158622.0000 - fn: 9743.0000 - accuracy: 0.6964 - precision: 0.1948 - recall: 0.6226 - auc: 0.7370 - val_loss: 0.4221 - val_tp: 1356.0000 - val_fp: 4246.0000 - val_tn: 28024.0000 - val_fn: 2292.0000 - val_accuracy: 0.8180 - val_precision: 0.2421 - val_recall: 0.3717 - val_auc: 0.7536\n",
      "Epoch 65/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6025 - tp: 16162.0000 - fp: 66870.0000 - tn: 158185.0000 - fn: 9657.0000 - accuracy: 0.6950 - precision: 0.1946 - recall: 0.6260 - auc: 0.7384 - val_loss: 0.4182 - val_tp: 1281.0000 - val_fp: 3969.0000 - val_tn: 28301.0000 - val_fn: 2367.0000 - val_accuracy: 0.8236 - val_precision: 0.2440 - val_recall: 0.3512 - val_auc: 0.7537\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 2s 66ms/step - loss: 0.9033 - tp: 10656.0000 - fp: 52064.0000 - tn: 205261.0000 - fn: 18811.0000 - accuracy: 0.7529 - precision: 0.1699 - recall: 0.3616 - auc: 0.6328 - val_loss: 0.4847 - val_tp: 1715.0000 - val_fp: 7026.0000 - val_tn: 25244.0000 - val_fn: 1933.0000 - val_accuracy: 0.7506 - val_precision: 0.1962 - val_recall: 0.4701 - val_auc: 0.7117\n",
      "Epoch 2/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6965 - tp: 12195.0000 - fp: 56127.0000 - tn: 168928.0000 - fn: 13624.0000 - accuracy: 0.7220 - precision: 0.1785 - recall: 0.4723 - auc: 0.6788 - val_loss: 0.4724 - val_tp: 1786.0000 - val_fp: 6530.0000 - val_tn: 25740.0000 - val_fn: 1862.0000 - val_accuracy: 0.7664 - val_precision: 0.2148 - val_recall: 0.4896 - val_auc: 0.7376\n",
      "Epoch 3/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6525 - tp: 13798.0000 - fp: 59137.0000 - tn: 165918.0000 - fn: 12021.0000 - accuracy: 0.7164 - precision: 0.1892 - recall: 0.5344 - auc: 0.7069 - val_loss: 0.4619 - val_tp: 1788.0000 - val_fp: 6255.0000 - val_tn: 26015.0000 - val_fn: 1860.0000 - val_accuracy: 0.7741 - val_precision: 0.2223 - val_recall: 0.4901 - val_auc: 0.7447\n",
      "Epoch 4/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6327 - tp: 14601.0000 - fp: 61779.0000 - tn: 163276.0000 - fn: 11218.0000 - accuracy: 0.7090 - precision: 0.1912 - recall: 0.5655 - auc: 0.7183 - val_loss: 0.4632 - val_tp: 1831.0000 - val_fp: 6412.0000 - val_tn: 25858.0000 - val_fn: 1817.0000 - val_accuracy: 0.7709 - val_precision: 0.2221 - val_recall: 0.5019 - val_auc: 0.7496\n",
      "Epoch 5/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6199 - tp: 15336.0000 - fp: 64497.0000 - tn: 160558.0000 - fn: 10483.0000 - accuracy: 0.7011 - precision: 0.1921 - recall: 0.5940 - auc: 0.7258 - val_loss: 0.4526 - val_tp: 1703.0000 - val_fp: 5744.0000 - val_tn: 26526.0000 - val_fn: 1945.0000 - val_accuracy: 0.7859 - val_precision: 0.2287 - val_recall: 0.4668 - val_auc: 0.7513\n",
      "Epoch 6/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6108 - tp: 15915.0000 - fp: 66219.0000 - tn: 158836.0000 - fn: 9904.0000 - accuracy: 0.6966 - precision: 0.1938 - recall: 0.6164 - auc: 0.7322 - val_loss: 0.4475 - val_tp: 1648.0000 - val_fp: 5465.0000 - val_tn: 26805.0000 - val_fn: 2000.0000 - val_accuracy: 0.7922 - val_precision: 0.2317 - val_recall: 0.4518 - val_auc: 0.7529\n",
      "Epoch 7/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6090 - tp: 16156.0000 - fp: 67919.0000 - tn: 157136.0000 - fn: 9663.0000 - accuracy: 0.6908 - precision: 0.1922 - recall: 0.6257 - auc: 0.7317 - val_loss: 0.4600 - val_tp: 1782.0000 - val_fp: 6203.0000 - val_tn: 26067.0000 - val_fn: 1866.0000 - val_accuracy: 0.7753 - val_precision: 0.2232 - val_recall: 0.4885 - val_auc: 0.7521\n",
      "Epoch 8/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6030 - tp: 16577.0000 - fp: 69255.0000 - tn: 155800.0000 - fn: 9242.0000 - accuracy: 0.6871 - precision: 0.1931 - recall: 0.6420 - auc: 0.7366 - val_loss: 0.4424 - val_tp: 1559.0000 - val_fp: 5013.0000 - val_tn: 27257.0000 - val_fn: 2089.0000 - val_accuracy: 0.8023 - val_precision: 0.2372 - val_recall: 0.4274 - val_auc: 0.7529\n",
      "Epoch 9/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6006 - tp: 16679.0000 - fp: 69434.0000 - tn: 155621.0000 - fn: 9140.0000 - accuracy: 0.6868 - precision: 0.1937 - recall: 0.6460 - auc: 0.7384 - val_loss: 0.4559 - val_tp: 1785.0000 - val_fp: 6060.0000 - val_tn: 26210.0000 - val_fn: 1863.0000 - val_accuracy: 0.7794 - val_precision: 0.2275 - val_recall: 0.4893 - val_auc: 0.7523\n",
      "Epoch 10/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5974 - tp: 17182.0000 - fp: 71710.0000 - tn: 153345.0000 - fn: 8637.0000 - accuracy: 0.6797 - precision: 0.1933 - recall: 0.6655 - auc: 0.7404 - val_loss: 0.4539 - val_tp: 1727.0000 - val_fp: 5915.0000 - val_tn: 26355.0000 - val_fn: 1921.0000 - val_accuracy: 0.7818 - val_precision: 0.2260 - val_recall: 0.4734 - val_auc: 0.7514\n",
      "Epoch 11/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5952 - tp: 17354.0000 - fp: 72255.0000 - tn: 152800.0000 - fn: 8465.0000 - accuracy: 0.6782 - precision: 0.1937 - recall: 0.6721 - auc: 0.7424 - val_loss: 0.4371 - val_tp: 1369.0000 - val_fp: 4310.0000 - val_tn: 27960.0000 - val_fn: 2279.0000 - val_accuracy: 0.8166 - val_precision: 0.2411 - val_recall: 0.3753 - val_auc: 0.7528\n",
      "Epoch 12/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5938 - tp: 17476.0000 - fp: 72733.0000 - tn: 152322.0000 - fn: 8343.0000 - accuracy: 0.6768 - precision: 0.1937 - recall: 0.6769 - auc: 0.7432 - val_loss: 0.4486 - val_tp: 1586.0000 - val_fp: 5214.0000 - val_tn: 27056.0000 - val_fn: 2062.0000 - val_accuracy: 0.7974 - val_precision: 0.2332 - val_recall: 0.4348 - val_auc: 0.7528\n",
      "Epoch 13/250\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.5905 - tp: 17947.0000 - fp: 74260.0000 - tn: 150795.0000 - fn: 7872.0000 - accuracy: 0.6726 - precision: 0.1946 - recall: 0.6951 - auc: 0.7467 - val_loss: 0.4450 - val_tp: 1575.0000 - val_fp: 5059.0000 - val_tn: 27211.0000 - val_fn: 2073.0000 - val_accuracy: 0.8014 - val_precision: 0.2374 - val_recall: 0.4317 - val_auc: 0.7520\n",
      "Epoch 14/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.5909 - tp: 17922.0000 - fp: 74374.0000 - tn: 150681.0000 - fn: 7897.0000 - accuracy: 0.6721 - precision: 0.1942 - recall: 0.6941 - auc: 0.7461 - val_loss: 0.4526 - val_tp: 1585.0000 - val_fp: 5205.0000 - val_tn: 27065.0000 - val_fn: 2063.0000 - val_accuracy: 0.7977 - val_precision: 0.2334 - val_recall: 0.4345 - val_auc: 0.7514\n",
      "Epoch 15/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5895 - tp: 18192.0000 - fp: 75389.0000 - tn: 149666.0000 - fn: 7627.0000 - accuracy: 0.6691 - precision: 0.1944 - recall: 0.7046 - auc: 0.7485 - val_loss: 0.4410 - val_tp: 1335.0000 - val_fp: 4147.0000 - val_tn: 28123.0000 - val_fn: 2313.0000 - val_accuracy: 0.8201 - val_precision: 0.2435 - val_recall: 0.3660 - val_auc: 0.7524\n",
      "Epoch 16/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5884 - tp: 18363.0000 - fp: 76158.0000 - tn: 148897.0000 - fn: 7456.0000 - accuracy: 0.6667 - precision: 0.1943 - recall: 0.7112 - auc: 0.7486 - val_loss: 0.4533 - val_tp: 1618.0000 - val_fp: 5490.0000 - val_tn: 26780.0000 - val_fn: 2030.0000 - val_accuracy: 0.7906 - val_precision: 0.2276 - val_recall: 0.4435 - val_auc: 0.7492\n",
      "Epoch 17/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5884 - tp: 18435.0000 - fp: 76210.0000 - tn: 148845.0000 - fn: 7384.0000 - accuracy: 0.6668 - precision: 0.1948 - recall: 0.7140 - auc: 0.7493 - val_loss: 0.4445 - val_tp: 1405.0000 - val_fp: 4424.0000 - val_tn: 27846.0000 - val_fn: 2243.0000 - val_accuracy: 0.8144 - val_precision: 0.2410 - val_recall: 0.3851 - val_auc: 0.7518\n",
      "Epoch 18/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5874 - tp: 18619.0000 - fp: 77236.0000 - tn: 147819.0000 - fn: 7200.0000 - accuracy: 0.6634 - precision: 0.1942 - recall: 0.7211 - auc: 0.7498 - val_loss: 0.4398 - val_tp: 1294.0000 - val_fp: 3936.0000 - val_tn: 28334.0000 - val_fn: 2354.0000 - val_accuracy: 0.8249 - val_precision: 0.2474 - val_recall: 0.3547 - val_auc: 0.7518\n",
      "Epoch 1/250\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 0.9686 - tp: 12359.0000 - fp: 66619.0000 - tn: 190706.0000 - fn: 17108.0000 - accuracy: 0.7081 - precision: 0.1565 - recall: 0.4194 - auc: 0.6207 - val_loss: 0.5639 - val_tp: 2377.0000 - val_fp: 10415.0000 - val_tn: 21855.0000 - val_fn: 1271.0000 - val_accuracy: 0.6746 - val_precision: 0.1858 - val_recall: 0.6516 - val_auc: 0.7202\n",
      "Epoch 2/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6234 - tp: 17378.0000 - fp: 80583.0000 - tn: 144472.0000 - fn: 8441.0000 - accuracy: 0.6451 - precision: 0.1774 - recall: 0.6731 - auc: 0.7122 - val_loss: 0.5595 - val_tp: 2543.0000 - val_fp: 10522.0000 - val_tn: 21748.0000 - val_fn: 1105.0000 - val_accuracy: 0.6763 - val_precision: 0.1946 - val_recall: 0.6971 - val_auc: 0.7446\n",
      "Epoch 3/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6046 - tp: 18366.0000 - fp: 81499.0000 - tn: 143556.0000 - fn: 7453.0000 - accuracy: 0.6454 - precision: 0.1839 - recall: 0.7113 - auc: 0.7323 - val_loss: 0.4821 - val_tp: 2003.0000 - val_fp: 7336.0000 - val_tn: 24934.0000 - val_fn: 1645.0000 - val_accuracy: 0.7500 - val_precision: 0.2145 - val_recall: 0.5491 - val_auc: 0.7458\n",
      "Epoch 4/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6023 - tp: 18137.0000 - fp: 79346.0000 - tn: 145709.0000 - fn: 7682.0000 - accuracy: 0.6531 - precision: 0.1861 - recall: 0.7025 - auc: 0.7348 - val_loss: 0.5430 - val_tp: 2405.0000 - val_fp: 9536.0000 - val_tn: 22734.0000 - val_fn: 1243.0000 - val_accuracy: 0.6999 - val_precision: 0.2014 - val_recall: 0.6593 - val_auc: 0.7487\n",
      "Epoch 5/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5981 - tp: 18458.0000 - fp: 79866.0000 - tn: 145189.0000 - fn: 7361.0000 - accuracy: 0.6523 - precision: 0.1877 - recall: 0.7149 - auc: 0.7393 - val_loss: 0.4644 - val_tp: 1419.0000 - val_fp: 4516.0000 - val_tn: 27754.0000 - val_fn: 2229.0000 - val_accuracy: 0.8122 - val_precision: 0.2391 - val_recall: 0.3890 - val_auc: 0.7504\n",
      "Epoch 6/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5976 - tp: 18445.0000 - fp: 79900.0000 - tn: 145155.0000 - fn: 7374.0000 - accuracy: 0.6521 - precision: 0.1876 - recall: 0.7144 - auc: 0.7398 - val_loss: 0.4965 - val_tp: 2167.0000 - val_fp: 7998.0000 - val_tn: 24272.0000 - val_fn: 1481.0000 - val_accuracy: 0.7361 - val_precision: 0.2132 - val_recall: 0.5940 - val_auc: 0.7515\n",
      "Epoch 7/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5954 - tp: 18609.0000 - fp: 79760.0000 - tn: 145295.0000 - fn: 7210.0000 - accuracy: 0.6533 - precision: 0.1892 - recall: 0.7207 - auc: 0.7426 - val_loss: 0.5179 - val_tp: 2249.0000 - val_fp: 8649.0000 - val_tn: 23621.0000 - val_fn: 1399.0000 - val_accuracy: 0.7203 - val_precision: 0.2064 - val_recall: 0.6165 - val_auc: 0.7521\n",
      "Epoch 8/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5940 - tp: 18892.0000 - fp: 80918.0000 - tn: 144137.0000 - fn: 6927.0000 - accuracy: 0.6498 - precision: 0.1893 - recall: 0.7317 - auc: 0.7447 - val_loss: 0.4832 - val_tp: 2037.0000 - val_fp: 7386.0000 - val_tn: 24884.0000 - val_fn: 1611.0000 - val_accuracy: 0.7495 - val_precision: 0.2162 - val_recall: 0.5584 - val_auc: 0.7508\n",
      "Epoch 9/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5935 - tp: 18868.0000 - fp: 80632.0000 - tn: 144423.0000 - fn: 6951.0000 - accuracy: 0.6509 - precision: 0.1896 - recall: 0.7308 - auc: 0.7456 - val_loss: 0.4651 - val_tp: 1713.0000 - val_fp: 5815.0000 - val_tn: 26455.0000 - val_fn: 1935.0000 - val_accuracy: 0.7842 - val_precision: 0.2276 - val_recall: 0.4696 - val_auc: 0.7506\n",
      "Epoch 10/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5918 - tp: 18850.0000 - fp: 80288.0000 - tn: 144767.0000 - fn: 6969.0000 - accuracy: 0.6522 - precision: 0.1901 - recall: 0.7301 - auc: 0.7467 - val_loss: 0.4657 - val_tp: 1492.0000 - val_fp: 4918.0000 - val_tn: 27352.0000 - val_fn: 2156.0000 - val_accuracy: 0.8031 - val_precision: 0.2328 - val_recall: 0.4090 - val_auc: 0.7464\n",
      "Epoch 11/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5940 - tp: 18600.0000 - fp: 78619.0000 - tn: 146436.0000 - fn: 7219.0000 - accuracy: 0.6578 - precision: 0.1913 - recall: 0.7204 - auc: 0.7461 - val_loss: 0.4667 - val_tp: 1504.0000 - val_fp: 4922.0000 - val_tn: 27348.0000 - val_fn: 2144.0000 - val_accuracy: 0.8033 - val_precision: 0.2340 - val_recall: 0.4123 - val_auc: 0.7488\n",
      "Epoch 12/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5923 - tp: 18869.0000 - fp: 80152.0000 - tn: 144903.0000 - fn: 6950.0000 - accuracy: 0.6528 - precision: 0.1906 - recall: 0.7308 - auc: 0.7466 - val_loss: 0.4688 - val_tp: 1544.0000 - val_fp: 5102.0000 - val_tn: 27168.0000 - val_fn: 2104.0000 - val_accuracy: 0.7994 - val_precision: 0.2323 - val_recall: 0.4232 - val_auc: 0.7485\n",
      "Epoch 13/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5928 - tp: 18802.0000 - fp: 79677.0000 - tn: 145378.0000 - fn: 7017.0000 - accuracy: 0.6544 - precision: 0.1909 - recall: 0.7282 - auc: 0.7467 - val_loss: 0.4492 - val_tp: 1656.0000 - val_fp: 5661.0000 - val_tn: 26609.0000 - val_fn: 1992.0000 - val_accuracy: 0.7869 - val_precision: 0.2263 - val_recall: 0.4539 - val_auc: 0.7478\n",
      "Epoch 14/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5922 - tp: 18938.0000 - fp: 80322.0000 - tn: 144733.0000 - fn: 6881.0000 - accuracy: 0.6524 - precision: 0.1908 - recall: 0.7335 - auc: 0.7469 - val_loss: 0.4564 - val_tp: 1101.0000 - val_fp: 3385.0000 - val_tn: 28885.0000 - val_fn: 2547.0000 - val_accuracy: 0.8348 - val_precision: 0.2454 - val_recall: 0.3018 - val_auc: 0.7461\n",
      "Epoch 15/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5908 - tp: 19032.0000 - fp: 79686.0000 - tn: 145369.0000 - fn: 6787.0000 - accuracy: 0.6553 - precision: 0.1928 - recall: 0.7371 - auc: 0.7490 - val_loss: 0.4556 - val_tp: 1230.0000 - val_fp: 3666.0000 - val_tn: 28604.0000 - val_fn: 2418.0000 - val_accuracy: 0.8306 - val_precision: 0.2512 - val_recall: 0.3372 - val_auc: 0.7467\n",
      "Epoch 16/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5922 - tp: 18649.0000 - fp: 78170.0000 - tn: 146885.0000 - fn: 7170.0000 - accuracy: 0.6598 - precision: 0.1926 - recall: 0.7223 - auc: 0.7473 - val_loss: 0.4425 - val_tp: 1448.0000 - val_fp: 4683.0000 - val_tn: 27587.0000 - val_fn: 2200.0000 - val_accuracy: 0.8084 - val_precision: 0.2362 - val_recall: 0.3969 - val_auc: 0.7452\n",
      "Epoch 17/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5892 - tp: 19133.0000 - fp: 80435.0000 - tn: 144620.0000 - fn: 6686.0000 - accuracy: 0.6527 - precision: 0.1922 - recall: 0.7410 - auc: 0.7508 - val_loss: 0.4804 - val_tp: 1454.0000 - val_fp: 4639.0000 - val_tn: 27631.0000 - val_fn: 2194.0000 - val_accuracy: 0.8098 - val_precision: 0.2386 - val_recall: 0.3986 - val_auc: 0.7487\n",
      "Epoch 1/250\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 16.5241 - tp: 17729.0000 - fp: 114075.0000 - tn: 143250.0000 - fn: 11738.0000 - accuracy: 0.5613 - precision: 0.1345 - recall: 0.6017 - auc: 0.5800 - val_loss: 0.8933 - val_tp: 2507.0000 - val_fp: 12225.0000 - val_tn: 20045.0000 - val_fn: 1141.0000 - val_accuracy: 0.6279 - val_precision: 0.1702 - val_recall: 0.6872 - val_auc: 0.6757\n",
      "Epoch 2/250\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.1739 - tp: 21754.0000 - fp: 140142.0000 - tn: 84913.0000 - fn: 4065.0000 - accuracy: 0.4252 - precision: 0.1344 - recall: 0.8426 - auc: 0.6017 - val_loss: 0.5822 - val_tp: 2913.0000 - val_fp: 16226.0000 - val_tn: 16044.0000 - val_fn: 735.0000 - val_accuracy: 0.5278 - val_precision: 0.1522 - val_recall: 0.7985 - val_auc: 0.6737\n",
      "Epoch 3/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6933 - tp: 23206.0000 - fp: 152903.0000 - tn: 72152.0000 - fn: 2613.0000 - accuracy: 0.3801 - precision: 0.1318 - recall: 0.8988 - auc: 0.6149 - val_loss: 0.6045 - val_tp: 3070.0000 - val_fp: 18184.0000 - val_tn: 14086.0000 - val_fn: 578.0000 - val_accuracy: 0.4776 - val_precision: 0.1444 - val_recall: 0.8416 - val_auc: 0.6686\n",
      "Epoch 4/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6654 - tp: 23525.0000 - fp: 153010.0000 - tn: 72045.0000 - fn: 2294.0000 - accuracy: 0.3809 - precision: 0.1333 - recall: 0.9112 - auc: 0.6262 - val_loss: 0.5704 - val_tp: 3026.0000 - val_fp: 16860.0000 - val_tn: 15410.0000 - val_fn: 622.0000 - val_accuracy: 0.5133 - val_precision: 0.1522 - val_recall: 0.8295 - val_auc: 0.6910\n",
      "Epoch 5/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6580 - tp: 23731.0000 - fp: 153041.0000 - tn: 72014.0000 - fn: 2088.0000 - accuracy: 0.3816 - precision: 0.1342 - recall: 0.9191 - auc: 0.6326 - val_loss: 1.1114 - val_tp: 3511.0000 - val_fp: 28528.0000 - val_tn: 3742.0000 - val_fn: 137.0000 - val_accuracy: 0.2019 - val_precision: 0.1096 - val_recall: 0.9624 - val_auc: 0.4412\n",
      "Epoch 6/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 34ms/step - loss: 0.8394 - tp: 20242.0000 - fp: 136156.0000 - tn: 88899.0000 - fn: 5577.0000 - accuracy: 0.4350 - precision: 0.1294 - recall: 0.7840 - auc: 0.6022 - val_loss: 0.5240 - val_tp: 2901.0000 - val_fp: 15641.0000 - val_tn: 16629.0000 - val_fn: 747.0000 - val_accuracy: 0.5437 - val_precision: 0.1565 - val_recall: 0.7952 - val_auc: 0.6737\n",
      "Epoch 7/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6700 - tp: 23179.0000 - fp: 154315.0000 - tn: 70740.0000 - fn: 2640.0000 - accuracy: 0.3744 - precision: 0.1306 - recall: 0.8977 - auc: 0.6158 - val_loss: 0.6459 - val_tp: 3360.0000 - val_fp: 21593.0000 - val_tn: 10677.0000 - val_fn: 288.0000 - val_accuracy: 0.3908 - val_precision: 0.1347 - val_recall: 0.9211 - val_auc: 0.6428\n",
      "Epoch 8/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6521 - tp: 24307.0000 - fp: 160379.0000 - tn: 64676.0000 - fn: 1512.0000 - accuracy: 0.3547 - precision: 0.1316 - recall: 0.9414 - auc: 0.6282 - val_loss: 0.6405 - val_tp: 3290.0000 - val_fp: 20025.0000 - val_tn: 12245.0000 - val_fn: 358.0000 - val_accuracy: 0.4325 - val_precision: 0.1411 - val_recall: 0.9019 - val_auc: 0.6777\n",
      "Epoch 9/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6452 - tp: 24030.0000 - fp: 154030.0000 - tn: 71025.0000 - fn: 1789.0000 - accuracy: 0.3789 - precision: 0.1350 - recall: 0.9307 - auc: 0.6440 - val_loss: 0.9211 - val_tp: 3574.0000 - val_fp: 29207.0000 - val_tn: 3063.0000 - val_fn: 74.0000 - val_accuracy: 0.1848 - val_precision: 0.1090 - val_recall: 0.9797 - val_auc: 0.4881\n",
      "Epoch 10/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.7051 - tp: 21321.0000 - fp: 141575.0000 - tn: 83480.0000 - fn: 4498.0000 - accuracy: 0.4177 - precision: 0.1309 - recall: 0.8258 - auc: 0.6121 - val_loss: 0.6056 - val_tp: 3273.0000 - val_fp: 19963.0000 - val_tn: 12307.0000 - val_fn: 375.0000 - val_accuracy: 0.4338 - val_precision: 0.1409 - val_recall: 0.8972 - val_auc: 0.6718\n",
      "Epoch 11/250\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6494 - tp: 24141.0000 - fp: 158119.0000 - tn: 66936.0000 - fn: 1678.0000 - accuracy: 0.3630 - precision: 0.1325 - recall: 0.9350 - auc: 0.6247 - val_loss: 0.6100 - val_tp: 3253.0000 - val_fp: 19272.0000 - val_tn: 12998.0000 - val_fn: 395.0000 - val_accuracy: 0.4524 - val_precision: 0.1444 - val_recall: 0.8917 - val_auc: 0.6880\n",
      "Epoch 12/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6443 - tp: 23867.0000 - fp: 152145.0000 - tn: 72910.0000 - fn: 1952.0000 - accuracy: 0.3858 - precision: 0.1356 - recall: 0.9244 - auc: 0.6416 - val_loss: 0.6184 - val_tp: 3204.0000 - val_fp: 18470.0000 - val_tn: 13800.0000 - val_fn: 444.0000 - val_accuracy: 0.4734 - val_precision: 0.1478 - val_recall: 0.8783 - val_auc: 0.6962\n",
      "Epoch 13/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6381 - tp: 23801.0000 - fp: 148932.0000 - tn: 76123.0000 - fn: 2018.0000 - accuracy: 0.3983 - precision: 0.1378 - recall: 0.9218 - auc: 0.6484 - val_loss: 0.6280 - val_tp: 3247.0000 - val_fp: 19134.0000 - val_tn: 13136.0000 - val_fn: 401.0000 - val_accuracy: 0.4561 - val_precision: 0.1451 - val_recall: 0.8901 - val_auc: 0.6918\n",
      "Epoch 14/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6408 - tp: 23684.0000 - fp: 147447.0000 - tn: 77608.0000 - fn: 2135.0000 - accuracy: 0.4038 - precision: 0.1384 - recall: 0.9173 - auc: 0.6573 - val_loss: 0.5709 - val_tp: 3095.0000 - val_fp: 17039.0000 - val_tn: 15231.0000 - val_fn: 553.0000 - val_accuracy: 0.5102 - val_precision: 0.1537 - val_recall: 0.8484 - val_auc: 0.6995\n",
      "Epoch 15/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6367 - tp: 23549.0000 - fp: 144314.0000 - tn: 80741.0000 - fn: 2270.0000 - accuracy: 0.4157 - precision: 0.1403 - recall: 0.9121 - auc: 0.6579 - val_loss: 0.6416 - val_tp: 3255.0000 - val_fp: 19193.0000 - val_tn: 13077.0000 - val_fn: 393.0000 - val_accuracy: 0.4547 - val_precision: 0.1450 - val_recall: 0.8923 - val_auc: 0.7035\n",
      "Epoch 16/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6367 - tp: 23478.0000 - fp: 144301.0000 - tn: 80754.0000 - fn: 2341.0000 - accuracy: 0.4155 - precision: 0.1399 - recall: 0.9093 - auc: 0.6629 - val_loss: 0.5716 - val_tp: 3045.0000 - val_fp: 16543.0000 - val_tn: 15727.0000 - val_fn: 603.0000 - val_accuracy: 0.5226 - val_precision: 0.1555 - val_recall: 0.8347 - val_auc: 0.7029\n",
      "Epoch 17/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6362 - tp: 23539.0000 - fp: 144092.0000 - tn: 80963.0000 - fn: 2280.0000 - accuracy: 0.4166 - precision: 0.1404 - recall: 0.9117 - auc: 0.6607 - val_loss: 0.6140 - val_tp: 3134.0000 - val_fp: 17904.0000 - val_tn: 14366.0000 - val_fn: 514.0000 - val_accuracy: 0.4872 - val_precision: 0.1490 - val_recall: 0.8591 - val_auc: 0.6939\n",
      "Epoch 18/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6370 - tp: 23450.0000 - fp: 143193.0000 - tn: 81862.0000 - fn: 2369.0000 - accuracy: 0.4198 - precision: 0.1407 - recall: 0.9082 - auc: 0.6554 - val_loss: 0.5956 - val_tp: 3069.0000 - val_fp: 16850.0000 - val_tn: 15420.0000 - val_fn: 579.0000 - val_accuracy: 0.5148 - val_precision: 0.1541 - val_recall: 0.8413 - val_auc: 0.7037\n",
      "Epoch 19/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6328 - tp: 23406.0000 - fp: 141594.0000 - tn: 83461.0000 - fn: 2413.0000 - accuracy: 0.4260 - precision: 0.1419 - recall: 0.9065 - auc: 0.6652 - val_loss: 0.6613 - val_tp: 3298.0000 - val_fp: 20886.0000 - val_tn: 11384.0000 - val_fn: 350.0000 - val_accuracy: 0.4088 - val_precision: 0.1364 - val_recall: 0.9041 - val_auc: 0.6420\n",
      "Epoch 20/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6411 - tp: 23294.0000 - fp: 141812.0000 - tn: 83243.0000 - fn: 2525.0000 - accuracy: 0.4247 - precision: 0.1411 - recall: 0.9022 - auc: 0.6494 - val_loss: 0.6055 - val_tp: 3145.0000 - val_fp: 17717.0000 - val_tn: 14553.0000 - val_fn: 503.0000 - val_accuracy: 0.4927 - val_precision: 0.1508 - val_recall: 0.8621 - val_auc: 0.7029\n",
      "Epoch 21/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6314 - tp: 23292.0000 - fp: 139972.0000 - tn: 85083.0000 - fn: 2527.0000 - accuracy: 0.4320 - precision: 0.1427 - recall: 0.9021 - auc: 0.6677 - val_loss: 0.6145 - val_tp: 3232.0000 - val_fp: 18459.0000 - val_tn: 13811.0000 - val_fn: 416.0000 - val_accuracy: 0.4745 - val_precision: 0.1490 - val_recall: 0.8860 - val_auc: 0.6997\n",
      "Epoch 22/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6294 - tp: 23225.0000 - fp: 137091.0000 - tn: 87964.0000 - fn: 2594.0000 - accuracy: 0.4432 - precision: 0.1449 - recall: 0.8995 - auc: 0.6685 - val_loss: 0.6514 - val_tp: 3261.0000 - val_fp: 19881.0000 - val_tn: 12389.0000 - val_fn: 387.0000 - val_accuracy: 0.4357 - val_precision: 0.1409 - val_recall: 0.8939 - val_auc: 0.6840\n",
      "Epoch 23/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6332 - tp: 23357.0000 - fp: 140427.0000 - tn: 84628.0000 - fn: 2462.0000 - accuracy: 0.4304 - precision: 0.1426 - recall: 0.9046 - auc: 0.6632 - val_loss: 0.5595 - val_tp: 3013.0000 - val_fp: 15986.0000 - val_tn: 16284.0000 - val_fn: 635.0000 - val_accuracy: 0.5373 - val_precision: 0.1586 - val_recall: 0.8259 - val_auc: 0.7014\n",
      "Epoch 24/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6313 - tp: 23342.0000 - fp: 139756.0000 - tn: 85299.0000 - fn: 2477.0000 - accuracy: 0.4331 - precision: 0.1431 - recall: 0.9041 - auc: 0.6707 - val_loss: 0.6671 - val_tp: 3295.0000 - val_fp: 20318.0000 - val_tn: 11952.0000 - val_fn: 353.0000 - val_accuracy: 0.4245 - val_precision: 0.1395 - val_recall: 0.9032 - val_auc: 0.6790\n",
      "Epoch 25/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6344 - tp: 23184.0000 - fp: 139456.0000 - tn: 85599.0000 - fn: 2635.0000 - accuracy: 0.4336 - precision: 0.1425 - recall: 0.8979 - auc: 0.6659 - val_loss: 0.5759 - val_tp: 3110.0000 - val_fp: 16653.0000 - val_tn: 15617.0000 - val_fn: 538.0000 - val_accuracy: 0.5214 - val_precision: 0.1574 - val_recall: 0.8525 - val_auc: 0.7054\n",
      "Epoch 26/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6325 - tp: 23271.0000 - fp: 138441.0000 - tn: 86614.0000 - fn: 2548.0000 - accuracy: 0.4380 - precision: 0.1439 - recall: 0.9013 - auc: 0.6690 - val_loss: 0.5706 - val_tp: 3041.0000 - val_fp: 16338.0000 - val_tn: 15932.0000 - val_fn: 607.0000 - val_accuracy: 0.5282 - val_precision: 0.1569 - val_recall: 0.8336 - val_auc: 0.6998\n",
      "Epoch 27/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6356 - tp: 23187.0000 - fp: 138496.0000 - tn: 86559.0000 - fn: 2632.0000 - accuracy: 0.4375 - precision: 0.1434 - recall: 0.8981 - auc: 0.6674 - val_loss: 0.5146 - val_tp: 2817.0000 - val_fp: 14432.0000 - val_tn: 17838.0000 - val_fn: 831.0000 - val_accuracy: 0.5751 - val_precision: 0.1633 - val_recall: 0.7722 - val_auc: 0.6943\n",
      "Epoch 28/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6343 - tp: 23141.0000 - fp: 137624.0000 - tn: 87431.0000 - fn: 2678.0000 - accuracy: 0.4407 - precision: 0.1439 - recall: 0.8963 - auc: 0.6631 - val_loss: 0.6141 - val_tp: 3199.0000 - val_fp: 18114.0000 - val_tn: 14156.0000 - val_fn: 449.0000 - val_accuracy: 0.4832 - val_precision: 0.1501 - val_recall: 0.8769 - val_auc: 0.7031\n",
      "Epoch 29/250\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6333 - tp: 23297.0000 - fp: 138723.0000 - tn: 86332.0000 - fn: 2522.0000 - accuracy: 0.4370 - precision: 0.1438 - recall: 0.9023 - auc: 0.6677 - val_loss: 0.6024 - val_tp: 3126.0000 - val_fp: 16984.0000 - val_tn: 15286.0000 - val_fn: 522.0000 - val_accuracy: 0.5126 - val_precision: 0.1554 - val_recall: 0.8569 - val_auc: 0.7033\n",
      "Epoch 30/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6302 - tp: 23276.0000 - fp: 138443.0000 - tn: 86612.0000 - fn: 2543.0000 - accuracy: 0.4380 - precision: 0.1439 - recall: 0.9015 - auc: 0.6717 - val_loss: 0.5555 - val_tp: 2948.0000 - val_fp: 15557.0000 - val_tn: 16713.0000 - val_fn: 700.0000 - val_accuracy: 0.5474 - val_precision: 0.1593 - val_recall: 0.8081 - val_auc: 0.7095\n",
      "Epoch 31/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6277 - tp: 23076.0000 - fp: 135410.0000 - tn: 89645.0000 - fn: 2743.0000 - accuracy: 0.4493 - precision: 0.1456 - recall: 0.8938 - auc: 0.6770 - val_loss: 0.5394 - val_tp: 2914.0000 - val_fp: 14673.0000 - val_tn: 17597.0000 - val_fn: 734.0000 - val_accuracy: 0.5711 - val_precision: 0.1657 - val_recall: 0.7988 - val_auc: 0.7137\n",
      "Epoch 32/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6260 - tp: 23092.0000 - fp: 135567.0000 - tn: 89488.0000 - fn: 2727.0000 - accuracy: 0.4488 - precision: 0.1455 - recall: 0.8944 - auc: 0.6783 - val_loss: 0.6750 - val_tp: 3159.0000 - val_fp: 19559.0000 - val_tn: 12711.0000 - val_fn: 489.0000 - val_accuracy: 0.4418 - val_precision: 0.1391 - val_recall: 0.8660 - val_auc: 0.6328\n",
      "Epoch 33/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6520 - tp: 23120.0000 - fp: 140506.0000 - tn: 84549.0000 - fn: 2699.0000 - accuracy: 0.4292 - precision: 0.1413 - recall: 0.8955 - auc: 0.6521 - val_loss: 0.6363 - val_tp: 3104.0000 - val_fp: 18036.0000 - val_tn: 14234.0000 - val_fn: 544.0000 - val_accuracy: 0.4827 - val_precision: 0.1468 - val_recall: 0.8509 - val_auc: 0.6802\n",
      "Epoch 34/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6369 - tp: 23172.0000 - fp: 141257.0000 - tn: 83798.0000 - fn: 2647.0000 - accuracy: 0.4264 - precision: 0.1409 - recall: 0.8975 - auc: 0.6624 - val_loss: 0.5513 - val_tp: 2943.0000 - val_fp: 15371.0000 - val_tn: 16899.0000 - val_fn: 705.0000 - val_accuracy: 0.5524 - val_precision: 0.1607 - val_recall: 0.8067 - val_auc: 0.7062\n",
      "Epoch 35/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6360 - tp: 23207.0000 - fp: 138867.0000 - tn: 86188.0000 - fn: 2612.0000 - accuracy: 0.4361 - precision: 0.1432 - recall: 0.8988 - auc: 0.6677 - val_loss: 0.5534 - val_tp: 2991.0000 - val_fp: 15796.0000 - val_tn: 16474.0000 - val_fn: 657.0000 - val_accuracy: 0.5419 - val_precision: 0.1592 - val_recall: 0.8199 - val_auc: 0.7105\n",
      "Epoch 36/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6369 - tp: 23114.0000 - fp: 137759.0000 - tn: 87296.0000 - fn: 2705.0000 - accuracy: 0.4401 - precision: 0.1437 - recall: 0.8952 - auc: 0.6674 - val_loss: 0.5961 - val_tp: 3053.0000 - val_fp: 16441.0000 - val_tn: 15829.0000 - val_fn: 595.0000 - val_accuracy: 0.5257 - val_precision: 0.1566 - val_recall: 0.8369 - val_auc: 0.7083\n",
      "Epoch 37/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6331 - tp: 22987.0000 - fp: 138233.0000 - tn: 86822.0000 - fn: 2832.0000 - accuracy: 0.4377 - precision: 0.1426 - recall: 0.8903 - auc: 0.6668 - val_loss: 0.5205 - val_tp: 2800.0000 - val_fp: 13954.0000 - val_tn: 18316.0000 - val_fn: 848.0000 - val_accuracy: 0.5879 - val_precision: 0.1671 - val_recall: 0.7675 - val_auc: 0.7123\n",
      "Epoch 38/250\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6333 - tp: 23111.0000 - fp: 137665.0000 - tn: 87390.0000 - fn: 2708.0000 - accuracy: 0.4405 - precision: 0.1437 - recall: 0.8951 - auc: 0.6680 - val_loss: 0.5781 - val_tp: 3061.0000 - val_fp: 16571.0000 - val_tn: 15699.0000 - val_fn: 587.0000 - val_accuracy: 0.5223 - val_precision: 0.1559 - val_recall: 0.8391 - val_auc: 0.7047\n",
      "Epoch 39/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6317 - tp: 23159.0000 - fp: 138047.0000 - tn: 87008.0000 - fn: 2660.0000 - accuracy: 0.4391 - precision: 0.1437 - recall: 0.8970 - auc: 0.6697 - val_loss: 1.4281 - val_tp: 3566.0000 - val_fp: 29895.0000 - val_tn: 2375.0000 - val_fn: 82.0000 - val_accuracy: 0.1654 - val_precision: 0.1066 - val_recall: 0.9775 - val_auc: 0.4268\n",
      "Epoch 40/250\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.7448 - tp: 22770.0000 - fp: 145627.0000 - tn: 79428.0000 - fn: 3049.0000 - accuracy: 0.4074 - precision: 0.1352 - recall: 0.8819 - auc: 0.6249 - val_loss: 0.6693 - val_tp: 3162.0000 - val_fp: 19057.0000 - val_tn: 13213.0000 - val_fn: 486.0000 - val_accuracy: 0.4559 - val_precision: 0.1423 - val_recall: 0.8668 - val_auc: 0.6846\n",
      "Epoch 41/250\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6484 - tp: 23215.0000 - fp: 145274.0000 - tn: 79781.0000 - fn: 2604.0000 - accuracy: 0.4105 - precision: 0.1378 - recall: 0.8991 - auc: 0.6443 - val_loss: 0.5689 - val_tp: 3063.0000 - val_fp: 17551.0000 - val_tn: 14719.0000 - val_fn: 585.0000 - val_accuracy: 0.4951 - val_precision: 0.1486 - val_recall: 0.8396 - val_auc: 0.6446\n",
      "Epoch 1/500\n",
      "26/26 [==============================] - 2s 79ms/step - loss: 1.2247 - tp: 5821.0000 - fp: 31107.0000 - tn: 226218.0000 - fn: 23646.0000 - accuracy: 0.8091 - precision: 0.1576 - recall: 0.1975 - auc: 0.6001 - val_loss: 0.4064 - val_tp: 898.0000 - val_fp: 3767.0000 - val_tn: 28503.0000 - val_fn: 2750.0000 - val_accuracy: 0.8186 - val_precision: 0.1925 - val_recall: 0.2462 - val_auc: 0.6448\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.0012 - tp: 7840.0000 - fp: 39408.0000 - tn: 185647.0000 - fn: 17979.0000 - accuracy: 0.7713 - precision: 0.1659 - recall: 0.3037 - auc: 0.6209 - val_loss: 0.4531 - val_tp: 1272.0000 - val_fp: 5809.0000 - val_tn: 26461.0000 - val_fn: 2376.0000 - val_accuracy: 0.7721 - val_precision: 0.1796 - val_recall: 0.3487 - val_auc: 0.6564\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.9082 - tp: 8844.0000 - fp: 44060.0000 - tn: 180995.0000 - fn: 16975.0000 - accuracy: 0.7567 - precision: 0.1672 - recall: 0.3425 - auc: 0.6278 - val_loss: 0.4456 - val_tp: 1287.0000 - val_fp: 5551.0000 - val_tn: 26719.0000 - val_fn: 2361.0000 - val_accuracy: 0.7797 - val_precision: 0.1882 - val_recall: 0.3528 - val_auc: 0.6666\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.8462 - tp: 9423.0000 - fp: 47299.0000 - tn: 177756.0000 - fn: 16396.0000 - accuracy: 0.7461 - precision: 0.1661 - recall: 0.3650 - auc: 0.6307 - val_loss: 0.4437 - val_tp: 1280.0000 - val_fp: 5302.0000 - val_tn: 26968.0000 - val_fn: 2368.0000 - val_accuracy: 0.7865 - val_precision: 0.1945 - val_recall: 0.3509 - val_auc: 0.6767\n",
      "Epoch 5/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 35ms/step - loss: 0.8100 - tp: 9820.0000 - fp: 49210.0000 - tn: 175845.0000 - fn: 15999.0000 - accuracy: 0.7401 - precision: 0.1664 - recall: 0.3803 - auc: 0.6370 - val_loss: 0.4449 - val_tp: 1327.0000 - val_fp: 5347.0000 - val_tn: 26923.0000 - val_fn: 2321.0000 - val_accuracy: 0.7865 - val_precision: 0.1988 - val_recall: 0.3638 - val_auc: 0.6871\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.7865 - tp: 10021.0000 - fp: 50262.0000 - tn: 174793.0000 - fn: 15798.0000 - accuracy: 0.7367 - precision: 0.1662 - recall: 0.3881 - auc: 0.6421 - val_loss: 0.4471 - val_tp: 1380.0000 - val_fp: 5429.0000 - val_tn: 26841.0000 - val_fn: 2268.0000 - val_accuracy: 0.7857 - val_precision: 0.2027 - val_recall: 0.3783 - val_auc: 0.6960\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.7663 - tp: 10517.0000 - fp: 50874.0000 - tn: 174181.0000 - fn: 15302.0000 - accuracy: 0.7362 - precision: 0.1713 - recall: 0.4073 - auc: 0.6508 - val_loss: 0.4439 - val_tp: 1373.0000 - val_fp: 5230.0000 - val_tn: 27040.0000 - val_fn: 2275.0000 - val_accuracy: 0.7911 - val_precision: 0.2079 - val_recall: 0.3764 - val_auc: 0.7040\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.7456 - tp: 11049.0000 - fp: 53001.0000 - tn: 172054.0000 - fn: 14770.0000 - accuracy: 0.7299 - precision: 0.1725 - recall: 0.4279 - auc: 0.6590 - val_loss: 0.4473 - val_tp: 1407.0000 - val_fp: 5344.0000 - val_tn: 26926.0000 - val_fn: 2241.0000 - val_accuracy: 0.7888 - val_precision: 0.2084 - val_recall: 0.3857 - val_auc: 0.7105\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.7315 - tp: 11245.0000 - fp: 52986.0000 - tn: 172069.0000 - fn: 14574.0000 - accuracy: 0.7307 - precision: 0.1751 - recall: 0.4355 - auc: 0.6639 - val_loss: 0.4528 - val_tp: 1472.0000 - val_fp: 5627.0000 - val_tn: 26643.0000 - val_fn: 2176.0000 - val_accuracy: 0.7828 - val_precision: 0.2074 - val_recall: 0.4035 - val_auc: 0.7159\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.7200 - tp: 11640.0000 - fp: 54984.0000 - tn: 170071.0000 - fn: 14179.0000 - accuracy: 0.7243 - precision: 0.1747 - recall: 0.4508 - auc: 0.6677 - val_loss: 0.4502 - val_tp: 1493.0000 - val_fp: 5568.0000 - val_tn: 26702.0000 - val_fn: 2155.0000 - val_accuracy: 0.7850 - val_precision: 0.2114 - val_recall: 0.4093 - val_auc: 0.7212\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7073 - tp: 11840.0000 - fp: 54440.0000 - tn: 170615.0000 - fn: 13979.0000 - accuracy: 0.7273 - precision: 0.1786 - recall: 0.4586 - auc: 0.6760 - val_loss: 0.4520 - val_tp: 1523.0000 - val_fp: 5679.0000 - val_tn: 26591.0000 - val_fn: 2125.0000 - val_accuracy: 0.7827 - val_precision: 0.2115 - val_recall: 0.4175 - val_auc: 0.7256\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7001 - tp: 12218.0000 - fp: 55479.0000 - tn: 169576.0000 - fn: 13601.0000 - accuracy: 0.7246 - precision: 0.1805 - recall: 0.4732 - auc: 0.6801 - val_loss: 0.4450 - val_tp: 1493.0000 - val_fp: 5401.0000 - val_tn: 26869.0000 - val_fn: 2155.0000 - val_accuracy: 0.7896 - val_precision: 0.2166 - val_recall: 0.4093 - val_auc: 0.7299\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6930 - tp: 12325.0000 - fp: 54868.0000 - tn: 170187.0000 - fn: 13494.0000 - accuracy: 0.7275 - precision: 0.1834 - recall: 0.4774 - auc: 0.6850 - val_loss: 0.4481 - val_tp: 1560.0000 - val_fp: 5549.0000 - val_tn: 26721.0000 - val_fn: 2088.0000 - val_accuracy: 0.7874 - val_precision: 0.2194 - val_recall: 0.4276 - val_auc: 0.7324\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6869 - tp: 12601.0000 - fp: 56347.0000 - tn: 168708.0000 - fn: 13218.0000 - accuracy: 0.7227 - precision: 0.1828 - recall: 0.4881 - auc: 0.6883 - val_loss: 0.4480 - val_tp: 1583.0000 - val_fp: 5614.0000 - val_tn: 26656.0000 - val_fn: 2065.0000 - val_accuracy: 0.7862 - val_precision: 0.2200 - val_recall: 0.4339 - val_auc: 0.7349\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6787 - tp: 12840.0000 - fp: 56437.0000 - tn: 168618.0000 - fn: 12979.0000 - accuracy: 0.7233 - precision: 0.1853 - recall: 0.4973 - auc: 0.6940 - val_loss: 0.4444 - val_tp: 1539.0000 - val_fp: 5396.0000 - val_tn: 26874.0000 - val_fn: 2109.0000 - val_accuracy: 0.7911 - val_precision: 0.2219 - val_recall: 0.4219 - val_auc: 0.7375\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6738 - tp: 13043.0000 - fp: 57418.0000 - tn: 167637.0000 - fn: 12776.0000 - accuracy: 0.7202 - precision: 0.1851 - recall: 0.5052 - auc: 0.6963 - val_loss: 0.4445 - val_tp: 1564.0000 - val_fp: 5489.0000 - val_tn: 26781.0000 - val_fn: 2084.0000 - val_accuracy: 0.7892 - val_precision: 0.2217 - val_recall: 0.4287 - val_auc: 0.7391\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6716 - tp: 13089.0000 - fp: 57105.0000 - tn: 167950.0000 - fn: 12730.0000 - accuracy: 0.7216 - precision: 0.1865 - recall: 0.5070 - auc: 0.6982 - val_loss: 0.4424 - val_tp: 1562.0000 - val_fp: 5396.0000 - val_tn: 26874.0000 - val_fn: 2086.0000 - val_accuracy: 0.7917 - val_precision: 0.2245 - val_recall: 0.4282 - val_auc: 0.7406\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6676 - tp: 13282.0000 - fp: 57781.0000 - tn: 167274.0000 - fn: 12537.0000 - accuracy: 0.7197 - precision: 0.1869 - recall: 0.5144 - auc: 0.7003 - val_loss: 0.4454 - val_tp: 1621.0000 - val_fp: 5643.0000 - val_tn: 26627.0000 - val_fn: 2027.0000 - val_accuracy: 0.7865 - val_precision: 0.2232 - val_recall: 0.4444 - val_auc: 0.7417\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6636 - tp: 13489.0000 - fp: 57805.0000 - tn: 167250.0000 - fn: 12330.0000 - accuracy: 0.7204 - precision: 0.1892 - recall: 0.5224 - auc: 0.7038 - val_loss: 0.4441 - val_tp: 1612.0000 - val_fp: 5578.0000 - val_tn: 26692.0000 - val_fn: 2036.0000 - val_accuracy: 0.7880 - val_precision: 0.2242 - val_recall: 0.4419 - val_auc: 0.7430\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.6593 - tp: 13581.0000 - fp: 58500.0000 - tn: 166555.0000 - fn: 12238.0000 - accuracy: 0.7180 - precision: 0.1884 - recall: 0.5260 - auc: 0.7059 - val_loss: 0.4426 - val_tp: 1607.0000 - val_fp: 5510.0000 - val_tn: 26760.0000 - val_fn: 2041.0000 - val_accuracy: 0.7898 - val_precision: 0.2258 - val_recall: 0.4405 - val_auc: 0.7443\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.6559 - tp: 13751.0000 - fp: 58812.0000 - tn: 166243.0000 - fn: 12068.0000 - accuracy: 0.7175 - precision: 0.1895 - recall: 0.5326 - auc: 0.7082 - val_loss: 0.4435 - val_tp: 1638.0000 - val_fp: 5624.0000 - val_tn: 26646.0000 - val_fn: 2010.0000 - val_accuracy: 0.7875 - val_precision: 0.2256 - val_recall: 0.4490 - val_auc: 0.7453\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.6510 - tp: 13979.0000 - fp: 59129.0000 - tn: 165926.0000 - fn: 11840.0000 - accuracy: 0.7171 - precision: 0.1912 - recall: 0.5414 - auc: 0.7114 - val_loss: 0.4411 - val_tp: 1624.0000 - val_fp: 5508.0000 - val_tn: 26762.0000 - val_fn: 2024.0000 - val_accuracy: 0.7903 - val_precision: 0.2277 - val_recall: 0.4452 - val_auc: 0.7461\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.6526 - tp: 13715.0000 - fp: 58804.0000 - tn: 166251.0000 - fn: 12104.0000 - accuracy: 0.7174 - precision: 0.1891 - recall: 0.5312 - auc: 0.7095 - val_loss: 0.4400 - val_tp: 1609.0000 - val_fp: 5466.0000 - val_tn: 26804.0000 - val_fn: 2039.0000 - val_accuracy: 0.7911 - val_precision: 0.2274 - val_recall: 0.4411 - val_auc: 0.7470\n",
      "Epoch 24/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6487 - tp: 14084.0000 - fp: 59573.0000 - tn: 165482.0000 - fn: 11735.0000 - accuracy: 0.7158 - precision: 0.1912 - recall: 0.5455 - auc: 0.7126 - val_loss: 0.4425 - val_tp: 1642.0000 - val_fp: 5638.0000 - val_tn: 26632.0000 - val_fn: 2006.0000 - val_accuracy: 0.7872 - val_precision: 0.2255 - val_recall: 0.4501 - val_auc: 0.7474\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6445 - tp: 14291.0000 - fp: 60279.0000 - tn: 164776.0000 - fn: 11528.0000 - accuracy: 0.7138 - precision: 0.1916 - recall: 0.5535 - auc: 0.7150 - val_loss: 0.4413 - val_tp: 1628.0000 - val_fp: 5538.0000 - val_tn: 26732.0000 - val_fn: 2020.0000 - val_accuracy: 0.7896 - val_precision: 0.2272 - val_recall: 0.4463 - val_auc: 0.7483\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6427 - tp: 14224.0000 - fp: 59817.0000 - tn: 165238.0000 - fn: 11595.0000 - accuracy: 0.7153 - precision: 0.1921 - recall: 0.5509 - auc: 0.7162 - val_loss: 0.4361 - val_tp: 1601.0000 - val_fp: 5328.0000 - val_tn: 26942.0000 - val_fn: 2047.0000 - val_accuracy: 0.7947 - val_precision: 0.2311 - val_recall: 0.4389 - val_auc: 0.7491\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.6427 - tp: 14211.0000 - fp: 60026.0000 - tn: 165029.0000 - fn: 11608.0000 - accuracy: 0.7145 - precision: 0.1914 - recall: 0.5504 - auc: 0.7158 - val_loss: 0.4388 - val_tp: 1630.0000 - val_fp: 5441.0000 - val_tn: 26829.0000 - val_fn: 2018.0000 - val_accuracy: 0.7923 - val_precision: 0.2305 - val_recall: 0.4468 - val_auc: 0.7495\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 0.6386 - tp: 14437.0000 - fp: 60389.0000 - tn: 164666.0000 - fn: 11382.0000 - accuracy: 0.7139 - precision: 0.1929 - recall: 0.5592 - auc: 0.7187 - val_loss: 0.4400 - val_tp: 1648.0000 - val_fp: 5579.0000 - val_tn: 26691.0000 - val_fn: 2000.0000 - val_accuracy: 0.7890 - val_precision: 0.2280 - val_recall: 0.4518 - val_auc: 0.7494\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6370 - tp: 14426.0000 - fp: 60166.0000 - tn: 164889.0000 - fn: 11393.0000 - accuracy: 0.7148 - precision: 0.1934 - recall: 0.5587 - auc: 0.7198 - val_loss: 0.4365 - val_tp: 1617.0000 - val_fp: 5396.0000 - val_tn: 26874.0000 - val_fn: 2031.0000 - val_accuracy: 0.7932 - val_precision: 0.2306 - val_recall: 0.4433 - val_auc: 0.7502\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6357 - tp: 14622.0000 - fp: 61052.0000 - tn: 164003.0000 - fn: 11197.0000 - accuracy: 0.7120 - precision: 0.1932 - recall: 0.5663 - auc: 0.7206 - val_loss: 0.4343 - val_tp: 1579.0000 - val_fp: 5221.0000 - val_tn: 27049.0000 - val_fn: 2069.0000 - val_accuracy: 0.7970 - val_precision: 0.2322 - val_recall: 0.4328 - val_auc: 0.7509\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6357 - tp: 14544.0000 - fp: 61026.0000 - tn: 164029.0000 - fn: 11275.0000 - accuracy: 0.7118 - precision: 0.1925 - recall: 0.5633 - auc: 0.7201 - val_loss: 0.4342 - val_tp: 1592.0000 - val_fp: 5255.0000 - val_tn: 27015.0000 - val_fn: 2056.0000 - val_accuracy: 0.7965 - val_precision: 0.2325 - val_recall: 0.4364 - val_auc: 0.7512\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6332 - tp: 14692.0000 - fp: 61311.0000 - tn: 163744.0000 - fn: 11127.0000 - accuracy: 0.7113 - precision: 0.1933 - recall: 0.5690 - auc: 0.7221 - val_loss: 0.4325 - val_tp: 1581.0000 - val_fp: 5179.0000 - val_tn: 27091.0000 - val_fn: 2067.0000 - val_accuracy: 0.7983 - val_precision: 0.2339 - val_recall: 0.4334 - val_auc: 0.7512\n",
      "Epoch 33/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6323 - tp: 14607.0000 - fp: 61616.0000 - tn: 163439.0000 - fn: 11212.0000 - accuracy: 0.7097 - precision: 0.1916 - recall: 0.5657 - auc: 0.7219 - val_loss: 0.4327 - val_tp: 1582.0000 - val_fp: 5173.0000 - val_tn: 27097.0000 - val_fn: 2066.0000 - val_accuracy: 0.7985 - val_precision: 0.2342 - val_recall: 0.4337 - val_auc: 0.7520\n",
      "Epoch 34/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6291 - tp: 14744.0000 - fp: 61447.0000 - tn: 163608.0000 - fn: 11075.0000 - accuracy: 0.7109 - precision: 0.1935 - recall: 0.5711 - auc: 0.7240 - val_loss: 0.4302 - val_tp: 1546.0000 - val_fp: 5013.0000 - val_tn: 27257.0000 - val_fn: 2102.0000 - val_accuracy: 0.8019 - val_precision: 0.2357 - val_recall: 0.4238 - val_auc: 0.7522\n",
      "Epoch 35/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6280 - tp: 14941.0000 - fp: 62460.0000 - tn: 162595.0000 - fn: 10878.0000 - accuracy: 0.7077 - precision: 0.1930 - recall: 0.5787 - auc: 0.7243 - val_loss: 0.4298 - val_tp: 1529.0000 - val_fp: 4948.0000 - val_tn: 27322.0000 - val_fn: 2119.0000 - val_accuracy: 0.8032 - val_precision: 0.2361 - val_recall: 0.4191 - val_auc: 0.7526\n",
      "Epoch 36/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6277 - tp: 14813.0000 - fp: 62329.0000 - tn: 162726.0000 - fn: 11006.0000 - accuracy: 0.7077 - precision: 0.1920 - recall: 0.5737 - auc: 0.7241 - val_loss: 0.4308 - val_tp: 1558.0000 - val_fp: 5031.0000 - val_tn: 27239.0000 - val_fn: 2090.0000 - val_accuracy: 0.8017 - val_precision: 0.2365 - val_recall: 0.4271 - val_auc: 0.7524\n",
      "Epoch 37/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6268 - tp: 14942.0000 - fp: 62498.0000 - tn: 162557.0000 - fn: 10877.0000 - accuracy: 0.7075 - precision: 0.1929 - recall: 0.5787 - auc: 0.7245 - val_loss: 0.4322 - val_tp: 1578.0000 - val_fp: 5155.0000 - val_tn: 27115.0000 - val_fn: 2070.0000 - val_accuracy: 0.7988 - val_precision: 0.2344 - val_recall: 0.4326 - val_auc: 0.7522\n",
      "Epoch 38/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6239 - tp: 15055.0000 - fp: 62644.0000 - tn: 162411.0000 - fn: 10764.0000 - accuracy: 0.7074 - precision: 0.1938 - recall: 0.5831 - auc: 0.7270 - val_loss: 0.4314 - val_tp: 1580.0000 - val_fp: 5152.0000 - val_tn: 27118.0000 - val_fn: 2068.0000 - val_accuracy: 0.7990 - val_precision: 0.2347 - val_recall: 0.4331 - val_auc: 0.7522\n",
      "Epoch 39/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6210 - tp: 15200.0000 - fp: 62826.0000 - tn: 162229.0000 - fn: 10619.0000 - accuracy: 0.7072 - precision: 0.1948 - recall: 0.5887 - auc: 0.7293 - val_loss: 0.4303 - val_tp: 1550.0000 - val_fp: 5038.0000 - val_tn: 27232.0000 - val_fn: 2098.0000 - val_accuracy: 0.8013 - val_precision: 0.2353 - val_recall: 0.4249 - val_auc: 0.7525\n",
      "Epoch 40/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6228 - tp: 15018.0000 - fp: 62732.0000 - tn: 162323.0000 - fn: 10801.0000 - accuracy: 0.7069 - precision: 0.1932 - recall: 0.5817 - auc: 0.7271 - val_loss: 0.4341 - val_tp: 1592.0000 - val_fp: 5240.0000 - val_tn: 27030.0000 - val_fn: 2056.0000 - val_accuracy: 0.7969 - val_precision: 0.2330 - val_recall: 0.4364 - val_auc: 0.7523\n",
      "Epoch 41/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6212 - tp: 15203.0000 - fp: 63258.0000 - tn: 161797.0000 - fn: 10616.0000 - accuracy: 0.7055 - precision: 0.1938 - recall: 0.5888 - auc: 0.7280 - val_loss: 0.4301 - val_tp: 1554.0000 - val_fp: 5098.0000 - val_tn: 27172.0000 - val_fn: 2094.0000 - val_accuracy: 0.7998 - val_precision: 0.2336 - val_recall: 0.4260 - val_auc: 0.7524\n",
      "Epoch 42/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6191 - tp: 15321.0000 - fp: 63867.0000 - tn: 161188.0000 - fn: 10498.0000 - accuracy: 0.7036 - precision: 0.1935 - recall: 0.5934 - auc: 0.7295 - val_loss: 0.4272 - val_tp: 1496.0000 - val_fp: 4783.0000 - val_tn: 27487.0000 - val_fn: 2152.0000 - val_accuracy: 0.8069 - val_precision: 0.2383 - val_recall: 0.4101 - val_auc: 0.7535\n",
      "Epoch 43/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6208 - tp: 15258.0000 - fp: 63886.0000 - tn: 161169.0000 - fn: 10561.0000 - accuracy: 0.7032 - precision: 0.1928 - recall: 0.5910 - auc: 0.7272 - val_loss: 0.4282 - val_tp: 1502.0000 - val_fp: 4772.0000 - val_tn: 27498.0000 - val_fn: 2146.0000 - val_accuracy: 0.8074 - val_precision: 0.2394 - val_recall: 0.4117 - val_auc: 0.7533\n",
      "Epoch 44/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6190 - tp: 15169.0000 - fp: 63339.0000 - tn: 161716.0000 - fn: 10650.0000 - accuracy: 0.7051 - precision: 0.1932 - recall: 0.5875 - auc: 0.7289 - val_loss: 0.4291 - val_tp: 1512.0000 - val_fp: 4872.0000 - val_tn: 27398.0000 - val_fn: 2136.0000 - val_accuracy: 0.8049 - val_precision: 0.2368 - val_recall: 0.4145 - val_auc: 0.7531\n",
      "Epoch 45/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6179 - tp: 15365.0000 - fp: 64231.0000 - tn: 160824.0000 - fn: 10454.0000 - accuracy: 0.7023 - precision: 0.1930 - recall: 0.5951 - auc: 0.7293 - val_loss: 0.4253 - val_tp: 1467.0000 - val_fp: 4650.0000 - val_tn: 27620.0000 - val_fn: 2181.0000 - val_accuracy: 0.8098 - val_precision: 0.2398 - val_recall: 0.4021 - val_auc: 0.7535\n",
      "Epoch 46/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6183 - tp: 15372.0000 - fp: 63800.0000 - tn: 161255.0000 - fn: 10447.0000 - accuracy: 0.7040 - precision: 0.1942 - recall: 0.5954 - auc: 0.7287 - val_loss: 0.4290 - val_tp: 1517.0000 - val_fp: 4923.0000 - val_tn: 27347.0000 - val_fn: 2131.0000 - val_accuracy: 0.8036 - val_precision: 0.2356 - val_recall: 0.4158 - val_auc: 0.7528\n",
      "Epoch 47/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6145 - tp: 15500.0000 - fp: 64313.0000 - tn: 160742.0000 - fn: 10319.0000 - accuracy: 0.7025 - precision: 0.1942 - recall: 0.6003 - auc: 0.7321 - val_loss: 0.4256 - val_tp: 1462.0000 - val_fp: 4631.0000 - val_tn: 27639.0000 - val_fn: 2186.0000 - val_accuracy: 0.8102 - val_precision: 0.2399 - val_recall: 0.4008 - val_auc: 0.7533\n",
      "Epoch 48/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6141 - tp: 15430.0000 - fp: 63972.0000 - tn: 161083.0000 - fn: 10389.0000 - accuracy: 0.7036 - precision: 0.1943 - recall: 0.5976 - auc: 0.7320 - val_loss: 0.4219 - val_tp: 1400.0000 - val_fp: 4395.0000 - val_tn: 27875.0000 - val_fn: 2248.0000 - val_accuracy: 0.8151 - val_precision: 0.2416 - val_recall: 0.3838 - val_auc: 0.7534\n",
      "Epoch 49/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6129 - tp: 15573.0000 - fp: 64026.0000 - tn: 161029.0000 - fn: 10246.0000 - accuracy: 0.7039 - precision: 0.1956 - recall: 0.6032 - auc: 0.7330 - val_loss: 0.4235 - val_tp: 1416.0000 - val_fp: 4438.0000 - val_tn: 27832.0000 - val_fn: 2232.0000 - val_accuracy: 0.8143 - val_precision: 0.2419 - val_recall: 0.3882 - val_auc: 0.7534\n",
      "Epoch 50/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6120 - tp: 15723.0000 - fp: 64717.0000 - tn: 160338.0000 - fn: 10096.0000 - accuracy: 0.7018 - precision: 0.1955 - recall: 0.6090 - auc: 0.7332 - val_loss: 0.4256 - val_tp: 1430.0000 - val_fp: 4503.0000 - val_tn: 27767.0000 - val_fn: 2218.0000 - val_accuracy: 0.8129 - val_precision: 0.2410 - val_recall: 0.3920 - val_auc: 0.7532\n",
      "Epoch 51/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6116 - tp: 15673.0000 - fp: 64726.0000 - tn: 160329.0000 - fn: 10146.0000 - accuracy: 0.7016 - precision: 0.1949 - recall: 0.6070 - auc: 0.7331 - val_loss: 0.4243 - val_tp: 1399.0000 - val_fp: 4434.0000 - val_tn: 27836.0000 - val_fn: 2249.0000 - val_accuracy: 0.8139 - val_precision: 0.2398 - val_recall: 0.3835 - val_auc: 0.7534\n",
      "Epoch 52/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6116 - tp: 15779.0000 - fp: 65484.0000 - tn: 159571.0000 - fn: 10040.0000 - accuracy: 0.6990 - precision: 0.1942 - recall: 0.6111 - auc: 0.7329 - val_loss: 0.4223 - val_tp: 1405.0000 - val_fp: 4407.0000 - val_tn: 27863.0000 - val_fn: 2243.0000 - val_accuracy: 0.8149 - val_precision: 0.2417 - val_recall: 0.3851 - val_auc: 0.7534\n",
      "Epoch 53/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6124 - tp: 15662.0000 - fp: 65032.0000 - tn: 160023.0000 - fn: 10157.0000 - accuracy: 0.7003 - precision: 0.1941 - recall: 0.6066 - auc: 0.7324 - val_loss: 0.4204 - val_tp: 1364.0000 - val_fp: 4218.0000 - val_tn: 28052.0000 - val_fn: 2284.0000 - val_accuracy: 0.8190 - val_precision: 0.2444 - val_recall: 0.3739 - val_auc: 0.7537\n",
      "Epoch 54/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6106 - tp: 15735.0000 - fp: 65396.0000 - tn: 159659.0000 - fn: 10084.0000 - accuracy: 0.6991 - precision: 0.1939 - recall: 0.6094 - auc: 0.7330 - val_loss: 0.4230 - val_tp: 1378.0000 - val_fp: 4269.0000 - val_tn: 28001.0000 - val_fn: 2270.0000 - val_accuracy: 0.8179 - val_precision: 0.2440 - val_recall: 0.3777 - val_auc: 0.7538\n",
      "Epoch 55/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6094 - tp: 15860.0000 - fp: 65775.0000 - tn: 159280.0000 - fn: 9959.0000 - accuracy: 0.6981 - precision: 0.1943 - recall: 0.6143 - auc: 0.7342 - val_loss: 0.4216 - val_tp: 1378.0000 - val_fp: 4264.0000 - val_tn: 28006.0000 - val_fn: 2270.0000 - val_accuracy: 0.8181 - val_precision: 0.2442 - val_recall: 0.3777 - val_auc: 0.7537\n",
      "Epoch 56/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6070 - tp: 15906.0000 - fp: 66111.0000 - tn: 158944.0000 - fn: 9913.0000 - accuracy: 0.6970 - precision: 0.1939 - recall: 0.6161 - auc: 0.7353 - val_loss: 0.4261 - val_tp: 1396.0000 - val_fp: 4371.0000 - val_tn: 27899.0000 - val_fn: 2252.0000 - val_accuracy: 0.8156 - val_precision: 0.2421 - val_recall: 0.3827 - val_auc: 0.7538\n",
      "Epoch 57/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6077 - tp: 16093.0000 - fp: 67567.0000 - tn: 157488.0000 - fn: 9726.0000 - accuracy: 0.6919 - precision: 0.1924 - recall: 0.6233 - auc: 0.7338 - val_loss: 0.4276 - val_tp: 1429.0000 - val_fp: 4467.0000 - val_tn: 27803.0000 - val_fn: 2219.0000 - val_accuracy: 0.8139 - val_precision: 0.2424 - val_recall: 0.3917 - val_auc: 0.7534\n",
      "Epoch 58/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6048 - tp: 16106.0000 - fp: 66261.0000 - tn: 158794.0000 - fn: 9713.0000 - accuracy: 0.6972 - precision: 0.1955 - recall: 0.6238 - auc: 0.7367 - val_loss: 0.4231 - val_tp: 1336.0000 - val_fp: 4094.0000 - val_tn: 28176.0000 - val_fn: 2312.0000 - val_accuracy: 0.8216 - val_precision: 0.2460 - val_recall: 0.3662 - val_auc: 0.7537\n",
      "Epoch 59/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6037 - tp: 16425.0000 - fp: 67826.0000 - tn: 157229.0000 - fn: 9394.0000 - accuracy: 0.6922 - precision: 0.1950 - recall: 0.6362 - auc: 0.7374 - val_loss: 0.4253 - val_tp: 1385.0000 - val_fp: 4330.0000 - val_tn: 27940.0000 - val_fn: 2263.0000 - val_accuracy: 0.8164 - val_precision: 0.2423 - val_recall: 0.3797 - val_auc: 0.7535\n",
      "Epoch 60/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6039 - tp: 16210.0000 - fp: 67026.0000 - tn: 158029.0000 - fn: 9609.0000 - accuracy: 0.6945 - precision: 0.1947 - recall: 0.6278 - auc: 0.7373 - val_loss: 0.4234 - val_tp: 1328.0000 - val_fp: 4094.0000 - val_tn: 28176.0000 - val_fn: 2320.0000 - val_accuracy: 0.8214 - val_precision: 0.2449 - val_recall: 0.3640 - val_auc: 0.7538\n",
      "Epoch 61/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6035 - tp: 16325.0000 - fp: 67513.0000 - tn: 157542.0000 - fn: 9494.0000 - accuracy: 0.6930 - precision: 0.1947 - recall: 0.6323 - auc: 0.7371 - val_loss: 0.4228 - val_tp: 1307.0000 - val_fp: 4045.0000 - val_tn: 28225.0000 - val_fn: 2341.0000 - val_accuracy: 0.8222 - val_precision: 0.2442 - val_recall: 0.3583 - val_auc: 0.7536\n",
      "Epoch 62/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6004 - tp: 16486.0000 - fp: 67831.0000 - tn: 157224.0000 - fn: 9333.0000 - accuracy: 0.6924 - precision: 0.1955 - recall: 0.6385 - auc: 0.7398 - val_loss: 0.4234 - val_tp: 1368.0000 - val_fp: 4262.0000 - val_tn: 28008.0000 - val_fn: 2280.0000 - val_accuracy: 0.8179 - val_precision: 0.2430 - val_recall: 0.3750 - val_auc: 0.7532\n",
      "Epoch 63/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6031 - tp: 16201.0000 - fp: 67098.0000 - tn: 157957.0000 - fn: 9618.0000 - accuracy: 0.6942 - precision: 0.1945 - recall: 0.6275 - auc: 0.7373 - val_loss: 0.4266 - val_tp: 1400.0000 - val_fp: 4377.0000 - val_tn: 27893.0000 - val_fn: 2248.0000 - val_accuracy: 0.8156 - val_precision: 0.2423 - val_recall: 0.3838 - val_auc: 0.7535\n",
      "Epoch 64/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6036 - tp: 16314.0000 - fp: 68133.0000 - tn: 156922.0000 - fn: 9505.0000 - accuracy: 0.6905 - precision: 0.1932 - recall: 0.6319 - auc: 0.7363 - val_loss: 0.4231 - val_tp: 1326.0000 - val_fp: 4128.0000 - val_tn: 28142.0000 - val_fn: 2322.0000 - val_accuracy: 0.8204 - val_precision: 0.2431 - val_recall: 0.3635 - val_auc: 0.7538\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 2s 67ms/step - loss: 0.9007 - tp: 10688.0000 - fp: 51905.0000 - tn: 205420.0000 - fn: 18779.0000 - accuracy: 0.7535 - precision: 0.1708 - recall: 0.3627 - auc: 0.6327 - val_loss: 0.4703 - val_tp: 1573.0000 - val_fp: 6161.0000 - val_tn: 26109.0000 - val_fn: 2075.0000 - val_accuracy: 0.7707 - val_precision: 0.2034 - val_recall: 0.4312 - val_auc: 0.7138\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6953 - tp: 12345.0000 - fp: 56410.0000 - tn: 168645.0000 - fn: 13474.0000 - accuracy: 0.7214 - precision: 0.1796 - recall: 0.4781 - auc: 0.6808 - val_loss: 0.4535 - val_tp: 1584.0000 - val_fp: 5414.0000 - val_tn: 26856.0000 - val_fn: 2064.0000 - val_accuracy: 0.7918 - val_precision: 0.2264 - val_recall: 0.4342 - val_auc: 0.7392\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6531 - tp: 13803.0000 - fp: 59657.0000 - tn: 165398.0000 - fn: 12016.0000 - accuracy: 0.7143 - precision: 0.1879 - recall: 0.5346 - auc: 0.7059 - val_loss: 0.4517 - val_tp: 1709.0000 - val_fp: 5860.0000 - val_tn: 26410.0000 - val_fn: 1939.0000 - val_accuracy: 0.7829 - val_precision: 0.2258 - val_recall: 0.4685 - val_auc: 0.7465\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6320 - tp: 14671.0000 - fp: 62156.0000 - tn: 162899.0000 - fn: 11148.0000 - accuracy: 0.7078 - precision: 0.1910 - recall: 0.5682 - auc: 0.7186 - val_loss: 0.4726 - val_tp: 1918.0000 - val_fp: 6845.0000 - val_tn: 25425.0000 - val_fn: 1730.0000 - val_accuracy: 0.7613 - val_precision: 0.2189 - val_recall: 0.5258 - val_auc: 0.7485\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6207 - tp: 15333.0000 - fp: 64951.0000 - tn: 160104.0000 - fn: 10486.0000 - accuracy: 0.6993 - precision: 0.1910 - recall: 0.5939 - auc: 0.7245 - val_loss: 0.4608 - val_tp: 1850.0000 - val_fp: 6410.0000 - val_tn: 25860.0000 - val_fn: 1798.0000 - val_accuracy: 0.7715 - val_precision: 0.2240 - val_recall: 0.5071 - val_auc: 0.7496\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6130 - tp: 15852.0000 - fp: 66490.0000 - tn: 158565.0000 - fn: 9967.0000 - accuracy: 0.6952 - precision: 0.1925 - recall: 0.6140 - auc: 0.7302 - val_loss: 0.4518 - val_tp: 1675.0000 - val_fp: 5590.0000 - val_tn: 26680.0000 - val_fn: 1973.0000 - val_accuracy: 0.7894 - val_precision: 0.2306 - val_recall: 0.4592 - val_auc: 0.7518\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6083 - tp: 16095.0000 - fp: 67235.0000 - tn: 157820.0000 - fn: 9724.0000 - accuracy: 0.6932 - precision: 0.1931 - recall: 0.6234 - auc: 0.7326 - val_loss: 0.4550 - val_tp: 1683.0000 - val_fp: 5711.0000 - val_tn: 26559.0000 - val_fn: 1965.0000 - val_accuracy: 0.7863 - val_precision: 0.2276 - val_recall: 0.4613 - val_auc: 0.7520\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6059 - tp: 16432.0000 - fp: 69060.0000 - tn: 155995.0000 - fn: 9387.0000 - accuracy: 0.6873 - precision: 0.1922 - recall: 0.6364 - auc: 0.7338 - val_loss: 0.4439 - val_tp: 1513.0000 - val_fp: 4909.0000 - val_tn: 27361.0000 - val_fn: 2135.0000 - val_accuracy: 0.8039 - val_precision: 0.2356 - val_recall: 0.4147 - val_auc: 0.7530\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6004 - tp: 16675.0000 - fp: 69073.0000 - tn: 155982.0000 - fn: 9144.0000 - accuracy: 0.6882 - precision: 0.1945 - recall: 0.6458 - auc: 0.7387 - val_loss: 0.4427 - val_tp: 1469.0000 - val_fp: 4664.0000 - val_tn: 27606.0000 - val_fn: 2179.0000 - val_accuracy: 0.8095 - val_precision: 0.2395 - val_recall: 0.4027 - val_auc: 0.7526\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5975 - tp: 17151.0000 - fp: 71813.0000 - tn: 153242.0000 - fn: 8668.0000 - accuracy: 0.6792 - precision: 0.1928 - recall: 0.6643 - auc: 0.7404 - val_loss: 0.4474 - val_tp: 1626.0000 - val_fp: 5341.0000 - val_tn: 26929.0000 - val_fn: 2022.0000 - val_accuracy: 0.7950 - val_precision: 0.2334 - val_recall: 0.4457 - val_auc: 0.7534\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.5939 - tp: 17322.0000 - fp: 71978.0000 - tn: 153077.0000 - fn: 8497.0000 - accuracy: 0.6792 - precision: 0.1940 - recall: 0.6709 - auc: 0.7433 - val_loss: 0.4459 - val_tp: 1644.0000 - val_fp: 5421.0000 - val_tn: 26849.0000 - val_fn: 2004.0000 - val_accuracy: 0.7933 - val_precision: 0.2327 - val_recall: 0.4507 - val_auc: 0.7524\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5945 - tp: 17436.0000 - fp: 72662.0000 - tn: 152393.0000 - fn: 8383.0000 - accuracy: 0.6769 - precision: 0.1935 - recall: 0.6753 - auc: 0.7427 - val_loss: 0.4508 - val_tp: 1679.0000 - val_fp: 5619.0000 - val_tn: 26651.0000 - val_fn: 1969.0000 - val_accuracy: 0.7887 - val_precision: 0.2301 - val_recall: 0.4603 - val_auc: 0.7518\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5944 - tp: 17653.0000 - fp: 74259.0000 - tn: 150796.0000 - fn: 8166.0000 - accuracy: 0.6714 - precision: 0.1921 - recall: 0.6837 - auc: 0.7425 - val_loss: 0.4539 - val_tp: 1667.0000 - val_fp: 5649.0000 - val_tn: 26621.0000 - val_fn: 1981.0000 - val_accuracy: 0.7876 - val_precision: 0.2279 - val_recall: 0.4570 - val_auc: 0.7507\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5906 - tp: 17931.0000 - fp: 74440.0000 - tn: 150615.0000 - fn: 7888.0000 - accuracy: 0.6718 - precision: 0.1941 - recall: 0.6945 - auc: 0.7464 - val_loss: 0.4397 - val_tp: 1357.0000 - val_fp: 4218.0000 - val_tn: 28052.0000 - val_fn: 2291.0000 - val_accuracy: 0.8188 - val_precision: 0.2434 - val_recall: 0.3720 - val_auc: 0.7521\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5894 - tp: 18257.0000 - fp: 75651.0000 - tn: 149404.0000 - fn: 7562.0000 - accuracy: 0.6683 - precision: 0.1944 - recall: 0.7071 - auc: 0.7485 - val_loss: 0.4408 - val_tp: 1443.0000 - val_fp: 4498.0000 - val_tn: 27772.0000 - val_fn: 2205.0000 - val_accuracy: 0.8134 - val_precision: 0.2429 - val_recall: 0.3956 - val_auc: 0.7517\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5889 - tp: 18289.0000 - fp: 76113.0000 - tn: 148942.0000 - fn: 7530.0000 - accuracy: 0.6666 - precision: 0.1937 - recall: 0.7084 - auc: 0.7487 - val_loss: 0.4503 - val_tp: 1539.0000 - val_fp: 4987.0000 - val_tn: 27283.0000 - val_fn: 2109.0000 - val_accuracy: 0.8024 - val_precision: 0.2358 - val_recall: 0.4219 - val_auc: 0.7514\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5863 - tp: 18576.0000 - fp: 76511.0000 - tn: 148544.0000 - fn: 7243.0000 - accuracy: 0.6662 - precision: 0.1954 - recall: 0.7195 - auc: 0.7516 - val_loss: 0.4440 - val_tp: 1342.0000 - val_fp: 4239.0000 - val_tn: 28031.0000 - val_fn: 2306.0000 - val_accuracy: 0.8178 - val_precision: 0.2405 - val_recall: 0.3679 - val_auc: 0.7508\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5891 - tp: 18401.0000 - fp: 76530.0000 - tn: 148525.0000 - fn: 7418.0000 - accuracy: 0.6654 - precision: 0.1938 - recall: 0.7127 - auc: 0.7483 - val_loss: 0.4421 - val_tp: 1362.0000 - val_fp: 4181.0000 - val_tn: 28089.0000 - val_fn: 2286.0000 - val_accuracy: 0.8200 - val_precision: 0.2457 - val_recall: 0.3734 - val_auc: 0.7511\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5857 - tp: 18716.0000 - fp: 77527.0000 - tn: 147528.0000 - fn: 7103.0000 - accuracy: 0.6627 - precision: 0.1945 - recall: 0.7249 - auc: 0.7525 - val_loss: 0.4319 - val_tp: 1102.0000 - val_fp: 3207.0000 - val_tn: 29063.0000 - val_fn: 2546.0000 - val_accuracy: 0.8398 - val_precision: 0.2557 - val_recall: 0.3021 - val_auc: 0.7490\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5856 - tp: 18694.0000 - fp: 77173.0000 - tn: 147882.0000 - fn: 7125.0000 - accuracy: 0.6640 - precision: 0.1950 - recall: 0.7240 - auc: 0.7526 - val_loss: 0.4319 - val_tp: 1125.0000 - val_fp: 3210.0000 - val_tn: 29060.0000 - val_fn: 2523.0000 - val_accuracy: 0.8404 - val_precision: 0.2595 - val_recall: 0.3084 - val_auc: 0.7501\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 2s 81ms/step - loss: 1.0045 - tp: 11046.0000 - fp: 63071.0000 - tn: 194254.0000 - fn: 18421.0000 - accuracy: 0.7158 - precision: 0.1490 - recall: 0.3749 - auc: 0.6027 - val_loss: 0.5089 - val_tp: 1850.0000 - val_fp: 6986.0000 - val_tn: 25284.0000 - val_fn: 1798.0000 - val_accuracy: 0.7554 - val_precision: 0.2094 - val_recall: 0.5071 - val_auc: 0.7257\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6266 - tp: 17229.0000 - fp: 81456.0000 - tn: 143599.0000 - fn: 8590.0000 - accuracy: 0.6411 - precision: 0.1746 - recall: 0.6673 - auc: 0.7065 - val_loss: 0.5376 - val_tp: 2525.0000 - val_fp: 10875.0000 - val_tn: 21395.0000 - val_fn: 1123.0000 - val_accuracy: 0.6660 - val_precision: 0.1884 - val_recall: 0.6922 - val_auc: 0.7386\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6075 - tp: 18958.0000 - fp: 87995.0000 - tn: 137060.0000 - fn: 6861.0000 - accuracy: 0.6219 - precision: 0.1773 - recall: 0.7343 - auc: 0.7283 - val_loss: 0.4963 - val_tp: 2139.0000 - val_fp: 8136.0000 - val_tn: 24134.0000 - val_fn: 1509.0000 - val_accuracy: 0.7315 - val_precision: 0.2082 - val_recall: 0.5863 - val_auc: 0.7456\n",
      "Epoch 4/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6009 - tp: 18709.0000 - fp: 83696.0000 - tn: 141359.0000 - fn: 7110.0000 - accuracy: 0.6380 - precision: 0.1827 - recall: 0.7246 - auc: 0.7346 - val_loss: 0.5421 - val_tp: 2521.0000 - val_fp: 10364.0000 - val_tn: 21906.0000 - val_fn: 1127.0000 - val_accuracy: 0.6801 - val_precision: 0.1957 - val_recall: 0.6911 - val_auc: 0.7487\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5990 - tp: 18787.0000 - fp: 82593.0000 - tn: 142462.0000 - fn: 7032.0000 - accuracy: 0.6427 - precision: 0.1853 - recall: 0.7276 - auc: 0.7380 - val_loss: 0.4904 - val_tp: 2232.0000 - val_fp: 8497.0000 - val_tn: 23773.0000 - val_fn: 1416.0000 - val_accuracy: 0.7240 - val_precision: 0.2080 - val_recall: 0.6118 - val_auc: 0.7500\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5972 - tp: 19072.0000 - fp: 84180.0000 - tn: 140875.0000 - fn: 6747.0000 - accuracy: 0.6376 - precision: 0.1847 - recall: 0.7387 - auc: 0.7399 - val_loss: 0.4810 - val_tp: 2111.0000 - val_fp: 7774.0000 - val_tn: 24496.0000 - val_fn: 1537.0000 - val_accuracy: 0.7408 - val_precision: 0.2136 - val_recall: 0.5787 - val_auc: 0.7503\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5950 - tp: 18825.0000 - fp: 81527.0000 - tn: 143528.0000 - fn: 6994.0000 - accuracy: 0.6471 - precision: 0.1876 - recall: 0.7291 - auc: 0.7424 - val_loss: 0.5203 - val_tp: 2305.0000 - val_fp: 8914.0000 - val_tn: 23356.0000 - val_fn: 1343.0000 - val_accuracy: 0.7144 - val_precision: 0.2055 - val_recall: 0.6319 - val_auc: 0.7512\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5949 - tp: 18900.0000 - fp: 81499.0000 - tn: 143556.0000 - fn: 6919.0000 - accuracy: 0.6476 - precision: 0.1882 - recall: 0.7320 - auc: 0.7437 - val_loss: 0.4780 - val_tp: 2011.0000 - val_fp: 7168.0000 - val_tn: 25102.0000 - val_fn: 1637.0000 - val_accuracy: 0.7549 - val_precision: 0.2191 - val_recall: 0.5513 - val_auc: 0.7489\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5931 - tp: 19476.0000 - fp: 85083.0000 - tn: 139972.0000 - fn: 6343.0000 - accuracy: 0.6356 - precision: 0.1863 - recall: 0.7543 - auc: 0.7445 - val_loss: 0.4532 - val_tp: 1556.0000 - val_fp: 5068.0000 - val_tn: 27202.0000 - val_fn: 2092.0000 - val_accuracy: 0.8007 - val_precision: 0.2349 - val_recall: 0.4265 - val_auc: 0.7492\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5928 - tp: 18811.0000 - fp: 80105.0000 - tn: 144950.0000 - fn: 7008.0000 - accuracy: 0.6528 - precision: 0.1902 - recall: 0.7286 - auc: 0.7451 - val_loss: 0.5113 - val_tp: 2227.0000 - val_fp: 8585.0000 - val_tn: 23685.0000 - val_fn: 1421.0000 - val_accuracy: 0.7214 - val_precision: 0.2060 - val_recall: 0.6105 - val_auc: 0.7480\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5927 - tp: 18768.0000 - fp: 79906.0000 - tn: 145149.0000 - fn: 7051.0000 - accuracy: 0.6534 - precision: 0.1902 - recall: 0.7269 - auc: 0.7458 - val_loss: 0.4839 - val_tp: 1995.0000 - val_fp: 7267.0000 - val_tn: 25003.0000 - val_fn: 1653.0000 - val_accuracy: 0.7517 - val_precision: 0.2154 - val_recall: 0.5469 - val_auc: 0.7502\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5923 - tp: 19395.0000 - fp: 84348.0000 - tn: 140707.0000 - fn: 6424.0000 - accuracy: 0.6382 - precision: 0.1870 - recall: 0.7512 - auc: 0.7465 - val_loss: 0.4982 - val_tp: 2060.0000 - val_fp: 7748.0000 - val_tn: 24522.0000 - val_fn: 1588.0000 - val_accuracy: 0.7401 - val_precision: 0.2100 - val_recall: 0.5647 - val_auc: 0.7477\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5936 - tp: 19165.0000 - fp: 82460.0000 - tn: 142595.0000 - fn: 6654.0000 - accuracy: 0.6448 - precision: 0.1886 - recall: 0.7423 - auc: 0.7452 - val_loss: 0.5596 - val_tp: 1957.0000 - val_fp: 7394.0000 - val_tn: 24876.0000 - val_fn: 1691.0000 - val_accuracy: 0.7471 - val_precision: 0.2093 - val_recall: 0.5365 - val_auc: 0.7393\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5964 - tp: 18999.0000 - fp: 81667.0000 - tn: 143388.0000 - fn: 6820.0000 - accuracy: 0.6473 - precision: 0.1887 - recall: 0.7359 - auc: 0.7443 - val_loss: 0.4701 - val_tp: 1793.0000 - val_fp: 6138.0000 - val_tn: 26132.0000 - val_fn: 1855.0000 - val_accuracy: 0.7775 - val_precision: 0.2261 - val_recall: 0.4915 - val_auc: 0.7486\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5947 - tp: 18942.0000 - fp: 80468.0000 - tn: 144587.0000 - fn: 6877.0000 - accuracy: 0.6518 - precision: 0.1905 - recall: 0.7336 - auc: 0.7448 - val_loss: 0.4924 - val_tp: 1767.0000 - val_fp: 6205.0000 - val_tn: 26065.0000 - val_fn: 1881.0000 - val_accuracy: 0.7749 - val_precision: 0.2217 - val_recall: 0.4844 - val_auc: 0.7469\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.5974 - tp: 19130.0000 - fp: 82728.0000 - tn: 142327.0000 - fn: 6689.0000 - accuracy: 0.6436 - precision: 0.1878 - recall: 0.7409 - auc: 0.7428 - val_loss: 0.5885 - val_tp: 2031.0000 - val_fp: 7464.0000 - val_tn: 24806.0000 - val_fn: 1617.0000 - val_accuracy: 0.7472 - val_precision: 0.2139 - val_recall: 0.5567 - val_auc: 0.7464\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.5969 - tp: 19180.0000 - fp: 82866.0000 - tn: 142189.0000 - fn: 6639.0000 - accuracy: 0.6432 - precision: 0.1880 - recall: 0.7429 - auc: 0.7446 - val_loss: 0.4552 - val_tp: 1553.0000 - val_fp: 5252.0000 - val_tn: 27018.0000 - val_fn: 2095.0000 - val_accuracy: 0.7955 - val_precision: 0.2282 - val_recall: 0.4257 - val_auc: 0.7468\n",
      "Epoch 1/500\n",
      "26/26 [==============================] - 2s 66ms/step - loss: 20.1160 - tp: 17939.0000 - fp: 112662.0000 - tn: 144663.0000 - fn: 11528.0000 - accuracy: 0.5670 - precision: 0.1374 - recall: 0.6088 - auc: 0.5874 - val_loss: 1.0875 - val_tp: 1923.0000 - val_fp: 11459.0000 - val_tn: 20811.0000 - val_fn: 1725.0000 - val_accuracy: 0.6329 - val_precision: 0.1437 - val_recall: 0.5271 - val_auc: 0.6246\n",
      "Epoch 2/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.3638 - tp: 19539.0000 - fp: 130207.0000 - tn: 94848.0000 - fn: 6280.0000 - accuracy: 0.4560 - precision: 0.1305 - recall: 0.7568 - auc: 0.5924 - val_loss: 0.5479 - val_tp: 2584.0000 - val_fp: 13380.0000 - val_tn: 18890.0000 - val_fn: 1064.0000 - val_accuracy: 0.5979 - val_precision: 0.1619 - val_recall: 0.7083 - val_auc: 0.6819\n",
      "Epoch 3/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7723 - tp: 23477.0000 - fp: 152878.0000 - tn: 72177.0000 - fn: 2342.0000 - accuracy: 0.3813 - precision: 0.1331 - recall: 0.9093 - auc: 0.6076 - val_loss: 0.5943 - val_tp: 3152.0000 - val_fp: 18277.0000 - val_tn: 13993.0000 - val_fn: 496.0000 - val_accuracy: 0.4773 - val_precision: 0.1471 - val_recall: 0.8640 - val_auc: 0.6810\n",
      "Epoch 4/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7124 - tp: 24133.0000 - fp: 159906.0000 - tn: 65149.0000 - fn: 1686.0000 - accuracy: 0.3559 - precision: 0.1311 - recall: 0.9347 - auc: 0.6131 - val_loss: 0.5793 - val_tp: 3146.0000 - val_fp: 17693.0000 - val_tn: 14577.0000 - val_fn: 502.0000 - val_accuracy: 0.4934 - val_precision: 0.1510 - val_recall: 0.8624 - val_auc: 0.6808\n",
      "Epoch 5/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6853 - tp: 24370.0000 - fp: 163343.0000 - tn: 61712.0000 - fn: 1449.0000 - accuracy: 0.3431 - precision: 0.1298 - recall: 0.9439 - auc: 0.6096 - val_loss: 0.6214 - val_tp: 2995.0000 - val_fp: 16113.0000 - val_tn: 16157.0000 - val_fn: 653.0000 - val_accuracy: 0.5332 - val_precision: 0.1567 - val_recall: 0.8210 - val_auc: 0.6822\n",
      "Epoch 6/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.8127 - tp: 20634.0000 - fp: 139015.0000 - tn: 86040.0000 - fn: 5185.0000 - accuracy: 0.4252 - precision: 0.1292 - recall: 0.7992 - auc: 0.6087 - val_loss: 0.6002 - val_tp: 3326.0000 - val_fp: 21215.0000 - val_tn: 11055.0000 - val_fn: 322.0000 - val_accuracy: 0.4004 - val_precision: 0.1355 - val_recall: 0.9117 - val_auc: 0.6266\n",
      "Epoch 7/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6666 - tp: 24585.0000 - fp: 166958.0000 - tn: 58097.0000 - fn: 1234.0000 - accuracy: 0.3296 - precision: 0.1284 - recall: 0.9522 - auc: 0.6119 - val_loss: 0.5902 - val_tp: 3244.0000 - val_fp: 19287.0000 - val_tn: 12983.0000 - val_fn: 404.0000 - val_accuracy: 0.4518 - val_precision: 0.1440 - val_recall: 0.8893 - val_auc: 0.6768\n",
      "Epoch 8/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6571 - tp: 24444.0000 - fp: 163195.0000 - tn: 61860.0000 - fn: 1375.0000 - accuracy: 0.3440 - precision: 0.1303 - recall: 0.9467 - auc: 0.6219 - val_loss: 0.6325 - val_tp: 3360.0000 - val_fp: 21188.0000 - val_tn: 11082.0000 - val_fn: 288.0000 - val_accuracy: 0.4021 - val_precision: 0.1369 - val_recall: 0.9211 - val_auc: 0.6674\n",
      "Epoch 9/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6487 - tp: 24216.0000 - fp: 158128.0000 - tn: 66927.0000 - fn: 1603.0000 - accuracy: 0.3633 - precision: 0.1328 - recall: 0.9379 - auc: 0.6346 - val_loss: 0.6005 - val_tp: 3181.0000 - val_fp: 18747.0000 - val_tn: 13523.0000 - val_fn: 467.0000 - val_accuracy: 0.4651 - val_precision: 0.1451 - val_recall: 0.8720 - val_auc: 0.6818\n",
      "Epoch 10/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6542 - tp: 24095.0000 - fp: 155952.0000 - tn: 69103.0000 - fn: 1724.0000 - accuracy: 0.3715 - precision: 0.1338 - recall: 0.9332 - auc: 0.6321 - val_loss: 0.5789 - val_tp: 3168.0000 - val_fp: 18172.0000 - val_tn: 14098.0000 - val_fn: 480.0000 - val_accuracy: 0.4807 - val_precision: 0.1485 - val_recall: 0.8684 - val_auc: 0.6867\n",
      "Epoch 11/500\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 0.6431 - tp: 24166.0000 - fp: 154156.0000 - tn: 70899.0000 - fn: 1653.0000 - accuracy: 0.3789 - precision: 0.1355 - recall: 0.9360 - auc: 0.6441 - val_loss: 0.5953 - val_tp: 3191.0000 - val_fp: 18286.0000 - val_tn: 13984.0000 - val_fn: 457.0000 - val_accuracy: 0.4782 - val_precision: 0.1486 - val_recall: 0.8747 - val_auc: 0.6900\n",
      "Epoch 12/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6412 - tp: 23954.0000 - fp: 151363.0000 - tn: 73692.0000 - fn: 1865.0000 - accuracy: 0.3892 - precision: 0.1366 - recall: 0.9278 - auc: 0.6494 - val_loss: 0.5947 - val_tp: 3127.0000 - val_fp: 17917.0000 - val_tn: 14353.0000 - val_fn: 521.0000 - val_accuracy: 0.4867 - val_precision: 0.1486 - val_recall: 0.8572 - val_auc: 0.6971\n",
      "Epoch 13/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6429 - tp: 23848.0000 - fp: 149688.0000 - tn: 75367.0000 - fn: 1971.0000 - accuracy: 0.3955 - precision: 0.1374 - recall: 0.9237 - auc: 0.6507 - val_loss: 0.5534 - val_tp: 2992.0000 - val_fp: 16087.0000 - val_tn: 16183.0000 - val_fn: 656.0000 - val_accuracy: 0.5339 - val_precision: 0.1568 - val_recall: 0.8202 - val_auc: 0.6973\n",
      "Epoch 14/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6381 - tp: 23776.0000 - fp: 147112.0000 - tn: 77943.0000 - fn: 2043.0000 - accuracy: 0.4055 - precision: 0.1391 - recall: 0.9209 - auc: 0.6497 - val_loss: 0.5625 - val_tp: 3056.0000 - val_fp: 16598.0000 - val_tn: 15672.0000 - val_fn: 592.0000 - val_accuracy: 0.5214 - val_precision: 0.1555 - val_recall: 0.8377 - val_auc: 0.7012\n",
      "Epoch 15/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6379 - tp: 23637.0000 - fp: 144978.0000 - tn: 80077.0000 - fn: 2182.0000 - accuracy: 0.4134 - precision: 0.1402 - recall: 0.9155 - auc: 0.6540 - val_loss: 0.5966 - val_tp: 3147.0000 - val_fp: 17457.0000 - val_tn: 14813.0000 - val_fn: 501.0000 - val_accuracy: 0.5000 - val_precision: 0.1527 - val_recall: 0.8627 - val_auc: 0.7025\n",
      "Epoch 16/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6348 - tp: 23633.0000 - fp: 144282.0000 - tn: 80773.0000 - fn: 2186.0000 - accuracy: 0.4162 - precision: 0.1407 - recall: 0.9153 - auc: 0.6630 - val_loss: 0.5715 - val_tp: 3064.0000 - val_fp: 16611.0000 - val_tn: 15659.0000 - val_fn: 584.0000 - val_accuracy: 0.5213 - val_precision: 0.1557 - val_recall: 0.8399 - val_auc: 0.7020\n",
      "Epoch 17/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6370 - tp: 23497.0000 - fp: 143607.0000 - tn: 81448.0000 - fn: 2322.0000 - accuracy: 0.4183 - precision: 0.1406 - recall: 0.9101 - auc: 0.6607 - val_loss: 0.6361 - val_tp: 3317.0000 - val_fp: 20308.0000 - val_tn: 11962.0000 - val_fn: 331.0000 - val_accuracy: 0.4254 - val_precision: 0.1404 - val_recall: 0.9093 - val_auc: 0.6754\n",
      "Epoch 18/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6430 - tp: 23718.0000 - fp: 147700.0000 - tn: 77355.0000 - fn: 2101.0000 - accuracy: 0.4029 - precision: 0.1384 - recall: 0.9186 - auc: 0.6490 - val_loss: 0.5696 - val_tp: 3124.0000 - val_fp: 17473.0000 - val_tn: 14797.0000 - val_fn: 524.0000 - val_accuracy: 0.4989 - val_precision: 0.1517 - val_recall: 0.8564 - val_auc: 0.6847\n",
      "Epoch 19/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6369 - tp: 23708.0000 - fp: 144919.0000 - tn: 80136.0000 - fn: 2111.0000 - accuracy: 0.4139 - precision: 0.1406 - recall: 0.9182 - auc: 0.6552 - val_loss: 0.6415 - val_tp: 3260.0000 - val_fp: 19366.0000 - val_tn: 12904.0000 - val_fn: 388.0000 - val_accuracy: 0.4500 - val_precision: 0.1441 - val_recall: 0.8936 - val_auc: 0.6756\n",
      "Epoch 20/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6370 - tp: 23617.0000 - fp: 144770.0000 - tn: 80285.0000 - fn: 2202.0000 - accuracy: 0.4142 - precision: 0.1403 - recall: 0.9147 - auc: 0.6610 - val_loss: 0.5809 - val_tp: 3113.0000 - val_fp: 17025.0000 - val_tn: 15245.0000 - val_fn: 535.0000 - val_accuracy: 0.5111 - val_precision: 0.1546 - val_recall: 0.8533 - val_auc: 0.7023\n",
      "Epoch 21/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6369 - tp: 23612.0000 - fp: 143118.0000 - tn: 81937.0000 - fn: 2207.0000 - accuracy: 0.4207 - precision: 0.1416 - recall: 0.9145 - auc: 0.6598 - val_loss: 0.5633 - val_tp: 3062.0000 - val_fp: 16721.0000 - val_tn: 15549.0000 - val_fn: 586.0000 - val_accuracy: 0.5182 - val_precision: 0.1548 - val_recall: 0.8394 - val_auc: 0.6932\n",
      "Epoch 22/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6384 - tp: 23395.0000 - fp: 142800.0000 - tn: 82255.0000 - fn: 2424.0000 - accuracy: 0.4211 - precision: 0.1408 - recall: 0.9061 - auc: 0.6596 - val_loss: 0.5934 - val_tp: 3088.0000 - val_fp: 17034.0000 - val_tn: 15236.0000 - val_fn: 560.0000 - val_accuracy: 0.5102 - val_precision: 0.1535 - val_recall: 0.8465 - val_auc: 0.7036\n",
      "Epoch 23/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6366 - tp: 23368.0000 - fp: 141359.0000 - tn: 83696.0000 - fn: 2451.0000 - accuracy: 0.4268 - precision: 0.1419 - recall: 0.9051 - auc: 0.6613 - val_loss: 0.5973 - val_tp: 3164.0000 - val_fp: 17881.0000 - val_tn: 14389.0000 - val_fn: 484.0000 - val_accuracy: 0.4887 - val_precision: 0.1503 - val_recall: 0.8673 - val_auc: 0.7019\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6350 - tp: 23555.0000 - fp: 142332.0000 - tn: 82723.0000 - fn: 2264.0000 - accuracy: 0.4236 - precision: 0.1420 - recall: 0.9123 - auc: 0.6656 - val_loss: 0.6140 - val_tp: 3201.0000 - val_fp: 18246.0000 - val_tn: 14024.0000 - val_fn: 447.0000 - val_accuracy: 0.4796 - val_precision: 0.1493 - val_recall: 0.8775 - val_auc: 0.6951\n",
      "Epoch 25/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6340 - tp: 23421.0000 - fp: 141414.0000 - tn: 83641.0000 - fn: 2398.0000 - accuracy: 0.4268 - precision: 0.1421 - recall: 0.9071 - auc: 0.6652 - val_loss: 0.5775 - val_tp: 3043.0000 - val_fp: 16401.0000 - val_tn: 15869.0000 - val_fn: 605.0000 - val_accuracy: 0.5265 - val_precision: 0.1565 - val_recall: 0.8342 - val_auc: 0.6990\n",
      "Epoch 26/500\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.6315 - tp: 23320.0000 - fp: 138885.0000 - tn: 86170.0000 - fn: 2499.0000 - accuracy: 0.4364 - precision: 0.1438 - recall: 0.9032 - auc: 0.6658 - val_loss: 0.6176 - val_tp: 3162.0000 - val_fp: 17978.0000 - val_tn: 14292.0000 - val_fn: 486.0000 - val_accuracy: 0.4859 - val_precision: 0.1496 - val_recall: 0.8668 - val_auc: 0.6954\n",
      "Epoch 27/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6333 - tp: 23327.0000 - fp: 139719.0000 - tn: 85336.0000 - fn: 2492.0000 - accuracy: 0.4331 - precision: 0.1431 - recall: 0.9035 - auc: 0.6629 - val_loss: 1.1010 - val_tp: 3575.0000 - val_fp: 29202.0000 - val_tn: 3068.0000 - val_fn: 73.0000 - val_accuracy: 0.1849 - val_precision: 0.1091 - val_recall: 0.9800 - val_auc: 0.4375\n",
      "Epoch 28/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6834 - tp: 21700.0000 - fp: 140327.0000 - tn: 84728.0000 - fn: 4119.0000 - accuracy: 0.4242 - precision: 0.1339 - recall: 0.8405 - auc: 0.6228 - val_loss: 0.5882 - val_tp: 3175.0000 - val_fp: 18355.0000 - val_tn: 13915.0000 - val_fn: 473.0000 - val_accuracy: 0.4758 - val_precision: 0.1475 - val_recall: 0.8703 - val_auc: 0.6808\n",
      "Epoch 29/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6449 - tp: 23792.0000 - fp: 152686.0000 - tn: 72369.0000 - fn: 2027.0000 - accuracy: 0.3833 - precision: 0.1348 - recall: 0.9215 - auc: 0.6345 - val_loss: 0.6653 - val_tp: 3333.0000 - val_fp: 20790.0000 - val_tn: 11480.0000 - val_fn: 315.0000 - val_accuracy: 0.4124 - val_precision: 0.1382 - val_recall: 0.9137 - val_auc: 0.6814\n",
      "Epoch 30/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6436 - tp: 23555.0000 - fp: 148592.0000 - tn: 76463.0000 - fn: 2264.0000 - accuracy: 0.3987 - precision: 0.1368 - recall: 0.9123 - auc: 0.6427 - val_loss: 0.6619 - val_tp: 3235.0000 - val_fp: 21148.0000 - val_tn: 11122.0000 - val_fn: 413.0000 - val_accuracy: 0.3997 - val_precision: 0.1327 - val_recall: 0.8868 - val_auc: 0.5805\n",
      "Epoch 31/500\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.6518 - tp: 22479.0000 - fp: 140551.0000 - tn: 84504.0000 - fn: 3340.0000 - accuracy: 0.4264 - precision: 0.1379 - recall: 0.8706 - auc: 0.6384 - val_loss: 0.6475 - val_tp: 3250.0000 - val_fp: 19118.0000 - val_tn: 13152.0000 - val_fn: 398.0000 - val_accuracy: 0.4567 - val_precision: 0.1453 - val_recall: 0.8909 - val_auc: 0.6973\n",
      "Epoch 32/500\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.6402 - tp: 23435.0000 - fp: 145581.0000 - tn: 79474.0000 - fn: 2384.0000 - accuracy: 0.4102 - precision: 0.1387 - recall: 0.9077 - auc: 0.6493 - val_loss: 0.6114 - val_tp: 3148.0000 - val_fp: 18183.0000 - val_tn: 14087.0000 - val_fn: 500.0000 - val_accuracy: 0.4798 - val_precision: 0.1476 - val_recall: 0.8629 - val_auc: 0.6796\n"
     ]
    }
   ],
   "source": [
    "saved_iterations = {}\n",
    "\n",
    "for i, j, k in every_cart:       \n",
    "    weighted_model = make_model(lr = k)\n",
    "    weighted_model.load_weights(initial_weights)\n",
    "\n",
    "    weighted_history = weighted_model.fit(\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        batch_size=i,\n",
    "        epochs=j,\n",
    "        callbacks = [early_stopping],\n",
    "        validation_data=(val_features, val_labels),\n",
    "        # The class weights go here\n",
    "        class_weight=class_weight) \n",
    "\n",
    "    val_predictions_weighted = weighted_model.predict(val_features, batch_size=i)\n",
    "    AP = average_precision_score(val_labels, val_predictions_weighted)\n",
    "    AUC = AUCcalc(val_labels, val_predictions_weighted)\n",
    "    \n",
    "    saved_iterations[(i, j, k)] = [AP, AUC]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">2000</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">100</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.235348</td>\n",
       "      <td>0.753119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.233074</td>\n",
       "      <td>0.750650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.232000</td>\n",
       "      <td>0.748911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.161545</td>\n",
       "      <td>0.691135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">250</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.235943</td>\n",
       "      <td>0.753092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.235689</td>\n",
       "      <td>0.752046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.227027</td>\n",
       "      <td>0.745434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.155777</td>\n",
       "      <td>0.683875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">500</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.235630</td>\n",
       "      <td>0.753509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.233426</td>\n",
       "      <td>0.752742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.222945</td>\n",
       "      <td>0.743213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.154232</td>\n",
       "      <td>0.672083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">10000</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">100</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.235064</td>\n",
       "      <td>0.753736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.236980</td>\n",
       "      <td>0.753478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.233964</td>\n",
       "      <td>0.750968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.171967</td>\n",
       "      <td>0.708612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">250</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.235999</td>\n",
       "      <td>0.754114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.233218</td>\n",
       "      <td>0.752934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.235561</td>\n",
       "      <td>0.752175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.176511</td>\n",
       "      <td>0.714220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">500</th>\n",
       "      <th>0.001</th>\n",
       "      <td>0.235616</td>\n",
       "      <td>0.753837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.235587</td>\n",
       "      <td>0.753455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.234127</td>\n",
       "      <td>0.751174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.170580</td>\n",
       "      <td>0.704695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0         1\n",
       "2000  100 0.001  0.235348  0.753119\n",
       "          0.010  0.233074  0.750650\n",
       "          0.100  0.232000  0.748911\n",
       "          1.000  0.161545  0.691135\n",
       "      250 0.001  0.235943  0.753092\n",
       "          0.010  0.235689  0.752046\n",
       "          0.100  0.227027  0.745434\n",
       "          1.000  0.155777  0.683875\n",
       "      500 0.001  0.235630  0.753509\n",
       "          0.010  0.233426  0.752742\n",
       "          0.100  0.222945  0.743213\n",
       "          1.000  0.154232  0.672083\n",
       "10000 100 0.001  0.235064  0.753736\n",
       "          0.010  0.236980  0.753478\n",
       "          0.100  0.233964  0.750968\n",
       "          1.000  0.171967  0.708612\n",
       "      250 0.001  0.235999  0.754114\n",
       "          0.010  0.233218  0.752934\n",
       "          0.100  0.235561  0.752175\n",
       "          1.000  0.176511  0.714220\n",
       "      500 0.001  0.235616  0.753837\n",
       "          0.010  0.235587  0.753455\n",
       "          0.100  0.234127  0.751174\n",
       "          1.000  0.170580  0.704695"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(saved_iterations).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 1.4381 - tp: 3739.0000 - fp: 25710.0000 - tn: 231615.0000 - fn: 25728.0000 - accuracy: 0.8206 - precision: 0.1270 - recall: 0.1269 - auc: 0.5634 - val_loss: 0.3433 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5949\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.4331 - tp: 280.0000 - fp: 1698.0000 - tn: 223357.0000 - fn: 25539.0000 - accuracy: 0.8914 - precision: 0.1416 - recall: 0.0108 - auc: 0.5661 - val_loss: 0.3431 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5959\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.4263 - tp: 290.0000 - fp: 1729.0000 - tn: 223326.0000 - fn: 25529.0000 - accuracy: 0.8913 - precision: 0.1436 - recall: 0.0112 - auc: 0.5680 - val_loss: 0.3429 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5965\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 1.4228 - tp: 292.0000 - fp: 1750.0000 - tn: 223305.0000 - fn: 25527.0000 - accuracy: 0.8913 - precision: 0.1430 - recall: 0.0113 - auc: 0.5693 - val_loss: 0.3427 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5972\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 1.4255 - tp: 312.0000 - fp: 1855.0000 - tn: 223200.0000 - fn: 25507.0000 - accuracy: 0.8909 - precision: 0.1440 - recall: 0.0121 - auc: 0.5694 - val_loss: 0.3425 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5978\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 1.4219 - tp: 314.0000 - fp: 1837.0000 - tn: 223218.0000 - fn: 25505.0000 - accuracy: 0.8910 - precision: 0.1460 - recall: 0.0122 - auc: 0.5678 - val_loss: 0.3423 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5985\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 1.4198 - tp: 321.0000 - fp: 1796.0000 - tn: 223259.0000 - fn: 25498.0000 - accuracy: 0.8912 - precision: 0.1516 - recall: 0.0124 - auc: 0.5695 - val_loss: 0.3421 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5992\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 1.4128 - tp: 322.0000 - fp: 1817.0000 - tn: 223238.0000 - fn: 25497.0000 - accuracy: 0.8911 - precision: 0.1505 - recall: 0.0125 - auc: 0.5714 - val_loss: 0.3419 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6000\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.4103 - tp: 333.0000 - fp: 1896.0000 - tn: 223159.0000 - fn: 25486.0000 - accuracy: 0.8909 - precision: 0.1494 - recall: 0.0129 - auc: 0.5708 - val_loss: 0.3417 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6006\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 1.4100 - tp: 322.0000 - fp: 1918.0000 - tn: 223137.0000 - fn: 25497.0000 - accuracy: 0.8907 - precision: 0.1437 - recall: 0.0125 - auc: 0.5716 - val_loss: 0.3415 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6010\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 2s 17ms/step - loss: 1.4091 - tp: 331.0000 - fp: 1939.0000 - tn: 223116.0000 - fn: 25488.0000 - accuracy: 0.8907 - precision: 0.1458 - recall: 0.0128 - auc: 0.5699 - val_loss: 0.3414 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6016\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 1.4079 - tp: 356.0000 - fp: 1962.0000 - tn: 223093.0000 - fn: 25463.0000 - accuracy: 0.8907 - precision: 0.1536 - recall: 0.0138 - auc: 0.5719 - val_loss: 0.3412 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6024\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 1.4038 - tp: 339.0000 - fp: 2065.0000 - tn: 222990.0000 - fn: 25480.0000 - accuracy: 0.8902 - precision: 0.1410 - recall: 0.0131 - auc: 0.5725 - val_loss: 0.3410 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6029\n",
      "Epoch 14/100\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 1.3976 - tp: 334.0000 - fp: 2085.0000 - tn: 222970.0000 - fn: 25485.0000 - accuracy: 0.8901 - precision: 0.1381 - recall: 0.0129 - auc: 0.5741 - val_loss: 0.3409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6036\n",
      "Epoch 15/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.3936 - tp: 390.0000 - fp: 2131.0000 - tn: 222924.0000 - fn: 25429.0000 - accuracy: 0.8901 - precision: 0.1547 - recall: 0.0151 - auc: 0.5749 - val_loss: 0.3407 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6042\n",
      "Epoch 16/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 1.3969 - tp: 378.0000 - fp: 2128.0000 - tn: 222927.0000 - fn: 25441.0000 - accuracy: 0.8901 - precision: 0.1508 - recall: 0.0146 - auc: 0.5722 - val_loss: 0.3405 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6046\n",
      "Epoch 17/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 1.3947 - tp: 401.0000 - fp: 2235.0000 - tn: 222820.0000 - fn: 25418.0000 - accuracy: 0.8898 - precision: 0.1521 - recall: 0.0155 - auc: 0.5755 - val_loss: 0.3404 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6052\n",
      "Epoch 18/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 1.3923 - tp: 407.0000 - fp: 2143.0000 - tn: 222912.0000 - fn: 25412.0000 - accuracy: 0.8902 - precision: 0.1596 - recall: 0.0158 - auc: 0.5754 - val_loss: 0.3402 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6058\n",
      "Epoch 19/100\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 1.3913 - tp: 391.0000 - fp: 2344.0000 - tn: 222711.0000 - fn: 25428.0000 - accuracy: 0.8893 - precision: 0.1430 - recall: 0.0151 - auc: 0.5751 - val_loss: 0.3401 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6065\n",
      "Epoch 20/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 1.3831 - tp: 418.0000 - fp: 2317.0000 - tn: 222738.0000 - fn: 25401.0000 - accuracy: 0.8895 - precision: 0.1528 - recall: 0.0162 - auc: 0.5782 - val_loss: 0.3400 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 1.3847 - tp: 430.0000 - fp: 2315.0000 - tn: 222740.0000 - fn: 25389.0000 - accuracy: 0.8896 - precision: 0.1566 - recall: 0.0167 - auc: 0.5758 - val_loss: 0.3398 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6073\n",
      "Epoch 22/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.3811 - tp: 438.0000 - fp: 2353.0000 - tn: 222702.0000 - fn: 25381.0000 - accuracy: 0.8895 - precision: 0.1569 - recall: 0.0170 - auc: 0.5776 - val_loss: 0.3397 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6077\n",
      "Epoch 23/100\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1.3824 - tp: 429.0000 - fp: 2448.0000 - tn: 222607.0000 - fn: 25390.0000 - accuracy: 0.8890 - precision: 0.1491 - recall: 0.0166 - auc: 0.5756 - val_loss: 0.3396 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6083\n",
      "Epoch 24/100\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1.3733 - tp: 448.0000 - fp: 2500.0000 - tn: 222555.0000 - fn: 25371.0000 - accuracy: 0.8889 - precision: 0.1520 - recall: 0.0174 - auc: 0.5801 - val_loss: 0.3395 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6089\n",
      "Epoch 25/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.3763 - tp: 475.0000 - fp: 2554.0000 - tn: 222501.0000 - fn: 25344.0000 - accuracy: 0.8888 - precision: 0.1568 - recall: 0.0184 - auc: 0.5777 - val_loss: 0.3393 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6093\n",
      "Epoch 26/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 1.3673 - tp: 483.0000 - fp: 2606.0000 - tn: 222449.0000 - fn: 25336.0000 - accuracy: 0.8886 - precision: 0.1564 - recall: 0.0187 - auc: 0.5809 - val_loss: 0.3392 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6098\n",
      "Epoch 27/100\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 1.3684 - tp: 530.0000 - fp: 2652.0000 - tn: 222403.0000 - fn: 25289.0000 - accuracy: 0.8886 - precision: 0.1666 - recall: 0.0205 - auc: 0.5800 - val_loss: 0.3391 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6103\n",
      "Epoch 28/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 1.3662 - tp: 504.0000 - fp: 2772.0000 - tn: 222283.0000 - fn: 25315.0000 - accuracy: 0.8880 - precision: 0.1538 - recall: 0.0195 - auc: 0.5804 - val_loss: 0.3390 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6107\n",
      "Epoch 29/100\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 1.3642 - tp: 514.0000 - fp: 2787.0000 - tn: 222268.0000 - fn: 25305.0000 - accuracy: 0.8880 - precision: 0.1557 - recall: 0.0199 - auc: 0.5809 - val_loss: 0.3389 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6112\n",
      "Epoch 30/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.3591 - tp: 530.0000 - fp: 2901.0000 - tn: 222154.0000 - fn: 25289.0000 - accuracy: 0.8876 - precision: 0.1545 - recall: 0.0205 - auc: 0.5828 - val_loss: 0.3388 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6117\n",
      "Epoch 31/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3573 - tp: 495.0000 - fp: 2830.0000 - tn: 222225.0000 - fn: 25324.0000 - accuracy: 0.8878 - precision: 0.1489 - recall: 0.0192 - auc: 0.5826 - val_loss: 0.3387 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6120\n",
      "Epoch 32/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3589 - tp: 568.0000 - fp: 3007.0000 - tn: 222048.0000 - fn: 25251.0000 - accuracy: 0.8874 - precision: 0.1589 - recall: 0.0220 - auc: 0.5814 - val_loss: 0.3387 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6126\n",
      "Epoch 33/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3550 - tp: 565.0000 - fp: 3036.0000 - tn: 222019.0000 - fn: 25254.0000 - accuracy: 0.8872 - precision: 0.1569 - recall: 0.0219 - auc: 0.5827 - val_loss: 0.3386 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6128\n",
      "Epoch 34/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.3510 - tp: 601.0000 - fp: 3181.0000 - tn: 221874.0000 - fn: 25218.0000 - accuracy: 0.8868 - precision: 0.1589 - recall: 0.0233 - auc: 0.5833 - val_loss: 0.3385 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 32269.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6133\n",
      "Epoch 35/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.3516 - tp: 588.0000 - fp: 3244.0000 - tn: 221811.0000 - fn: 25231.0000 - accuracy: 0.8865 - precision: 0.1534 - recall: 0.0228 - auc: 0.5829 - val_loss: 0.3384 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 32269.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6137\n",
      "Epoch 36/100\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 1.3444 - tp: 617.0000 - fp: 3183.0000 - tn: 221872.0000 - fn: 25202.0000 - accuracy: 0.8869 - precision: 0.1624 - recall: 0.0239 - auc: 0.5856 - val_loss: 0.3384 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 32269.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6141\n",
      "Epoch 37/100\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1.3450 - tp: 629.0000 - fp: 3242.0000 - tn: 221813.0000 - fn: 25190.0000 - accuracy: 0.8867 - precision: 0.1625 - recall: 0.0244 - auc: 0.5852 - val_loss: 0.3383 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6145\n",
      "Epoch 38/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.3411 - tp: 669.0000 - fp: 3376.0000 - tn: 221679.0000 - fn: 25150.0000 - accuracy: 0.8863 - precision: 0.1654 - recall: 0.0259 - auc: 0.5859 - val_loss: 0.3383 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6149\n",
      "Epoch 39/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.3389 - tp: 652.0000 - fp: 3345.0000 - tn: 221710.0000 - fn: 25167.0000 - accuracy: 0.8863 - precision: 0.1631 - recall: 0.0253 - auc: 0.5874 - val_loss: 0.3382 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6153\n",
      "Epoch 40/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3406 - tp: 676.0000 - fp: 3507.0000 - tn: 221548.0000 - fn: 25143.0000 - accuracy: 0.8858 - precision: 0.1616 - recall: 0.0262 - auc: 0.5844 - val_loss: 0.3382 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3353 - tp: 704.0000 - fp: 3586.0000 - tn: 221469.0000 - fn: 25115.0000 - accuracy: 0.8856 - precision: 0.1641 - recall: 0.0273 - auc: 0.5867 - val_loss: 0.3381 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6163\n",
      "Epoch 42/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.3345 - tp: 733.0000 - fp: 3618.0000 - tn: 221437.0000 - fn: 25086.0000 - accuracy: 0.8856 - precision: 0.1685 - recall: 0.0284 - auc: 0.5861 - val_loss: 0.3381 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6166\n",
      "Epoch 43/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3318 - tp: 751.0000 - fp: 3781.0000 - tn: 221274.0000 - fn: 25068.0000 - accuracy: 0.8850 - precision: 0.1657 - recall: 0.0291 - auc: 0.5874 - val_loss: 0.3380 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6169\n",
      "Epoch 44/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.3289 - tp: 761.0000 - fp: 3775.0000 - tn: 221280.0000 - fn: 25058.0000 - accuracy: 0.8851 - precision: 0.1678 - recall: 0.0295 - auc: 0.5877 - val_loss: 0.3380 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6171\n",
      "Epoch 45/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.3255 - tp: 793.0000 - fp: 3839.0000 - tn: 221216.0000 - fn: 25026.0000 - accuracy: 0.8849 - precision: 0.1712 - recall: 0.0307 - auc: 0.5893 - val_loss: 0.3380 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6175\n",
      "Epoch 46/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3263 - tp: 746.0000 - fp: 4020.0000 - tn: 221035.0000 - fn: 25073.0000 - accuracy: 0.8840 - precision: 0.1565 - recall: 0.0289 - auc: 0.5879 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6179\n",
      "Epoch 47/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3218 - tp: 760.0000 - fp: 4094.0000 - tn: 220961.0000 - fn: 25059.0000 - accuracy: 0.8838 - precision: 0.1566 - recall: 0.0294 - auc: 0.5894 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 32267.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6183\n",
      "Epoch 48/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 1.3191 - tp: 785.0000 - fp: 4178.0000 - tn: 220877.0000 - fn: 25034.0000 - accuracy: 0.8836 - precision: 0.1582 - recall: 0.0304 - auc: 0.5892 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 32267.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6187\n",
      "Epoch 49/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3188 - tp: 779.0000 - fp: 4124.0000 - tn: 220931.0000 - fn: 25040.0000 - accuracy: 0.8838 - precision: 0.1589 - recall: 0.0302 - auc: 0.5894 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 32267.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6191\n",
      "Epoch 50/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.3180 - tp: 826.0000 - fp: 4286.0000 - tn: 220769.0000 - fn: 24993.0000 - accuracy: 0.8833 - precision: 0.1616 - recall: 0.0320 - auc: 0.5886 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 4.0000 - val_tn: 32266.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6194\n",
      "Epoch 51/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.3100 - tp: 848.0000 - fp: 4389.0000 - tn: 220666.0000 - fn: 24971.0000 - accuracy: 0.8830 - precision: 0.1619 - recall: 0.0328 - auc: 0.5917 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 32265.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6196\n",
      "Epoch 52/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3122 - tp: 893.0000 - fp: 4546.0000 - tn: 220509.0000 - fn: 24926.0000 - accuracy: 0.8825 - precision: 0.1642 - recall: 0.0346 - auc: 0.5909 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 32265.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6200\n",
      "Epoch 53/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 1.3037 - tp: 956.0000 - fp: 4735.0000 - tn: 220320.0000 - fn: 24863.0000 - accuracy: 0.8820 - precision: 0.1680 - recall: 0.0370 - auc: 0.5927 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 32265.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6203\n",
      "Epoch 54/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.3015 - tp: 1009.0000 - fp: 4807.0000 - tn: 220248.0000 - fn: 24810.0000 - accuracy: 0.8819 - precision: 0.1735 - recall: 0.0391 - auc: 0.5935 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 32265.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6206\n",
      "Epoch 55/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.2974 - tp: 997.0000 - fp: 4786.0000 - tn: 220269.0000 - fn: 24822.0000 - accuracy: 0.8820 - precision: 0.1724 - recall: 0.0386 - auc: 0.5947 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 6.0000 - val_tn: 32264.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6209\n",
      "Epoch 56/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.2998 - tp: 989.0000 - fp: 4860.0000 - tn: 220195.0000 - fn: 24830.0000 - accuracy: 0.8817 - precision: 0.1691 - recall: 0.0383 - auc: 0.5936 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 6.0000 - val_tn: 32264.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6212\n",
      "Epoch 57/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.3041 - tp: 978.0000 - fp: 4911.0000 - tn: 220144.0000 - fn: 24841.0000 - accuracy: 0.8814 - precision: 0.1661 - recall: 0.0379 - auc: 0.5904 - val_loss: 0.3380 - val_tp: 0.0000e+00 - val_fp: 7.0000 - val_tn: 32263.0000 - val_fn: 3648.0000 - val_accuracy: 0.8982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6215\n",
      "Epoch 58/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.2960 - tp: 1034.0000 - fp: 5195.0000 - tn: 219860.0000 - fn: 24785.0000 - accuracy: 0.8805 - precision: 0.1660 - recall: 0.0400 - auc: 0.5926 - val_loss: 0.3380 - val_tp: 0.0000e+00 - val_fp: 10.0000 - val_tn: 32260.0000 - val_fn: 3648.0000 - val_accuracy: 0.8982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6219\n",
      "Epoch 59/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.2928 - tp: 1069.0000 - fp: 5141.0000 - tn: 219914.0000 - fn: 24750.0000 - accuracy: 0.8809 - precision: 0.1721 - recall: 0.0414 - auc: 0.5934 - val_loss: 0.3380 - val_tp: 0.0000e+00 - val_fp: 10.0000 - val_tn: 32260.0000 - val_fn: 3648.0000 - val_accuracy: 0.8982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6223\n",
      "Epoch 60/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2981 - tp: 1089.0000 - fp: 5326.0000 - tn: 219729.0000 - fn: 24730.0000 - accuracy: 0.8802 - precision: 0.1698 - recall: 0.0422 - auc: 0.5926 - val_loss: 0.3381 - val_tp: 0.0000e+00 - val_fp: 10.0000 - val_tn: 32260.0000 - val_fn: 3648.0000 - val_accuracy: 0.8982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2915 - tp: 1083.0000 - fp: 5441.0000 - tn: 219614.0000 - fn: 24736.0000 - accuracy: 0.8797 - precision: 0.1660 - recall: 0.0419 - auc: 0.5944 - val_loss: 0.3381 - val_tp: 1.0000 - val_fp: 13.0000 - val_tn: 32257.0000 - val_fn: 3647.0000 - val_accuracy: 0.8981 - val_precision: 0.0714 - val_recall: 2.7412e-04 - val_auc: 0.6228\n",
      "Epoch 62/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2923 - tp: 1135.0000 - fp: 5503.0000 - tn: 219552.0000 - fn: 24684.0000 - accuracy: 0.8797 - precision: 0.1710 - recall: 0.0440 - auc: 0.5926 - val_loss: 0.3381 - val_tp: 1.0000 - val_fp: 13.0000 - val_tn: 32257.0000 - val_fn: 3647.0000 - val_accuracy: 0.8981 - val_precision: 0.0714 - val_recall: 2.7412e-04 - val_auc: 0.6231\n",
      "Epoch 63/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2845 - tp: 1169.0000 - fp: 5549.0000 - tn: 219506.0000 - fn: 24650.0000 - accuracy: 0.8796 - precision: 0.1740 - recall: 0.0453 - auc: 0.5963 - val_loss: 0.3382 - val_tp: 1.0000 - val_fp: 13.0000 - val_tn: 32257.0000 - val_fn: 3647.0000 - val_accuracy: 0.8981 - val_precision: 0.0714 - val_recall: 2.7412e-04 - val_auc: 0.6233\n",
      "Epoch 64/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2809 - tp: 1196.0000 - fp: 5661.0000 - tn: 219394.0000 - fn: 24623.0000 - accuracy: 0.8793 - precision: 0.1744 - recall: 0.0463 - auc: 0.5961 - val_loss: 0.3383 - val_tp: 2.0000 - val_fp: 16.0000 - val_tn: 32254.0000 - val_fn: 3646.0000 - val_accuracy: 0.8980 - val_precision: 0.1111 - val_recall: 5.4825e-04 - val_auc: 0.6236\n",
      "Epoch 65/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2822 - tp: 1237.0000 - fp: 5911.0000 - tn: 219144.0000 - fn: 24582.0000 - accuracy: 0.8785 - precision: 0.1731 - recall: 0.0479 - auc: 0.5956 - val_loss: 0.3383 - val_tp: 2.0000 - val_fp: 17.0000 - val_tn: 32253.0000 - val_fn: 3646.0000 - val_accuracy: 0.8980 - val_precision: 0.1053 - val_recall: 5.4825e-04 - val_auc: 0.6239\n",
      "Epoch 66/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2775 - tp: 1244.0000 - fp: 6008.0000 - tn: 219047.0000 - fn: 24575.0000 - accuracy: 0.8781 - precision: 0.1715 - recall: 0.0482 - auc: 0.5955 - val_loss: 0.3384 - val_tp: 2.0000 - val_fp: 18.0000 - val_tn: 32252.0000 - val_fn: 3646.0000 - val_accuracy: 0.8980 - val_precision: 0.1000 - val_recall: 5.4825e-04 - val_auc: 0.6241\n",
      "Epoch 67/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2809 - tp: 1266.0000 - fp: 5978.0000 - tn: 219077.0000 - fn: 24553.0000 - accuracy: 0.8783 - precision: 0.1748 - recall: 0.0490 - auc: 0.5941 - val_loss: 0.3385 - val_tp: 2.0000 - val_fp: 18.0000 - val_tn: 32252.0000 - val_fn: 3646.0000 - val_accuracy: 0.8980 - val_precision: 0.1000 - val_recall: 5.4825e-04 - val_auc: 0.6244\n",
      "Epoch 68/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2831 - tp: 1213.0000 - fp: 6223.0000 - tn: 218832.0000 - fn: 24606.0000 - accuracy: 0.8771 - precision: 0.1631 - recall: 0.0470 - auc: 0.5936 - val_loss: 0.3385 - val_tp: 2.0000 - val_fp: 19.0000 - val_tn: 32251.0000 - val_fn: 3646.0000 - val_accuracy: 0.8980 - val_precision: 0.0952 - val_recall: 5.4825e-04 - val_auc: 0.6246\n",
      "Epoch 69/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2720 - tp: 1341.0000 - fp: 6250.0000 - tn: 218805.0000 - fn: 24478.0000 - accuracy: 0.8775 - precision: 0.1767 - recall: 0.0519 - auc: 0.5965 - val_loss: 0.3386 - val_tp: 2.0000 - val_fp: 20.0000 - val_tn: 32250.0000 - val_fn: 3646.0000 - val_accuracy: 0.8979 - val_precision: 0.0909 - val_recall: 5.4825e-04 - val_auc: 0.6249\n",
      "Epoch 70/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2735 - tp: 1377.0000 - fp: 6463.0000 - tn: 218592.0000 - fn: 24442.0000 - accuracy: 0.8768 - precision: 0.1756 - recall: 0.0533 - auc: 0.5968 - val_loss: 0.3387 - val_tp: 2.0000 - val_fp: 21.0000 - val_tn: 32249.0000 - val_fn: 3646.0000 - val_accuracy: 0.8979 - val_precision: 0.0870 - val_recall: 5.4825e-04 - val_auc: 0.6252\n",
      "Epoch 71/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2692 - tp: 1352.0000 - fp: 6615.0000 - tn: 218440.0000 - fn: 24467.0000 - accuracy: 0.8761 - precision: 0.1697 - recall: 0.0524 - auc: 0.5968 - val_loss: 0.3388 - val_tp: 3.0000 - val_fp: 22.0000 - val_tn: 32248.0000 - val_fn: 3645.0000 - val_accuracy: 0.8979 - val_precision: 0.1200 - val_recall: 8.2237e-04 - val_auc: 0.6254\n",
      "Epoch 72/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2673 - tp: 1420.0000 - fp: 6627.0000 - tn: 218428.0000 - fn: 24399.0000 - accuracy: 0.8763 - precision: 0.1765 - recall: 0.0550 - auc: 0.5993 - val_loss: 0.3389 - val_tp: 3.0000 - val_fp: 26.0000 - val_tn: 32244.0000 - val_fn: 3645.0000 - val_accuracy: 0.8978 - val_precision: 0.1034 - val_recall: 8.2237e-04 - val_auc: 0.6256\n",
      "Epoch 73/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.2671 - tp: 1403.0000 - fp: 6709.0000 - tn: 218346.0000 - fn: 24416.0000 - accuracy: 0.8759 - precision: 0.1730 - recall: 0.0543 - auc: 0.5968 - val_loss: 0.3390 - val_tp: 3.0000 - val_fp: 26.0000 - val_tn: 32244.0000 - val_fn: 3645.0000 - val_accuracy: 0.8978 - val_precision: 0.1034 - val_recall: 8.2237e-04 - val_auc: 0.6258\n",
      "Epoch 74/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.2630 - tp: 1367.0000 - fp: 6903.0000 - tn: 218152.0000 - fn: 24452.0000 - accuracy: 0.8750 - precision: 0.1653 - recall: 0.0529 - auc: 0.5983 - val_loss: 0.3391 - val_tp: 3.0000 - val_fp: 27.0000 - val_tn: 32243.0000 - val_fn: 3645.0000 - val_accuracy: 0.8978 - val_precision: 0.1000 - val_recall: 8.2237e-04 - val_auc: 0.6260\n",
      "Epoch 75/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.2601 - tp: 1503.0000 - fp: 6939.0000 - tn: 218116.0000 - fn: 24316.0000 - accuracy: 0.8754 - precision: 0.1780 - recall: 0.0582 - auc: 0.5991 - val_loss: 0.3392 - val_tp: 3.0000 - val_fp: 30.0000 - val_tn: 32240.0000 - val_fn: 3645.0000 - val_accuracy: 0.8977 - val_precision: 0.0909 - val_recall: 8.2237e-04 - val_auc: 0.6262\n",
      "Epoch 76/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2594 - tp: 1516.0000 - fp: 7164.0000 - tn: 217891.0000 - fn: 24303.0000 - accuracy: 0.8746 - precision: 0.1747 - recall: 0.0587 - auc: 0.5992 - val_loss: 0.3393 - val_tp: 4.0000 - val_fp: 31.0000 - val_tn: 32239.0000 - val_fn: 3644.0000 - val_accuracy: 0.8977 - val_precision: 0.1143 - val_recall: 0.0011 - val_auc: 0.6266\n",
      "Epoch 77/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.2633 - tp: 1491.0000 - fp: 7344.0000 - tn: 217711.0000 - fn: 24328.0000 - accuracy: 0.8738 - precision: 0.1688 - recall: 0.0577 - auc: 0.5973 - val_loss: 0.3394 - val_tp: 5.0000 - val_fp: 33.0000 - val_tn: 32237.0000 - val_fn: 3643.0000 - val_accuracy: 0.8977 - val_precision: 0.1316 - val_recall: 0.0014 - val_auc: 0.6268\n",
      "Epoch 78/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.2553 - tp: 1489.0000 - fp: 7554.0000 - tn: 217501.0000 - fn: 24330.0000 - accuracy: 0.8729 - precision: 0.1647 - recall: 0.0577 - auc: 0.5985 - val_loss: 0.3395 - val_tp: 5.0000 - val_fp: 36.0000 - val_tn: 32234.0000 - val_fn: 3643.0000 - val_accuracy: 0.8976 - val_precision: 0.1220 - val_recall: 0.0014 - val_auc: 0.6270\n",
      "Epoch 79/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2533 - tp: 1585.0000 - fp: 7593.0000 - tn: 217462.0000 - fn: 24234.0000 - accuracy: 0.8731 - precision: 0.1727 - recall: 0.0614 - auc: 0.5997 - val_loss: 0.3396 - val_tp: 6.0000 - val_fp: 36.0000 - val_tn: 32234.0000 - val_fn: 3642.0000 - val_accuracy: 0.8976 - val_precision: 0.1429 - val_recall: 0.0016 - val_auc: 0.6273\n",
      "Epoch 80/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2501 - tp: 1639.0000 - fp: 7819.0000 - tn: 217236.0000 - fn: 24180.0000 - accuracy: 0.8724 - precision: 0.1733 - recall: 0.0635 - auc: 0.6011 - val_loss: 0.3398 - val_tp: 7.0000 - val_fp: 39.0000 - val_tn: 32231.0000 - val_fn: 3641.0000 - val_accuracy: 0.8975 - val_precision: 0.1522 - val_recall: 0.0019 - val_auc: 0.6275\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2514 - tp: 1639.0000 - fp: 7834.0000 - tn: 217221.0000 - fn: 24180.0000 - accuracy: 0.8724 - precision: 0.1730 - recall: 0.0635 - auc: 0.5992 - val_loss: 0.3399 - val_tp: 9.0000 - val_fp: 42.0000 - val_tn: 32228.0000 - val_fn: 3639.0000 - val_accuracy: 0.8975 - val_precision: 0.1765 - val_recall: 0.0025 - val_auc: 0.6278\n",
      "Epoch 82/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2495 - tp: 1665.0000 - fp: 8003.0000 - tn: 217052.0000 - fn: 24154.0000 - accuracy: 0.8718 - precision: 0.1722 - recall: 0.0645 - auc: 0.5995 - val_loss: 0.3400 - val_tp: 9.0000 - val_fp: 45.0000 - val_tn: 32225.0000 - val_fn: 3639.0000 - val_accuracy: 0.8974 - val_precision: 0.1667 - val_recall: 0.0025 - val_auc: 0.6281\n",
      "Epoch 83/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2485 - tp: 1651.0000 - fp: 8146.0000 - tn: 216909.0000 - fn: 24168.0000 - accuracy: 0.8712 - precision: 0.1685 - recall: 0.0639 - auc: 0.5994 - val_loss: 0.3402 - val_tp: 10.0000 - val_fp: 49.0000 - val_tn: 32221.0000 - val_fn: 3638.0000 - val_accuracy: 0.8973 - val_precision: 0.1695 - val_recall: 0.0027 - val_auc: 0.6282\n",
      "Epoch 84/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.2411 - tp: 1719.0000 - fp: 8319.0000 - tn: 216736.0000 - fn: 24100.0000 - accuracy: 0.8708 - precision: 0.1712 - recall: 0.0666 - auc: 0.6016 - val_loss: 0.3403 - val_tp: 10.0000 - val_fp: 53.0000 - val_tn: 32217.0000 - val_fn: 3638.0000 - val_accuracy: 0.8972 - val_precision: 0.1587 - val_recall: 0.0027 - val_auc: 0.6284\n",
      "Epoch 85/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2465 - tp: 1806.0000 - fp: 8523.0000 - tn: 216532.0000 - fn: 24013.0000 - accuracy: 0.8703 - precision: 0.1748 - recall: 0.0699 - auc: 0.5980 - val_loss: 0.3405 - val_tp: 13.0000 - val_fp: 55.0000 - val_tn: 32215.0000 - val_fn: 3635.0000 - val_accuracy: 0.8973 - val_precision: 0.1912 - val_recall: 0.0036 - val_auc: 0.6286\n",
      "Epoch 86/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2353 - tp: 1856.0000 - fp: 8581.0000 - tn: 216474.0000 - fn: 23963.0000 - accuracy: 0.8703 - precision: 0.1778 - recall: 0.0719 - auc: 0.6026 - val_loss: 0.3407 - val_tp: 13.0000 - val_fp: 60.0000 - val_tn: 32210.0000 - val_fn: 3635.0000 - val_accuracy: 0.8971 - val_precision: 0.1781 - val_recall: 0.0036 - val_auc: 0.6289\n",
      "Epoch 87/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2405 - tp: 1782.0000 - fp: 8652.0000 - tn: 216403.0000 - fn: 24037.0000 - accuracy: 0.8697 - precision: 0.1708 - recall: 0.0690 - auc: 0.6008 - val_loss: 0.3408 - val_tp: 13.0000 - val_fp: 62.0000 - val_tn: 32208.0000 - val_fn: 3635.0000 - val_accuracy: 0.8971 - val_precision: 0.1733 - val_recall: 0.0036 - val_auc: 0.6291\n",
      "Epoch 88/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2391 - tp: 1834.0000 - fp: 8875.0000 - tn: 216180.0000 - fn: 23985.0000 - accuracy: 0.8690 - precision: 0.1713 - recall: 0.0710 - auc: 0.6007 - val_loss: 0.3410 - val_tp: 15.0000 - val_fp: 65.0000 - val_tn: 32205.0000 - val_fn: 3633.0000 - val_accuracy: 0.8970 - val_precision: 0.1875 - val_recall: 0.0041 - val_auc: 0.6292\n",
      "Epoch 89/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2348 - tp: 1889.0000 - fp: 9090.0000 - tn: 215965.0000 - fn: 23930.0000 - accuracy: 0.8684 - precision: 0.1721 - recall: 0.0732 - auc: 0.6011 - val_loss: 0.3412 - val_tp: 17.0000 - val_fp: 67.0000 - val_tn: 32203.0000 - val_fn: 3631.0000 - val_accuracy: 0.8970 - val_precision: 0.2024 - val_recall: 0.0047 - val_auc: 0.6294\n",
      "Epoch 90/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2344 - tp: 1914.0000 - fp: 9174.0000 - tn: 215881.0000 - fn: 23905.0000 - accuracy: 0.8681 - precision: 0.1726 - recall: 0.0741 - auc: 0.6006 - val_loss: 0.3413 - val_tp: 18.0000 - val_fp: 72.0000 - val_tn: 32198.0000 - val_fn: 3630.0000 - val_accuracy: 0.8969 - val_precision: 0.2000 - val_recall: 0.0049 - val_auc: 0.6297\n",
      "Epoch 91/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2330 - tp: 1997.0000 - fp: 9269.0000 - tn: 215786.0000 - fn: 23822.0000 - accuracy: 0.8681 - precision: 0.1773 - recall: 0.0773 - auc: 0.6018 - val_loss: 0.3415 - val_tp: 18.0000 - val_fp: 76.0000 - val_tn: 32194.0000 - val_fn: 3630.0000 - val_accuracy: 0.8968 - val_precision: 0.1915 - val_recall: 0.0049 - val_auc: 0.6300\n",
      "Epoch 92/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.2272 - tp: 2078.0000 - fp: 9263.0000 - tn: 215792.0000 - fn: 23741.0000 - accuracy: 0.8684 - precision: 0.1832 - recall: 0.0805 - auc: 0.6028 - val_loss: 0.3417 - val_tp: 20.0000 - val_fp: 79.0000 - val_tn: 32191.0000 - val_fn: 3628.0000 - val_accuracy: 0.8968 - val_precision: 0.2020 - val_recall: 0.0055 - val_auc: 0.6301\n",
      "Epoch 93/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2251 - tp: 2042.0000 - fp: 9515.0000 - tn: 215540.0000 - fn: 23777.0000 - accuracy: 0.8673 - precision: 0.1767 - recall: 0.0791 - auc: 0.6040 - val_loss: 0.3419 - val_tp: 20.0000 - val_fp: 84.0000 - val_tn: 32186.0000 - val_fn: 3628.0000 - val_accuracy: 0.8967 - val_precision: 0.1923 - val_recall: 0.0055 - val_auc: 0.6303\n",
      "Epoch 94/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2252 - tp: 2026.0000 - fp: 9615.0000 - tn: 215440.0000 - fn: 23793.0000 - accuracy: 0.8668 - precision: 0.1740 - recall: 0.0785 - auc: 0.6032 - val_loss: 0.3421 - val_tp: 21.0000 - val_fp: 90.0000 - val_tn: 32180.0000 - val_fn: 3627.0000 - val_accuracy: 0.8965 - val_precision: 0.1892 - val_recall: 0.0058 - val_auc: 0.6305\n",
      "Epoch 95/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2285 - tp: 2035.0000 - fp: 9940.0000 - tn: 215115.0000 - fn: 23784.0000 - accuracy: 0.8656 - precision: 0.1699 - recall: 0.0788 - auc: 0.6010 - val_loss: 0.3423 - val_tp: 22.0000 - val_fp: 98.0000 - val_tn: 32172.0000 - val_fn: 3626.0000 - val_accuracy: 0.8963 - val_precision: 0.1833 - val_recall: 0.0060 - val_auc: 0.6307\n",
      "Epoch 96/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2234 - tp: 2151.0000 - fp: 9989.0000 - tn: 215066.0000 - fn: 23668.0000 - accuracy: 0.8658 - precision: 0.1772 - recall: 0.0833 - auc: 0.6030 - val_loss: 0.3425 - val_tp: 27.0000 - val_fp: 102.0000 - val_tn: 32168.0000 - val_fn: 3621.0000 - val_accuracy: 0.8963 - val_precision: 0.2093 - val_recall: 0.0074 - val_auc: 0.6309\n",
      "Epoch 97/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2205 - tp: 2182.0000 - fp: 10370.0000 - tn: 214685.0000 - fn: 23637.0000 - accuracy: 0.8644 - precision: 0.1738 - recall: 0.0845 - auc: 0.6040 - val_loss: 0.3427 - val_tp: 28.0000 - val_fp: 105.0000 - val_tn: 32165.0000 - val_fn: 3620.0000 - val_accuracy: 0.8963 - val_precision: 0.2105 - val_recall: 0.0077 - val_auc: 0.6310\n",
      "Epoch 98/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2128 - tp: 2247.0000 - fp: 10391.0000 - tn: 214664.0000 - fn: 23572.0000 - accuracy: 0.8646 - precision: 0.1778 - recall: 0.0870 - auc: 0.6058 - val_loss: 0.3429 - val_tp: 32.0000 - val_fp: 111.0000 - val_tn: 32159.0000 - val_fn: 3616.0000 - val_accuracy: 0.8962 - val_precision: 0.2238 - val_recall: 0.0088 - val_auc: 0.6312\n",
      "Epoch 99/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2208 - tp: 2192.0000 - fp: 10401.0000 - tn: 214654.0000 - fn: 23627.0000 - accuracy: 0.8644 - precision: 0.1741 - recall: 0.0849 - auc: 0.6025 - val_loss: 0.3431 - val_tp: 35.0000 - val_fp: 121.0000 - val_tn: 32149.0000 - val_fn: 3613.0000 - val_accuracy: 0.8960 - val_precision: 0.2244 - val_recall: 0.0096 - val_auc: 0.6314\n",
      "Epoch 100/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2174 - tp: 2216.0000 - fp: 10838.0000 - tn: 214217.0000 - fn: 23603.0000 - accuracy: 0.8627 - precision: 0.1698 - recall: 0.0858 - auc: 0.6036 - val_loss: 0.3433 - val_tp: 37.0000 - val_fp: 131.0000 - val_tn: 32139.0000 - val_fn: 3611.0000 - val_accuracy: 0.8958 - val_precision: 0.2202 - val_recall: 0.0101 - val_auc: 0.6315\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 2s 19ms/step - loss: 1.4278 - tp: 334.0000 - fp: 1983.0000 - tn: 255342.0000 - fn: 29133.0000 - accuracy: 0.8915 - precision: 0.1442 - recall: 0.0113 - auc: 0.5740 - val_loss: 0.3415 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6010\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.3973 - tp: 362.0000 - fp: 2174.0000 - tn: 222881.0000 - fn: 25457.0000 - accuracy: 0.8899 - precision: 0.1427 - recall: 0.0140 - auc: 0.5740 - val_loss: 0.3400 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6070\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.3672 - tp: 489.0000 - fp: 2642.0000 - tn: 222413.0000 - fn: 25330.0000 - accuracy: 0.8885 - precision: 0.1562 - recall: 0.0189 - auc: 0.5818 - val_loss: 0.3389 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6117\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3443 - tp: 632.0000 - fp: 3183.0000 - tn: 221872.0000 - fn: 25187.0000 - accuracy: 0.8869 - precision: 0.1657 - recall: 0.0245 - auc: 0.5849 - val_loss: 0.3382 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6160\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.3252 - tp: 772.0000 - fp: 4076.0000 - tn: 220979.0000 - fn: 25047.0000 - accuracy: 0.8839 - precision: 0.1592 - recall: 0.0299 - auc: 0.5879 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 32265.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6194\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3098 - tp: 960.0000 - fp: 4865.0000 - tn: 220190.0000 - fn: 24859.0000 - accuracy: 0.8815 - precision: 0.1648 - recall: 0.0372 - auc: 0.5885 - val_loss: 0.3381 - val_tp: 0.0000e+00 - val_fp: 10.0000 - val_tn: 32260.0000 - val_fn: 3648.0000 - val_accuracy: 0.8982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6225\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2837 - tp: 1204.0000 - fp: 5969.0000 - tn: 219086.0000 - fn: 24615.0000 - accuracy: 0.8781 - precision: 0.1679 - recall: 0.0466 - auc: 0.5935 - val_loss: 0.3387 - val_tp: 2.0000 - val_fp: 21.0000 - val_tn: 32249.0000 - val_fn: 3646.0000 - val_accuracy: 0.8979 - val_precision: 0.0870 - val_recall: 5.4825e-04 - val_auc: 0.6250\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.2613 - tp: 1470.0000 - fp: 7296.0000 - tn: 217759.0000 - fn: 24349.0000 - accuracy: 0.8739 - precision: 0.1677 - recall: 0.0569 - auc: 0.5978 - val_loss: 0.3398 - val_tp: 6.0000 - val_fp: 38.0000 - val_tn: 32232.0000 - val_fn: 3642.0000 - val_accuracy: 0.8975 - val_precision: 0.1364 - val_recall: 0.0016 - val_auc: 0.6273\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.2437 - tp: 1689.0000 - fp: 8419.0000 - tn: 216636.0000 - fn: 24130.0000 - accuracy: 0.8703 - precision: 0.1671 - recall: 0.0654 - auc: 0.6021 - val_loss: 0.3412 - val_tp: 16.0000 - val_fp: 67.0000 - val_tn: 32203.0000 - val_fn: 3632.0000 - val_accuracy: 0.8970 - val_precision: 0.1928 - val_recall: 0.0044 - val_auc: 0.6294\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2244 - tp: 2100.0000 - fp: 9720.0000 - tn: 215335.0000 - fn: 23719.0000 - accuracy: 0.8667 - precision: 0.1777 - recall: 0.0813 - auc: 0.6036 - val_loss: 0.3430 - val_tp: 32.0000 - val_fp: 115.0000 - val_tn: 32155.0000 - val_fn: 3616.0000 - val_accuracy: 0.8961 - val_precision: 0.2177 - val_recall: 0.0088 - val_auc: 0.6311\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.2050 - tp: 2382.0000 - fp: 11225.0000 - tn: 213830.0000 - fn: 23437.0000 - accuracy: 0.8618 - precision: 0.1751 - recall: 0.0923 - auc: 0.6065 - val_loss: 0.3452 - val_tp: 47.0000 - val_fp: 206.0000 - val_tn: 32064.0000 - val_fn: 3601.0000 - val_accuracy: 0.8940 - val_precision: 0.1858 - val_recall: 0.0129 - val_auc: 0.6328\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.1917 - tp: 2639.0000 - fp: 12814.0000 - tn: 212241.0000 - fn: 23180.0000 - accuracy: 0.8565 - precision: 0.1708 - recall: 0.1022 - auc: 0.6067 - val_loss: 0.3478 - val_tp: 73.0000 - val_fp: 312.0000 - val_tn: 31958.0000 - val_fn: 3575.0000 - val_accuracy: 0.8918 - val_precision: 0.1896 - val_recall: 0.0200 - val_auc: 0.6340\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.1783 - tp: 3042.0000 - fp: 14409.0000 - tn: 210646.0000 - fn: 22777.0000 - accuracy: 0.8518 - precision: 0.1743 - recall: 0.1178 - auc: 0.6067 - val_loss: 0.3507 - val_tp: 127.0000 - val_fp: 468.0000 - val_tn: 31802.0000 - val_fn: 3521.0000 - val_accuracy: 0.8889 - val_precision: 0.2134 - val_recall: 0.0348 - val_auc: 0.6353\n",
      "Epoch 14/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.1599 - tp: 3468.0000 - fp: 15950.0000 - tn: 209105.0000 - fn: 22351.0000 - accuracy: 0.8473 - precision: 0.1786 - recall: 0.1343 - auc: 0.6110 - val_loss: 0.3538 - val_tp: 177.0000 - val_fp: 662.0000 - val_tn: 31608.0000 - val_fn: 3471.0000 - val_accuracy: 0.8849 - val_precision: 0.2110 - val_recall: 0.0485 - val_auc: 0.6365\n",
      "Epoch 15/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.1469 - tp: 3737.0000 - fp: 17525.0000 - tn: 207530.0000 - fn: 22082.0000 - accuracy: 0.8421 - precision: 0.1758 - recall: 0.1447 - auc: 0.6119 - val_loss: 0.3572 - val_tp: 251.0000 - val_fp: 874.0000 - val_tn: 31396.0000 - val_fn: 3397.0000 - val_accuracy: 0.8811 - val_precision: 0.2231 - val_recall: 0.0688 - val_auc: 0.6374\n",
      "Epoch 16/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.1360 - tp: 4039.0000 - fp: 19021.0000 - tn: 206034.0000 - fn: 21780.0000 - accuracy: 0.8374 - precision: 0.1752 - recall: 0.1564 - auc: 0.6121 - val_loss: 0.3608 - val_tp: 311.0000 - val_fp: 1131.0000 - val_tn: 31139.0000 - val_fn: 3337.0000 - val_accuracy: 0.8756 - val_precision: 0.2157 - val_recall: 0.0853 - val_auc: 0.6385\n",
      "Epoch 17/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.1257 - tp: 4257.0000 - fp: 20544.0000 - tn: 204511.0000 - fn: 21562.0000 - accuracy: 0.8322 - precision: 0.1716 - recall: 0.1649 - auc: 0.6132 - val_loss: 0.3645 - val_tp: 371.0000 - val_fp: 1372.0000 - val_tn: 30898.0000 - val_fn: 3277.0000 - val_accuracy: 0.8706 - val_precision: 0.2129 - val_recall: 0.1017 - val_auc: 0.6395\n",
      "Epoch 18/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.1116 - tp: 4623.0000 - fp: 22335.0000 - tn: 202720.0000 - fn: 21196.0000 - accuracy: 0.8265 - precision: 0.1715 - recall: 0.1791 - auc: 0.6143 - val_loss: 0.3682 - val_tp: 428.0000 - val_fp: 1608.0000 - val_tn: 30662.0000 - val_fn: 3220.0000 - val_accuracy: 0.8656 - val_precision: 0.2102 - val_recall: 0.1173 - val_auc: 0.6403\n",
      "Epoch 19/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.1053 - tp: 4866.0000 - fp: 23372.0000 - tn: 201683.0000 - fn: 20953.0000 - accuracy: 0.8233 - precision: 0.1723 - recall: 0.1885 - auc: 0.6143 - val_loss: 0.3720 - val_tp: 492.0000 - val_fp: 1868.0000 - val_tn: 30402.0000 - val_fn: 3156.0000 - val_accuracy: 0.8601 - val_precision: 0.2085 - val_recall: 0.1349 - val_auc: 0.6411\n",
      "Epoch 20/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 1.0867 - tp: 5297.0000 - fp: 24660.0000 - tn: 200395.0000 - fn: 20522.0000 - accuracy: 0.8199 - precision: 0.1768 - recall: 0.2052 - auc: 0.6189 - val_loss: 0.3759 - val_tp: 561.0000 - val_fp: 2135.0000 - val_tn: 30135.0000 - val_fn: 3087.0000 - val_accuracy: 0.8546 - val_precision: 0.2081 - val_recall: 0.1538 - val_auc: 0.6419\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 10ms/step - loss: 1.0895 - tp: 5345.0000 - fp: 25996.0000 - tn: 199059.0000 - fn: 20474.0000 - accuracy: 0.8148 - precision: 0.1705 - recall: 0.2070 - auc: 0.6148 - val_loss: 0.3794 - val_tp: 610.0000 - val_fp: 2370.0000 - val_tn: 29900.0000 - val_fn: 3038.0000 - val_accuracy: 0.8494 - val_precision: 0.2047 - val_recall: 0.1672 - val_auc: 0.6427\n",
      "Epoch 22/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.0762 - tp: 5644.0000 - fp: 27371.0000 - tn: 197684.0000 - fn: 20175.0000 - accuracy: 0.8105 - precision: 0.1710 - recall: 0.2186 - auc: 0.6165 - val_loss: 0.3832 - val_tp: 665.0000 - val_fp: 2641.0000 - val_tn: 29629.0000 - val_fn: 2983.0000 - val_accuracy: 0.8434 - val_precision: 0.2011 - val_recall: 0.1823 - val_auc: 0.6434\n",
      "Epoch 23/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.0689 - tp: 5805.0000 - fp: 28278.0000 - tn: 196777.0000 - fn: 20014.0000 - accuracy: 0.8075 - precision: 0.1703 - recall: 0.2248 - auc: 0.6164 - val_loss: 0.3869 - val_tp: 725.0000 - val_fp: 2861.0000 - val_tn: 29409.0000 - val_fn: 2923.0000 - val_accuracy: 0.8390 - val_precision: 0.2022 - val_recall: 0.1987 - val_auc: 0.6439\n",
      "Epoch 24/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.0651 - tp: 5988.0000 - fp: 29368.0000 - tn: 195687.0000 - fn: 19831.0000 - accuracy: 0.8039 - precision: 0.1694 - recall: 0.2319 - auc: 0.6159 - val_loss: 0.3903 - val_tp: 777.0000 - val_fp: 3067.0000 - val_tn: 29203.0000 - val_fn: 2871.0000 - val_accuracy: 0.8347 - val_precision: 0.2021 - val_recall: 0.2130 - val_auc: 0.6445\n",
      "Epoch 25/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.0516 - tp: 6229.0000 - fp: 29974.0000 - tn: 195081.0000 - fn: 19590.0000 - accuracy: 0.8024 - precision: 0.1721 - recall: 0.2413 - auc: 0.6190 - val_loss: 0.3938 - val_tp: 810.0000 - val_fp: 3257.0000 - val_tn: 29013.0000 - val_fn: 2838.0000 - val_accuracy: 0.8303 - val_precision: 0.1992 - val_recall: 0.2220 - val_auc: 0.6453\n",
      "Epoch 26/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.0480 - tp: 6353.0000 - fp: 31200.0000 - tn: 193855.0000 - fn: 19466.0000 - accuracy: 0.7980 - precision: 0.1692 - recall: 0.2461 - auc: 0.6180 - val_loss: 0.3972 - val_tp: 853.0000 - val_fp: 3426.0000 - val_tn: 28844.0000 - val_fn: 2795.0000 - val_accuracy: 0.8268 - val_precision: 0.1993 - val_recall: 0.2338 - val_auc: 0.6458\n",
      "Epoch 27/100\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 1.0350 - tp: 6568.0000 - fp: 31823.0000 - tn: 193232.0000 - fn: 19251.0000 - accuracy: 0.7964 - precision: 0.1711 - recall: 0.2544 - auc: 0.6210 - val_loss: 0.4004 - val_tp: 895.0000 - val_fp: 3591.0000 - val_tn: 28679.0000 - val_fn: 2753.0000 - val_accuracy: 0.8234 - val_precision: 0.1995 - val_recall: 0.2453 - val_auc: 0.6463\n",
      "Epoch 28/100\n",
      "126/126 [==============================] - 2s 17ms/step - loss: 1.0355 - tp: 6639.0000 - fp: 32729.0000 - tn: 192326.0000 - fn: 19180.0000 - accuracy: 0.7931 - precision: 0.1686 - recall: 0.2571 - auc: 0.6190 - val_loss: 0.4033 - val_tp: 921.0000 - val_fp: 3733.0000 - val_tn: 28537.0000 - val_fn: 2727.0000 - val_accuracy: 0.8201 - val_precision: 0.1979 - val_recall: 0.2525 - val_auc: 0.6470\n",
      "Epoch 29/100\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 1.0244 - tp: 6740.0000 - fp: 33482.0000 - tn: 191573.0000 - fn: 19079.0000 - accuracy: 0.7905 - precision: 0.1676 - recall: 0.2610 - auc: 0.6216 - val_loss: 0.4064 - val_tp: 947.0000 - val_fp: 3905.0000 - val_tn: 28365.0000 - val_fn: 2701.0000 - val_accuracy: 0.8161 - val_precision: 0.1952 - val_recall: 0.2596 - val_auc: 0.6476\n",
      "Epoch 30/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.0139 - tp: 6982.0000 - fp: 34158.0000 - tn: 190897.0000 - fn: 18837.0000 - accuracy: 0.7888 - precision: 0.1697 - recall: 0.2704 - auc: 0.6238 - val_loss: 0.4088 - val_tp: 968.0000 - val_fp: 4025.0000 - val_tn: 28245.0000 - val_fn: 2680.0000 - val_accuracy: 0.8133 - val_precision: 0.1939 - val_recall: 0.2654 - val_auc: 0.6481\n",
      "Epoch 31/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.0197 - tp: 6974.0000 - fp: 34723.0000 - tn: 190332.0000 - fn: 18845.0000 - accuracy: 0.7865 - precision: 0.1673 - recall: 0.2701 - auc: 0.6178 - val_loss: 0.4113 - val_tp: 989.0000 - val_fp: 4152.0000 - val_tn: 28118.0000 - val_fn: 2659.0000 - val_accuracy: 0.8104 - val_precision: 0.1924 - val_recall: 0.2711 - val_auc: 0.6488\n",
      "Epoch 32/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.0057 - tp: 7156.0000 - fp: 35423.0000 - tn: 189632.0000 - fn: 18663.0000 - accuracy: 0.7844 - precision: 0.1681 - recall: 0.2772 - auc: 0.6230 - val_loss: 0.4138 - val_tp: 1013.0000 - val_fp: 4299.0000 - val_tn: 27971.0000 - val_fn: 2635.0000 - val_accuracy: 0.8069 - val_precision: 0.1907 - val_recall: 0.2777 - val_auc: 0.6494\n",
      "Epoch 33/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 1.0018 - tp: 7257.0000 - fp: 35938.0000 - tn: 189117.0000 - fn: 18562.0000 - accuracy: 0.7828 - precision: 0.1680 - recall: 0.2811 - auc: 0.6217 - val_loss: 0.4156 - val_tp: 1030.0000 - val_fp: 4385.0000 - val_tn: 27885.0000 - val_fn: 2618.0000 - val_accuracy: 0.8050 - val_precision: 0.1902 - val_recall: 0.2823 - val_auc: 0.6498\n",
      "Epoch 34/100\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.9997 - tp: 7323.0000 - fp: 36439.0000 - tn: 188616.0000 - fn: 18496.0000 - accuracy: 0.7810 - precision: 0.1673 - recall: 0.2836 - auc: 0.6214 - val_loss: 0.4176 - val_tp: 1043.0000 - val_fp: 4471.0000 - val_tn: 27799.0000 - val_fn: 2605.0000 - val_accuracy: 0.8030 - val_precision: 0.1892 - val_recall: 0.2859 - val_auc: 0.6503\n",
      "Epoch 35/100\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.9897 - tp: 7545.0000 - fp: 36831.0000 - tn: 188224.0000 - fn: 18274.0000 - accuracy: 0.7803 - precision: 0.1700 - recall: 0.2922 - auc: 0.6229 - val_loss: 0.4192 - val_tp: 1059.0000 - val_fp: 4537.0000 - val_tn: 27733.0000 - val_fn: 2589.0000 - val_accuracy: 0.8016 - val_precision: 0.1892 - val_recall: 0.2903 - val_auc: 0.6509\n",
      "Epoch 36/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.9870 - tp: 7474.0000 - fp: 37328.0000 - tn: 187727.0000 - fn: 18345.0000 - accuracy: 0.7781 - precision: 0.1668 - recall: 0.2895 - auc: 0.6218 - val_loss: 0.4205 - val_tp: 1067.0000 - val_fp: 4598.0000 - val_tn: 27672.0000 - val_fn: 2581.0000 - val_accuracy: 0.8001 - val_precision: 0.1883 - val_recall: 0.2925 - val_auc: 0.6515\n",
      "Epoch 37/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.9807 - tp: 7623.0000 - fp: 37622.0000 - tn: 187433.0000 - fn: 18196.0000 - accuracy: 0.7775 - precision: 0.1685 - recall: 0.2952 - auc: 0.6232 - val_loss: 0.4220 - val_tp: 1080.0000 - val_fp: 4665.0000 - val_tn: 27605.0000 - val_fn: 2568.0000 - val_accuracy: 0.7986 - val_precision: 0.1880 - val_recall: 0.2961 - val_auc: 0.6522\n",
      "Epoch 38/100\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.9744 - tp: 7722.0000 - fp: 37542.0000 - tn: 187513.0000 - fn: 18097.0000 - accuracy: 0.7782 - precision: 0.1706 - recall: 0.2991 - auc: 0.6246 - val_loss: 0.4234 - val_tp: 1092.0000 - val_fp: 4727.0000 - val_tn: 27543.0000 - val_fn: 2556.0000 - val_accuracy: 0.7972 - val_precision: 0.1877 - val_recall: 0.2993 - val_auc: 0.6528\n",
      "Epoch 39/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.9749 - tp: 7701.0000 - fp: 38346.0000 - tn: 186709.0000 - fn: 18118.0000 - accuracy: 0.7749 - precision: 0.1672 - recall: 0.2983 - auc: 0.6228 - val_loss: 0.4247 - val_tp: 1104.0000 - val_fp: 4777.0000 - val_tn: 27493.0000 - val_fn: 2544.0000 - val_accuracy: 0.7962 - val_precision: 0.1877 - val_recall: 0.3026 - val_auc: 0.6532\n",
      "Epoch 40/100\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.9684 - tp: 7706.0000 - fp: 38555.0000 - tn: 186500.0000 - fn: 18113.0000 - accuracy: 0.7741 - precision: 0.1666 - recall: 0.2985 - auc: 0.6229 - val_loss: 0.4261 - val_tp: 1115.0000 - val_fp: 4854.0000 - val_tn: 27416.0000 - val_fn: 2533.0000 - val_accuracy: 0.7943 - val_precision: 0.1868 - val_recall: 0.3056 - val_auc: 0.6538\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 2s 17ms/step - loss: 0.9607 - tp: 7809.0000 - fp: 38822.0000 - tn: 186233.0000 - fn: 18010.0000 - accuracy: 0.7735 - precision: 0.1675 - recall: 0.3025 - auc: 0.6245 - val_loss: 0.4272 - val_tp: 1125.0000 - val_fp: 4896.0000 - val_tn: 27374.0000 - val_fn: 2523.0000 - val_accuracy: 0.7934 - val_precision: 0.1868 - val_recall: 0.3084 - val_auc: 0.6543\n",
      "Epoch 42/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.9606 - tp: 7898.0000 - fp: 39188.0000 - tn: 185867.0000 - fn: 17921.0000 - accuracy: 0.7724 - precision: 0.1677 - recall: 0.3059 - auc: 0.6234 - val_loss: 0.4276 - val_tp: 1128.0000 - val_fp: 4919.0000 - val_tn: 27351.0000 - val_fn: 2520.0000 - val_accuracy: 0.7929 - val_precision: 0.1865 - val_recall: 0.3092 - val_auc: 0.6549\n",
      "Epoch 43/100\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 0.9517 - tp: 7963.0000 - fp: 39687.0000 - tn: 185368.0000 - fn: 17856.0000 - accuracy: 0.7706 - precision: 0.1671 - recall: 0.3084 - auc: 0.6250 - val_loss: 0.4285 - val_tp: 1138.0000 - val_fp: 4942.0000 - val_tn: 27328.0000 - val_fn: 2510.0000 - val_accuracy: 0.7925 - val_precision: 0.1872 - val_recall: 0.3120 - val_auc: 0.6555\n",
      "Epoch 44/100\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.9459 - tp: 8049.0000 - fp: 39594.0000 - tn: 185461.0000 - fn: 17770.0000 - accuracy: 0.7713 - precision: 0.1689 - recall: 0.3117 - auc: 0.6264 - val_loss: 0.4293 - val_tp: 1149.0000 - val_fp: 4981.0000 - val_tn: 27289.0000 - val_fn: 2499.0000 - val_accuracy: 0.7917 - val_precision: 0.1874 - val_recall: 0.3150 - val_auc: 0.6560\n",
      "Epoch 45/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.9435 - tp: 8054.0000 - fp: 39940.0000 - tn: 185115.0000 - fn: 17765.0000 - accuracy: 0.7700 - precision: 0.1678 - recall: 0.3119 - auc: 0.6259 - val_loss: 0.4299 - val_tp: 1155.0000 - val_fp: 5016.0000 - val_tn: 27254.0000 - val_fn: 2493.0000 - val_accuracy: 0.7909 - val_precision: 0.1872 - val_recall: 0.3166 - val_auc: 0.6566\n",
      "Epoch 46/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.9391 - tp: 8126.0000 - fp: 39940.0000 - tn: 185115.0000 - fn: 17693.0000 - accuracy: 0.7703 - precision: 0.1691 - recall: 0.3147 - auc: 0.6262 - val_loss: 0.4303 - val_tp: 1161.0000 - val_fp: 5043.0000 - val_tn: 27227.0000 - val_fn: 2487.0000 - val_accuracy: 0.7904 - val_precision: 0.1871 - val_recall: 0.3183 - val_auc: 0.6572\n",
      "Epoch 47/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.9347 - tp: 8249.0000 - fp: 40361.0000 - tn: 184694.0000 - fn: 17570.0000 - accuracy: 0.7691 - precision: 0.1697 - recall: 0.3195 - auc: 0.6266 - val_loss: 0.4307 - val_tp: 1163.0000 - val_fp: 5057.0000 - val_tn: 27213.0000 - val_fn: 2485.0000 - val_accuracy: 0.7900 - val_precision: 0.1870 - val_recall: 0.3188 - val_auc: 0.6577\n",
      "Epoch 48/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.9288 - tp: 8206.0000 - fp: 40446.0000 - tn: 184609.0000 - fn: 17613.0000 - accuracy: 0.7686 - precision: 0.1687 - recall: 0.3178 - auc: 0.6268 - val_loss: 0.4313 - val_tp: 1172.0000 - val_fp: 5086.0000 - val_tn: 27184.0000 - val_fn: 2476.0000 - val_accuracy: 0.7895 - val_precision: 0.1873 - val_recall: 0.3213 - val_auc: 0.6582\n",
      "Epoch 49/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.9261 - tp: 8348.0000 - fp: 40694.0000 - tn: 184361.0000 - fn: 17471.0000 - accuracy: 0.7682 - precision: 0.1702 - recall: 0.3233 - auc: 0.6275 - val_loss: 0.4316 - val_tp: 1175.0000 - val_fp: 5097.0000 - val_tn: 27173.0000 - val_fn: 2473.0000 - val_accuracy: 0.7892 - val_precision: 0.1873 - val_recall: 0.3221 - val_auc: 0.6589\n",
      "Epoch 50/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.9223 - tp: 8363.0000 - fp: 41204.0000 - tn: 183851.0000 - fn: 17456.0000 - accuracy: 0.7662 - precision: 0.1687 - recall: 0.3239 - auc: 0.6271 - val_loss: 0.4322 - val_tp: 1179.0000 - val_fp: 5113.0000 - val_tn: 27157.0000 - val_fn: 2469.0000 - val_accuracy: 0.7889 - val_precision: 0.1874 - val_recall: 0.3232 - val_auc: 0.6594\n",
      "Epoch 51/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.9121 - tp: 8430.0000 - fp: 41100.0000 - tn: 183955.0000 - fn: 17389.0000 - accuracy: 0.7669 - precision: 0.1702 - recall: 0.3265 - auc: 0.6301 - val_loss: 0.4326 - val_tp: 1180.0000 - val_fp: 5110.0000 - val_tn: 27160.0000 - val_fn: 2468.0000 - val_accuracy: 0.7890 - val_precision: 0.1876 - val_recall: 0.3235 - val_auc: 0.6599\n",
      "Epoch 52/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.9098 - tp: 8411.0000 - fp: 41031.0000 - tn: 184024.0000 - fn: 17408.0000 - accuracy: 0.7671 - precision: 0.1701 - recall: 0.3258 - auc: 0.6298 - val_loss: 0.4336 - val_tp: 1189.0000 - val_fp: 5147.0000 - val_tn: 27123.0000 - val_fn: 2459.0000 - val_accuracy: 0.7882 - val_precision: 0.1877 - val_recall: 0.3259 - val_auc: 0.6605\n",
      "Epoch 53/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.9074 - tp: 8445.0000 - fp: 41544.0000 - tn: 183511.0000 - fn: 17374.0000 - accuracy: 0.7651 - precision: 0.1689 - recall: 0.3271 - auc: 0.6291 - val_loss: 0.4338 - val_tp: 1191.0000 - val_fp: 5155.0000 - val_tn: 27115.0000 - val_fn: 2457.0000 - val_accuracy: 0.7881 - val_precision: 0.1877 - val_recall: 0.3265 - val_auc: 0.6610\n",
      "Epoch 54/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.9054 - tp: 8534.0000 - fp: 41838.0000 - tn: 183217.0000 - fn: 17285.0000 - accuracy: 0.7643 - precision: 0.1694 - recall: 0.3305 - auc: 0.6295 - val_loss: 0.4343 - val_tp: 1199.0000 - val_fp: 5164.0000 - val_tn: 27106.0000 - val_fn: 2449.0000 - val_accuracy: 0.7880 - val_precision: 0.1884 - val_recall: 0.3287 - val_auc: 0.6615\n",
      "Epoch 55/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.9007 - tp: 8602.0000 - fp: 42333.0000 - tn: 182722.0000 - fn: 17217.0000 - accuracy: 0.7626 - precision: 0.1689 - recall: 0.3332 - auc: 0.6290 - val_loss: 0.4347 - val_tp: 1204.0000 - val_fp: 5175.0000 - val_tn: 27095.0000 - val_fn: 2444.0000 - val_accuracy: 0.7879 - val_precision: 0.1887 - val_recall: 0.3300 - val_auc: 0.6621\n",
      "Epoch 56/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8953 - tp: 8684.0000 - fp: 42362.0000 - tn: 182693.0000 - fn: 17135.0000 - accuracy: 0.7628 - precision: 0.1701 - recall: 0.3363 - auc: 0.6300 - val_loss: 0.4346 - val_tp: 1200.0000 - val_fp: 5181.0000 - val_tn: 27089.0000 - val_fn: 2448.0000 - val_accuracy: 0.7876 - val_precision: 0.1881 - val_recall: 0.3289 - val_auc: 0.6626\n",
      "Epoch 57/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8962 - tp: 8629.0000 - fp: 42484.0000 - tn: 182571.0000 - fn: 17190.0000 - accuracy: 0.7621 - precision: 0.1688 - recall: 0.3342 - auc: 0.6280 - val_loss: 0.4351 - val_tp: 1211.0000 - val_fp: 5201.0000 - val_tn: 27069.0000 - val_fn: 2437.0000 - val_accuracy: 0.7873 - val_precision: 0.1889 - val_recall: 0.3320 - val_auc: 0.6631\n",
      "Epoch 58/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8931 - tp: 8661.0000 - fp: 42844.0000 - tn: 182211.0000 - fn: 17158.0000 - accuracy: 0.7608 - precision: 0.1682 - recall: 0.3355 - auc: 0.6284 - val_loss: 0.4356 - val_tp: 1216.0000 - val_fp: 5215.0000 - val_tn: 27055.0000 - val_fn: 2432.0000 - val_accuracy: 0.7871 - val_precision: 0.1891 - val_recall: 0.3333 - val_auc: 0.6638\n",
      "Epoch 59/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8902 - tp: 8661.0000 - fp: 43014.0000 - tn: 182041.0000 - fn: 17158.0000 - accuracy: 0.7602 - precision: 0.1676 - recall: 0.3355 - auc: 0.6282 - val_loss: 0.4362 - val_tp: 1221.0000 - val_fp: 5239.0000 - val_tn: 27031.0000 - val_fn: 2427.0000 - val_accuracy: 0.7866 - val_precision: 0.1890 - val_recall: 0.3347 - val_auc: 0.6644\n",
      "Epoch 60/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8831 - tp: 8771.0000 - fp: 43434.0000 - tn: 181621.0000 - fn: 17048.0000 - accuracy: 0.7589 - precision: 0.1680 - recall: 0.3397 - auc: 0.6304 - val_loss: 0.4365 - val_tp: 1226.0000 - val_fp: 5247.0000 - val_tn: 27023.0000 - val_fn: 2422.0000 - val_accuracy: 0.7865 - val_precision: 0.1894 - val_recall: 0.3361 - val_auc: 0.6648\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8833 - tp: 8740.0000 - fp: 43196.0000 - tn: 181859.0000 - fn: 17079.0000 - accuracy: 0.7597 - precision: 0.1683 - recall: 0.3385 - auc: 0.6294 - val_loss: 0.4370 - val_tp: 1229.0000 - val_fp: 5266.0000 - val_tn: 27004.0000 - val_fn: 2419.0000 - val_accuracy: 0.7860 - val_precision: 0.1892 - val_recall: 0.3369 - val_auc: 0.6653\n",
      "Epoch 62/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8783 - tp: 8733.0000 - fp: 43446.0000 - tn: 181609.0000 - fn: 17086.0000 - accuracy: 0.7587 - precision: 0.1674 - recall: 0.3382 - auc: 0.6303 - val_loss: 0.4374 - val_tp: 1238.0000 - val_fp: 5278.0000 - val_tn: 26992.0000 - val_fn: 2410.0000 - val_accuracy: 0.7860 - val_precision: 0.1900 - val_recall: 0.3394 - val_auc: 0.6659\n",
      "Epoch 63/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8737 - tp: 8901.0000 - fp: 43913.0000 - tn: 181142.0000 - fn: 16918.0000 - accuracy: 0.7575 - precision: 0.1685 - recall: 0.3447 - auc: 0.6315 - val_loss: 0.4373 - val_tp: 1237.0000 - val_fp: 5264.0000 - val_tn: 27006.0000 - val_fn: 2411.0000 - val_accuracy: 0.7863 - val_precision: 0.1903 - val_recall: 0.3391 - val_auc: 0.6664\n",
      "Epoch 64/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8723 - tp: 8947.0000 - fp: 44036.0000 - tn: 181019.0000 - fn: 16872.0000 - accuracy: 0.7572 - precision: 0.1689 - recall: 0.3465 - auc: 0.6303 - val_loss: 0.4379 - val_tp: 1238.0000 - val_fp: 5272.0000 - val_tn: 26998.0000 - val_fn: 2410.0000 - val_accuracy: 0.7861 - val_precision: 0.1902 - val_recall: 0.3394 - val_auc: 0.6671\n",
      "Epoch 65/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8662 - tp: 8973.0000 - fp: 44169.0000 - tn: 180886.0000 - fn: 16846.0000 - accuracy: 0.7568 - precision: 0.1688 - recall: 0.3475 - auc: 0.6331 - val_loss: 0.4392 - val_tp: 1246.0000 - val_fp: 5306.0000 - val_tn: 26964.0000 - val_fn: 2402.0000 - val_accuracy: 0.7854 - val_precision: 0.1902 - val_recall: 0.3416 - val_auc: 0.6675\n",
      "Epoch 66/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8661 - tp: 8968.0000 - fp: 44680.0000 - tn: 180375.0000 - fn: 16851.0000 - accuracy: 0.7547 - precision: 0.1672 - recall: 0.3473 - auc: 0.6305 - val_loss: 0.4395 - val_tp: 1255.0000 - val_fp: 5305.0000 - val_tn: 26965.0000 - val_fn: 2393.0000 - val_accuracy: 0.7857 - val_precision: 0.1913 - val_recall: 0.3440 - val_auc: 0.6681\n",
      "Epoch 67/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.8612 - tp: 9111.0000 - fp: 44875.0000 - tn: 180180.0000 - fn: 16708.0000 - accuracy: 0.7545 - precision: 0.1688 - recall: 0.3529 - auc: 0.6324 - val_loss: 0.4392 - val_tp: 1257.0000 - val_fp: 5280.0000 - val_tn: 26990.0000 - val_fn: 2391.0000 - val_accuracy: 0.7864 - val_precision: 0.1923 - val_recall: 0.3446 - val_auc: 0.6686\n",
      "Epoch 68/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8597 - tp: 9124.0000 - fp: 44998.0000 - tn: 180057.0000 - fn: 16695.0000 - accuracy: 0.7541 - precision: 0.1686 - recall: 0.3534 - auc: 0.6316 - val_loss: 0.4392 - val_tp: 1256.0000 - val_fp: 5274.0000 - val_tn: 26996.0000 - val_fn: 2392.0000 - val_accuracy: 0.7866 - val_precision: 0.1923 - val_recall: 0.3443 - val_auc: 0.6693\n",
      "Epoch 69/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8598 - tp: 9115.0000 - fp: 45295.0000 - tn: 179760.0000 - fn: 16704.0000 - accuracy: 0.7529 - precision: 0.1675 - recall: 0.3530 - auc: 0.6304 - val_loss: 0.4398 - val_tp: 1260.0000 - val_fp: 5289.0000 - val_tn: 26981.0000 - val_fn: 2388.0000 - val_accuracy: 0.7863 - val_precision: 0.1924 - val_recall: 0.3454 - val_auc: 0.6698\n",
      "Epoch 70/100\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.8551 - tp: 9172.0000 - fp: 45766.0000 - tn: 179289.0000 - fn: 16647.0000 - accuracy: 0.7512 - precision: 0.1670 - recall: 0.3552 - auc: 0.6315 - val_loss: 0.4404 - val_tp: 1263.0000 - val_fp: 5305.0000 - val_tn: 26965.0000 - val_fn: 2385.0000 - val_accuracy: 0.7859 - val_precision: 0.1923 - val_recall: 0.3462 - val_auc: 0.6704\n",
      "Epoch 71/100\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.8542 - tp: 9218.0000 - fp: 45819.0000 - tn: 179236.0000 - fn: 16601.0000 - accuracy: 0.7512 - precision: 0.1675 - recall: 0.3570 - auc: 0.6316 - val_loss: 0.4403 - val_tp: 1259.0000 - val_fp: 5293.0000 - val_tn: 26977.0000 - val_fn: 2389.0000 - val_accuracy: 0.7861 - val_precision: 0.1922 - val_recall: 0.3451 - val_auc: 0.6708\n",
      "Epoch 72/100\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.8550 - tp: 9094.0000 - fp: 46067.0000 - tn: 178988.0000 - fn: 16725.0000 - accuracy: 0.7497 - precision: 0.1649 - recall: 0.3522 - auc: 0.6292 - val_loss: 0.4404 - val_tp: 1257.0000 - val_fp: 5286.0000 - val_tn: 26984.0000 - val_fn: 2391.0000 - val_accuracy: 0.7863 - val_precision: 0.1921 - val_recall: 0.3446 - val_auc: 0.6715\n",
      "Epoch 73/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.8502 - tp: 9205.0000 - fp: 46395.0000 - tn: 178660.0000 - fn: 16614.0000 - accuracy: 0.7488 - precision: 0.1656 - recall: 0.3565 - auc: 0.6306 - val_loss: 0.4408 - val_tp: 1264.0000 - val_fp: 5298.0000 - val_tn: 26972.0000 - val_fn: 2384.0000 - val_accuracy: 0.7861 - val_precision: 0.1926 - val_recall: 0.3465 - val_auc: 0.6721\n",
      "Epoch 74/100\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.8474 - tp: 9243.0000 - fp: 46664.0000 - tn: 178391.0000 - fn: 16576.0000 - accuracy: 0.7479 - precision: 0.1653 - recall: 0.3580 - auc: 0.6316 - val_loss: 0.4409 - val_tp: 1267.0000 - val_fp: 5287.0000 - val_tn: 26983.0000 - val_fn: 2381.0000 - val_accuracy: 0.7865 - val_precision: 0.1933 - val_recall: 0.3473 - val_auc: 0.6726\n",
      "Epoch 75/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.8434 - tp: 9390.0000 - fp: 46837.0000 - tn: 178218.0000 - fn: 16429.0000 - accuracy: 0.7478 - precision: 0.1670 - recall: 0.3637 - auc: 0.6325 - val_loss: 0.4414 - val_tp: 1269.0000 - val_fp: 5298.0000 - val_tn: 26972.0000 - val_fn: 2379.0000 - val_accuracy: 0.7863 - val_precision: 0.1932 - val_recall: 0.3479 - val_auc: 0.6732\n",
      "Epoch 76/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.8396 - tp: 9442.0000 - fp: 46993.0000 - tn: 178062.0000 - fn: 16377.0000 - accuracy: 0.7474 - precision: 0.1673 - recall: 0.3657 - auc: 0.6336 - val_loss: 0.4412 - val_tp: 1269.0000 - val_fp: 5275.0000 - val_tn: 26995.0000 - val_fn: 2379.0000 - val_accuracy: 0.7869 - val_precision: 0.1939 - val_recall: 0.3479 - val_auc: 0.6737\n",
      "Epoch 77/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8384 - tp: 9398.0000 - fp: 47085.0000 - tn: 177970.0000 - fn: 16421.0000 - accuracy: 0.7469 - precision: 0.1664 - recall: 0.3640 - auc: 0.6332 - val_loss: 0.4417 - val_tp: 1271.0000 - val_fp: 5294.0000 - val_tn: 26976.0000 - val_fn: 2377.0000 - val_accuracy: 0.7864 - val_precision: 0.1936 - val_recall: 0.3484 - val_auc: 0.6743\n",
      "Epoch 78/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8353 - tp: 9435.0000 - fp: 47364.0000 - tn: 177691.0000 - fn: 16384.0000 - accuracy: 0.7459 - precision: 0.1661 - recall: 0.3654 - auc: 0.6336 - val_loss: 0.4419 - val_tp: 1272.0000 - val_fp: 5293.0000 - val_tn: 26977.0000 - val_fn: 2376.0000 - val_accuracy: 0.7865 - val_precision: 0.1938 - val_recall: 0.3487 - val_auc: 0.6748\n",
      "Epoch 79/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8304 - tp: 9499.0000 - fp: 47540.0000 - tn: 177515.0000 - fn: 16320.0000 - accuracy: 0.7454 - precision: 0.1665 - recall: 0.3679 - auc: 0.6364 - val_loss: 0.4425 - val_tp: 1280.0000 - val_fp: 5316.0000 - val_tn: 26954.0000 - val_fn: 2368.0000 - val_accuracy: 0.7861 - val_precision: 0.1941 - val_recall: 0.3509 - val_auc: 0.6754\n",
      "Epoch 80/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8327 - tp: 9547.0000 - fp: 47636.0000 - tn: 177419.0000 - fn: 16272.0000 - accuracy: 0.7453 - precision: 0.1670 - recall: 0.3698 - auc: 0.6335 - val_loss: 0.4431 - val_tp: 1281.0000 - val_fp: 5333.0000 - val_tn: 26937.0000 - val_fn: 2367.0000 - val_accuracy: 0.7856 - val_precision: 0.1937 - val_recall: 0.3512 - val_auc: 0.6759\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8296 - tp: 9451.0000 - fp: 47885.0000 - tn: 177170.0000 - fn: 16368.0000 - accuracy: 0.7439 - precision: 0.1648 - recall: 0.3660 - auc: 0.6344 - val_loss: 0.4435 - val_tp: 1284.0000 - val_fp: 5336.0000 - val_tn: 26934.0000 - val_fn: 2364.0000 - val_accuracy: 0.7856 - val_precision: 0.1940 - val_recall: 0.3520 - val_auc: 0.6765\n",
      "Epoch 82/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8251 - tp: 9621.0000 - fp: 48187.0000 - tn: 176868.0000 - fn: 16198.0000 - accuracy: 0.7434 - precision: 0.1664 - recall: 0.3726 - auc: 0.6349 - val_loss: 0.4435 - val_tp: 1289.0000 - val_fp: 5321.0000 - val_tn: 26949.0000 - val_fn: 2359.0000 - val_accuracy: 0.7862 - val_precision: 0.1950 - val_recall: 0.3533 - val_auc: 0.6771\n",
      "Epoch 83/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8232 - tp: 9673.0000 - fp: 48392.0000 - tn: 176663.0000 - fn: 16146.0000 - accuracy: 0.7427 - precision: 0.1666 - recall: 0.3746 - auc: 0.6364 - val_loss: 0.4440 - val_tp: 1295.0000 - val_fp: 5337.0000 - val_tn: 26933.0000 - val_fn: 2353.0000 - val_accuracy: 0.7859 - val_precision: 0.1953 - val_recall: 0.3550 - val_auc: 0.6777\n",
      "Epoch 84/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8231 - tp: 9678.0000 - fp: 48874.0000 - tn: 176181.0000 - fn: 16141.0000 - accuracy: 0.7408 - precision: 0.1653 - recall: 0.3748 - auc: 0.6355 - val_loss: 0.4443 - val_tp: 1295.0000 - val_fp: 5342.0000 - val_tn: 26928.0000 - val_fn: 2353.0000 - val_accuracy: 0.7858 - val_precision: 0.1951 - val_recall: 0.3550 - val_auc: 0.6782\n",
      "Epoch 85/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8214 - tp: 9681.0000 - fp: 48979.0000 - tn: 176076.0000 - fn: 16138.0000 - accuracy: 0.7404 - precision: 0.1650 - recall: 0.3750 - auc: 0.6353 - val_loss: 0.4444 - val_tp: 1296.0000 - val_fp: 5349.0000 - val_tn: 26921.0000 - val_fn: 2352.0000 - val_accuracy: 0.7856 - val_precision: 0.1950 - val_recall: 0.3553 - val_auc: 0.6788\n",
      "Epoch 86/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8202 - tp: 9723.0000 - fp: 48990.0000 - tn: 176065.0000 - fn: 16096.0000 - accuracy: 0.7406 - precision: 0.1656 - recall: 0.3766 - auc: 0.6349 - val_loss: 0.4447 - val_tp: 1297.0000 - val_fp: 5354.0000 - val_tn: 26916.0000 - val_fn: 2351.0000 - val_accuracy: 0.7855 - val_precision: 0.1950 - val_recall: 0.3555 - val_auc: 0.6794\n",
      "Epoch 87/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8196 - tp: 9840.0000 - fp: 48859.0000 - tn: 176196.0000 - fn: 15979.0000 - accuracy: 0.7416 - precision: 0.1676 - recall: 0.3811 - auc: 0.6348 - val_loss: 0.4449 - val_tp: 1305.0000 - val_fp: 5352.0000 - val_tn: 26918.0000 - val_fn: 2343.0000 - val_accuracy: 0.7858 - val_precision: 0.1960 - val_recall: 0.3577 - val_auc: 0.6800\n",
      "Epoch 88/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8149 - tp: 9746.0000 - fp: 49121.0000 - tn: 175934.0000 - fn: 16073.0000 - accuracy: 0.7401 - precision: 0.1656 - recall: 0.3775 - auc: 0.6365 - val_loss: 0.4451 - val_tp: 1307.0000 - val_fp: 5337.0000 - val_tn: 26933.0000 - val_fn: 2341.0000 - val_accuracy: 0.7862 - val_precision: 0.1967 - val_recall: 0.3583 - val_auc: 0.6805\n",
      "Epoch 89/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8173 - tp: 9764.0000 - fp: 49150.0000 - tn: 175905.0000 - fn: 16055.0000 - accuracy: 0.7401 - precision: 0.1657 - recall: 0.3782 - auc: 0.6349 - val_loss: 0.4455 - val_tp: 1316.0000 - val_fp: 5342.0000 - val_tn: 26928.0000 - val_fn: 2332.0000 - val_accuracy: 0.7863 - val_precision: 0.1977 - val_recall: 0.3607 - val_auc: 0.6811\n",
      "Epoch 90/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8127 - tp: 9762.0000 - fp: 49542.0000 - tn: 175513.0000 - fn: 16057.0000 - accuracy: 0.7385 - precision: 0.1646 - recall: 0.3781 - auc: 0.6368 - val_loss: 0.4458 - val_tp: 1323.0000 - val_fp: 5351.0000 - val_tn: 26919.0000 - val_fn: 2325.0000 - val_accuracy: 0.7863 - val_precision: 0.1982 - val_recall: 0.3627 - val_auc: 0.6817\n",
      "Epoch 91/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8129 - tp: 9840.0000 - fp: 49463.0000 - tn: 175592.0000 - fn: 15979.0000 - accuracy: 0.7391 - precision: 0.1659 - recall: 0.3811 - auc: 0.6360 - val_loss: 0.4461 - val_tp: 1327.0000 - val_fp: 5352.0000 - val_tn: 26918.0000 - val_fn: 2321.0000 - val_accuracy: 0.7864 - val_precision: 0.1987 - val_recall: 0.3638 - val_auc: 0.6823\n",
      "Epoch 92/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8105 - tp: 9845.0000 - fp: 50099.0000 - tn: 174956.0000 - fn: 15974.0000 - accuracy: 0.7366 - precision: 0.1642 - recall: 0.3813 - auc: 0.6363 - val_loss: 0.4466 - val_tp: 1336.0000 - val_fp: 5368.0000 - val_tn: 26902.0000 - val_fn: 2312.0000 - val_accuracy: 0.7862 - val_precision: 0.1993 - val_recall: 0.3662 - val_auc: 0.6828\n",
      "Epoch 93/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8072 - tp: 9975.0000 - fp: 49990.0000 - tn: 175065.0000 - fn: 15844.0000 - accuracy: 0.7376 - precision: 0.1663 - recall: 0.3863 - auc: 0.6377 - val_loss: 0.4464 - val_tp: 1335.0000 - val_fp: 5347.0000 - val_tn: 26923.0000 - val_fn: 2313.0000 - val_accuracy: 0.7867 - val_precision: 0.1998 - val_recall: 0.3660 - val_auc: 0.6835\n",
      "Epoch 94/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.8024 - tp: 10135.0000 - fp: 49971.0000 - tn: 175084.0000 - fn: 15684.0000 - accuracy: 0.7383 - precision: 0.1686 - recall: 0.3925 - auc: 0.6399 - val_loss: 0.4465 - val_tp: 1338.0000 - val_fp: 5343.0000 - val_tn: 26927.0000 - val_fn: 2310.0000 - val_accuracy: 0.7869 - val_precision: 0.2003 - val_recall: 0.3668 - val_auc: 0.6840\n",
      "Epoch 95/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.8022 - tp: 10032.0000 - fp: 50470.0000 - tn: 174585.0000 - fn: 15787.0000 - accuracy: 0.7359 - precision: 0.1658 - recall: 0.3886 - auc: 0.6392 - val_loss: 0.4464 - val_tp: 1333.0000 - val_fp: 5333.0000 - val_tn: 26937.0000 - val_fn: 2315.0000 - val_accuracy: 0.7871 - val_precision: 0.2000 - val_recall: 0.3654 - val_auc: 0.6846\n",
      "Epoch 96/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.7998 - tp: 10149.0000 - fp: 50563.0000 - tn: 174492.0000 - fn: 15670.0000 - accuracy: 0.7360 - precision: 0.1672 - recall: 0.3931 - auc: 0.6398 - val_loss: 0.4467 - val_tp: 1343.0000 - val_fp: 5349.0000 - val_tn: 26921.0000 - val_fn: 2305.0000 - val_accuracy: 0.7869 - val_precision: 0.2007 - val_recall: 0.3681 - val_auc: 0.6852\n",
      "Epoch 97/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.7992 - tp: 10101.0000 - fp: 50492.0000 - tn: 174563.0000 - fn: 15718.0000 - accuracy: 0.7361 - precision: 0.1667 - recall: 0.3912 - auc: 0.6400 - val_loss: 0.4470 - val_tp: 1347.0000 - val_fp: 5357.0000 - val_tn: 26913.0000 - val_fn: 2301.0000 - val_accuracy: 0.7868 - val_precision: 0.2009 - val_recall: 0.3692 - val_auc: 0.6858\n",
      "Epoch 98/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.7963 - tp: 10208.0000 - fp: 50614.0000 - tn: 174441.0000 - fn: 15611.0000 - accuracy: 0.7360 - precision: 0.1678 - recall: 0.3954 - auc: 0.6411 - val_loss: 0.4475 - val_tp: 1347.0000 - val_fp: 5374.0000 - val_tn: 26896.0000 - val_fn: 2301.0000 - val_accuracy: 0.7863 - val_precision: 0.2004 - val_recall: 0.3692 - val_auc: 0.6864\n",
      "Epoch 99/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.7941 - tp: 10215.0000 - fp: 50936.0000 - tn: 174119.0000 - fn: 15604.0000 - accuracy: 0.7348 - precision: 0.1670 - recall: 0.3956 - auc: 0.6417 - val_loss: 0.4473 - val_tp: 1343.0000 - val_fp: 5366.0000 - val_tn: 26904.0000 - val_fn: 2305.0000 - val_accuracy: 0.7864 - val_precision: 0.2002 - val_recall: 0.3681 - val_auc: 0.6868\n",
      "Epoch 100/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.7951 - tp: 10125.0000 - fp: 50850.0000 - tn: 174205.0000 - fn: 15694.0000 - accuracy: 0.7348 - precision: 0.1661 - recall: 0.3922 - auc: 0.6407 - val_loss: 0.4477 - val_tp: 1348.0000 - val_fp: 5380.0000 - val_tn: 26890.0000 - val_fn: 2300.0000 - val_accuracy: 0.7862 - val_precision: 0.2004 - val_recall: 0.3695 - val_auc: 0.6874\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 3s 21ms/step - loss: 1.3164 - tp: 2329.0000 - fp: 10264.0000 - tn: 247061.0000 - fn: 27138.0000 - accuracy: 0.8696 - precision: 0.1849 - recall: 0.0790 - auc: 0.5893 - val_loss: 0.3439 - val_tp: 37.0000 - val_fp: 130.0000 - val_tn: 32140.0000 - val_fn: 3611.0000 - val_accuracy: 0.8958 - val_precision: 0.2216 - val_recall: 0.0101 - val_auc: 0.6313\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 1.1470 - tp: 3858.0000 - fp: 18333.0000 - tn: 206722.0000 - fn: 21961.0000 - accuracy: 0.8394 - precision: 0.1739 - recall: 0.1494 - auc: 0.6113 - val_loss: 0.3756 - val_tp: 553.0000 - val_fp: 2117.0000 - val_tn: 30153.0000 - val_fn: 3095.0000 - val_accuracy: 0.8549 - val_precision: 0.2071 - val_recall: 0.1516 - val_auc: 0.6417\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 1.0562 - tp: 6166.0000 - fp: 30078.0000 - tn: 194977.0000 - fn: 19653.0000 - accuracy: 0.8018 - precision: 0.1701 - recall: 0.2388 - auc: 0.6169 - val_loss: 0.4061 - val_tp: 943.0000 - val_fp: 3901.0000 - val_tn: 28369.0000 - val_fn: 2705.0000 - val_accuracy: 0.8161 - val_precision: 0.1947 - val_recall: 0.2585 - val_auc: 0.6476\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.9946 - tp: 7298.0000 - fp: 36144.0000 - tn: 188911.0000 - fn: 18521.0000 - accuracy: 0.7821 - precision: 0.1680 - recall: 0.2827 - auc: 0.6211 - val_loss: 0.4231 - val_tp: 1091.0000 - val_fp: 4710.0000 - val_tn: 27560.0000 - val_fn: 2557.0000 - val_accuracy: 0.7977 - val_precision: 0.1881 - val_recall: 0.2991 - val_auc: 0.6527\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.9464 - tp: 8013.0000 - fp: 39451.0000 - tn: 185604.0000 - fn: 17806.0000 - accuracy: 0.7718 - precision: 0.1688 - recall: 0.3104 - auc: 0.6247 - val_loss: 0.4306 - val_tp: 1154.0000 - val_fp: 5022.0000 - val_tn: 27248.0000 - val_fn: 2494.0000 - val_accuracy: 0.7907 - val_precision: 0.1869 - val_recall: 0.3163 - val_auc: 0.6572\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.9109 - tp: 8500.0000 - fp: 42171.0000 - tn: 182884.0000 - fn: 17319.0000 - accuracy: 0.7629 - precision: 0.1677 - recall: 0.3292 - auc: 0.6254 - val_loss: 0.4372 - val_tp: 1210.0000 - val_fp: 5236.0000 - val_tn: 27034.0000 - val_fn: 2438.0000 - val_accuracy: 0.7863 - val_precision: 0.1877 - val_recall: 0.3317 - val_auc: 0.6615\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.8832 - tp: 8822.0000 - fp: 44636.0000 - tn: 180419.0000 - fn: 16997.0000 - accuracy: 0.7543 - precision: 0.1650 - recall: 0.3417 - auc: 0.6270 - val_loss: 0.4426 - val_tp: 1256.0000 - val_fp: 5426.0000 - val_tn: 26844.0000 - val_fn: 2392.0000 - val_accuracy: 0.7823 - val_precision: 0.1880 - val_recall: 0.3443 - val_auc: 0.6658\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8631 - tp: 9132.0000 - fp: 46430.0000 - tn: 178625.0000 - fn: 16687.0000 - accuracy: 0.7484 - precision: 0.1644 - recall: 0.3537 - auc: 0.6283 - val_loss: 0.4418 - val_tp: 1256.0000 - val_fp: 5341.0000 - val_tn: 26929.0000 - val_fn: 2392.0000 - val_accuracy: 0.7847 - val_precision: 0.1904 - val_recall: 0.3443 - val_auc: 0.6704\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.8391 - tp: 9466.0000 - fp: 47338.0000 - tn: 177717.0000 - fn: 16353.0000 - accuracy: 0.7461 - precision: 0.1666 - recall: 0.3666 - auc: 0.6347 - val_loss: 0.4432 - val_tp: 1282.0000 - val_fp: 5373.0000 - val_tn: 26897.0000 - val_fn: 2366.0000 - val_accuracy: 0.7845 - val_precision: 0.1926 - val_recall: 0.3514 - val_auc: 0.6752\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.8299 - tp: 9604.0000 - fp: 48757.0000 - tn: 176298.0000 - fn: 16215.0000 - accuracy: 0.7410 - precision: 0.1646 - recall: 0.3720 - auc: 0.6334 - val_loss: 0.4421 - val_tp: 1287.0000 - val_fp: 5313.0000 - val_tn: 26957.0000 - val_fn: 2361.0000 - val_accuracy: 0.7863 - val_precision: 0.1950 - val_recall: 0.3528 - val_auc: 0.6800\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8122 - tp: 9782.0000 - fp: 48840.0000 - tn: 176215.0000 - fn: 16037.0000 - accuracy: 0.7414 - precision: 0.1669 - recall: 0.3789 - auc: 0.6389 - val_loss: 0.4420 - val_tp: 1305.0000 - val_fp: 5243.0000 - val_tn: 27027.0000 - val_fn: 2343.0000 - val_accuracy: 0.7888 - val_precision: 0.1993 - val_recall: 0.3577 - val_auc: 0.6845\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.8021 - tp: 9956.0000 - fp: 49750.0000 - tn: 175305.0000 - fn: 15863.0000 - accuracy: 0.7385 - precision: 0.1668 - recall: 0.3856 - auc: 0.6403 - val_loss: 0.4427 - val_tp: 1324.0000 - val_fp: 5252.0000 - val_tn: 27018.0000 - val_fn: 2324.0000 - val_accuracy: 0.7891 - val_precision: 0.2013 - val_recall: 0.3629 - val_auc: 0.6888\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7913 - tp: 10242.0000 - fp: 50581.0000 - tn: 174474.0000 - fn: 15577.0000 - accuracy: 0.7363 - precision: 0.1684 - recall: 0.3967 - auc: 0.6436 - val_loss: 0.4423 - val_tp: 1341.0000 - val_fp: 5221.0000 - val_tn: 27049.0000 - val_fn: 2307.0000 - val_accuracy: 0.7904 - val_precision: 0.2044 - val_recall: 0.3676 - val_auc: 0.6933\n",
      "Epoch 14/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7780 - tp: 10392.0000 - fp: 50836.0000 - tn: 174219.0000 - fn: 15427.0000 - accuracy: 0.7359 - precision: 0.1697 - recall: 0.4025 - auc: 0.6477 - val_loss: 0.4404 - val_tp: 1330.0000 - val_fp: 5106.0000 - val_tn: 27164.0000 - val_fn: 2318.0000 - val_accuracy: 0.7933 - val_precision: 0.2067 - val_recall: 0.3646 - val_auc: 0.6973\n",
      "Epoch 15/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7669 - tp: 10672.0000 - fp: 51693.0000 - tn: 173362.0000 - fn: 15147.0000 - accuracy: 0.7336 - precision: 0.1711 - recall: 0.4133 - auc: 0.6513 - val_loss: 0.4449 - val_tp: 1376.0000 - val_fp: 5314.0000 - val_tn: 26956.0000 - val_fn: 2272.0000 - val_accuracy: 0.7888 - val_precision: 0.2057 - val_recall: 0.3772 - val_auc: 0.7006\n",
      "Epoch 16/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7608 - tp: 10738.0000 - fp: 52389.0000 - tn: 172666.0000 - fn: 15081.0000 - accuracy: 0.7311 - precision: 0.1701 - recall: 0.4159 - auc: 0.6525 - val_loss: 0.4479 - val_tp: 1409.0000 - val_fp: 5446.0000 - val_tn: 26824.0000 - val_fn: 2239.0000 - val_accuracy: 0.7860 - val_precision: 0.2055 - val_recall: 0.3862 - val_auc: 0.7041\n",
      "Epoch 17/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7506 - tp: 11027.0000 - fp: 53212.0000 - tn: 171843.0000 - fn: 14792.0000 - accuracy: 0.7289 - precision: 0.1717 - recall: 0.4271 - auc: 0.6566 - val_loss: 0.4499 - val_tp: 1429.0000 - val_fp: 5514.0000 - val_tn: 26756.0000 - val_fn: 2219.0000 - val_accuracy: 0.7847 - val_precision: 0.2058 - val_recall: 0.3917 - val_auc: 0.7072\n",
      "Epoch 18/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7427 - tp: 11279.0000 - fp: 53756.0000 - tn: 171299.0000 - fn: 14540.0000 - accuracy: 0.7278 - precision: 0.1734 - recall: 0.4368 - auc: 0.6591 - val_loss: 0.4506 - val_tp: 1447.0000 - val_fp: 5534.0000 - val_tn: 26736.0000 - val_fn: 2201.0000 - val_accuracy: 0.7846 - val_precision: 0.2073 - val_recall: 0.3967 - val_auc: 0.7102\n",
      "Epoch 19/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7356 - tp: 11386.0000 - fp: 54507.0000 - tn: 170548.0000 - fn: 14433.0000 - accuracy: 0.7252 - precision: 0.1728 - recall: 0.4410 - auc: 0.6620 - val_loss: 0.4481 - val_tp: 1437.0000 - val_fp: 5406.0000 - val_tn: 26864.0000 - val_fn: 2211.0000 - val_accuracy: 0.7879 - val_precision: 0.2100 - val_recall: 0.3939 - val_auc: 0.7133\n",
      "Epoch 20/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7299 - tp: 11514.0000 - fp: 54356.0000 - tn: 170699.0000 - fn: 14305.0000 - accuracy: 0.7263 - precision: 0.1748 - recall: 0.4460 - auc: 0.6650 - val_loss: 0.4462 - val_tp: 1435.0000 - val_fp: 5336.0000 - val_tn: 26934.0000 - val_fn: 2213.0000 - val_accuracy: 0.7898 - val_precision: 0.2119 - val_recall: 0.3934 - val_auc: 0.7166\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 10ms/step - loss: 0.7248 - tp: 11669.0000 - fp: 54591.0000 - tn: 170464.0000 - fn: 14150.0000 - accuracy: 0.7260 - precision: 0.1761 - recall: 0.4520 - auc: 0.6672 - val_loss: 0.4476 - val_tp: 1459.0000 - val_fp: 5419.0000 - val_tn: 26851.0000 - val_fn: 2189.0000 - val_accuracy: 0.7882 - val_precision: 0.2121 - val_recall: 0.3999 - val_auc: 0.7191\n",
      "Epoch 22/100\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.7165 - tp: 11804.0000 - fp: 54581.0000 - tn: 170474.0000 - fn: 14015.0000 - accuracy: 0.7266 - precision: 0.1778 - recall: 0.4572 - auc: 0.6714 - val_loss: 0.4494 - val_tp: 1498.0000 - val_fp: 5539.0000 - val_tn: 26731.0000 - val_fn: 2150.0000 - val_accuracy: 0.7859 - val_precision: 0.2129 - val_recall: 0.4106 - val_auc: 0.7212\n",
      "Epoch 23/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.7118 - tp: 11953.0000 - fp: 55190.0000 - tn: 169865.0000 - fn: 13866.0000 - accuracy: 0.7247 - precision: 0.1780 - recall: 0.4630 - auc: 0.6738 - val_loss: 0.4507 - val_tp: 1521.0000 - val_fp: 5629.0000 - val_tn: 26641.0000 - val_fn: 2127.0000 - val_accuracy: 0.7841 - val_precision: 0.2127 - val_recall: 0.4169 - val_auc: 0.7232\n",
      "Epoch 24/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7092 - tp: 12111.0000 - fp: 55929.0000 - tn: 169126.0000 - fn: 13708.0000 - accuracy: 0.7224 - precision: 0.1780 - recall: 0.4691 - auc: 0.6748 - val_loss: 0.4472 - val_tp: 1500.0000 - val_fp: 5442.0000 - val_tn: 26828.0000 - val_fn: 2148.0000 - val_accuracy: 0.7887 - val_precision: 0.2161 - val_recall: 0.4112 - val_auc: 0.7256\n",
      "Epoch 25/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7043 - tp: 12059.0000 - fp: 55735.0000 - tn: 169320.0000 - fn: 13760.0000 - accuracy: 0.7230 - precision: 0.1779 - recall: 0.4671 - auc: 0.6774 - val_loss: 0.4485 - val_tp: 1525.0000 - val_fp: 5505.0000 - val_tn: 26765.0000 - val_fn: 2123.0000 - val_accuracy: 0.7876 - val_precision: 0.2169 - val_recall: 0.4180 - val_auc: 0.7273\n",
      "Epoch 26/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6989 - tp: 12218.0000 - fp: 55991.0000 - tn: 169064.0000 - fn: 13601.0000 - accuracy: 0.7226 - precision: 0.1791 - recall: 0.4732 - auc: 0.6804 - val_loss: 0.4474 - val_tp: 1523.0000 - val_fp: 5461.0000 - val_tn: 26809.0000 - val_fn: 2125.0000 - val_accuracy: 0.7888 - val_precision: 0.2181 - val_recall: 0.4175 - val_auc: 0.7291\n",
      "Epoch 27/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6968 - tp: 12451.0000 - fp: 56807.0000 - tn: 168248.0000 - fn: 13368.0000 - accuracy: 0.7203 - precision: 0.1798 - recall: 0.4822 - auc: 0.6810 - val_loss: 0.4463 - val_tp: 1527.0000 - val_fp: 5448.0000 - val_tn: 26822.0000 - val_fn: 2121.0000 - val_accuracy: 0.7893 - val_precision: 0.2189 - val_recall: 0.4186 - val_auc: 0.7308\n",
      "Epoch 28/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6922 - tp: 12416.0000 - fp: 56332.0000 - tn: 168723.0000 - fn: 13403.0000 - accuracy: 0.7220 - precision: 0.1806 - recall: 0.4809 - auc: 0.6838 - val_loss: 0.4489 - val_tp: 1560.0000 - val_fp: 5586.0000 - val_tn: 26684.0000 - val_fn: 2088.0000 - val_accuracy: 0.7863 - val_precision: 0.2183 - val_recall: 0.4276 - val_auc: 0.7322\n",
      "Epoch 29/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6881 - tp: 12681.0000 - fp: 56783.0000 - tn: 168272.0000 - fn: 13138.0000 - accuracy: 0.7213 - precision: 0.1826 - recall: 0.4911 - auc: 0.6864 - val_loss: 0.4476 - val_tp: 1553.0000 - val_fp: 5502.0000 - val_tn: 26768.0000 - val_fn: 2095.0000 - val_accuracy: 0.7885 - val_precision: 0.2201 - val_recall: 0.4257 - val_auc: 0.7336\n",
      "Epoch 30/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6875 - tp: 12594.0000 - fp: 56984.0000 - tn: 168071.0000 - fn: 13225.0000 - accuracy: 0.7201 - precision: 0.1810 - recall: 0.4878 - auc: 0.6863 - val_loss: 0.4470 - val_tp: 1553.0000 - val_fp: 5465.0000 - val_tn: 26805.0000 - val_fn: 2095.0000 - val_accuracy: 0.7895 - val_precision: 0.2213 - val_recall: 0.4257 - val_auc: 0.7348\n",
      "Epoch 31/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6831 - tp: 12782.0000 - fp: 57461.0000 - tn: 167594.0000 - fn: 13037.0000 - accuracy: 0.7190 - precision: 0.1820 - recall: 0.4951 - auc: 0.6888 - val_loss: 0.4479 - val_tp: 1575.0000 - val_fp: 5542.0000 - val_tn: 26728.0000 - val_fn: 2073.0000 - val_accuracy: 0.7880 - val_precision: 0.2213 - val_recall: 0.4317 - val_auc: 0.7357\n",
      "Epoch 32/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6818 - tp: 12720.0000 - fp: 57376.0000 - tn: 167679.0000 - fn: 13099.0000 - accuracy: 0.7191 - precision: 0.1815 - recall: 0.4927 - auc: 0.6891 - val_loss: 0.4505 - val_tp: 1607.0000 - val_fp: 5684.0000 - val_tn: 26586.0000 - val_fn: 2041.0000 - val_accuracy: 0.7849 - val_precision: 0.2204 - val_recall: 0.4405 - val_auc: 0.7365\n",
      "Epoch 33/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6777 - tp: 13025.0000 - fp: 57993.0000 - tn: 167062.0000 - fn: 12794.0000 - accuracy: 0.7178 - precision: 0.1834 - recall: 0.5045 - auc: 0.6918 - val_loss: 0.4482 - val_tp: 1593.0000 - val_fp: 5595.0000 - val_tn: 26675.0000 - val_fn: 2055.0000 - val_accuracy: 0.7870 - val_precision: 0.2216 - val_recall: 0.4367 - val_auc: 0.7375\n",
      "Epoch 34/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6764 - tp: 12957.0000 - fp: 58238.0000 - tn: 166817.0000 - fn: 12862.0000 - accuracy: 0.7166 - precision: 0.1820 - recall: 0.5018 - auc: 0.6917 - val_loss: 0.4481 - val_tp: 1590.0000 - val_fp: 5568.0000 - val_tn: 26702.0000 - val_fn: 2058.0000 - val_accuracy: 0.7877 - val_precision: 0.2221 - val_recall: 0.4359 - val_auc: 0.7385\n",
      "Epoch 35/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6708 - tp: 13252.0000 - fp: 58262.0000 - tn: 166793.0000 - fn: 12567.0000 - accuracy: 0.7177 - precision: 0.1853 - recall: 0.5133 - auc: 0.6961 - val_loss: 0.4473 - val_tp: 1593.0000 - val_fp: 5550.0000 - val_tn: 26720.0000 - val_fn: 2055.0000 - val_accuracy: 0.7883 - val_precision: 0.2230 - val_recall: 0.4367 - val_auc: 0.7392\n",
      "Epoch 36/100\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.6680 - tp: 13374.0000 - fp: 58543.0000 - tn: 166512.0000 - fn: 12445.0000 - accuracy: 0.7170 - precision: 0.1860 - recall: 0.5180 - auc: 0.6977 - val_loss: 0.4478 - val_tp: 1590.0000 - val_fp: 5578.0000 - val_tn: 26692.0000 - val_fn: 2058.0000 - val_accuracy: 0.7874 - val_precision: 0.2218 - val_recall: 0.4359 - val_auc: 0.7401\n",
      "Epoch 37/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6680 - tp: 13417.0000 - fp: 59068.0000 - tn: 165987.0000 - fn: 12402.0000 - accuracy: 0.7151 - precision: 0.1851 - recall: 0.5197 - auc: 0.6973 - val_loss: 0.4489 - val_tp: 1621.0000 - val_fp: 5675.0000 - val_tn: 26595.0000 - val_fn: 2027.0000 - val_accuracy: 0.7856 - val_precision: 0.2222 - val_recall: 0.4444 - val_auc: 0.7406\n",
      "Epoch 38/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6656 - tp: 13389.0000 - fp: 59066.0000 - tn: 165989.0000 - fn: 12430.0000 - accuracy: 0.7150 - precision: 0.1848 - recall: 0.5186 - auc: 0.6987 - val_loss: 0.4466 - val_tp: 1595.0000 - val_fp: 5526.0000 - val_tn: 26744.0000 - val_fn: 2053.0000 - val_accuracy: 0.7890 - val_precision: 0.2240 - val_recall: 0.4372 - val_auc: 0.7414\n",
      "Epoch 39/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6656 - tp: 13299.0000 - fp: 59167.0000 - tn: 165888.0000 - fn: 12520.0000 - accuracy: 0.7143 - precision: 0.1835 - recall: 0.5151 - auc: 0.6976 - val_loss: 0.4485 - val_tp: 1621.0000 - val_fp: 5632.0000 - val_tn: 26638.0000 - val_fn: 2027.0000 - val_accuracy: 0.7868 - val_precision: 0.2235 - val_recall: 0.4444 - val_auc: 0.7419\n",
      "Epoch 40/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6610 - tp: 13621.0000 - fp: 59833.0000 - tn: 165222.0000 - fn: 12198.0000 - accuracy: 0.7129 - precision: 0.1854 - recall: 0.5276 - auc: 0.7010 - val_loss: 0.4460 - val_tp: 1591.0000 - val_fp: 5494.0000 - val_tn: 26776.0000 - val_fn: 2057.0000 - val_accuracy: 0.7898 - val_precision: 0.2246 - val_recall: 0.4361 - val_auc: 0.7427\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6577 - tp: 13708.0000 - fp: 59624.0000 - tn: 165431.0000 - fn: 12111.0000 - accuracy: 0.7141 - precision: 0.1869 - recall: 0.5309 - auc: 0.7035 - val_loss: 0.4463 - val_tp: 1589.0000 - val_fp: 5492.0000 - val_tn: 26778.0000 - val_fn: 2059.0000 - val_accuracy: 0.7898 - val_precision: 0.2244 - val_recall: 0.4356 - val_auc: 0.7433\n",
      "Epoch 42/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6564 - tp: 13708.0000 - fp: 59700.0000 - tn: 165355.0000 - fn: 12111.0000 - accuracy: 0.7138 - precision: 0.1867 - recall: 0.5309 - auc: 0.7039 - val_loss: 0.4468 - val_tp: 1609.0000 - val_fp: 5516.0000 - val_tn: 26754.0000 - val_fn: 2039.0000 - val_accuracy: 0.7897 - val_precision: 0.2258 - val_recall: 0.4411 - val_auc: 0.7436\n",
      "Epoch 43/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6568 - tp: 13712.0000 - fp: 59928.0000 - tn: 165127.0000 - fn: 12107.0000 - accuracy: 0.7129 - precision: 0.1862 - recall: 0.5311 - auc: 0.7030 - val_loss: 0.4469 - val_tp: 1605.0000 - val_fp: 5526.0000 - val_tn: 26744.0000 - val_fn: 2043.0000 - val_accuracy: 0.7893 - val_precision: 0.2251 - val_recall: 0.4400 - val_auc: 0.7441\n",
      "Epoch 44/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6531 - tp: 13793.0000 - fp: 60210.0000 - tn: 164845.0000 - fn: 12026.0000 - accuracy: 0.7121 - precision: 0.1864 - recall: 0.5342 - auc: 0.7056 - val_loss: 0.4462 - val_tp: 1601.0000 - val_fp: 5511.0000 - val_tn: 26759.0000 - val_fn: 2047.0000 - val_accuracy: 0.7896 - val_precision: 0.2251 - val_recall: 0.4389 - val_auc: 0.7444\n",
      "Epoch 45/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6526 - tp: 13935.0000 - fp: 60590.0000 - tn: 164465.0000 - fn: 11884.0000 - accuracy: 0.7111 - precision: 0.1870 - recall: 0.5397 - auc: 0.7056 - val_loss: 0.4483 - val_tp: 1639.0000 - val_fp: 5606.0000 - val_tn: 26664.0000 - val_fn: 2009.0000 - val_accuracy: 0.7880 - val_precision: 0.2262 - val_recall: 0.4493 - val_auc: 0.7449\n",
      "Epoch 46/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6489 - tp: 14094.0000 - fp: 61164.0000 - tn: 163891.0000 - fn: 11725.0000 - accuracy: 0.7095 - precision: 0.1873 - recall: 0.5459 - auc: 0.7077 - val_loss: 0.4521 - val_tp: 1679.0000 - val_fp: 5784.0000 - val_tn: 26486.0000 - val_fn: 1969.0000 - val_accuracy: 0.7841 - val_precision: 0.2250 - val_recall: 0.4603 - val_auc: 0.7452\n",
      "Epoch 47/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6478 - tp: 14238.0000 - fp: 61850.0000 - tn: 163205.0000 - fn: 11581.0000 - accuracy: 0.7073 - precision: 0.1871 - recall: 0.5515 - auc: 0.7075 - val_loss: 0.4531 - val_tp: 1687.0000 - val_fp: 5795.0000 - val_tn: 26475.0000 - val_fn: 1961.0000 - val_accuracy: 0.7841 - val_precision: 0.2255 - val_recall: 0.4624 - val_auc: 0.7456\n",
      "Epoch 48/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6420 - tp: 14428.0000 - fp: 62280.0000 - tn: 162775.0000 - fn: 11391.0000 - accuracy: 0.7063 - precision: 0.1881 - recall: 0.5588 - auc: 0.7117 - val_loss: 0.4552 - val_tp: 1702.0000 - val_fp: 5904.0000 - val_tn: 26366.0000 - val_fn: 1946.0000 - val_accuracy: 0.7814 - val_precision: 0.2238 - val_recall: 0.4666 - val_auc: 0.7458\n",
      "Epoch 49/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6415 - tp: 14457.0000 - fp: 62594.0000 - tn: 162461.0000 - fn: 11362.0000 - accuracy: 0.7052 - precision: 0.1876 - recall: 0.5599 - auc: 0.7113 - val_loss: 0.4531 - val_tp: 1673.0000 - val_fp: 5766.0000 - val_tn: 26504.0000 - val_fn: 1975.0000 - val_accuracy: 0.7845 - val_precision: 0.2249 - val_recall: 0.4586 - val_auc: 0.7463\n",
      "Epoch 50/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6408 - tp: 14405.0000 - fp: 62706.0000 - tn: 162349.0000 - fn: 11414.0000 - accuracy: 0.7046 - precision: 0.1868 - recall: 0.5579 - auc: 0.7114 - val_loss: 0.4526 - val_tp: 1669.0000 - val_fp: 5735.0000 - val_tn: 26535.0000 - val_fn: 1979.0000 - val_accuracy: 0.7852 - val_precision: 0.2254 - val_recall: 0.4575 - val_auc: 0.7466\n",
      "Epoch 51/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6400 - tp: 14511.0000 - fp: 63147.0000 - tn: 161908.0000 - fn: 11308.0000 - accuracy: 0.7032 - precision: 0.1869 - recall: 0.5620 - auc: 0.7116 - val_loss: 0.4514 - val_tp: 1662.0000 - val_fp: 5689.0000 - val_tn: 26581.0000 - val_fn: 1986.0000 - val_accuracy: 0.7863 - val_precision: 0.2261 - val_recall: 0.4556 - val_auc: 0.7470\n",
      "Epoch 52/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6391 - tp: 14557.0000 - fp: 62849.0000 - tn: 162206.0000 - fn: 11262.0000 - accuracy: 0.7046 - precision: 0.1881 - recall: 0.5638 - auc: 0.7121 - val_loss: 0.4546 - val_tp: 1693.0000 - val_fp: 5843.0000 - val_tn: 26427.0000 - val_fn: 1955.0000 - val_accuracy: 0.7829 - val_precision: 0.2247 - val_recall: 0.4641 - val_auc: 0.7469\n",
      "Epoch 53/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6351 - tp: 14763.0000 - fp: 63763.0000 - tn: 161292.0000 - fn: 11056.0000 - accuracy: 0.7018 - precision: 0.1880 - recall: 0.5718 - auc: 0.7146 - val_loss: 0.4531 - val_tp: 1666.0000 - val_fp: 5747.0000 - val_tn: 26523.0000 - val_fn: 1982.0000 - val_accuracy: 0.7848 - val_precision: 0.2247 - val_recall: 0.4567 - val_auc: 0.7472\n",
      "Epoch 54/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6353 - tp: 14781.0000 - fp: 64046.0000 - tn: 161009.0000 - fn: 11038.0000 - accuracy: 0.7007 - precision: 0.1875 - recall: 0.5725 - auc: 0.7137 - val_loss: 0.4561 - val_tp: 1690.0000 - val_fp: 5912.0000 - val_tn: 26358.0000 - val_fn: 1958.0000 - val_accuracy: 0.7809 - val_precision: 0.2223 - val_recall: 0.4633 - val_auc: 0.7471\n",
      "Epoch 55/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6328 - tp: 14782.0000 - fp: 63708.0000 - tn: 161347.0000 - fn: 11037.0000 - accuracy: 0.7021 - precision: 0.1883 - recall: 0.5725 - auc: 0.7155 - val_loss: 0.4552 - val_tp: 1677.0000 - val_fp: 5860.0000 - val_tn: 26410.0000 - val_fn: 1971.0000 - val_accuracy: 0.7820 - val_precision: 0.2225 - val_recall: 0.4597 - val_auc: 0.7474\n",
      "Epoch 56/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6306 - tp: 14946.0000 - fp: 63963.0000 - tn: 161092.0000 - fn: 10873.0000 - accuracy: 0.7017 - precision: 0.1894 - recall: 0.5789 - auc: 0.7172 - val_loss: 0.4553 - val_tp: 1686.0000 - val_fp: 5885.0000 - val_tn: 26385.0000 - val_fn: 1962.0000 - val_accuracy: 0.7815 - val_precision: 0.2227 - val_recall: 0.4622 - val_auc: 0.7476\n",
      "Epoch 57/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6291 - tp: 15040.0000 - fp: 64415.0000 - tn: 160640.0000 - fn: 10779.0000 - accuracy: 0.7003 - precision: 0.1893 - recall: 0.5825 - auc: 0.7183 - val_loss: 0.4534 - val_tp: 1668.0000 - val_fp: 5795.0000 - val_tn: 26475.0000 - val_fn: 1980.0000 - val_accuracy: 0.7835 - val_precision: 0.2235 - val_recall: 0.4572 - val_auc: 0.7479\n",
      "Epoch 58/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6273 - tp: 15035.0000 - fp: 63978.0000 - tn: 161077.0000 - fn: 10784.0000 - accuracy: 0.7020 - precision: 0.1903 - recall: 0.5823 - auc: 0.7202 - val_loss: 0.4525 - val_tp: 1664.0000 - val_fp: 5741.0000 - val_tn: 26529.0000 - val_fn: 1984.0000 - val_accuracy: 0.7849 - val_precision: 0.2247 - val_recall: 0.4561 - val_auc: 0.7482\n",
      "Epoch 59/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6299 - tp: 14946.0000 - fp: 64265.0000 - tn: 160790.0000 - fn: 10873.0000 - accuracy: 0.7005 - precision: 0.1887 - recall: 0.5789 - auc: 0.7172 - val_loss: 0.4517 - val_tp: 1657.0000 - val_fp: 5712.0000 - val_tn: 26558.0000 - val_fn: 1991.0000 - val_accuracy: 0.7855 - val_precision: 0.2249 - val_recall: 0.4542 - val_auc: 0.7485\n",
      "Epoch 60/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6273 - tp: 15015.0000 - fp: 64379.0000 - tn: 160676.0000 - fn: 10804.0000 - accuracy: 0.7003 - precision: 0.1891 - recall: 0.5815 - auc: 0.7190 - val_loss: 0.4521 - val_tp: 1655.0000 - val_fp: 5694.0000 - val_tn: 26576.0000 - val_fn: 1993.0000 - val_accuracy: 0.7860 - val_precision: 0.2252 - val_recall: 0.4537 - val_auc: 0.7487\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 2s 14ms/step - loss: 0.6274 - tp: 15096.0000 - fp: 64780.0000 - tn: 160275.0000 - fn: 10723.0000 - accuracy: 0.6990 - precision: 0.1890 - recall: 0.5847 - auc: 0.7187 - val_loss: 0.4511 - val_tp: 1657.0000 - val_fp: 5656.0000 - val_tn: 26614.0000 - val_fn: 1991.0000 - val_accuracy: 0.7871 - val_precision: 0.2266 - val_recall: 0.4542 - val_auc: 0.7490\n",
      "Epoch 62/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6261 - tp: 15184.0000 - fp: 64549.0000 - tn: 160506.0000 - fn: 10635.0000 - accuracy: 0.7003 - precision: 0.1904 - recall: 0.5881 - auc: 0.7200 - val_loss: 0.4516 - val_tp: 1667.0000 - val_fp: 5702.0000 - val_tn: 26568.0000 - val_fn: 1981.0000 - val_accuracy: 0.7861 - val_precision: 0.2262 - val_recall: 0.4570 - val_auc: 0.7491\n",
      "Epoch 63/100\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.6233 - tp: 15265.0000 - fp: 64859.0000 - tn: 160196.0000 - fn: 10554.0000 - accuracy: 0.6994 - precision: 0.1905 - recall: 0.5912 - auc: 0.7219 - val_loss: 0.4520 - val_tp: 1671.0000 - val_fp: 5713.0000 - val_tn: 26557.0000 - val_fn: 1977.0000 - val_accuracy: 0.7859 - val_precision: 0.2263 - val_recall: 0.4581 - val_auc: 0.7493\n",
      "Epoch 64/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6242 - tp: 15254.0000 - fp: 65042.0000 - tn: 160013.0000 - fn: 10565.0000 - accuracy: 0.6986 - precision: 0.1900 - recall: 0.5908 - auc: 0.7212 - val_loss: 0.4512 - val_tp: 1674.0000 - val_fp: 5692.0000 - val_tn: 26578.0000 - val_fn: 1974.0000 - val_accuracy: 0.7866 - val_precision: 0.2273 - val_recall: 0.4589 - val_auc: 0.7493\n",
      "Epoch 65/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.6231 - tp: 15308.0000 - fp: 65122.0000 - tn: 159933.0000 - fn: 10511.0000 - accuracy: 0.6985 - precision: 0.1903 - recall: 0.5929 - auc: 0.7219 - val_loss: 0.4511 - val_tp: 1670.0000 - val_fp: 5696.0000 - val_tn: 26574.0000 - val_fn: 1978.0000 - val_accuracy: 0.7863 - val_precision: 0.2267 - val_recall: 0.4578 - val_auc: 0.7495\n",
      "Epoch 66/100\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 0.6209 - tp: 15435.0000 - fp: 65304.0000 - tn: 159751.0000 - fn: 10384.0000 - accuracy: 0.6983 - precision: 0.1912 - recall: 0.5978 - auc: 0.7241 - val_loss: 0.4498 - val_tp: 1659.0000 - val_fp: 5641.0000 - val_tn: 26629.0000 - val_fn: 1989.0000 - val_accuracy: 0.7876 - val_precision: 0.2273 - val_recall: 0.4548 - val_auc: 0.7498\n",
      "Epoch 67/100\n",
      "126/126 [==============================] - 3s 22ms/step - loss: 0.6220 - tp: 15381.0000 - fp: 65315.0000 - tn: 159740.0000 - fn: 10438.0000 - accuracy: 0.6980 - precision: 0.1906 - recall: 0.5957 - auc: 0.7228 - val_loss: 0.4489 - val_tp: 1657.0000 - val_fp: 5628.0000 - val_tn: 26642.0000 - val_fn: 1991.0000 - val_accuracy: 0.7879 - val_precision: 0.2275 - val_recall: 0.4542 - val_auc: 0.7498\n",
      "Epoch 68/100\n",
      "126/126 [==============================] - 2s 18ms/step - loss: 0.6198 - tp: 15445.0000 - fp: 64993.0000 - tn: 160062.0000 - fn: 10374.0000 - accuracy: 0.6996 - precision: 0.1920 - recall: 0.5982 - auc: 0.7249 - val_loss: 0.4502 - val_tp: 1669.0000 - val_fp: 5668.0000 - val_tn: 26602.0000 - val_fn: 1979.0000 - val_accuracy: 0.7871 - val_precision: 0.2275 - val_recall: 0.4575 - val_auc: 0.7499\n",
      "Epoch 69/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.6192 - tp: 15455.0000 - fp: 66061.0000 - tn: 158994.0000 - fn: 10364.0000 - accuracy: 0.6954 - precision: 0.1896 - recall: 0.5986 - auc: 0.7246 - val_loss: 0.4490 - val_tp: 1653.0000 - val_fp: 5603.0000 - val_tn: 26667.0000 - val_fn: 1995.0000 - val_accuracy: 0.7885 - val_precision: 0.2278 - val_recall: 0.4531 - val_auc: 0.7503\n",
      "Epoch 70/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6174 - tp: 15557.0000 - fp: 65627.0000 - tn: 159428.0000 - fn: 10262.0000 - accuracy: 0.6975 - precision: 0.1916 - recall: 0.6025 - auc: 0.7262 - val_loss: 0.4483 - val_tp: 1642.0000 - val_fp: 5568.0000 - val_tn: 26702.0000 - val_fn: 2006.0000 - val_accuracy: 0.7891 - val_precision: 0.2277 - val_recall: 0.4501 - val_auc: 0.7503\n",
      "Epoch 71/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6173 - tp: 15494.0000 - fp: 65777.0000 - tn: 159278.0000 - fn: 10325.0000 - accuracy: 0.6967 - precision: 0.1906 - recall: 0.6001 - auc: 0.7259 - val_loss: 0.4493 - val_tp: 1655.0000 - val_fp: 5634.0000 - val_tn: 26636.0000 - val_fn: 1993.0000 - val_accuracy: 0.7877 - val_precision: 0.2271 - val_recall: 0.4537 - val_auc: 0.7503\n",
      "Epoch 72/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6183 - tp: 15506.0000 - fp: 66143.0000 - tn: 158912.0000 - fn: 10313.0000 - accuracy: 0.6952 - precision: 0.1899 - recall: 0.6006 - auc: 0.7249 - val_loss: 0.4473 - val_tp: 1637.0000 - val_fp: 5517.0000 - val_tn: 26753.0000 - val_fn: 2011.0000 - val_accuracy: 0.7904 - val_precision: 0.2288 - val_recall: 0.4487 - val_auc: 0.7506\n",
      "Epoch 73/100\n",
      "126/126 [==============================] - 2s 16ms/step - loss: 0.6155 - tp: 15665.0000 - fp: 66201.0000 - tn: 158854.0000 - fn: 10154.0000 - accuracy: 0.6956 - precision: 0.1913 - recall: 0.6067 - auc: 0.7272 - val_loss: 0.4475 - val_tp: 1643.0000 - val_fp: 5532.0000 - val_tn: 26738.0000 - val_fn: 2005.0000 - val_accuracy: 0.7902 - val_precision: 0.2290 - val_recall: 0.4504 - val_auc: 0.7507\n",
      "Epoch 74/100\n",
      "126/126 [==============================] - 1s 12ms/step - loss: 0.6171 - tp: 15597.0000 - fp: 66139.0000 - tn: 158916.0000 - fn: 10222.0000 - accuracy: 0.6956 - precision: 0.1908 - recall: 0.6041 - auc: 0.7255 - val_loss: 0.4454 - val_tp: 1612.0000 - val_fp: 5391.0000 - val_tn: 26879.0000 - val_fn: 2036.0000 - val_accuracy: 0.7932 - val_precision: 0.2302 - val_recall: 0.4419 - val_auc: 0.7511\n",
      "Epoch 75/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6156 - tp: 15626.0000 - fp: 66106.0000 - tn: 158949.0000 - fn: 10193.0000 - accuracy: 0.6959 - precision: 0.1912 - recall: 0.6052 - auc: 0.7268 - val_loss: 0.4452 - val_tp: 1608.0000 - val_fp: 5376.0000 - val_tn: 26894.0000 - val_fn: 2040.0000 - val_accuracy: 0.7935 - val_precision: 0.2302 - val_recall: 0.4408 - val_auc: 0.7511\n",
      "Epoch 76/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6150 - tp: 15723.0000 - fp: 66328.0000 - tn: 158727.0000 - fn: 10096.0000 - accuracy: 0.6954 - precision: 0.1916 - recall: 0.6090 - auc: 0.7273 - val_loss: 0.4455 - val_tp: 1621.0000 - val_fp: 5441.0000 - val_tn: 26829.0000 - val_fn: 2027.0000 - val_accuracy: 0.7921 - val_precision: 0.2295 - val_recall: 0.4444 - val_auc: 0.7510\n",
      "Epoch 77/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6161 - tp: 15660.0000 - fp: 66556.0000 - tn: 158499.0000 - fn: 10159.0000 - accuracy: 0.6942 - precision: 0.1905 - recall: 0.6065 - auc: 0.7258 - val_loss: 0.4472 - val_tp: 1636.0000 - val_fp: 5515.0000 - val_tn: 26755.0000 - val_fn: 2012.0000 - val_accuracy: 0.7904 - val_precision: 0.2288 - val_recall: 0.4485 - val_auc: 0.7509\n",
      "Epoch 78/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6132 - tp: 15793.0000 - fp: 66890.0000 - tn: 158165.0000 - fn: 10026.0000 - accuracy: 0.6934 - precision: 0.1910 - recall: 0.6117 - auc: 0.7284 - val_loss: 0.4473 - val_tp: 1634.0000 - val_fp: 5505.0000 - val_tn: 26765.0000 - val_fn: 2014.0000 - val_accuracy: 0.7907 - val_precision: 0.2289 - val_recall: 0.4479 - val_auc: 0.7510\n",
      "Epoch 79/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6143 - tp: 15754.0000 - fp: 66929.0000 - tn: 158126.0000 - fn: 10065.0000 - accuracy: 0.6931 - precision: 0.1905 - recall: 0.6102 - auc: 0.7274 - val_loss: 0.4474 - val_tp: 1644.0000 - val_fp: 5561.0000 - val_tn: 26709.0000 - val_fn: 2004.0000 - val_accuracy: 0.7894 - val_precision: 0.2282 - val_recall: 0.4507 - val_auc: 0.7510\n",
      "Epoch 80/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6109 - tp: 16056.0000 - fp: 67193.0000 - tn: 157862.0000 - fn: 9763.0000 - accuracy: 0.6932 - precision: 0.1929 - recall: 0.6219 - auc: 0.7307 - val_loss: 0.4440 - val_tp: 1592.0000 - val_fp: 5327.0000 - val_tn: 26943.0000 - val_fn: 2056.0000 - val_accuracy: 0.7944 - val_precision: 0.2301 - val_recall: 0.4364 - val_auc: 0.7515\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6121 - tp: 15906.0000 - fp: 66925.0000 - tn: 158130.0000 - fn: 9913.0000 - accuracy: 0.6937 - precision: 0.1920 - recall: 0.6161 - auc: 0.7291 - val_loss: 0.4456 - val_tp: 1615.0000 - val_fp: 5409.0000 - val_tn: 26861.0000 - val_fn: 2033.0000 - val_accuracy: 0.7928 - val_precision: 0.2299 - val_recall: 0.4427 - val_auc: 0.7514\n",
      "Epoch 82/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6104 - tp: 15994.0000 - fp: 67059.0000 - tn: 157996.0000 - fn: 9825.0000 - accuracy: 0.6935 - precision: 0.1926 - recall: 0.6195 - auc: 0.7309 - val_loss: 0.4445 - val_tp: 1593.0000 - val_fp: 5314.0000 - val_tn: 26956.0000 - val_fn: 2055.0000 - val_accuracy: 0.7948 - val_precision: 0.2306 - val_recall: 0.4367 - val_auc: 0.7516\n",
      "Epoch 83/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6104 - tp: 15956.0000 - fp: 67437.0000 - tn: 157618.0000 - fn: 9863.0000 - accuracy: 0.6919 - precision: 0.1913 - recall: 0.6180 - auc: 0.7297 - val_loss: 0.4446 - val_tp: 1592.0000 - val_fp: 5309.0000 - val_tn: 26961.0000 - val_fn: 2056.0000 - val_accuracy: 0.7949 - val_precision: 0.2307 - val_recall: 0.4364 - val_auc: 0.7517\n",
      "Epoch 84/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6089 - tp: 16039.0000 - fp: 67232.0000 - tn: 157823.0000 - fn: 9780.0000 - accuracy: 0.6930 - precision: 0.1926 - recall: 0.6212 - auc: 0.7318 - val_loss: 0.4466 - val_tp: 1626.0000 - val_fp: 5477.0000 - val_tn: 26793.0000 - val_fn: 2022.0000 - val_accuracy: 0.7912 - val_precision: 0.2289 - val_recall: 0.4457 - val_auc: 0.7515\n",
      "Epoch 85/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6099 - tp: 16068.0000 - fp: 67877.0000 - tn: 157178.0000 - fn: 9751.0000 - accuracy: 0.6906 - precision: 0.1914 - recall: 0.6223 - auc: 0.7307 - val_loss: 0.4445 - val_tp: 1596.0000 - val_fp: 5315.0000 - val_tn: 26955.0000 - val_fn: 2052.0000 - val_accuracy: 0.7949 - val_precision: 0.2309 - val_recall: 0.4375 - val_auc: 0.7516\n",
      "Epoch 86/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6101 - tp: 15974.0000 - fp: 67578.0000 - tn: 157477.0000 - fn: 9845.0000 - accuracy: 0.6914 - precision: 0.1912 - recall: 0.6187 - auc: 0.7302 - val_loss: 0.4438 - val_tp: 1590.0000 - val_fp: 5269.0000 - val_tn: 27001.0000 - val_fn: 2058.0000 - val_accuracy: 0.7960 - val_precision: 0.2318 - val_recall: 0.4359 - val_auc: 0.7518\n",
      "Epoch 87/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6080 - tp: 16107.0000 - fp: 67576.0000 - tn: 157479.0000 - fn: 9712.0000 - accuracy: 0.6919 - precision: 0.1925 - recall: 0.6238 - auc: 0.7325 - val_loss: 0.4444 - val_tp: 1593.0000 - val_fp: 5284.0000 - val_tn: 26986.0000 - val_fn: 2055.0000 - val_accuracy: 0.7957 - val_precision: 0.2316 - val_recall: 0.4367 - val_auc: 0.7519\n",
      "Epoch 88/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6072 - tp: 16255.0000 - fp: 68096.0000 - tn: 156959.0000 - fn: 9564.0000 - accuracy: 0.6904 - precision: 0.1927 - recall: 0.6296 - auc: 0.7325 - val_loss: 0.4433 - val_tp: 1587.0000 - val_fp: 5224.0000 - val_tn: 27046.0000 - val_fn: 2061.0000 - val_accuracy: 0.7972 - val_precision: 0.2330 - val_recall: 0.4350 - val_auc: 0.7519\n",
      "Epoch 89/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6075 - tp: 16230.0000 - fp: 68168.0000 - tn: 156887.0000 - fn: 9589.0000 - accuracy: 0.6901 - precision: 0.1923 - recall: 0.6286 - auc: 0.7322 - val_loss: 0.4449 - val_tp: 1606.0000 - val_fp: 5360.0000 - val_tn: 26910.0000 - val_fn: 2042.0000 - val_accuracy: 0.7939 - val_precision: 0.2305 - val_recall: 0.4402 - val_auc: 0.7519\n",
      "Epoch 90/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6068 - tp: 16250.0000 - fp: 68602.0000 - tn: 156453.0000 - fn: 9569.0000 - accuracy: 0.6884 - precision: 0.1915 - recall: 0.6294 - auc: 0.7327 - val_loss: 0.4438 - val_tp: 1587.0000 - val_fp: 5252.0000 - val_tn: 27018.0000 - val_fn: 2061.0000 - val_accuracy: 0.7964 - val_precision: 0.2321 - val_recall: 0.4350 - val_auc: 0.7520\n",
      "Epoch 91/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6081 - tp: 16153.0000 - fp: 68449.0000 - tn: 156606.0000 - fn: 9666.0000 - accuracy: 0.6886 - precision: 0.1909 - recall: 0.6256 - auc: 0.7313 - val_loss: 0.4441 - val_tp: 1586.0000 - val_fp: 5249.0000 - val_tn: 27021.0000 - val_fn: 2062.0000 - val_accuracy: 0.7965 - val_precision: 0.2320 - val_recall: 0.4348 - val_auc: 0.7520\n",
      "Epoch 92/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6056 - tp: 16390.0000 - fp: 68517.0000 - tn: 156538.0000 - fn: 9429.0000 - accuracy: 0.6893 - precision: 0.1930 - recall: 0.6348 - auc: 0.7337 - val_loss: 0.4440 - val_tp: 1586.0000 - val_fp: 5246.0000 - val_tn: 27024.0000 - val_fn: 2062.0000 - val_accuracy: 0.7965 - val_precision: 0.2321 - val_recall: 0.4348 - val_auc: 0.7520\n",
      "Epoch 93/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6045 - tp: 16352.0000 - fp: 68459.0000 - tn: 156596.0000 - fn: 9467.0000 - accuracy: 0.6894 - precision: 0.1928 - recall: 0.6333 - auc: 0.7347 - val_loss: 0.4444 - val_tp: 1592.0000 - val_fp: 5294.0000 - val_tn: 26976.0000 - val_fn: 2056.0000 - val_accuracy: 0.7954 - val_precision: 0.2312 - val_recall: 0.4364 - val_auc: 0.7521\n",
      "Epoch 94/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6058 - tp: 16278.0000 - fp: 68938.0000 - tn: 156117.0000 - fn: 9541.0000 - accuracy: 0.6872 - precision: 0.1910 - recall: 0.6305 - auc: 0.7332 - val_loss: 0.4437 - val_tp: 1582.0000 - val_fp: 5203.0000 - val_tn: 27067.0000 - val_fn: 2066.0000 - val_accuracy: 0.7976 - val_precision: 0.2332 - val_recall: 0.4337 - val_auc: 0.7522\n",
      "Epoch 95/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6054 - tp: 16278.0000 - fp: 68521.0000 - tn: 156534.0000 - fn: 9541.0000 - accuracy: 0.6888 - precision: 0.1920 - recall: 0.6305 - auc: 0.7333 - val_loss: 0.4436 - val_tp: 1579.0000 - val_fp: 5209.0000 - val_tn: 27061.0000 - val_fn: 2069.0000 - val_accuracy: 0.7974 - val_precision: 0.2326 - val_recall: 0.4328 - val_auc: 0.7522\n",
      "Epoch 96/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6026 - tp: 16436.0000 - fp: 68809.0000 - tn: 156246.0000 - fn: 9383.0000 - accuracy: 0.6883 - precision: 0.1928 - recall: 0.6366 - auc: 0.7363 - val_loss: 0.4441 - val_tp: 1584.0000 - val_fp: 5206.0000 - val_tn: 27064.0000 - val_fn: 2064.0000 - val_accuracy: 0.7976 - val_precision: 0.2333 - val_recall: 0.4342 - val_auc: 0.7523\n",
      "Epoch 97/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6046 - tp: 16439.0000 - fp: 69057.0000 - tn: 155998.0000 - fn: 9380.0000 - accuracy: 0.6873 - precision: 0.1923 - recall: 0.6367 - auc: 0.7339 - val_loss: 0.4432 - val_tp: 1564.0000 - val_fp: 5125.0000 - val_tn: 27145.0000 - val_fn: 2084.0000 - val_accuracy: 0.7993 - val_precision: 0.2338 - val_recall: 0.4287 - val_auc: 0.7525\n",
      "Epoch 98/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6047 - tp: 16470.0000 - fp: 69466.0000 - tn: 155589.0000 - fn: 9349.0000 - accuracy: 0.6858 - precision: 0.1917 - recall: 0.6379 - auc: 0.7342 - val_loss: 0.4442 - val_tp: 1583.0000 - val_fp: 5215.0000 - val_tn: 27055.0000 - val_fn: 2065.0000 - val_accuracy: 0.7973 - val_precision: 0.2329 - val_recall: 0.4339 - val_auc: 0.7522\n",
      "Epoch 99/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6024 - tp: 16545.0000 - fp: 69183.0000 - tn: 155872.0000 - fn: 9274.0000 - accuracy: 0.6873 - precision: 0.1930 - recall: 0.6408 - auc: 0.7360 - val_loss: 0.4425 - val_tp: 1552.0000 - val_fp: 5102.0000 - val_tn: 27168.0000 - val_fn: 2096.0000 - val_accuracy: 0.7996 - val_precision: 0.2332 - val_recall: 0.4254 - val_auc: 0.7523\n",
      "Epoch 100/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6027 - tp: 16619.0000 - fp: 69316.0000 - tn: 155739.0000 - fn: 9200.0000 - accuracy: 0.6870 - precision: 0.1934 - recall: 0.6437 - auc: 0.7357 - val_loss: 0.4435 - val_tp: 1577.0000 - val_fp: 5185.0000 - val_tn: 27085.0000 - val_fn: 2071.0000 - val_accuracy: 0.7980 - val_precision: 0.2332 - val_recall: 0.4323 - val_auc: 0.7523\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 2s 15ms/step - loss: 0.9838 - tp: 8950.0000 - fp: 43033.0000 - tn: 214292.0000 - fn: 20517.0000 - accuracy: 0.7784 - precision: 0.1722 - recall: 0.3037 - auc: 0.6238 - val_loss: 0.4393 - val_tp: 1256.0000 - val_fp: 5115.0000 - val_tn: 27155.0000 - val_fn: 2392.0000 - val_accuracy: 0.7910 - val_precision: 0.1971 - val_recall: 0.3443 - val_auc: 0.6793\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7714 - tp: 10608.0000 - fp: 51950.0000 - tn: 173105.0000 - fn: 15211.0000 - accuracy: 0.7323 - precision: 0.1696 - recall: 0.4109 - auc: 0.6484 - val_loss: 0.4530 - val_tp: 1474.0000 - val_fp: 5619.0000 - val_tn: 26651.0000 - val_fn: 2174.0000 - val_accuracy: 0.7830 - val_precision: 0.2078 - val_recall: 0.4041 - val_auc: 0.7131\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7120 - tp: 12058.0000 - fp: 55577.0000 - tn: 169478.0000 - fn: 13761.0000 - accuracy: 0.7236 - precision: 0.1783 - recall: 0.4670 - auc: 0.6742 - val_loss: 0.4486 - val_tp: 1556.0000 - val_fp: 5570.0000 - val_tn: 26700.0000 - val_fn: 2092.0000 - val_accuracy: 0.7867 - val_precision: 0.2184 - val_recall: 0.4265 - val_auc: 0.7317\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6849 - tp: 12761.0000 - fp: 57497.0000 - tn: 167558.0000 - fn: 13058.0000 - accuracy: 0.7188 - precision: 0.1816 - recall: 0.4942 - auc: 0.6879 - val_loss: 0.4405 - val_tp: 1528.0000 - val_fp: 5315.0000 - val_tn: 26955.0000 - val_fn: 2120.0000 - val_accuracy: 0.7930 - val_precision: 0.2233 - val_recall: 0.4189 - val_auc: 0.7395\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.6626 - tp: 13534.0000 - fp: 58918.0000 - tn: 166137.0000 - fn: 12285.0000 - accuracy: 0.7162 - precision: 0.1868 - recall: 0.5242 - auc: 0.7020 - val_loss: 0.4397 - val_tp: 1563.0000 - val_fp: 5196.0000 - val_tn: 27074.0000 - val_fn: 2085.0000 - val_accuracy: 0.7973 - val_precision: 0.2312 - val_recall: 0.4285 - val_auc: 0.7449\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.6522 - tp: 13919.0000 - fp: 60395.0000 - tn: 164660.0000 - fn: 11900.0000 - accuracy: 0.7118 - precision: 0.1873 - recall: 0.5391 - auc: 0.7073 - val_loss: 0.4406 - val_tp: 1598.0000 - val_fp: 5406.0000 - val_tn: 26864.0000 - val_fn: 2050.0000 - val_accuracy: 0.7924 - val_precision: 0.2282 - val_recall: 0.4380 - val_auc: 0.7472\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6407 - tp: 14283.0000 - fp: 60905.0000 - tn: 164150.0000 - fn: 11536.0000 - accuracy: 0.7112 - precision: 0.1900 - recall: 0.5532 - auc: 0.7149 - val_loss: 0.4393 - val_tp: 1547.0000 - val_fp: 5090.0000 - val_tn: 27180.0000 - val_fn: 2101.0000 - val_accuracy: 0.7998 - val_precision: 0.2331 - val_recall: 0.4241 - val_auc: 0.7491\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.6308 - tp: 14962.0000 - fp: 63268.0000 - tn: 161787.0000 - fn: 10857.0000 - accuracy: 0.7045 - precision: 0.1913 - recall: 0.5795 - auc: 0.7200 - val_loss: 0.4501 - val_tp: 1686.0000 - val_fp: 5711.0000 - val_tn: 26559.0000 - val_fn: 1962.0000 - val_accuracy: 0.7864 - val_precision: 0.2279 - val_recall: 0.4622 - val_auc: 0.7498\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.6235 - tp: 15266.0000 - fp: 64566.0000 - tn: 160489.0000 - fn: 10553.0000 - accuracy: 0.7006 - precision: 0.1912 - recall: 0.5913 - auc: 0.7231 - val_loss: 0.4448 - val_tp: 1597.0000 - val_fp: 5299.0000 - val_tn: 26971.0000 - val_fn: 2051.0000 - val_accuracy: 0.7954 - val_precision: 0.2316 - val_recall: 0.4378 - val_auc: 0.7508\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6182 - tp: 15487.0000 - fp: 65338.0000 - tn: 159717.0000 - fn: 10332.0000 - accuracy: 0.6984 - precision: 0.1916 - recall: 0.5998 - auc: 0.7264 - val_loss: 0.4527 - val_tp: 1689.0000 - val_fp: 5739.0000 - val_tn: 26531.0000 - val_fn: 1959.0000 - val_accuracy: 0.7857 - val_precision: 0.2274 - val_recall: 0.4630 - val_auc: 0.7511\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6137 - tp: 15768.0000 - fp: 66773.0000 - tn: 158282.0000 - fn: 10051.0000 - accuracy: 0.6938 - precision: 0.1910 - recall: 0.6107 - auc: 0.7288 - val_loss: 0.4392 - val_tp: 1545.0000 - val_fp: 5057.0000 - val_tn: 27213.0000 - val_fn: 2103.0000 - val_accuracy: 0.8007 - val_precision: 0.2340 - val_recall: 0.4235 - val_auc: 0.7520\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6108 - tp: 16008.0000 - fp: 66864.0000 - tn: 158191.0000 - fn: 9811.0000 - accuracy: 0.6944 - precision: 0.1932 - recall: 0.6200 - auc: 0.7312 - val_loss: 0.4433 - val_tp: 1583.0000 - val_fp: 5224.0000 - val_tn: 27046.0000 - val_fn: 2065.0000 - val_accuracy: 0.7971 - val_precision: 0.2326 - val_recall: 0.4339 - val_auc: 0.7523\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6073 - tp: 16231.0000 - fp: 67457.0000 - tn: 157598.0000 - fn: 9588.0000 - accuracy: 0.6929 - precision: 0.1939 - recall: 0.6286 - auc: 0.7335 - val_loss: 0.4397 - val_tp: 1553.0000 - val_fp: 5081.0000 - val_tn: 27189.0000 - val_fn: 2095.0000 - val_accuracy: 0.8002 - val_precision: 0.2341 - val_recall: 0.4257 - val_auc: 0.7526\n",
      "Epoch 14/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6056 - tp: 16280.0000 - fp: 68257.0000 - tn: 156798.0000 - fn: 9539.0000 - accuracy: 0.6899 - precision: 0.1926 - recall: 0.6305 - auc: 0.7341 - val_loss: 0.4438 - val_tp: 1614.0000 - val_fp: 5375.0000 - val_tn: 26895.0000 - val_fn: 2034.0000 - val_accuracy: 0.7937 - val_precision: 0.2309 - val_recall: 0.4424 - val_auc: 0.7521\n",
      "Epoch 15/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6013 - tp: 16615.0000 - fp: 68962.0000 - tn: 156093.0000 - fn: 9204.0000 - accuracy: 0.6884 - precision: 0.1942 - recall: 0.6435 - auc: 0.7383 - val_loss: 0.4354 - val_tp: 1481.0000 - val_fp: 4751.0000 - val_tn: 27519.0000 - val_fn: 2167.0000 - val_accuracy: 0.8074 - val_precision: 0.2376 - val_recall: 0.4060 - val_auc: 0.7524\n",
      "Epoch 16/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6008 - tp: 16741.0000 - fp: 69607.0000 - tn: 155448.0000 - fn: 9078.0000 - accuracy: 0.6864 - precision: 0.1939 - recall: 0.6484 - auc: 0.7382 - val_loss: 0.4363 - val_tp: 1489.0000 - val_fp: 4720.0000 - val_tn: 27550.0000 - val_fn: 2159.0000 - val_accuracy: 0.8085 - val_precision: 0.2398 - val_recall: 0.4082 - val_auc: 0.7527\n",
      "Epoch 17/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.5984 - tp: 16849.0000 - fp: 69820.0000 - tn: 155235.0000 - fn: 8970.0000 - accuracy: 0.6859 - precision: 0.1944 - recall: 0.6526 - auc: 0.7398 - val_loss: 0.4410 - val_tp: 1524.0000 - val_fp: 4906.0000 - val_tn: 27364.0000 - val_fn: 2124.0000 - val_accuracy: 0.8043 - val_precision: 0.2370 - val_recall: 0.4178 - val_auc: 0.7528\n",
      "Epoch 18/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5966 - tp: 17010.0000 - fp: 70939.0000 - tn: 154116.0000 - fn: 8809.0000 - accuracy: 0.6821 - precision: 0.1934 - recall: 0.6588 - auc: 0.7414 - val_loss: 0.4363 - val_tp: 1424.0000 - val_fp: 4460.0000 - val_tn: 27810.0000 - val_fn: 2224.0000 - val_accuracy: 0.8139 - val_precision: 0.2420 - val_recall: 0.3904 - val_auc: 0.7530\n",
      "Epoch 19/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5942 - tp: 17328.0000 - fp: 71100.0000 - tn: 153955.0000 - fn: 8491.0000 - accuracy: 0.6827 - precision: 0.1960 - recall: 0.6711 - auc: 0.7433 - val_loss: 0.4360 - val_tp: 1458.0000 - val_fp: 4627.0000 - val_tn: 27643.0000 - val_fn: 2190.0000 - val_accuracy: 0.8102 - val_precision: 0.2396 - val_recall: 0.3997 - val_auc: 0.7522\n",
      "Epoch 20/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5933 - tp: 17399.0000 - fp: 71943.0000 - tn: 153112.0000 - fn: 8420.0000 - accuracy: 0.6797 - precision: 0.1947 - recall: 0.6739 - auc: 0.7441 - val_loss: 0.4313 - val_tp: 1380.0000 - val_fp: 4292.0000 - val_tn: 27978.0000 - val_fn: 2268.0000 - val_accuracy: 0.8174 - val_precision: 0.2433 - val_recall: 0.3783 - val_auc: 0.7515\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5925 - tp: 17503.0000 - fp: 72581.0000 - tn: 152474.0000 - fn: 8316.0000 - accuracy: 0.6775 - precision: 0.1943 - recall: 0.6779 - auc: 0.7442 - val_loss: 0.4375 - val_tp: 1406.0000 - val_fp: 4406.0000 - val_tn: 27864.0000 - val_fn: 2242.0000 - val_accuracy: 0.8149 - val_precision: 0.2419 - val_recall: 0.3854 - val_auc: 0.7523\n",
      "Epoch 22/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5912 - tp: 17602.0000 - fp: 72683.0000 - tn: 152372.0000 - fn: 8217.0000 - accuracy: 0.6775 - precision: 0.1950 - recall: 0.6817 - auc: 0.7455 - val_loss: 0.4324 - val_tp: 1390.0000 - val_fp: 4325.0000 - val_tn: 27945.0000 - val_fn: 2258.0000 - val_accuracy: 0.8167 - val_precision: 0.2432 - val_recall: 0.3810 - val_auc: 0.7520\n",
      "Epoch 23/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5912 - tp: 17751.0000 - fp: 73726.0000 - tn: 151329.0000 - fn: 8068.0000 - accuracy: 0.6740 - precision: 0.1940 - recall: 0.6875 - auc: 0.7455 - val_loss: 0.4367 - val_tp: 1357.0000 - val_fp: 4266.0000 - val_tn: 28004.0000 - val_fn: 2291.0000 - val_accuracy: 0.8174 - val_precision: 0.2413 - val_recall: 0.3720 - val_auc: 0.7506\n",
      "Epoch 24/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5889 - tp: 17977.0000 - fp: 73877.0000 - tn: 151178.0000 - fn: 7842.0000 - accuracy: 0.6743 - precision: 0.1957 - recall: 0.6963 - auc: 0.7482 - val_loss: 0.4339 - val_tp: 1293.0000 - val_fp: 3973.0000 - val_tn: 28297.0000 - val_fn: 2355.0000 - val_accuracy: 0.8238 - val_precision: 0.2455 - val_recall: 0.3544 - val_auc: 0.7509\n",
      "Epoch 25/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5890 - tp: 18042.0000 - fp: 74817.0000 - tn: 150238.0000 - fn: 7777.0000 - accuracy: 0.6708 - precision: 0.1943 - recall: 0.6988 - auc: 0.7480 - val_loss: 0.4360 - val_tp: 1313.0000 - val_fp: 4026.0000 - val_tn: 28244.0000 - val_fn: 2335.0000 - val_accuracy: 0.8229 - val_precision: 0.2459 - val_recall: 0.3599 - val_auc: 0.7507\n",
      "Epoch 26/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5871 - tp: 18192.0000 - fp: 74758.0000 - tn: 150297.0000 - fn: 7627.0000 - accuracy: 0.6716 - precision: 0.1957 - recall: 0.7046 - auc: 0.7505 - val_loss: 0.4284 - val_tp: 1128.0000 - val_fp: 3284.0000 - val_tn: 28986.0000 - val_fn: 2520.0000 - val_accuracy: 0.8384 - val_precision: 0.2557 - val_recall: 0.3092 - val_auc: 0.7504\n",
      "Epoch 27/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5870 - tp: 18203.0000 - fp: 75181.0000 - tn: 149874.0000 - fn: 7616.0000 - accuracy: 0.6700 - precision: 0.1949 - recall: 0.7050 - auc: 0.7501 - val_loss: 0.4292 - val_tp: 1200.0000 - val_fp: 3599.0000 - val_tn: 28671.0000 - val_fn: 2448.0000 - val_accuracy: 0.8316 - val_precision: 0.2501 - val_recall: 0.3289 - val_auc: 0.7488\n",
      "Epoch 28/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5859 - tp: 18377.0000 - fp: 75488.0000 - tn: 149567.0000 - fn: 7442.0000 - accuracy: 0.6694 - precision: 0.1958 - recall: 0.7118 - auc: 0.7518 - val_loss: 0.4310 - val_tp: 1183.0000 - val_fp: 3516.0000 - val_tn: 28754.0000 - val_fn: 2465.0000 - val_accuracy: 0.8335 - val_precision: 0.2518 - val_recall: 0.3243 - val_auc: 0.7489\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.7162 - tp: 14104.0000 - fp: 61986.0000 - tn: 195339.0000 - fn: 15363.0000 - accuracy: 0.7303 - precision: 0.1854 - recall: 0.4786 - auc: 0.6822 - val_loss: 0.4366 - val_tp: 1329.0000 - val_fp: 4161.0000 - val_tn: 28109.0000 - val_fn: 2319.0000 - val_accuracy: 0.8196 - val_precision: 0.2421 - val_recall: 0.3643 - val_auc: 0.7467\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6129 - tp: 16017.0000 - fp: 67895.0000 - tn: 157160.0000 - fn: 9802.0000 - accuracy: 0.6903 - precision: 0.1909 - recall: 0.6204 - auc: 0.7275 - val_loss: 0.4611 - val_tp: 1702.0000 - val_fp: 5851.0000 - val_tn: 26419.0000 - val_fn: 1946.0000 - val_accuracy: 0.7829 - val_precision: 0.2253 - val_recall: 0.4666 - val_auc: 0.7495\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5989 - tp: 17343.0000 - fp: 74003.0000 - tn: 151052.0000 - fn: 8476.0000 - accuracy: 0.6712 - precision: 0.1899 - recall: 0.6717 - auc: 0.7374 - val_loss: 0.4684 - val_tp: 1833.0000 - val_fp: 6347.0000 - val_tn: 25923.0000 - val_fn: 1815.0000 - val_accuracy: 0.7728 - val_precision: 0.2241 - val_recall: 0.5025 - val_auc: 0.7513\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5943 - tp: 18242.0000 - fp: 77515.0000 - tn: 147540.0000 - fn: 7577.0000 - accuracy: 0.6608 - precision: 0.1905 - recall: 0.7065 - auc: 0.7426 - val_loss: 0.4645 - val_tp: 1734.0000 - val_fp: 5897.0000 - val_tn: 26373.0000 - val_fn: 1914.0000 - val_accuracy: 0.7825 - val_precision: 0.2272 - val_recall: 0.4753 - val_auc: 0.7493\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5917 - tp: 18598.0000 - fp: 78611.0000 - tn: 146444.0000 - fn: 7221.0000 - accuracy: 0.6579 - precision: 0.1913 - recall: 0.7203 - auc: 0.7457 - val_loss: 0.4542 - val_tp: 1621.0000 - val_fp: 5392.0000 - val_tn: 26878.0000 - val_fn: 2027.0000 - val_accuracy: 0.7934 - val_precision: 0.2311 - val_recall: 0.4444 - val_auc: 0.7510\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5892 - tp: 18739.0000 - fp: 78624.0000 - tn: 146431.0000 - fn: 7080.0000 - accuracy: 0.6584 - precision: 0.1925 - recall: 0.7258 - auc: 0.7490 - val_loss: 0.4501 - val_tp: 1363.0000 - val_fp: 4302.0000 - val_tn: 27968.0000 - val_fn: 2285.0000 - val_accuracy: 0.8166 - val_precision: 0.2406 - val_recall: 0.3736 - val_auc: 0.7501\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5885 - tp: 18934.0000 - fp: 79223.0000 - tn: 145832.0000 - fn: 6885.0000 - accuracy: 0.6568 - precision: 0.1929 - recall: 0.7333 - auc: 0.7494 - val_loss: 0.4542 - val_tp: 1510.0000 - val_fp: 4998.0000 - val_tn: 27272.0000 - val_fn: 2138.0000 - val_accuracy: 0.8013 - val_precision: 0.2320 - val_recall: 0.4139 - val_auc: 0.7482\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5890 - tp: 18905.0000 - fp: 78643.0000 - tn: 146412.0000 - fn: 6914.0000 - accuracy: 0.6590 - precision: 0.1938 - recall: 0.7322 - auc: 0.7500 - val_loss: 0.4462 - val_tp: 964.0000 - val_fp: 2683.0000 - val_tn: 29587.0000 - val_fn: 2684.0000 - val_accuracy: 0.8506 - val_precision: 0.2643 - val_recall: 0.2643 - val_auc: 0.7481\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5883 - tp: 18897.0000 - fp: 79003.0000 - tn: 146052.0000 - fn: 6922.0000 - accuracy: 0.6575 - precision: 0.1930 - recall: 0.7319 - auc: 0.7498 - val_loss: 0.4563 - val_tp: 1353.0000 - val_fp: 4207.0000 - val_tn: 28063.0000 - val_fn: 2295.0000 - val_accuracy: 0.8190 - val_precision: 0.2433 - val_recall: 0.3709 - val_auc: 0.7493\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5873 - tp: 19034.0000 - fp: 79508.0000 - tn: 145547.0000 - fn: 6785.0000 - accuracy: 0.6560 - precision: 0.1932 - recall: 0.7372 - auc: 0.7520 - val_loss: 0.4278 - val_tp: 1098.0000 - val_fp: 3149.0000 - val_tn: 29121.0000 - val_fn: 2550.0000 - val_accuracy: 0.8413 - val_precision: 0.2585 - val_recall: 0.3010 - val_auc: 0.7466\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5853 - tp: 19092.0000 - fp: 78820.0000 - tn: 146235.0000 - fn: 6727.0000 - accuracy: 0.6590 - precision: 0.1950 - recall: 0.7395 - auc: 0.7538 - val_loss: 0.4351 - val_tp: 996.0000 - val_fp: 2786.0000 - val_tn: 29484.0000 - val_fn: 2652.0000 - val_accuracy: 0.8486 - val_precision: 0.2634 - val_recall: 0.2730 - val_auc: 0.7441\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5857 - tp: 19004.0000 - fp: 78377.0000 - tn: 146678.0000 - fn: 6815.0000 - accuracy: 0.6604 - precision: 0.1952 - recall: 0.7360 - auc: 0.7534 - val_loss: 0.4140 - val_tp: 854.0000 - val_fp: 2292.0000 - val_tn: 29978.0000 - val_fn: 2794.0000 - val_accuracy: 0.8584 - val_precision: 0.2715 - val_recall: 0.2341 - val_auc: 0.7428\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.5853 - tp: 19013.0000 - fp: 78486.0000 - tn: 146569.0000 - fn: 6806.0000 - accuracy: 0.6600 - precision: 0.1950 - recall: 0.7364 - auc: 0.7540 - val_loss: 0.4285 - val_tp: 927.0000 - val_fp: 2568.0000 - val_tn: 29702.0000 - val_fn: 2721.0000 - val_accuracy: 0.8527 - val_precision: 0.2652 - val_recall: 0.2541 - val_auc: 0.7438\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.7013 - tp: 16625.0000 - fp: 79045.0000 - tn: 178280.0000 - fn: 12842.0000 - accuracy: 0.6796 - precision: 0.1738 - recall: 0.5642 - auc: 0.6780 - val_loss: 0.5112 - val_tp: 2153.0000 - val_fp: 8261.0000 - val_tn: 24009.0000 - val_fn: 1495.0000 - val_accuracy: 0.7284 - val_precision: 0.2067 - val_recall: 0.5902 - val_auc: 0.7439\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6086 - tp: 18135.0000 - fp: 81041.0000 - tn: 144014.0000 - fn: 7684.0000 - accuracy: 0.6463 - precision: 0.1829 - recall: 0.7024 - auc: 0.7296 - val_loss: 0.4881 - val_tp: 1854.0000 - val_fp: 6515.0000 - val_tn: 25755.0000 - val_fn: 1794.0000 - val_accuracy: 0.7687 - val_precision: 0.2215 - val_recall: 0.5082 - val_auc: 0.7461\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6122 - tp: 18295.0000 - fp: 82366.0000 - tn: 142689.0000 - fn: 7524.0000 - accuracy: 0.6417 - precision: 0.1817 - recall: 0.7086 - auc: 0.7277 - val_loss: 0.6080 - val_tp: 2538.0000 - val_fp: 10902.0000 - val_tn: 21368.0000 - val_fn: 1110.0000 - val_accuracy: 0.6656 - val_precision: 0.1888 - val_recall: 0.6957 - val_auc: 0.7360\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6116 - tp: 18091.0000 - fp: 80107.0000 - tn: 144948.0000 - fn: 7728.0000 - accuracy: 0.6499 - precision: 0.1842 - recall: 0.7007 - auc: 0.7303 - val_loss: 0.4452 - val_tp: 1106.0000 - val_fp: 3464.0000 - val_tn: 28806.0000 - val_fn: 2542.0000 - val_accuracy: 0.8328 - val_precision: 0.2420 - val_recall: 0.3032 - val_auc: 0.7346\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6136 - tp: 17695.0000 - fp: 77814.0000 - tn: 147241.0000 - fn: 8124.0000 - accuracy: 0.6574 - precision: 0.1853 - recall: 0.6853 - auc: 0.7283 - val_loss: 0.4847 - val_tp: 1334.0000 - val_fp: 4462.0000 - val_tn: 27808.0000 - val_fn: 2314.0000 - val_accuracy: 0.8113 - val_precision: 0.2302 - val_recall: 0.3657 - val_auc: 0.7365\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.6140 - tp: 17768.0000 - fp: 77541.0000 - tn: 147514.0000 - fn: 8051.0000 - accuracy: 0.6588 - precision: 0.1864 - recall: 0.6882 - auc: 0.7292 - val_loss: 0.4978 - val_tp: 1820.0000 - val_fp: 6651.0000 - val_tn: 25619.0000 - val_fn: 1828.0000 - val_accuracy: 0.7639 - val_precision: 0.2149 - val_recall: 0.4989 - val_auc: 0.7353\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6217 - tp: 17093.0000 - fp: 75008.0000 - tn: 150047.0000 - fn: 8726.0000 - accuracy: 0.6662 - precision: 0.1856 - recall: 0.6620 - auc: 0.7233 - val_loss: 0.4814 - val_tp: 966.0000 - val_fp: 3210.0000 - val_tn: 29060.0000 - val_fn: 2682.0000 - val_accuracy: 0.8360 - val_precision: 0.2313 - val_recall: 0.2648 - val_auc: 0.7244\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6173 - tp: 17596.0000 - fp: 77383.0000 - tn: 147672.0000 - fn: 8223.0000 - accuracy: 0.6588 - precision: 0.1853 - recall: 0.6815 - auc: 0.7266 - val_loss: 0.5275 - val_tp: 1394.0000 - val_fp: 4948.0000 - val_tn: 27322.0000 - val_fn: 2254.0000 - val_accuracy: 0.7995 - val_precision: 0.2198 - val_recall: 0.3821 - val_auc: 0.7325\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.6151 - tp: 17174.0000 - fp: 73893.0000 - tn: 151162.0000 - fn: 8645.0000 - accuracy: 0.6710 - precision: 0.1886 - recall: 0.6652 - auc: 0.7275 - val_loss: 0.4624 - val_tp: 486.0000 - val_fp: 1578.0000 - val_tn: 30692.0000 - val_fn: 3162.0000 - val_accuracy: 0.8680 - val_precision: 0.2355 - val_recall: 0.1332 - val_auc: 0.7199\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6244 - tp: 16684.0000 - fp: 72808.0000 - tn: 152247.0000 - fn: 9135.0000 - accuracy: 0.6734 - precision: 0.1864 - recall: 0.6462 - auc: 0.7200 - val_loss: 0.5264 - val_tp: 1673.0000 - val_fp: 6391.0000 - val_tn: 25879.0000 - val_fn: 1975.0000 - val_accuracy: 0.7671 - val_precision: 0.2075 - val_recall: 0.4586 - val_auc: 0.7249\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.6215 - tp: 17117.0000 - fp: 74213.0000 - tn: 150842.0000 - fn: 8702.0000 - accuracy: 0.6695 - precision: 0.1874 - recall: 0.6630 - auc: 0.7249 - val_loss: 0.4914 - val_tp: 811.0000 - val_fp: 2391.0000 - val_tn: 29879.0000 - val_fn: 2837.0000 - val_accuracy: 0.8544 - val_precision: 0.2533 - val_recall: 0.2223 - val_auc: 0.7290\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6164 - tp: 16676.0000 - fp: 69069.0000 - tn: 155986.0000 - fn: 9143.0000 - accuracy: 0.6882 - precision: 0.1945 - recall: 0.6459 - auc: 0.7288 - val_loss: 0.4340 - val_tp: 653.0000 - val_fp: 1808.0000 - val_tn: 30462.0000 - val_fn: 2995.0000 - val_accuracy: 0.8663 - val_precision: 0.2653 - val_recall: 0.1790 - val_auc: 0.7333\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 3s 21ms/step - loss: 4.6267 - tp: 21488.0000 - fp: 138750.0000 - tn: 118575.0000 - fn: 7979.0000 - accuracy: 0.4884 - precision: 0.1341 - recall: 0.7292 - auc: 0.6006 - val_loss: 0.6244 - val_tp: 3247.0000 - val_fp: 19346.0000 - val_tn: 12924.0000 - val_fn: 401.0000 - val_accuracy: 0.4502 - val_precision: 0.1437 - val_recall: 0.8901 - val_auc: 0.6533\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.7054 - tp: 23923.0000 - fp: 160297.0000 - tn: 64758.0000 - fn: 1896.0000 - accuracy: 0.3535 - precision: 0.1299 - recall: 0.9266 - auc: 0.6093 - val_loss: 0.5686 - val_tp: 3090.0000 - val_fp: 17910.0000 - val_tn: 14360.0000 - val_fn: 558.0000 - val_accuracy: 0.4858 - val_precision: 0.1471 - val_recall: 0.8470 - val_auc: 0.6679\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.6773 - tp: 23664.0000 - fp: 156527.0000 - tn: 68528.0000 - fn: 2155.0000 - accuracy: 0.3675 - precision: 0.1313 - recall: 0.9165 - auc: 0.6188 - val_loss: 0.5206 - val_tp: 2917.0000 - val_fp: 15368.0000 - val_tn: 16902.0000 - val_fn: 731.0000 - val_accuracy: 0.5518 - val_precision: 0.1595 - val_recall: 0.7996 - val_auc: 0.6844\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.6792 - tp: 22642.0000 - fp: 150386.0000 - tn: 74669.0000 - fn: 3177.0000 - accuracy: 0.3879 - precision: 0.1309 - recall: 0.8770 - auc: 0.6146 - val_loss: 0.5191 - val_tp: 2754.0000 - val_fp: 14966.0000 - val_tn: 17304.0000 - val_fn: 894.0000 - val_accuracy: 0.5584 - val_precision: 0.1554 - val_recall: 0.7549 - val_auc: 0.6729\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.6938 - tp: 23183.0000 - fp: 158122.0000 - tn: 66933.0000 - fn: 2636.0000 - accuracy: 0.3592 - precision: 0.1279 - recall: 0.8979 - auc: 0.6097 - val_loss: 0.6608 - val_tp: 3204.0000 - val_fp: 19974.0000 - val_tn: 12296.0000 - val_fn: 444.0000 - val_accuracy: 0.4315 - val_precision: 0.1382 - val_recall: 0.8783 - val_auc: 0.6705\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.6813 - tp: 23045.0000 - fp: 155221.0000 - tn: 69834.0000 - fn: 2774.0000 - accuracy: 0.3702 - precision: 0.1293 - recall: 0.8926 - auc: 0.6119 - val_loss: 0.5320 - val_tp: 2949.0000 - val_fp: 16350.0000 - val_tn: 15920.0000 - val_fn: 699.0000 - val_accuracy: 0.5253 - val_precision: 0.1528 - val_recall: 0.8084 - val_auc: 0.6645\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 0.7107 - tp: 22464.0000 - fp: 156892.0000 - tn: 68163.0000 - fn: 3355.0000 - accuracy: 0.3612 - precision: 0.1252 - recall: 0.8701 - auc: 0.5889 - val_loss: 0.5462 - val_tp: 3130.0000 - val_fp: 18596.0000 - val_tn: 13674.0000 - val_fn: 518.0000 - val_accuracy: 0.4678 - val_precision: 0.1441 - val_recall: 0.8580 - val_auc: 0.6380\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 2s 13ms/step - loss: 0.7075 - tp: 23737.0000 - fp: 170947.0000 - tn: 54108.0000 - fn: 2082.0000 - accuracy: 0.3103 - precision: 0.1219 - recall: 0.9194 - auc: 0.5785 - val_loss: 0.6240 - val_tp: 3154.0000 - val_fp: 20414.0000 - val_tn: 11856.0000 - val_fn: 494.0000 - val_accuracy: 0.4179 - val_precision: 0.1338 - val_recall: 0.8646 - val_auc: 0.6386\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 2s 14ms/step - loss: 0.7015 - tp: 22091.0000 - fp: 159616.0000 - tn: 65439.0000 - fn: 3728.0000 - accuracy: 0.3489 - precision: 0.1216 - recall: 0.8556 - auc: 0.5776 - val_loss: 0.5713 - val_tp: 3157.0000 - val_fp: 19894.0000 - val_tn: 12376.0000 - val_fn: 491.0000 - val_accuracy: 0.4325 - val_precision: 0.1370 - val_recall: 0.8654 - val_auc: 0.6376\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 2s 13ms/step - loss: 0.7600 - tp: 21413.0000 - fp: 158636.0000 - tn: 66419.0000 - fn: 4406.0000 - accuracy: 0.3501 - precision: 0.1189 - recall: 0.8294 - auc: 0.5661 - val_loss: 0.5875 - val_tp: 3192.0000 - val_fp: 21404.0000 - val_tn: 10866.0000 - val_fn: 456.0000 - val_accuracy: 0.3914 - val_precision: 0.1298 - val_recall: 0.8750 - val_auc: 0.6085\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 11ms/step - loss: 0.7312 - tp: 19737.0000 - fp: 153131.0000 - tn: 71924.0000 - fn: 6082.0000 - accuracy: 0.3654 - precision: 0.1142 - recall: 0.7644 - auc: 0.5500 - val_loss: 0.6101 - val_tp: 3326.0000 - val_fp: 22740.0000 - val_tn: 9530.0000 - val_fn: 322.0000 - val_accuracy: 0.3579 - val_precision: 0.1276 - val_recall: 0.9117 - val_auc: 0.6087\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.7207 - tp: 23157.0000 - fp: 178507.0000 - tn: 46548.0000 - fn: 2662.0000 - accuracy: 0.2778 - precision: 0.1148 - recall: 0.8969 - auc: 0.5509 - val_loss: 0.6948 - val_tp: 3231.0000 - val_fp: 23543.0000 - val_tn: 8727.0000 - val_fn: 417.0000 - val_accuracy: 0.3329 - val_precision: 0.1207 - val_recall: 0.8857 - val_auc: 0.5647\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 1.9473 - tp: 18548.0000 - fp: 146174.0000 - tn: 78881.0000 - fn: 7271.0000 - accuracy: 0.3884 - precision: 0.1126 - recall: 0.7184 - auc: 0.5427 - val_loss: 0.8379 - val_tp: 3437.0000 - val_fp: 25911.0000 - val_tn: 6359.0000 - val_fn: 211.0000 - val_accuracy: 0.2727 - val_precision: 0.1171 - val_recall: 0.9422 - val_auc: 0.5616\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 2s 19ms/step - loss: 8.5067 - tp: 23552.0000 - fp: 158560.0000 - tn: 98765.0000 - fn: 5915.0000 - accuracy: 0.4265 - precision: 0.1293 - recall: 0.7993 - auc: 0.5847 - val_loss: 0.6852 - val_tp: 3180.0000 - val_fp: 18631.0000 - val_tn: 13639.0000 - val_fn: 468.0000 - val_accuracy: 0.4683 - val_precision: 0.1458 - val_recall: 0.8717 - val_auc: 0.6705\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7557 - tp: 24036.0000 - fp: 161962.0000 - tn: 63093.0000 - fn: 1783.0000 - accuracy: 0.3473 - precision: 0.1292 - recall: 0.9309 - auc: 0.5999 - val_loss: 0.5313 - val_tp: 3015.0000 - val_fp: 16291.0000 - val_tn: 15979.0000 - val_fn: 633.0000 - val_accuracy: 0.5288 - val_precision: 0.1562 - val_recall: 0.8265 - val_auc: 0.6768\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6882 - tp: 23840.0000 - fp: 162910.0000 - tn: 62145.0000 - fn: 1979.0000 - accuracy: 0.3427 - precision: 0.1277 - recall: 0.9234 - auc: 0.6005 - val_loss: 0.6179 - val_tp: 3192.0000 - val_fp: 19026.0000 - val_tn: 13244.0000 - val_fn: 456.0000 - val_accuracy: 0.4576 - val_precision: 0.1437 - val_recall: 0.8750 - val_auc: 0.6701\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6818 - tp: 21795.0000 - fp: 149869.0000 - tn: 75186.0000 - fn: 4024.0000 - accuracy: 0.3866 - precision: 0.1270 - recall: 0.8441 - auc: 0.6000 - val_loss: 0.5952 - val_tp: 3253.0000 - val_fp: 19548.0000 - val_tn: 12722.0000 - val_fn: 395.0000 - val_accuracy: 0.4448 - val_precision: 0.1427 - val_recall: 0.8917 - val_auc: 0.6520\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6800 - tp: 23275.0000 - fp: 159508.0000 - tn: 65547.0000 - fn: 2544.0000 - accuracy: 0.3541 - precision: 0.1273 - recall: 0.9015 - auc: 0.5997 - val_loss: 0.5383 - val_tp: 3035.0000 - val_fp: 17542.0000 - val_tn: 14728.0000 - val_fn: 613.0000 - val_accuracy: 0.4945 - val_precision: 0.1475 - val_recall: 0.8320 - val_auc: 0.6641\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6983 - tp: 21471.0000 - fp: 151200.0000 - tn: 73855.0000 - fn: 4348.0000 - accuracy: 0.3800 - precision: 0.1243 - recall: 0.8316 - auc: 0.5867 - val_loss: 0.6792 - val_tp: 3204.0000 - val_fp: 21285.0000 - val_tn: 10985.0000 - val_fn: 444.0000 - val_accuracy: 0.3950 - val_precision: 0.1308 - val_recall: 0.8783 - val_auc: 0.6480\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7091 - tp: 20130.0000 - fp: 142374.0000 - tn: 82681.0000 - fn: 5689.0000 - accuracy: 0.4098 - precision: 0.1239 - recall: 0.7797 - auc: 0.5979 - val_loss: 0.5152 - val_tp: 277.0000 - val_fp: 1927.0000 - val_tn: 30343.0000 - val_fn: 3371.0000 - val_accuracy: 0.8525 - val_precision: 0.1257 - val_recall: 0.0759 - val_auc: 0.6221\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7038 - tp: 21086.0000 - fp: 155199.0000 - tn: 69856.0000 - fn: 4733.0000 - accuracy: 0.3625 - precision: 0.1196 - recall: 0.8167 - auc: 0.5722 - val_loss: 0.6120 - val_tp: 3263.0000 - val_fp: 20701.0000 - val_tn: 11569.0000 - val_fn: 385.0000 - val_accuracy: 0.4129 - val_precision: 0.1362 - val_recall: 0.8945 - val_auc: 0.6408\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.4586 - tp: 20468.0000 - fp: 149351.0000 - tn: 75704.0000 - fn: 5351.0000 - accuracy: 0.3833 - precision: 0.1205 - recall: 0.7927 - auc: 0.5744 - val_loss: 0.6490 - val_tp: 66.0000 - val_fp: 823.0000 - val_tn: 31447.0000 - val_fn: 3582.0000 - val_accuracy: 0.8774 - val_precision: 0.0742 - val_recall: 0.0181 - val_auc: 0.6189\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.9213 - tp: 19272.0000 - fp: 147643.0000 - tn: 77412.0000 - fn: 6547.0000 - accuracy: 0.3854 - precision: 0.1155 - recall: 0.7464 - auc: 0.5544 - val_loss: 0.7209 - val_tp: 3375.0000 - val_fp: 24152.0000 - val_tn: 8118.0000 - val_fn: 273.0000 - val_accuracy: 0.3200 - val_precision: 0.1226 - val_recall: 0.9252 - val_auc: 0.5818\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 2s 12ms/step - loss: 0.7628 - tp: 17255.0000 - fp: 135352.0000 - tn: 89703.0000 - fn: 8564.0000 - accuracy: 0.4263 - precision: 0.1131 - recall: 0.6683 - auc: 0.5474 - val_loss: 0.6434 - val_tp: 2910.0000 - val_fp: 22065.0000 - val_tn: 10205.0000 - val_fn: 738.0000 - val_accuracy: 0.3651 - val_precision: 0.1165 - val_recall: 0.7977 - val_auc: 0.5670\n",
      "Epoch 12/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7348 - tp: 17194.0000 - fp: 139841.0000 - tn: 85214.0000 - fn: 8625.0000 - accuracy: 0.4082 - precision: 0.1095 - recall: 0.6659 - auc: 0.5335 - val_loss: 0.6407 - val_tp: 3480.0000 - val_fp: 25980.0000 - val_tn: 6290.0000 - val_fn: 168.0000 - val_accuracy: 0.2720 - val_precision: 0.1181 - val_recall: 0.9539 - val_auc: 0.5754\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 11.4283 - tp: 24513.0000 - fp: 168696.0000 - tn: 88629.0000 - fn: 4954.0000 - accuracy: 0.3945 - precision: 0.1269 - recall: 0.8319 - auc: 0.5857 - val_loss: 0.6446 - val_tp: 3185.0000 - val_fp: 19084.0000 - val_tn: 13186.0000 - val_fn: 463.0000 - val_accuracy: 0.4558 - val_precision: 0.1430 - val_recall: 0.8731 - val_auc: 0.6480\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7922 - tp: 23829.0000 - fp: 171033.0000 - tn: 54022.0000 - fn: 1990.0000 - accuracy: 0.3103 - precision: 0.1223 - recall: 0.9229 - auc: 0.5777 - val_loss: 0.6242 - val_tp: 3302.0000 - val_fp: 22330.0000 - val_tn: 9940.0000 - val_fn: 346.0000 - val_accuracy: 0.3687 - val_precision: 0.1288 - val_recall: 0.9052 - val_auc: 0.5896\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7088 - tp: 20809.0000 - fp: 152666.0000 - tn: 72389.0000 - fn: 5010.0000 - accuracy: 0.3715 - precision: 0.1200 - recall: 0.8060 - auc: 0.5745 - val_loss: 0.5591 - val_tp: 3.0000 - val_fp: 36.0000 - val_tn: 32234.0000 - val_fn: 3645.0000 - val_accuracy: 0.8975 - val_precision: 0.0769 - val_recall: 8.2237e-04 - val_auc: 0.6344\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7075 - tp: 20227.0000 - fp: 150247.0000 - tn: 74808.0000 - fn: 5592.0000 - accuracy: 0.3788 - precision: 0.1187 - recall: 0.7834 - auc: 0.5688 - val_loss: 0.8033 - val_tp: 3462.0000 - val_fp: 24543.0000 - val_tn: 7727.0000 - val_fn: 186.0000 - val_accuracy: 0.3115 - val_precision: 0.1236 - val_recall: 0.9490 - val_auc: 0.6236\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6977 - tp: 20026.0000 - fp: 150078.0000 - tn: 74977.0000 - fn: 5793.0000 - accuracy: 0.3787 - precision: 0.1177 - recall: 0.7756 - auc: 0.5670 - val_loss: 0.5964 - val_tp: 3283.0000 - val_fp: 22091.0000 - val_tn: 10179.0000 - val_fn: 365.0000 - val_accuracy: 0.3748 - val_precision: 0.1294 - val_recall: 0.8999 - val_auc: 0.6142\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6888 - tp: 20004.0000 - fp: 151943.0000 - tn: 73112.0000 - fn: 5815.0000 - accuracy: 0.3712 - precision: 0.1163 - recall: 0.7748 - auc: 0.5619 - val_loss: 0.5844 - val_tp: 23.0000 - val_fp: 486.0000 - val_tn: 31784.0000 - val_fn: 3625.0000 - val_accuracy: 0.8855 - val_precision: 0.0452 - val_recall: 0.0063 - val_auc: 0.6126\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7003 - tp: 21218.0000 - fp: 161431.0000 - tn: 63624.0000 - fn: 4601.0000 - accuracy: 0.3382 - precision: 0.1162 - recall: 0.8218 - auc: 0.5576 - val_loss: 0.5876 - val_tp: 3344.0000 - val_fp: 22456.0000 - val_tn: 9814.0000 - val_fn: 304.0000 - val_accuracy: 0.3663 - val_precision: 0.1296 - val_recall: 0.9167 - val_auc: 0.6061\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7058 - tp: 19918.0000 - fp: 152265.0000 - tn: 72790.0000 - fn: 5901.0000 - accuracy: 0.3695 - precision: 0.1157 - recall: 0.7714 - auc: 0.5568 - val_loss: 0.7627 - val_tp: 3456.0000 - val_fp: 24101.0000 - val_tn: 8169.0000 - val_fn: 192.0000 - val_accuracy: 0.3237 - val_precision: 0.1254 - val_recall: 0.9474 - val_auc: 0.6107\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7613 - tp: 20516.0000 - fp: 158528.0000 - tn: 66527.0000 - fn: 5303.0000 - accuracy: 0.3470 - precision: 0.1146 - recall: 0.7946 - auc: 0.5479 - val_loss: 0.6064 - val_tp: 3389.0000 - val_fp: 23526.0000 - val_tn: 8744.0000 - val_fn: 259.0000 - val_accuracy: 0.3378 - val_precision: 0.1259 - val_recall: 0.9290 - val_auc: 0.6051\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7207 - tp: 16884.0000 - fp: 132673.0000 - tn: 92382.0000 - fn: 8935.0000 - accuracy: 0.4355 - precision: 0.1129 - recall: 0.6539 - auc: 0.5449 - val_loss: 0.7134 - val_tp: 3437.0000 - val_fp: 24615.0000 - val_tn: 7655.0000 - val_fn: 211.0000 - val_accuracy: 0.3088 - val_precision: 0.1225 - val_recall: 0.9422 - val_auc: 0.5907\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 3.1313 - tp: 16970.0000 - fp: 134933.0000 - tn: 90122.0000 - fn: 8849.0000 - accuracy: 0.4269 - precision: 0.1117 - recall: 0.6573 - auc: 0.5379 - val_loss: 1.1367 - val_tp: 57.0000 - val_fp: 828.0000 - val_tn: 31442.0000 - val_fn: 3591.0000 - val_accuracy: 0.8770 - val_precision: 0.0644 - val_recall: 0.0156 - val_auc: 0.5792\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 21.8401 - tp: 20059.0000 - fp: 134918.0000 - tn: 122407.0000 - fn: 9408.0000 - accuracy: 0.4968 - precision: 0.1294 - recall: 0.6807 - auc: 0.5839 - val_loss: 0.6526 - val_tp: 3262.0000 - val_fp: 20560.0000 - val_tn: 11710.0000 - val_fn: 386.0000 - val_accuracy: 0.4168 - val_precision: 0.1369 - val_recall: 0.8942 - val_auc: 0.6065\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.8449 - tp: 23880.0000 - fp: 167385.0000 - tn: 57670.0000 - fn: 1939.0000 - accuracy: 0.3251 - precision: 0.1249 - recall: 0.9249 - auc: 0.5829 - val_loss: 0.6764 - val_tp: 3425.0000 - val_fp: 22506.0000 - val_tn: 9764.0000 - val_fn: 223.0000 - val_accuracy: 0.3672 - val_precision: 0.1321 - val_recall: 0.9389 - val_auc: 0.6101\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7754 - tp: 20389.0000 - fp: 150262.0000 - tn: 74793.0000 - fn: 5430.0000 - accuracy: 0.3794 - precision: 0.1195 - recall: 0.7897 - auc: 0.5688 - val_loss: 0.6463 - val_tp: 3397.0000 - val_fp: 22752.0000 - val_tn: 9518.0000 - val_fn: 251.0000 - val_accuracy: 0.3596 - val_precision: 0.1299 - val_recall: 0.9312 - val_auc: 0.6217\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.7021 - tp: 22818.0000 - fp: 170564.0000 - tn: 54491.0000 - fn: 3001.0000 - accuracy: 0.3082 - precision: 0.1180 - recall: 0.8838 - auc: 0.5670 - val_loss: 0.6292 - val_tp: 3359.0000 - val_fp: 23842.0000 - val_tn: 8428.0000 - val_fn: 289.0000 - val_accuracy: 0.3282 - val_precision: 0.1235 - val_recall: 0.9208 - val_auc: 0.5905\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.6912 - tp: 20434.0000 - fp: 155178.0000 - tn: 69877.0000 - fn: 5385.0000 - accuracy: 0.3600 - precision: 0.1164 - recall: 0.7914 - auc: 0.5599 - val_loss: 0.5462 - val_tp: 9.0000 - val_fp: 159.0000 - val_tn: 32111.0000 - val_fn: 3639.0000 - val_accuracy: 0.8943 - val_precision: 0.0536 - val_recall: 0.0025 - val_auc: 0.6112\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6832 - tp: 21710.0000 - fp: 163792.0000 - tn: 61263.0000 - fn: 4109.0000 - accuracy: 0.3307 - precision: 0.1170 - recall: 0.8409 - auc: 0.5651 - val_loss: 0.6287 - val_tp: 3459.0000 - val_fp: 23994.0000 - val_tn: 8276.0000 - val_fn: 189.0000 - val_accuracy: 0.3267 - val_precision: 0.1260 - val_recall: 0.9482 - val_auc: 0.6045\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6947 - tp: 20191.0000 - fp: 153498.0000 - tn: 71557.0000 - fn: 5628.0000 - accuracy: 0.3657 - precision: 0.1162 - recall: 0.7820 - auc: 0.5624 - val_loss: 0.6469 - val_tp: 3391.0000 - val_fp: 23180.0000 - val_tn: 9090.0000 - val_fn: 257.0000 - val_accuracy: 0.3475 - val_precision: 0.1276 - val_recall: 0.9296 - val_auc: 0.6119\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7065 - tp: 18106.0000 - fp: 138178.0000 - tn: 86877.0000 - fn: 7713.0000 - accuracy: 0.4185 - precision: 0.1159 - recall: 0.7013 - auc: 0.5588 - val_loss: 0.6682 - val_tp: 3446.0000 - val_fp: 24343.0000 - val_tn: 7927.0000 - val_fn: 202.0000 - val_accuracy: 0.3166 - val_precision: 0.1240 - val_recall: 0.9446 - val_auc: 0.5958\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7011 - tp: 18563.0000 - fp: 145443.0000 - tn: 79612.0000 - fn: 7256.0000 - accuracy: 0.3913 - precision: 0.1132 - recall: 0.7190 - auc: 0.5483 - val_loss: 0.5445 - val_tp: 63.0000 - val_fp: 1243.0000 - val_tn: 31027.0000 - val_fn: 3585.0000 - val_accuracy: 0.8656 - val_precision: 0.0482 - val_recall: 0.0173 - val_auc: 0.5593\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 1.3192 - tp: 15312.0000 - fp: 121908.0000 - tn: 103147.0000 - fn: 10507.0000 - accuracy: 0.4722 - precision: 0.1116 - recall: 0.5931 - auc: 0.5428 - val_loss: 1.0477 - val_tp: 3365.0000 - val_fp: 24151.0000 - val_tn: 8119.0000 - val_fn: 283.0000 - val_accuracy: 0.3197 - val_precision: 0.1223 - val_recall: 0.9224 - val_auc: 0.5905\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 10ms/step - loss: 0.7980 - tp: 15172.0000 - fp: 121029.0000 - tn: 104026.0000 - fn: 10647.0000 - accuracy: 0.4751 - precision: 0.1114 - recall: 0.5876 - auc: 0.5407 - val_loss: 0.8111 - val_tp: 3575.0000 - val_fp: 29016.0000 - val_tn: 3254.0000 - val_fn: 73.0000 - val_accuracy: 0.1901 - val_precision: 0.1097 - val_recall: 0.9800 - val_auc: 0.5698\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7401 - tp: 15597.0000 - fp: 124376.0000 - tn: 100679.0000 - fn: 10222.0000 - accuracy: 0.4635 - precision: 0.1114 - recall: 0.6041 - auc: 0.5387 - val_loss: 0.5566 - val_tp: 22.0000 - val_fp: 274.0000 - val_tn: 31996.0000 - val_fn: 3626.0000 - val_accuracy: 0.8914 - val_precision: 0.0743 - val_recall: 0.0060 - val_auc: 0.5851\n",
      "Epoch 13/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7341 - tp: 15411.0000 - fp: 125555.0000 - tn: 99500.0000 - fn: 10408.0000 - accuracy: 0.4580 - precision: 0.1093 - recall: 0.5969 - auc: 0.5322 - val_loss: 0.7197 - val_tp: 3551.0000 - val_fp: 27981.0000 - val_tn: 4289.0000 - val_fn: 97.0000 - val_accuracy: 0.2183 - val_precision: 0.1126 - val_recall: 0.9734 - val_auc: 0.5496\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 24.8175 - tp: 23242.0000 - fp: 162359.0000 - tn: 94966.0000 - fn: 6225.0000 - accuracy: 0.4122 - precision: 0.1252 - recall: 0.7887 - auc: 0.5738 - val_loss: 0.6924 - val_tp: 3168.0000 - val_fp: 18905.0000 - val_tn: 13365.0000 - val_fn: 480.0000 - val_accuracy: 0.4603 - val_precision: 0.1435 - val_recall: 0.8684 - val_auc: 0.6396\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.9003 - tp: 21261.0000 - fp: 154015.0000 - tn: 71040.0000 - fn: 4558.0000 - accuracy: 0.3679 - precision: 0.1213 - recall: 0.8235 - auc: 0.5726 - val_loss: 0.7791 - val_tp: 3413.0000 - val_fp: 24834.0000 - val_tn: 7436.0000 - val_fn: 235.0000 - val_accuracy: 0.3020 - val_precision: 0.1208 - val_recall: 0.9356 - val_auc: 0.5395\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7761 - tp: 19383.0000 - fp: 146279.0000 - tn: 78776.0000 - fn: 6436.0000 - accuracy: 0.3913 - precision: 0.1170 - recall: 0.7507 - auc: 0.5615 - val_loss: 0.6847 - val_tp: 3471.0000 - val_fp: 24846.0000 - val_tn: 7424.0000 - val_fn: 177.0000 - val_accuracy: 0.3033 - val_precision: 0.1226 - val_recall: 0.9515 - val_auc: 0.5996\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7163 - tp: 19682.0000 - fp: 153059.0000 - tn: 71996.0000 - fn: 6137.0000 - accuracy: 0.3654 - precision: 0.1139 - recall: 0.7623 - auc: 0.5494 - val_loss: 0.6208 - val_tp: 3485.0000 - val_fp: 25005.0000 - val_tn: 7265.0000 - val_fn: 163.0000 - val_accuracy: 0.2993 - val_precision: 0.1223 - val_recall: 0.9553 - val_auc: 0.5921\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.6900 - tp: 20321.0000 - fp: 156093.0000 - tn: 68962.0000 - fn: 5498.0000 - accuracy: 0.3559 - precision: 0.1152 - recall: 0.7871 - auc: 0.5578 - val_loss: 0.5719 - val_tp: 50.0000 - val_fp: 376.0000 - val_tn: 31894.0000 - val_fn: 3598.0000 - val_accuracy: 0.8894 - val_precision: 0.1174 - val_recall: 0.0137 - val_auc: 0.5913\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7020 - tp: 17607.0000 - fp: 137648.0000 - tn: 87407.0000 - fn: 8212.0000 - accuracy: 0.4186 - precision: 0.1134 - recall: 0.6819 - auc: 0.5493 - val_loss: 0.5338 - val_tp: 0.0000e+00 - val_fp: 18.0000 - val_tn: 32252.0000 - val_fn: 3648.0000 - val_accuracy: 0.8979 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5873\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7079 - tp: 17228.0000 - fp: 136162.0000 - tn: 88893.0000 - fn: 8591.0000 - accuracy: 0.4230 - precision: 0.1123 - recall: 0.6673 - auc: 0.5463 - val_loss: 0.7221 - val_tp: 3534.0000 - val_fp: 25776.0000 - val_tn: 6494.0000 - val_fn: 114.0000 - val_accuracy: 0.2792 - val_precision: 0.1206 - val_recall: 0.9688 - val_auc: 0.5851\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7032 - tp: 16916.0000 - fp: 135237.0000 - tn: 89818.0000 - fn: 8903.0000 - accuracy: 0.4254 - precision: 0.1112 - recall: 0.6552 - auc: 0.5402 - val_loss: 0.5802 - val_tp: 113.0000 - val_fp: 1374.0000 - val_tn: 30896.0000 - val_fn: 3535.0000 - val_accuracy: 0.8633 - val_precision: 0.0760 - val_recall: 0.0310 - val_auc: 0.5615\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7145 - tp: 16127.0000 - fp: 129381.0000 - tn: 95674.0000 - fn: 9692.0000 - accuracy: 0.4456 - precision: 0.1108 - recall: 0.6246 - auc: 0.5371 - val_loss: 0.7417 - val_tp: 3495.0000 - val_fp: 26428.0000 - val_tn: 5842.0000 - val_fn: 153.0000 - val_accuracy: 0.2600 - val_precision: 0.1168 - val_recall: 0.9581 - val_auc: 0.5702\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7383 - tp: 16967.0000 - fp: 137333.0000 - tn: 87722.0000 - fn: 8852.0000 - accuracy: 0.4173 - precision: 0.1100 - recall: 0.6572 - auc: 0.5348 - val_loss: 0.7179 - val_tp: 3541.0000 - val_fp: 28193.0000 - val_tn: 4077.0000 - val_fn: 107.0000 - val_accuracy: 0.2121 - val_precision: 0.1116 - val_recall: 0.9707 - val_auc: 0.5379\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7218 - tp: 17964.0000 - fp: 146278.0000 - tn: 78777.0000 - fn: 7855.0000 - accuracy: 0.3856 - precision: 0.1094 - recall: 0.6958 - auc: 0.5313 - val_loss: 0.7659 - val_tp: 3576.0000 - val_fp: 28352.0000 - val_tn: 3918.0000 - val_fn: 72.0000 - val_accuracy: 0.2086 - val_precision: 0.1120 - val_recall: 0.9803 - val_auc: 0.5574\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 2s 15ms/step - loss: 32.5758 - tp: 23644.0000 - fp: 164749.0000 - tn: 92576.0000 - fn: 5823.0000 - accuracy: 0.4052 - precision: 0.1255 - recall: 0.8024 - auc: 0.5770 - val_loss: 1.1271 - val_tp: 3203.0000 - val_fp: 19126.0000 - val_tn: 13144.0000 - val_fn: 445.0000 - val_accuracy: 0.4551 - val_precision: 0.1434 - val_recall: 0.8780 - val_auc: 0.6453\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.0748 - tp: 19970.0000 - fp: 145966.0000 - tn: 79089.0000 - fn: 5849.0000 - accuracy: 0.3949 - precision: 0.1203 - recall: 0.7735 - auc: 0.5676 - val_loss: 0.7235 - val_tp: 3490.0000 - val_fp: 24953.0000 - val_tn: 7317.0000 - val_fn: 158.0000 - val_accuracy: 0.3009 - val_precision: 0.1227 - val_recall: 0.9567 - val_auc: 0.5766\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.8897 - tp: 17565.0000 - fp: 136157.0000 - tn: 88898.0000 - fn: 8254.0000 - accuracy: 0.4244 - precision: 0.1143 - recall: 0.6803 - auc: 0.5512 - val_loss: 0.7215 - val_tp: 3554.0000 - val_fp: 26856.0000 - val_tn: 5414.0000 - val_fn: 94.0000 - val_accuracy: 0.2497 - val_precision: 0.1169 - val_recall: 0.9742 - val_auc: 0.5577\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 9ms/step - loss: 0.7137 - tp: 18992.0000 - fp: 148710.0000 - tn: 76345.0000 - fn: 6827.0000 - accuracy: 0.3800 - precision: 0.1132 - recall: 0.7356 - auc: 0.5487 - val_loss: 0.6621 - val_tp: 3484.0000 - val_fp: 25957.0000 - val_tn: 6313.0000 - val_fn: 164.0000 - val_accuracy: 0.2728 - val_precision: 0.1183 - val_recall: 0.9550 - val_auc: 0.5731\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7607 - tp: 15543.0000 - fp: 127455.0000 - tn: 97600.0000 - fn: 10276.0000 - accuracy: 0.4510 - precision: 0.1087 - recall: 0.6020 - auc: 0.5299 - val_loss: 0.7853 - val_tp: 3545.0000 - val_fp: 28479.0000 - val_tn: 3791.0000 - val_fn: 103.0000 - val_accuracy: 0.2042 - val_precision: 0.1107 - val_recall: 0.9718 - val_auc: 0.5475\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7054 - tp: 16218.0000 - fp: 134341.0000 - tn: 90714.0000 - fn: 9601.0000 - accuracy: 0.4262 - precision: 0.1077 - recall: 0.6281 - auc: 0.5238 - val_loss: 0.5898 - val_tp: 1.0000 - val_fp: 54.0000 - val_tn: 32216.0000 - val_fn: 3647.0000 - val_accuracy: 0.8970 - val_precision: 0.0182 - val_recall: 2.7412e-04 - val_auc: 0.5530\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7211 - tp: 16343.0000 - fp: 133642.0000 - tn: 91413.0000 - fn: 9476.0000 - accuracy: 0.4295 - precision: 0.1090 - recall: 0.6330 - auc: 0.5286 - val_loss: 0.7061 - val_tp: 3562.0000 - val_fp: 28717.0000 - val_tn: 3553.0000 - val_fn: 86.0000 - val_accuracy: 0.1981 - val_precision: 0.1104 - val_recall: 0.9764 - val_auc: 0.5448\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7379 - tp: 16215.0000 - fp: 136273.0000 - tn: 88782.0000 - fn: 9604.0000 - accuracy: 0.4185 - precision: 0.1063 - recall: 0.6280 - auc: 0.5199 - val_loss: 0.4950 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 32265.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5410\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.8048 - tp: 13900.0000 - fp: 118154.0000 - tn: 106901.0000 - fn: 11919.0000 - accuracy: 0.4815 - precision: 0.1053 - recall: 0.5384 - auc: 0.5094 - val_loss: 0.8234 - val_tp: 3634.0000 - val_fp: 31317.0000 - val_tn: 953.0000 - val_fn: 14.0000 - val_accuracy: 0.1277 - val_precision: 0.1040 - val_recall: 0.9962 - val_auc: 0.5051\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7041 - tp: 13910.0000 - fp: 118342.0000 - tn: 106713.0000 - fn: 11909.0000 - accuracy: 0.4808 - precision: 0.1052 - recall: 0.5388 - auc: 0.5121 - val_loss: 0.7206 - val_tp: 3596.0000 - val_fp: 28611.0000 - val_tn: 3659.0000 - val_fn: 52.0000 - val_accuracy: 0.2020 - val_precision: 0.1117 - val_recall: 0.9857 - val_auc: 0.5497\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 1.1528 - tp: 15450.0000 - fp: 127727.0000 - tn: 97328.0000 - fn: 10369.0000 - accuracy: 0.4495 - precision: 0.1079 - recall: 0.5984 - auc: 0.5222 - val_loss: 0.6121 - val_tp: 22.0000 - val_fp: 535.0000 - val_tn: 31735.0000 - val_fn: 3626.0000 - val_accuracy: 0.8842 - val_precision: 0.0395 - val_recall: 0.0060 - val_auc: 0.5467\n",
      "Epoch 1/100\n",
      "126/126 [==============================] - 2s 17ms/step - loss: 35.4296 - tp: 19629.0000 - fp: 135294.0000 - tn: 122031.0000 - fn: 9838.0000 - accuracy: 0.4939 - precision: 0.1267 - recall: 0.6661 - auc: 0.5769 - val_loss: 1.4913 - val_tp: 3124.0000 - val_fp: 18181.0000 - val_tn: 14089.0000 - val_fn: 524.0000 - val_accuracy: 0.4792 - val_precision: 0.1466 - val_recall: 0.8564 - val_auc: 0.6515\n",
      "Epoch 2/100\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 1.2971 - tp: 18857.0000 - fp: 140262.0000 - tn: 84793.0000 - fn: 6962.0000 - accuracy: 0.4132 - precision: 0.1185 - recall: 0.7304 - auc: 0.5663 - val_loss: 0.7340 - val_tp: 3450.0000 - val_fp: 23854.0000 - val_tn: 8416.0000 - val_fn: 198.0000 - val_accuracy: 0.3304 - val_precision: 0.1264 - val_recall: 0.9457 - val_auc: 0.6068\n",
      "Epoch 3/100\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.8468 - tp: 18475.0000 - fp: 143575.0000 - tn: 81480.0000 - fn: 7344.0000 - accuracy: 0.3984 - precision: 0.1140 - recall: 0.7156 - auc: 0.5510 - val_loss: 0.6241 - val_tp: 6.0000 - val_fp: 43.0000 - val_tn: 32227.0000 - val_fn: 3642.0000 - val_accuracy: 0.8974 - val_precision: 0.1224 - val_recall: 0.0016 - val_auc: 0.5909\n",
      "Epoch 4/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7515 - tp: 17865.0000 - fp: 143507.0000 - tn: 81548.0000 - fn: 7954.0000 - accuracy: 0.3963 - precision: 0.1107 - recall: 0.6919 - auc: 0.5384 - val_loss: 0.5041 - val_tp: 4.0000 - val_fp: 174.0000 - val_tn: 32096.0000 - val_fn: 3644.0000 - val_accuracy: 0.8937 - val_precision: 0.0225 - val_recall: 0.0011 - val_auc: 0.5722\n",
      "Epoch 5/100\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7176 - tp: 17463.0000 - fp: 140546.0000 - tn: 84509.0000 - fn: 8356.0000 - accuracy: 0.4065 - precision: 0.1105 - recall: 0.6764 - auc: 0.5367 - val_loss: 0.6459 - val_tp: 29.0000 - val_fp: 1096.0000 - val_tn: 31174.0000 - val_fn: 3619.0000 - val_accuracy: 0.8687 - val_precision: 0.0258 - val_recall: 0.0079 - val_auc: 0.5540\n",
      "Epoch 6/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7174 - tp: 15118.0000 - fp: 122845.0000 - tn: 102210.0000 - fn: 10701.0000 - accuracy: 0.4677 - precision: 0.1096 - recall: 0.5855 - auc: 0.5332 - val_loss: 0.5921 - val_tp: 2.0000 - val_fp: 91.0000 - val_tn: 32179.0000 - val_fn: 3646.0000 - val_accuracy: 0.8960 - val_precision: 0.0215 - val_recall: 5.4825e-04 - val_auc: 0.5643\n",
      "Epoch 7/100\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7408 - tp: 17013.0000 - fp: 138621.0000 - tn: 86434.0000 - fn: 8806.0000 - accuracy: 0.4123 - precision: 0.1093 - recall: 0.6589 - auc: 0.5311 - val_loss: 0.6330 - val_tp: 11.0000 - val_fp: 222.0000 - val_tn: 32048.0000 - val_fn: 3637.0000 - val_accuracy: 0.8926 - val_precision: 0.0472 - val_recall: 0.0030 - val_auc: 0.5478\n",
      "Epoch 8/100\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7133 - tp: 14240.0000 - fp: 119462.0000 - tn: 105593.0000 - fn: 11579.0000 - accuracy: 0.4777 - precision: 0.1065 - recall: 0.5515 - auc: 0.5175 - val_loss: 0.6554 - val_tp: 3558.0000 - val_fp: 27790.0000 - val_tn: 4480.0000 - val_fn: 90.0000 - val_accuracy: 0.2238 - val_precision: 0.1135 - val_recall: 0.9753 - val_auc: 0.5575\n",
      "Epoch 9/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 0.7416 - tp: 15469.0000 - fp: 130445.0000 - tn: 94610.0000 - fn: 10350.0000 - accuracy: 0.4388 - precision: 0.1060 - recall: 0.5991 - auc: 0.5149 - val_loss: 0.6552 - val_tp: 3537.0000 - val_fp: 28010.0000 - val_tn: 4260.0000 - val_fn: 111.0000 - val_accuracy: 0.2171 - val_precision: 0.1121 - val_recall: 0.9696 - val_auc: 0.5518\n",
      "Epoch 10/100\n",
      "126/126 [==============================] - 1s 7ms/step - loss: 0.7556 - tp: 16909.0000 - fp: 139239.0000 - tn: 85816.0000 - fn: 8910.0000 - accuracy: 0.4095 - precision: 0.1083 - recall: 0.6549 - auc: 0.5271 - val_loss: 1.2738 - val_tp: 3364.0000 - val_fp: 23910.0000 - val_tn: 8360.0000 - val_fn: 284.0000 - val_accuracy: 0.3264 - val_precision: 0.1233 - val_recall: 0.9221 - val_auc: 0.5906\n",
      "Epoch 11/100\n",
      "126/126 [==============================] - 1s 8ms/step - loss: 2.5994 - tp: 16050.0000 - fp: 131930.0000 - tn: 93125.0000 - fn: 9769.0000 - accuracy: 0.4352 - precision: 0.1085 - recall: 0.6216 - auc: 0.5271 - val_loss: 0.8833 - val_tp: 0.0000e+00 - val_fp: 6.0000 - val_tn: 32264.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5703\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 64ms/step - loss: 1.4328 - tp: 285.0000 - fp: 1654.0000 - tn: 255671.0000 - fn: 29182.0000 - accuracy: 0.8925 - precision: 0.1470 - recall: 0.0097 - auc: 0.5605 - val_loss: 0.3435 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5944\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4379 - tp: 251.0000 - fp: 1629.0000 - tn: 223426.0000 - fn: 25568.0000 - accuracy: 0.8916 - precision: 0.1335 - recall: 0.0097 - auc: 0.5637 - val_loss: 0.3434 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5946\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4356 - tp: 283.0000 - fp: 1698.0000 - tn: 223357.0000 - fn: 25536.0000 - accuracy: 0.8914 - precision: 0.1429 - recall: 0.0110 - auc: 0.5639 - val_loss: 0.3434 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5947\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4367 - tp: 265.0000 - fp: 1697.0000 - tn: 223358.0000 - fn: 25554.0000 - accuracy: 0.8914 - precision: 0.1351 - recall: 0.0103 - auc: 0.5635 - val_loss: 0.3433 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5949\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 1.4335 - tp: 285.0000 - fp: 1630.0000 - tn: 223425.0000 - fn: 25534.0000 - accuracy: 0.8917 - precision: 0.1488 - recall: 0.0110 - auc: 0.5669 - val_loss: 0.3433 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5951\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 52ms/step - loss: 1.4321 - tp: 284.0000 - fp: 1691.0000 - tn: 223364.0000 - fn: 25535.0000 - accuracy: 0.8915 - precision: 0.1438 - recall: 0.0110 - auc: 0.5661 - val_loss: 0.3432 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5954\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 1.4321 - tp: 289.0000 - fp: 1632.0000 - tn: 223423.0000 - fn: 25530.0000 - accuracy: 0.8917 - precision: 0.1504 - recall: 0.0112 - auc: 0.5656 - val_loss: 0.3432 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5956\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4322 - tp: 264.0000 - fp: 1699.0000 - tn: 223356.0000 - fn: 25555.0000 - accuracy: 0.8914 - precision: 0.1345 - recall: 0.0102 - auc: 0.5654 - val_loss: 0.3431 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5958\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4308 - tp: 306.0000 - fp: 1671.0000 - tn: 223384.0000 - fn: 25513.0000 - accuracy: 0.8916 - precision: 0.1548 - recall: 0.0119 - auc: 0.5651 - val_loss: 0.3431 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5959\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4340 - tp: 260.0000 - fp: 1750.0000 - tn: 223305.0000 - fn: 25559.0000 - accuracy: 0.8911 - precision: 0.1294 - recall: 0.0101 - auc: 0.5643 - val_loss: 0.3430 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5960\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4272 - tp: 270.0000 - fp: 1737.0000 - tn: 223318.0000 - fn: 25549.0000 - accuracy: 0.8912 - precision: 0.1345 - recall: 0.0105 - auc: 0.5668 - val_loss: 0.3430 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5962\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4285 - tp: 299.0000 - fp: 1738.0000 - tn: 223317.0000 - fn: 25520.0000 - accuracy: 0.8913 - precision: 0.1468 - recall: 0.0116 - auc: 0.5665 - val_loss: 0.3429 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5964\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4262 - tp: 299.0000 - fp: 1725.0000 - tn: 223330.0000 - fn: 25520.0000 - accuracy: 0.8914 - precision: 0.1477 - recall: 0.0116 - auc: 0.5680 - val_loss: 0.3429 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5965\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 1.4257 - tp: 291.0000 - fp: 1790.0000 - tn: 223265.0000 - fn: 25528.0000 - accuracy: 0.8911 - precision: 0.1398 - recall: 0.0113 - auc: 0.5691 - val_loss: 0.3428 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5967\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.4264 - tp: 266.0000 - fp: 1757.0000 - tn: 223298.0000 - fn: 25553.0000 - accuracy: 0.8911 - precision: 0.1315 - recall: 0.0103 - auc: 0.5682 - val_loss: 0.3428 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5968\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.4304 - tp: 268.0000 - fp: 1732.0000 - tn: 223323.0000 - fn: 25551.0000 - accuracy: 0.8912 - precision: 0.1340 - recall: 0.0104 - auc: 0.5648 - val_loss: 0.3427 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5970\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 1.4255 - tp: 299.0000 - fp: 1688.0000 - tn: 223367.0000 - fn: 25520.0000 - accuracy: 0.8915 - precision: 0.1505 - recall: 0.0116 - auc: 0.5678 - val_loss: 0.3427 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5971\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 1.4225 - tp: 277.0000 - fp: 1752.0000 - tn: 223303.0000 - fn: 25542.0000 - accuracy: 0.8912 - precision: 0.1365 - recall: 0.0107 - auc: 0.5689 - val_loss: 0.3427 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5972\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4247 - tp: 306.0000 - fp: 1755.0000 - tn: 223300.0000 - fn: 25513.0000 - accuracy: 0.8913 - precision: 0.1485 - recall: 0.0119 - auc: 0.5685 - val_loss: 0.3426 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5973\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4240 - tp: 283.0000 - fp: 1748.0000 - tn: 223307.0000 - fn: 25536.0000 - accuracy: 0.8912 - precision: 0.1393 - recall: 0.0110 - auc: 0.5693 - val_loss: 0.3426 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5975\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4230 - tp: 310.0000 - fp: 1798.0000 - tn: 223257.0000 - fn: 25509.0000 - accuracy: 0.8912 - precision: 0.1471 - recall: 0.0120 - auc: 0.5686 - val_loss: 0.3425 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5977\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4197 - tp: 325.0000 - fp: 1817.0000 - tn: 223238.0000 - fn: 25494.0000 - accuracy: 0.8911 - precision: 0.1517 - recall: 0.0126 - auc: 0.5686 - val_loss: 0.3425 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5978\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4212 - tp: 294.0000 - fp: 1789.0000 - tn: 223266.0000 - fn: 25525.0000 - accuracy: 0.8911 - precision: 0.1411 - recall: 0.0114 - auc: 0.5671 - val_loss: 0.3424 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5981\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4214 - tp: 295.0000 - fp: 1823.0000 - tn: 223232.0000 - fn: 25524.0000 - accuracy: 0.8910 - precision: 0.1393 - recall: 0.0114 - auc: 0.5685 - val_loss: 0.3424 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5982\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4257 - tp: 286.0000 - fp: 1811.0000 - tn: 223244.0000 - fn: 25533.0000 - accuracy: 0.8910 - precision: 0.1364 - recall: 0.0111 - auc: 0.5670 - val_loss: 0.3423 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4220 - tp: 313.0000 - fp: 1747.0000 - tn: 223308.0000 - fn: 25506.0000 - accuracy: 0.8914 - precision: 0.1519 - recall: 0.0121 - auc: 0.5679 - val_loss: 0.3423 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5983\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.4213 - tp: 314.0000 - fp: 1844.0000 - tn: 223211.0000 - fn: 25505.0000 - accuracy: 0.8910 - precision: 0.1455 - recall: 0.0122 - auc: 0.5675 - val_loss: 0.3422 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5985\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4157 - tp: 297.0000 - fp: 1771.0000 - tn: 223284.0000 - fn: 25522.0000 - accuracy: 0.8912 - precision: 0.1436 - recall: 0.0115 - auc: 0.5681 - val_loss: 0.3422 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5988\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 1s 32ms/step - loss: 1.4215 - tp: 320.0000 - fp: 1840.0000 - tn: 223215.0000 - fn: 25499.0000 - accuracy: 0.8910 - precision: 0.1481 - recall: 0.0124 - auc: 0.5694 - val_loss: 0.3421 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5989\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.4146 - tp: 285.0000 - fp: 1802.0000 - tn: 223253.0000 - fn: 25534.0000 - accuracy: 0.8910 - precision: 0.1366 - recall: 0.0110 - auc: 0.5710 - val_loss: 0.3421 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5990\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.4179 - tp: 310.0000 - fp: 1834.0000 - tn: 223221.0000 - fn: 25509.0000 - accuracy: 0.8910 - precision: 0.1446 - recall: 0.0120 - auc: 0.5694 - val_loss: 0.3421 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5992\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.4151 - tp: 296.0000 - fp: 1816.0000 - tn: 223239.0000 - fn: 25523.0000 - accuracy: 0.8910 - precision: 0.1402 - recall: 0.0115 - auc: 0.5701 - val_loss: 0.3420 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5993\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.4135 - tp: 320.0000 - fp: 1885.0000 - tn: 223170.0000 - fn: 25499.0000 - accuracy: 0.8908 - precision: 0.1451 - recall: 0.0124 - auc: 0.5702 - val_loss: 0.3420 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5995\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4156 - tp: 342.0000 - fp: 1796.0000 - tn: 223259.0000 - fn: 25477.0000 - accuracy: 0.8913 - precision: 0.1600 - recall: 0.0132 - auc: 0.5696 - val_loss: 0.3419 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5996\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.4164 - tp: 303.0000 - fp: 1844.0000 - tn: 223211.0000 - fn: 25516.0000 - accuracy: 0.8909 - precision: 0.1411 - recall: 0.0117 - auc: 0.5691 - val_loss: 0.3419 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5998\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.4173 - tp: 294.0000 - fp: 1771.0000 - tn: 223284.0000 - fn: 25525.0000 - accuracy: 0.8912 - precision: 0.1424 - recall: 0.0114 - auc: 0.5691 - val_loss: 0.3418 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6000\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.4170 - tp: 321.0000 - fp: 1923.0000 - tn: 223132.0000 - fn: 25498.0000 - accuracy: 0.8907 - precision: 0.1430 - recall: 0.0124 - auc: 0.5700 - val_loss: 0.3418 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6002\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4110 - tp: 318.0000 - fp: 1873.0000 - tn: 223182.0000 - fn: 25501.0000 - accuracy: 0.8909 - precision: 0.1451 - recall: 0.0123 - auc: 0.5717 - val_loss: 0.3418 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6003\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4112 - tp: 304.0000 - fp: 1937.0000 - tn: 223118.0000 - fn: 25515.0000 - accuracy: 0.8906 - precision: 0.1357 - recall: 0.0118 - auc: 0.5720 - val_loss: 0.3417 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6005\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4116 - tp: 318.0000 - fp: 1834.0000 - tn: 223221.0000 - fn: 25501.0000 - accuracy: 0.8910 - precision: 0.1478 - recall: 0.0123 - auc: 0.5700 - val_loss: 0.3417 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6005\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4107 - tp: 320.0000 - fp: 1855.0000 - tn: 223200.0000 - fn: 25499.0000 - accuracy: 0.8910 - precision: 0.1471 - recall: 0.0124 - auc: 0.5706 - val_loss: 0.3416 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6008\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 1.4119 - tp: 312.0000 - fp: 1920.0000 - tn: 223135.0000 - fn: 25507.0000 - accuracy: 0.8907 - precision: 0.1398 - recall: 0.0121 - auc: 0.5697 - val_loss: 0.3416 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6009\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 1.4152 - tp: 322.0000 - fp: 1891.0000 - tn: 223164.0000 - fn: 25497.0000 - accuracy: 0.8908 - precision: 0.1455 - recall: 0.0125 - auc: 0.5699 - val_loss: 0.3415 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6009\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.4088 - tp: 342.0000 - fp: 1962.0000 - tn: 223093.0000 - fn: 25477.0000 - accuracy: 0.8906 - precision: 0.1484 - recall: 0.0132 - auc: 0.5720 - val_loss: 0.3415 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6010\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.4103 - tp: 310.0000 - fp: 1900.0000 - tn: 223155.0000 - fn: 25509.0000 - accuracy: 0.8907 - precision: 0.1403 - recall: 0.0120 - auc: 0.5709 - val_loss: 0.3415 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 1.4084 - tp: 362.0000 - fp: 1888.0000 - tn: 223167.0000 - fn: 25457.0000 - accuracy: 0.8910 - precision: 0.1609 - recall: 0.0140 - auc: 0.5707 - val_loss: 0.3414 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6011\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.4041 - tp: 348.0000 - fp: 2025.0000 - tn: 223030.0000 - fn: 25471.0000 - accuracy: 0.8904 - precision: 0.1466 - recall: 0.0135 - auc: 0.5729 - val_loss: 0.3414 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6013\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.4086 - tp: 370.0000 - fp: 1999.0000 - tn: 223056.0000 - fn: 25449.0000 - accuracy: 0.8906 - precision: 0.1562 - recall: 0.0143 - auc: 0.5701 - val_loss: 0.3413 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6015\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4079 - tp: 347.0000 - fp: 1939.0000 - tn: 223116.0000 - fn: 25472.0000 - accuracy: 0.8907 - precision: 0.1518 - recall: 0.0134 - auc: 0.5727 - val_loss: 0.3413 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6016\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4068 - tp: 315.0000 - fp: 2008.0000 - tn: 223047.0000 - fn: 25504.0000 - accuracy: 0.8903 - precision: 0.1356 - recall: 0.0122 - auc: 0.5721 - val_loss: 0.3413 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6018\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.4089 - tp: 332.0000 - fp: 1999.0000 - tn: 223056.0000 - fn: 25487.0000 - accuracy: 0.8904 - precision: 0.1424 - recall: 0.0129 - auc: 0.5708 - val_loss: 0.3412 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6020\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.4037 - tp: 355.0000 - fp: 2055.0000 - tn: 223000.0000 - fn: 25464.0000 - accuracy: 0.8903 - precision: 0.1473 - recall: 0.0137 - auc: 0.5716 - val_loss: 0.3412 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6022\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4010 - tp: 334.0000 - fp: 2018.0000 - tn: 223037.0000 - fn: 25485.0000 - accuracy: 0.8904 - precision: 0.1420 - recall: 0.0129 - auc: 0.5741 - val_loss: 0.3411 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6022\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.4031 - tp: 352.0000 - fp: 1998.0000 - tn: 223057.0000 - fn: 25467.0000 - accuracy: 0.8905 - precision: 0.1498 - recall: 0.0136 - auc: 0.5721 - val_loss: 0.3411 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6024\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.4033 - tp: 349.0000 - fp: 1993.0000 - tn: 223062.0000 - fn: 25470.0000 - accuracy: 0.8905 - precision: 0.1490 - recall: 0.0135 - auc: 0.5725 - val_loss: 0.3411 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6025\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4051 - tp: 349.0000 - fp: 1968.0000 - tn: 223087.0000 - fn: 25470.0000 - accuracy: 0.8906 - precision: 0.1506 - recall: 0.0135 - auc: 0.5722 - val_loss: 0.3410 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6026\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4022 - tp: 351.0000 - fp: 2080.0000 - tn: 222975.0000 - fn: 25468.0000 - accuracy: 0.8902 - precision: 0.1444 - recall: 0.0136 - auc: 0.5734 - val_loss: 0.3410 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6028\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.4047 - tp: 339.0000 - fp: 2030.0000 - tn: 223025.0000 - fn: 25480.0000 - accuracy: 0.8903 - precision: 0.1431 - recall: 0.0131 - auc: 0.5716 - val_loss: 0.3409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6029\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3993 - tp: 358.0000 - fp: 2054.0000 - tn: 223001.0000 - fn: 25461.0000 - accuracy: 0.8903 - precision: 0.1484 - recall: 0.0139 - auc: 0.5733 - val_loss: 0.3409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6031\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3992 - tp: 364.0000 - fp: 2042.0000 - tn: 223013.0000 - fn: 25455.0000 - accuracy: 0.8904 - precision: 0.1513 - recall: 0.0141 - auc: 0.5754 - val_loss: 0.3409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6032\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3992 - tp: 369.0000 - fp: 2103.0000 - tn: 222952.0000 - fn: 25450.0000 - accuracy: 0.8902 - precision: 0.1493 - recall: 0.0143 - auc: 0.5731 - val_loss: 0.3408 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6034\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3980 - tp: 361.0000 - fp: 2118.0000 - tn: 222937.0000 - fn: 25458.0000 - accuracy: 0.8901 - precision: 0.1456 - recall: 0.0140 - auc: 0.5736 - val_loss: 0.3408 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6035\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.3993 - tp: 365.0000 - fp: 2027.0000 - tn: 223028.0000 - fn: 25454.0000 - accuracy: 0.8905 - precision: 0.1526 - recall: 0.0141 - auc: 0.5734 - val_loss: 0.3408 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6036\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.3978 - tp: 344.0000 - fp: 2127.0000 - tn: 222928.0000 - fn: 25475.0000 - accuracy: 0.8900 - precision: 0.1392 - recall: 0.0133 - auc: 0.5748 - val_loss: 0.3407 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6038\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.4053 - tp: 399.0000 - fp: 2110.0000 - tn: 222945.0000 - fn: 25420.0000 - accuracy: 0.8903 - precision: 0.1590 - recall: 0.0155 - auc: 0.5706 - val_loss: 0.3407 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3958 - tp: 378.0000 - fp: 2123.0000 - tn: 222932.0000 - fn: 25441.0000 - accuracy: 0.8901 - precision: 0.1511 - recall: 0.0146 - auc: 0.5743 - val_loss: 0.3406 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6040\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3958 - tp: 389.0000 - fp: 2177.0000 - tn: 222878.0000 - fn: 25430.0000 - accuracy: 0.8900 - precision: 0.1516 - recall: 0.0151 - auc: 0.5723 - val_loss: 0.3406 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6042\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3957 - tp: 343.0000 - fp: 2100.0000 - tn: 222955.0000 - fn: 25476.0000 - accuracy: 0.8901 - precision: 0.1404 - recall: 0.0133 - auc: 0.5742 - val_loss: 0.3406 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6043\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3972 - tp: 356.0000 - fp: 2114.0000 - tn: 222941.0000 - fn: 25463.0000 - accuracy: 0.8901 - precision: 0.1441 - recall: 0.0138 - auc: 0.5736 - val_loss: 0.3405 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6044\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3913 - tp: 386.0000 - fp: 2141.0000 - tn: 222914.0000 - fn: 25433.0000 - accuracy: 0.8901 - precision: 0.1528 - recall: 0.0150 - auc: 0.5761 - val_loss: 0.3405 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6045\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3961 - tp: 360.0000 - fp: 2173.0000 - tn: 222882.0000 - fn: 25459.0000 - accuracy: 0.8899 - precision: 0.1421 - recall: 0.0139 - auc: 0.5729 - val_loss: 0.3405 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6046\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3927 - tp: 381.0000 - fp: 2135.0000 - tn: 222920.0000 - fn: 25438.0000 - accuracy: 0.8901 - precision: 0.1514 - recall: 0.0148 - auc: 0.5750 - val_loss: 0.3404 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6047\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3940 - tp: 393.0000 - fp: 2151.0000 - tn: 222904.0000 - fn: 25426.0000 - accuracy: 0.8901 - precision: 0.1545 - recall: 0.0152 - auc: 0.5733 - val_loss: 0.3404 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6049\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3930 - tp: 394.0000 - fp: 2223.0000 - tn: 222832.0000 - fn: 25425.0000 - accuracy: 0.8898 - precision: 0.1506 - recall: 0.0153 - auc: 0.5752 - val_loss: 0.3404 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6050\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3936 - tp: 398.0000 - fp: 2183.0000 - tn: 222872.0000 - fn: 25421.0000 - accuracy: 0.8900 - precision: 0.1542 - recall: 0.0154 - auc: 0.5757 - val_loss: 0.3403 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6052\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.3889 - tp: 386.0000 - fp: 2204.0000 - tn: 222851.0000 - fn: 25433.0000 - accuracy: 0.8898 - precision: 0.1490 - recall: 0.0150 - auc: 0.5752 - val_loss: 0.3403 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6055\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3908 - tp: 403.0000 - fp: 2212.0000 - tn: 222843.0000 - fn: 25416.0000 - accuracy: 0.8899 - precision: 0.1541 - recall: 0.0156 - auc: 0.5750 - val_loss: 0.3403 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6055\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3925 - tp: 402.0000 - fp: 2211.0000 - tn: 222844.0000 - fn: 25417.0000 - accuracy: 0.8899 - precision: 0.1538 - recall: 0.0156 - auc: 0.5750 - val_loss: 0.3402 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6056\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.3879 - tp: 407.0000 - fp: 2213.0000 - tn: 222842.0000 - fn: 25412.0000 - accuracy: 0.8899 - precision: 0.1553 - recall: 0.0158 - auc: 0.5766 - val_loss: 0.3402 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6057\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3865 - tp: 390.0000 - fp: 2284.0000 - tn: 222771.0000 - fn: 25429.0000 - accuracy: 0.8895 - precision: 0.1458 - recall: 0.0151 - auc: 0.5777 - val_loss: 0.3402 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6058\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3886 - tp: 378.0000 - fp: 2231.0000 - tn: 222824.0000 - fn: 25441.0000 - accuracy: 0.8897 - precision: 0.1449 - recall: 0.0146 - auc: 0.5761 - val_loss: 0.3401 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6059\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3877 - tp: 412.0000 - fp: 2187.0000 - tn: 222868.0000 - fn: 25407.0000 - accuracy: 0.8900 - precision: 0.1585 - recall: 0.0160 - auc: 0.5744 - val_loss: 0.3401 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6060\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.3845 - tp: 358.0000 - fp: 2291.0000 - tn: 222764.0000 - fn: 25461.0000 - accuracy: 0.8894 - precision: 0.1351 - recall: 0.0139 - auc: 0.5778 - val_loss: 0.3401 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6062\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.3893 - tp: 391.0000 - fp: 2176.0000 - tn: 222879.0000 - fn: 25428.0000 - accuracy: 0.8900 - precision: 0.1523 - recall: 0.0151 - auc: 0.5748 - val_loss: 0.3400 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6064\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3881 - tp: 444.0000 - fp: 2290.0000 - tn: 222765.0000 - fn: 25375.0000 - accuracy: 0.8897 - precision: 0.1624 - recall: 0.0172 - auc: 0.5764 - val_loss: 0.3400 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.3856 - tp: 432.0000 - fp: 2331.0000 - tn: 222724.0000 - fn: 25387.0000 - accuracy: 0.8895 - precision: 0.1564 - recall: 0.0167 - auc: 0.5760 - val_loss: 0.3400 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6066\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3888 - tp: 432.0000 - fp: 2322.0000 - tn: 222733.0000 - fn: 25387.0000 - accuracy: 0.8896 - precision: 0.1569 - recall: 0.0167 - auc: 0.5758 - val_loss: 0.3399 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6066\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 1s 33ms/step - loss: 1.3851 - tp: 419.0000 - fp: 2315.0000 - tn: 222740.0000 - fn: 25400.0000 - accuracy: 0.8895 - precision: 0.1533 - recall: 0.0162 - auc: 0.5758 - val_loss: 0.3399 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6068\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 1.3796 - tp: 435.0000 - fp: 2314.0000 - tn: 222741.0000 - fn: 25384.0000 - accuracy: 0.8896 - precision: 0.1582 - recall: 0.0168 - auc: 0.5791 - val_loss: 0.3399 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6069\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.3875 - tp: 463.0000 - fp: 2383.0000 - tn: 222672.0000 - fn: 25356.0000 - accuracy: 0.8894 - precision: 0.1627 - recall: 0.0179 - auc: 0.5759 - val_loss: 0.3398 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6071\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.3835 - tp: 431.0000 - fp: 2334.0000 - tn: 222721.0000 - fn: 25388.0000 - accuracy: 0.8895 - precision: 0.1559 - recall: 0.0167 - auc: 0.5773 - val_loss: 0.3398 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6072\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3811 - tp: 415.0000 - fp: 2385.0000 - tn: 222670.0000 - fn: 25404.0000 - accuracy: 0.8892 - precision: 0.1482 - recall: 0.0161 - auc: 0.5771 - val_loss: 0.3398 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6072\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.3829 - tp: 408.0000 - fp: 2395.0000 - tn: 222660.0000 - fn: 25411.0000 - accuracy: 0.8892 - precision: 0.1456 - recall: 0.0158 - auc: 0.5762 - val_loss: 0.3397 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6072\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3775 - tp: 447.0000 - fp: 2422.0000 - tn: 222633.0000 - fn: 25372.0000 - accuracy: 0.8892 - precision: 0.1558 - recall: 0.0173 - auc: 0.5785 - val_loss: 0.3397 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6073\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3838 - tp: 416.0000 - fp: 2399.0000 - tn: 222656.0000 - fn: 25403.0000 - accuracy: 0.8892 - precision: 0.1478 - recall: 0.0161 - auc: 0.5778 - val_loss: 0.3397 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6074\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3786 - tp: 429.0000 - fp: 2454.0000 - tn: 222601.0000 - fn: 25390.0000 - accuracy: 0.8890 - precision: 0.1488 - recall: 0.0166 - auc: 0.5781 - val_loss: 0.3397 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6075\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3789 - tp: 422.0000 - fp: 2343.0000 - tn: 222712.0000 - fn: 25397.0000 - accuracy: 0.8894 - precision: 0.1526 - recall: 0.0163 - auc: 0.5771 - val_loss: 0.3396 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6077\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.3827 - tp: 447.0000 - fp: 2382.0000 - tn: 222673.0000 - fn: 25372.0000 - accuracy: 0.8894 - precision: 0.1580 - recall: 0.0173 - auc: 0.5757 - val_loss: 0.3396 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6078\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3812 - tp: 432.0000 - fp: 2452.0000 - tn: 222603.0000 - fn: 25387.0000 - accuracy: 0.8890 - precision: 0.1498 - recall: 0.0167 - auc: 0.5768 - val_loss: 0.3396 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6079\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3798 - tp: 458.0000 - fp: 2447.0000 - tn: 222608.0000 - fn: 25361.0000 - accuracy: 0.8892 - precision: 0.1577 - recall: 0.0177 - auc: 0.5767 - val_loss: 0.3395 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6080\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 76ms/step - loss: 1.4327 - tp: 311.0000 - fp: 1725.0000 - tn: 255600.0000 - fn: 29156.0000 - accuracy: 0.8923 - precision: 0.1528 - recall: 0.0106 - auc: 0.5710 - val_loss: 0.3430 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5960\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.4323 - tp: 258.0000 - fp: 1712.0000 - tn: 223343.0000 - fn: 25561.0000 - accuracy: 0.8913 - precision: 0.1310 - recall: 0.0100 - auc: 0.5649 - val_loss: 0.3425 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5975\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 1.4272 - tp: 312.0000 - fp: 1741.0000 - tn: 223314.0000 - fn: 25507.0000 - accuracy: 0.8914 - precision: 0.1520 - recall: 0.0121 - auc: 0.5658 - val_loss: 0.3421 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5991\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4151 - tp: 320.0000 - fp: 1968.0000 - tn: 223087.0000 - fn: 25499.0000 - accuracy: 0.8905 - precision: 0.1399 - recall: 0.0124 - auc: 0.5694 - val_loss: 0.3417 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6007\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.4143 - tp: 314.0000 - fp: 1926.0000 - tn: 223129.0000 - fn: 25505.0000 - accuracy: 0.8907 - precision: 0.1402 - recall: 0.0122 - auc: 0.5670 - val_loss: 0.3412 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.4059 - tp: 350.0000 - fp: 1995.0000 - tn: 223060.0000 - fn: 25469.0000 - accuracy: 0.8905 - precision: 0.1493 - recall: 0.0136 - auc: 0.5715 - val_loss: 0.3409 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6033\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.3948 - tp: 375.0000 - fp: 2215.0000 - tn: 222840.0000 - fn: 25444.0000 - accuracy: 0.8897 - precision: 0.1448 - recall: 0.0145 - auc: 0.5752 - val_loss: 0.3405 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6045\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3899 - tp: 389.0000 - fp: 2160.0000 - tn: 222895.0000 - fn: 25430.0000 - accuracy: 0.8900 - precision: 0.1526 - recall: 0.0151 - auc: 0.5753 - val_loss: 0.3402 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6058\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.3874 - tp: 402.0000 - fp: 2300.0000 - tn: 222755.0000 - fn: 25417.0000 - accuracy: 0.8895 - precision: 0.1488 - recall: 0.0156 - auc: 0.5747 - val_loss: 0.3398 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6071\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.3760 - tp: 442.0000 - fp: 2333.0000 - tn: 222722.0000 - fn: 25377.0000 - accuracy: 0.8895 - precision: 0.1593 - recall: 0.0171 - auc: 0.5784 - val_loss: 0.3395 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6081\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3705 - tp: 481.0000 - fp: 2510.0000 - tn: 222545.0000 - fn: 25338.0000 - accuracy: 0.8890 - precision: 0.1608 - recall: 0.0186 - auc: 0.5793 - val_loss: 0.3393 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6090\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3684 - tp: 493.0000 - fp: 2549.0000 - tn: 222506.0000 - fn: 25326.0000 - accuracy: 0.8889 - precision: 0.1621 - recall: 0.0191 - auc: 0.5801 - val_loss: 0.3390 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6101\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3690 - tp: 491.0000 - fp: 2720.0000 - tn: 222335.0000 - fn: 25328.0000 - accuracy: 0.8882 - precision: 0.1529 - recall: 0.0190 - auc: 0.5790 - val_loss: 0.3388 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6111\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3554 - tp: 508.0000 - fp: 2844.0000 - tn: 222211.0000 - fn: 25311.0000 - accuracy: 0.8878 - precision: 0.1516 - recall: 0.0197 - auc: 0.5840 - val_loss: 0.3386 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6122\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.3540 - tp: 546.0000 - fp: 2986.0000 - tn: 222069.0000 - fn: 25273.0000 - accuracy: 0.8874 - precision: 0.1546 - recall: 0.0211 - auc: 0.5830 - val_loss: 0.3384 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 32269.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6131\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3484 - tp: 607.0000 - fp: 3099.0000 - tn: 221956.0000 - fn: 25212.0000 - accuracy: 0.8872 - precision: 0.1638 - recall: 0.0235 - auc: 0.5844 - val_loss: 0.3382 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6138\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3452 - tp: 570.0000 - fp: 3240.0000 - tn: 221815.0000 - fn: 25249.0000 - accuracy: 0.8864 - precision: 0.1496 - recall: 0.0221 - auc: 0.5834 - val_loss: 0.3381 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6147\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3371 - tp: 690.0000 - fp: 3456.0000 - tn: 221599.0000 - fn: 25129.0000 - accuracy: 0.8861 - precision: 0.1664 - recall: 0.0267 - auc: 0.5866 - val_loss: 0.3379 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6158\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.3372 - tp: 766.0000 - fp: 3546.0000 - tn: 221509.0000 - fn: 25053.0000 - accuracy: 0.8860 - precision: 0.1776 - recall: 0.0297 - auc: 0.5839 - val_loss: 0.3378 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6167\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.3259 - tp: 752.0000 - fp: 3767.0000 - tn: 221288.0000 - fn: 25067.0000 - accuracy: 0.8851 - precision: 0.1664 - recall: 0.0291 - auc: 0.5881 - val_loss: 0.3377 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6174\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3242 - tp: 773.0000 - fp: 3946.0000 - tn: 221109.0000 - fn: 25046.0000 - accuracy: 0.8844 - precision: 0.1638 - recall: 0.0299 - auc: 0.5870 - val_loss: 0.3377 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6181\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3174 - tp: 793.0000 - fp: 4299.0000 - tn: 220756.0000 - fn: 25026.0000 - accuracy: 0.8831 - precision: 0.1557 - recall: 0.0307 - auc: 0.5891 - val_loss: 0.3376 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 32267.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6188\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3079 - tp: 865.0000 - fp: 4333.0000 - tn: 220722.0000 - fn: 24954.0000 - accuracy: 0.8833 - precision: 0.1664 - recall: 0.0335 - auc: 0.5903 - val_loss: 0.3376 - val_tp: 0.0000e+00 - val_fp: 4.0000 - val_tn: 32266.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6196\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3045 - tp: 919.0000 - fp: 4637.0000 - tn: 220418.0000 - fn: 24900.0000 - accuracy: 0.8823 - precision: 0.1654 - recall: 0.0356 - auc: 0.5927 - val_loss: 0.3376 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 32265.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6204\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.3045 - tp: 993.0000 - fp: 4742.0000 - tn: 220313.0000 - fn: 24826.0000 - accuracy: 0.8821 - precision: 0.1731 - recall: 0.0385 - auc: 0.5913 - val_loss: 0.3376 - val_tp: 0.0000e+00 - val_fp: 6.0000 - val_tn: 32264.0000 - val_fn: 3648.0000 - val_accuracy: 0.8983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.2993 - tp: 1017.0000 - fp: 5009.0000 - tn: 220046.0000 - fn: 24802.0000 - accuracy: 0.8812 - precision: 0.1688 - recall: 0.0394 - auc: 0.5923 - val_loss: 0.3376 - val_tp: 0.0000e+00 - val_fp: 8.0000 - val_tn: 32262.0000 - val_fn: 3648.0000 - val_accuracy: 0.8982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6217\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.2941 - tp: 1062.0000 - fp: 5163.0000 - tn: 219892.0000 - fn: 24757.0000 - accuracy: 0.8807 - precision: 0.1706 - recall: 0.0411 - auc: 0.5941 - val_loss: 0.3377 - val_tp: 0.0000e+00 - val_fp: 10.0000 - val_tn: 32260.0000 - val_fn: 3648.0000 - val_accuracy: 0.8982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6224\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.2931 - tp: 1136.0000 - fp: 5592.0000 - tn: 219463.0000 - fn: 24683.0000 - accuracy: 0.8793 - precision: 0.1688 - recall: 0.0440 - auc: 0.5930 - val_loss: 0.3378 - val_tp: 0.0000e+00 - val_fp: 10.0000 - val_tn: 32260.0000 - val_fn: 3648.0000 - val_accuracy: 0.8982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6231\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.2852 - tp: 1179.0000 - fp: 5612.0000 - tn: 219443.0000 - fn: 24640.0000 - accuracy: 0.8794 - precision: 0.1736 - recall: 0.0457 - auc: 0.5947 - val_loss: 0.3378 - val_tp: 1.0000 - val_fp: 15.0000 - val_tn: 32255.0000 - val_fn: 3647.0000 - val_accuracy: 0.8980 - val_precision: 0.0625 - val_recall: 2.7412e-04 - val_auc: 0.6238\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.2803 - tp: 1273.0000 - fp: 5788.0000 - tn: 219267.0000 - fn: 24546.0000 - accuracy: 0.8791 - precision: 0.1803 - recall: 0.0493 - auc: 0.5951 - val_loss: 0.3380 - val_tp: 2.0000 - val_fp: 17.0000 - val_tn: 32253.0000 - val_fn: 3646.0000 - val_accuracy: 0.8980 - val_precision: 0.1053 - val_recall: 5.4825e-04 - val_auc: 0.6242\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.2742 - tp: 1265.0000 - fp: 6178.0000 - tn: 218877.0000 - fn: 24554.0000 - accuracy: 0.8775 - precision: 0.1700 - recall: 0.0490 - auc: 0.5964 - val_loss: 0.3381 - val_tp: 2.0000 - val_fp: 19.0000 - val_tn: 32251.0000 - val_fn: 3646.0000 - val_accuracy: 0.8980 - val_precision: 0.0952 - val_recall: 5.4825e-04 - val_auc: 0.6248\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.2720 - tp: 1274.0000 - fp: 6483.0000 - tn: 218572.0000 - fn: 24545.0000 - accuracy: 0.8763 - precision: 0.1642 - recall: 0.0493 - auc: 0.5948 - val_loss: 0.3383 - val_tp: 2.0000 - val_fp: 20.0000 - val_tn: 32250.0000 - val_fn: 3646.0000 - val_accuracy: 0.8979 - val_precision: 0.0909 - val_recall: 5.4825e-04 - val_auc: 0.6255\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.2629 - tp: 1349.0000 - fp: 6837.0000 - tn: 218218.0000 - fn: 24470.0000 - accuracy: 0.8752 - precision: 0.1648 - recall: 0.0522 - auc: 0.5982 - val_loss: 0.3385 - val_tp: 3.0000 - val_fp: 23.0000 - val_tn: 32247.0000 - val_fn: 3645.0000 - val_accuracy: 0.8979 - val_precision: 0.1154 - val_recall: 8.2237e-04 - val_auc: 0.6259\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.2617 - tp: 1481.0000 - fp: 6901.0000 - tn: 218154.0000 - fn: 24338.0000 - accuracy: 0.8755 - precision: 0.1767 - recall: 0.0574 - auc: 0.5978 - val_loss: 0.3387 - val_tp: 4.0000 - val_fp: 28.0000 - val_tn: 32242.0000 - val_fn: 3644.0000 - val_accuracy: 0.8978 - val_precision: 0.1250 - val_recall: 0.0011 - val_auc: 0.6264\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.2563 - tp: 1521.0000 - fp: 7220.0000 - tn: 217835.0000 - fn: 24298.0000 - accuracy: 0.8744 - precision: 0.1740 - recall: 0.0589 - auc: 0.5987 - val_loss: 0.3389 - val_tp: 5.0000 - val_fp: 33.0000 - val_tn: 32237.0000 - val_fn: 3643.0000 - val_accuracy: 0.8977 - val_precision: 0.1316 - val_recall: 0.0014 - val_auc: 0.6271\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 1.2553 - tp: 1596.0000 - fp: 7515.0000 - tn: 217540.0000 - fn: 24223.0000 - accuracy: 0.8735 - precision: 0.1752 - recall: 0.0618 - auc: 0.5993 - val_loss: 0.3391 - val_tp: 5.0000 - val_fp: 36.0000 - val_tn: 32234.0000 - val_fn: 3643.0000 - val_accuracy: 0.8976 - val_precision: 0.1220 - val_recall: 0.0014 - val_auc: 0.6277\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 1.2521 - tp: 1634.0000 - fp: 7711.0000 - tn: 217344.0000 - fn: 24185.0000 - accuracy: 0.8729 - precision: 0.1749 - recall: 0.0633 - auc: 0.5976 - val_loss: 0.3394 - val_tp: 8.0000 - val_fp: 39.0000 - val_tn: 32231.0000 - val_fn: 3640.0000 - val_accuracy: 0.8976 - val_precision: 0.1702 - val_recall: 0.0022 - val_auc: 0.6280\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 2s 67ms/step - loss: 1.2496 - tp: 1649.0000 - fp: 8069.0000 - tn: 216986.0000 - fn: 24170.0000 - accuracy: 0.8715 - precision: 0.1697 - recall: 0.0639 - auc: 0.5983 - val_loss: 0.3396 - val_tp: 11.0000 - val_fp: 49.0000 - val_tn: 32221.0000 - val_fn: 3637.0000 - val_accuracy: 0.8974 - val_precision: 0.1833 - val_recall: 0.0030 - val_auc: 0.6283\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 2s 60ms/step - loss: 1.2467 - tp: 1780.0000 - fp: 8444.0000 - tn: 216611.0000 - fn: 24039.0000 - accuracy: 0.8705 - precision: 0.1741 - recall: 0.0689 - auc: 0.5977 - val_loss: 0.3399 - val_tp: 13.0000 - val_fp: 54.0000 - val_tn: 32216.0000 - val_fn: 3635.0000 - val_accuracy: 0.8973 - val_precision: 0.1940 - val_recall: 0.0036 - val_auc: 0.6289\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 1.2354 - tp: 1837.0000 - fp: 8720.0000 - tn: 216335.0000 - fn: 23982.0000 - accuracy: 0.8696 - precision: 0.1740 - recall: 0.0711 - auc: 0.6007 - val_loss: 0.3402 - val_tp: 13.0000 - val_fp: 62.0000 - val_tn: 32208.0000 - val_fn: 3635.0000 - val_accuracy: 0.8971 - val_precision: 0.1733 - val_recall: 0.0036 - val_auc: 0.6293\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 1.2342 - tp: 1904.0000 - fp: 8893.0000 - tn: 216162.0000 - fn: 23915.0000 - accuracy: 0.8692 - precision: 0.1763 - recall: 0.0737 - auc: 0.6000 - val_loss: 0.3406 - val_tp: 16.0000 - val_fp: 66.0000 - val_tn: 32204.0000 - val_fn: 3632.0000 - val_accuracy: 0.8970 - val_precision: 0.1951 - val_recall: 0.0044 - val_auc: 0.6297\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 1s 57ms/step - loss: 1.2346 - tp: 1996.0000 - fp: 9282.0000 - tn: 215773.0000 - fn: 23823.0000 - accuracy: 0.8680 - precision: 0.1770 - recall: 0.0773 - auc: 0.5989 - val_loss: 0.3410 - val_tp: 19.0000 - val_fp: 74.0000 - val_tn: 32196.0000 - val_fn: 3629.0000 - val_accuracy: 0.8969 - val_precision: 0.2043 - val_recall: 0.0052 - val_auc: 0.6302\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.2253 - tp: 2027.0000 - fp: 9699.0000 - tn: 215356.0000 - fn: 23792.0000 - accuracy: 0.8665 - precision: 0.1729 - recall: 0.0785 - auc: 0.6020 - val_loss: 0.3413 - val_tp: 20.0000 - val_fp: 83.0000 - val_tn: 32187.0000 - val_fn: 3628.0000 - val_accuracy: 0.8967 - val_precision: 0.1942 - val_recall: 0.0055 - val_auc: 0.6306\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 2s 70ms/step - loss: 1.2214 - tp: 2053.0000 - fp: 9904.0000 - tn: 215151.0000 - fn: 23766.0000 - accuracy: 0.8658 - precision: 0.1717 - recall: 0.0795 - auc: 0.6037 - val_loss: 0.3416 - val_tp: 25.0000 - val_fp: 95.0000 - val_tn: 32175.0000 - val_fn: 3623.0000 - val_accuracy: 0.8965 - val_precision: 0.2083 - val_recall: 0.0069 - val_auc: 0.6310\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.2148 - tp: 2148.0000 - fp: 10330.0000 - tn: 214725.0000 - fn: 23671.0000 - accuracy: 0.8645 - precision: 0.1721 - recall: 0.0832 - auc: 0.6036 - val_loss: 0.3420 - val_tp: 29.0000 - val_fp: 105.0000 - val_tn: 32165.0000 - val_fn: 3619.0000 - val_accuracy: 0.8963 - val_precision: 0.2164 - val_recall: 0.0079 - val_auc: 0.6313\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 56ms/step - loss: 1.2135 - tp: 2203.0000 - fp: 10388.0000 - tn: 214667.0000 - fn: 23616.0000 - accuracy: 0.8645 - precision: 0.1750 - recall: 0.0853 - auc: 0.6043 - val_loss: 0.3424 - val_tp: 35.0000 - val_fp: 119.0000 - val_tn: 32151.0000 - val_fn: 3613.0000 - val_accuracy: 0.8961 - val_precision: 0.2273 - val_recall: 0.0096 - val_auc: 0.6316\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.2065 - tp: 2322.0000 - fp: 10832.0000 - tn: 214223.0000 - fn: 23497.0000 - accuracy: 0.8632 - precision: 0.1765 - recall: 0.0899 - auc: 0.6050 - val_loss: 0.3428 - val_tp: 39.0000 - val_fp: 134.0000 - val_tn: 32136.0000 - val_fn: 3609.0000 - val_accuracy: 0.8958 - val_precision: 0.2254 - val_recall: 0.0107 - val_auc: 0.6319\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.2033 - tp: 2331.0000 - fp: 11171.0000 - tn: 213884.0000 - fn: 23488.0000 - accuracy: 0.8618 - precision: 0.1726 - recall: 0.0903 - auc: 0.6058 - val_loss: 0.3433 - val_tp: 43.0000 - val_fp: 154.0000 - val_tn: 32116.0000 - val_fn: 3605.0000 - val_accuracy: 0.8953 - val_precision: 0.2183 - val_recall: 0.0118 - val_auc: 0.6322\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.2028 - tp: 2468.0000 - fp: 11462.0000 - tn: 213593.0000 - fn: 23351.0000 - accuracy: 0.8612 - precision: 0.1772 - recall: 0.0956 - auc: 0.6045 - val_loss: 0.3437 - val_tp: 45.0000 - val_fp: 183.0000 - val_tn: 32087.0000 - val_fn: 3603.0000 - val_accuracy: 0.8946 - val_precision: 0.1974 - val_recall: 0.0123 - val_auc: 0.6326\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.1972 - tp: 2577.0000 - fp: 11719.0000 - tn: 213336.0000 - fn: 23242.0000 - accuracy: 0.8606 - precision: 0.1803 - recall: 0.0998 - auc: 0.6059 - val_loss: 0.3442 - val_tp: 47.0000 - val_fp: 200.0000 - val_tn: 32070.0000 - val_fn: 3601.0000 - val_accuracy: 0.8942 - val_precision: 0.1903 - val_recall: 0.0129 - val_auc: 0.6329\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1968 - tp: 2533.0000 - fp: 12059.0000 - tn: 212996.0000 - fn: 23286.0000 - accuracy: 0.8591 - precision: 0.1736 - recall: 0.0981 - auc: 0.6047 - val_loss: 0.3448 - val_tp: 51.0000 - val_fp: 229.0000 - val_tn: 32041.0000 - val_fn: 3597.0000 - val_accuracy: 0.8935 - val_precision: 0.1821 - val_recall: 0.0140 - val_auc: 0.6332\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.1888 - tp: 2719.0000 - fp: 12522.0000 - tn: 212533.0000 - fn: 23100.0000 - accuracy: 0.8580 - precision: 0.1784 - recall: 0.1053 - auc: 0.6063 - val_loss: 0.3453 - val_tp: 54.0000 - val_fp: 250.0000 - val_tn: 32020.0000 - val_fn: 3594.0000 - val_accuracy: 0.8930 - val_precision: 0.1776 - val_recall: 0.0148 - val_auc: 0.6335\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 1.1844 - tp: 2772.0000 - fp: 12785.0000 - tn: 212270.0000 - fn: 23047.0000 - accuracy: 0.8572 - precision: 0.1782 - recall: 0.1074 - auc: 0.6080 - val_loss: 0.3458 - val_tp: 59.0000 - val_fp: 270.0000 - val_tn: 32000.0000 - val_fn: 3589.0000 - val_accuracy: 0.8926 - val_precision: 0.1793 - val_recall: 0.0162 - val_auc: 0.6338\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.1884 - tp: 2623.0000 - fp: 13311.0000 - tn: 211744.0000 - fn: 23196.0000 - accuracy: 0.8545 - precision: 0.1646 - recall: 0.1016 - auc: 0.6045 - val_loss: 0.3464 - val_tp: 69.0000 - val_fp: 296.0000 - val_tn: 31974.0000 - val_fn: 3579.0000 - val_accuracy: 0.8921 - val_precision: 0.1890 - val_recall: 0.0189 - val_auc: 0.6340\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.1802 - tp: 2929.0000 - fp: 13604.0000 - tn: 211451.0000 - fn: 22890.0000 - accuracy: 0.8545 - precision: 0.1772 - recall: 0.1134 - auc: 0.6067 - val_loss: 0.3470 - val_tp: 72.0000 - val_fp: 328.0000 - val_tn: 31942.0000 - val_fn: 3576.0000 - val_accuracy: 0.8913 - val_precision: 0.1800 - val_recall: 0.0197 - val_auc: 0.6345\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.1791 - tp: 2907.0000 - fp: 13884.0000 - tn: 211171.0000 - fn: 22912.0000 - accuracy: 0.8533 - precision: 0.1731 - recall: 0.1126 - auc: 0.6066 - val_loss: 0.3475 - val_tp: 82.0000 - val_fp: 358.0000 - val_tn: 31912.0000 - val_fn: 3566.0000 - val_accuracy: 0.8908 - val_precision: 0.1864 - val_recall: 0.0225 - val_auc: 0.6346\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.1756 - tp: 3006.0000 - fp: 14236.0000 - tn: 210819.0000 - fn: 22813.0000 - accuracy: 0.8523 - precision: 0.1743 - recall: 0.1164 - auc: 0.6067 - val_loss: 0.3481 - val_tp: 95.0000 - val_fp: 388.0000 - val_tn: 31882.0000 - val_fn: 3553.0000 - val_accuracy: 0.8903 - val_precision: 0.1967 - val_recall: 0.0260 - val_auc: 0.6349\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.1702 - tp: 3093.0000 - fp: 14399.0000 - tn: 210656.0000 - fn: 22726.0000 - accuracy: 0.8520 - precision: 0.1768 - recall: 0.1198 - auc: 0.6084 - val_loss: 0.3487 - val_tp: 111.0000 - val_fp: 423.0000 - val_tn: 31847.0000 - val_fn: 3537.0000 - val_accuracy: 0.8897 - val_precision: 0.2079 - val_recall: 0.0304 - val_auc: 0.6352\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 1.1660 - tp: 3203.0000 - fp: 14908.0000 - tn: 210147.0000 - fn: 22616.0000 - accuracy: 0.8504 - precision: 0.1769 - recall: 0.1241 - auc: 0.6093 - val_loss: 0.3493 - val_tp: 128.0000 - val_fp: 458.0000 - val_tn: 31812.0000 - val_fn: 3520.0000 - val_accuracy: 0.8892 - val_precision: 0.2184 - val_recall: 0.0351 - val_auc: 0.6356\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 1.1649 - tp: 3238.0000 - fp: 15492.0000 - tn: 209563.0000 - fn: 22581.0000 - accuracy: 0.8482 - precision: 0.1729 - recall: 0.1254 - auc: 0.6082 - val_loss: 0.3499 - val_tp: 140.0000 - val_fp: 502.0000 - val_tn: 31768.0000 - val_fn: 3508.0000 - val_accuracy: 0.8884 - val_precision: 0.2181 - val_recall: 0.0384 - val_auc: 0.6358\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.1574 - tp: 3438.0000 - fp: 15495.0000 - tn: 209560.0000 - fn: 22381.0000 - accuracy: 0.8490 - precision: 0.1816 - recall: 0.1332 - auc: 0.6114 - val_loss: 0.3505 - val_tp: 147.0000 - val_fp: 530.0000 - val_tn: 31740.0000 - val_fn: 3501.0000 - val_accuracy: 0.8878 - val_precision: 0.2171 - val_recall: 0.0403 - val_auc: 0.6361\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.1556 - tp: 3350.0000 - fp: 16025.0000 - tn: 209030.0000 - fn: 22469.0000 - accuracy: 0.8466 - precision: 0.1729 - recall: 0.1297 - auc: 0.6109 - val_loss: 0.3512 - val_tp: 154.0000 - val_fp: 571.0000 - val_tn: 31699.0000 - val_fn: 3494.0000 - val_accuracy: 0.8868 - val_precision: 0.2124 - val_recall: 0.0422 - val_auc: 0.6364\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.1565 - tp: 3431.0000 - fp: 16421.0000 - tn: 208634.0000 - fn: 22388.0000 - accuracy: 0.8453 - precision: 0.1728 - recall: 0.1329 - auc: 0.6087 - val_loss: 0.3518 - val_tp: 168.0000 - val_fp: 610.0000 - val_tn: 31660.0000 - val_fn: 3480.0000 - val_accuracy: 0.8861 - val_precision: 0.2159 - val_recall: 0.0461 - val_auc: 0.6366\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 2s 59ms/step - loss: 1.1502 - tp: 3488.0000 - fp: 16577.0000 - tn: 208478.0000 - fn: 22331.0000 - accuracy: 0.8449 - precision: 0.1738 - recall: 0.1351 - auc: 0.6105 - val_loss: 0.3525 - val_tp: 178.0000 - val_fp: 651.0000 - val_tn: 31619.0000 - val_fn: 3470.0000 - val_accuracy: 0.8853 - val_precision: 0.2147 - val_recall: 0.0488 - val_auc: 0.6369\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.1504 - tp: 3573.0000 - fp: 16975.0000 - tn: 208080.0000 - fn: 22246.0000 - accuracy: 0.8437 - precision: 0.1739 - recall: 0.1384 - auc: 0.6098 - val_loss: 0.3532 - val_tp: 197.0000 - val_fp: 691.0000 - val_tn: 31579.0000 - val_fn: 3451.0000 - val_accuracy: 0.8847 - val_precision: 0.2218 - val_recall: 0.0540 - val_auc: 0.6372\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 57ms/step - loss: 1.1476 - tp: 3671.0000 - fp: 17315.0000 - tn: 207740.0000 - fn: 22148.0000 - accuracy: 0.8427 - precision: 0.1749 - recall: 0.1422 - auc: 0.6095 - val_loss: 0.3538 - val_tp: 206.0000 - val_fp: 743.0000 - val_tn: 31527.0000 - val_fn: 3442.0000 - val_accuracy: 0.8835 - val_precision: 0.2171 - val_recall: 0.0565 - val_auc: 0.6375\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 1s 48ms/step - loss: 1.1409 - tp: 3633.0000 - fp: 17485.0000 - tn: 207570.0000 - fn: 22186.0000 - accuracy: 0.8419 - precision: 0.1720 - recall: 0.1407 - auc: 0.6110 - val_loss: 0.3545 - val_tp: 222.0000 - val_fp: 784.0000 - val_tn: 31486.0000 - val_fn: 3426.0000 - val_accuracy: 0.8828 - val_precision: 0.2207 - val_recall: 0.0609 - val_auc: 0.6378\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 1s 52ms/step - loss: 1.1373 - tp: 3858.0000 - fp: 17937.0000 - tn: 207118.0000 - fn: 21961.0000 - accuracy: 0.8410 - precision: 0.1770 - recall: 0.1494 - auc: 0.6127 - val_loss: 0.3553 - val_tp: 234.0000 - val_fp: 836.0000 - val_tn: 31434.0000 - val_fn: 3414.0000 - val_accuracy: 0.8817 - val_precision: 0.2187 - val_recall: 0.0641 - val_auc: 0.6380\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.1388 - tp: 3824.0000 - fp: 18199.0000 - tn: 206856.0000 - fn: 21995.0000 - accuracy: 0.8398 - precision: 0.1736 - recall: 0.1481 - auc: 0.6106 - val_loss: 0.3560 - val_tp: 250.0000 - val_fp: 884.0000 - val_tn: 31386.0000 - val_fn: 3398.0000 - val_accuracy: 0.8808 - val_precision: 0.2205 - val_recall: 0.0685 - val_auc: 0.6382\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 1s 58ms/step - loss: 1.1337 - tp: 3901.0000 - fp: 18473.0000 - tn: 206582.0000 - fn: 21918.0000 - accuracy: 0.8390 - precision: 0.1744 - recall: 0.1511 - auc: 0.6114 - val_loss: 0.3567 - val_tp: 267.0000 - val_fp: 929.0000 - val_tn: 31341.0000 - val_fn: 3381.0000 - val_accuracy: 0.8800 - val_precision: 0.2232 - val_recall: 0.0732 - val_auc: 0.6384\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 2s 62ms/step - loss: 1.1311 - tp: 3981.0000 - fp: 18796.0000 - tn: 206259.0000 - fn: 21838.0000 - accuracy: 0.8380 - precision: 0.1748 - recall: 0.1542 - auc: 0.6118 - val_loss: 0.3575 - val_tp: 285.0000 - val_fp: 983.0000 - val_tn: 31287.0000 - val_fn: 3363.0000 - val_accuracy: 0.8790 - val_precision: 0.2248 - val_recall: 0.0781 - val_auc: 0.6385\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.1262 - tp: 4110.0000 - fp: 19289.0000 - tn: 205766.0000 - fn: 21709.0000 - accuracy: 0.8366 - precision: 0.1756 - recall: 0.1592 - auc: 0.6133 - val_loss: 0.3582 - val_tp: 300.0000 - val_fp: 1049.0000 - val_tn: 31221.0000 - val_fn: 3348.0000 - val_accuracy: 0.8776 - val_precision: 0.2224 - val_recall: 0.0822 - val_auc: 0.6388\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 1.1248 - tp: 4149.0000 - fp: 19500.0000 - tn: 205555.0000 - fn: 21670.0000 - accuracy: 0.8359 - precision: 0.1754 - recall: 0.1607 - auc: 0.6122 - val_loss: 0.3590 - val_tp: 310.0000 - val_fp: 1107.0000 - val_tn: 31163.0000 - val_fn: 3338.0000 - val_accuracy: 0.8762 - val_precision: 0.2188 - val_recall: 0.0850 - val_auc: 0.6390\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1217 - tp: 4227.0000 - fp: 19912.0000 - tn: 205143.0000 - fn: 21592.0000 - accuracy: 0.8346 - precision: 0.1751 - recall: 0.1637 - auc: 0.6134 - val_loss: 0.3598 - val_tp: 325.0000 - val_fp: 1170.0000 - val_tn: 31100.0000 - val_fn: 3323.0000 - val_accuracy: 0.8749 - val_precision: 0.2174 - val_recall: 0.0891 - val_auc: 0.6392\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 1s 54ms/step - loss: 1.1238 - tp: 4187.0000 - fp: 20200.0000 - tn: 204855.0000 - fn: 21632.0000 - accuracy: 0.8333 - precision: 0.1717 - recall: 0.1622 - auc: 0.6108 - val_loss: 0.3606 - val_tp: 343.0000 - val_fp: 1218.0000 - val_tn: 31052.0000 - val_fn: 3305.0000 - val_accuracy: 0.8741 - val_precision: 0.2197 - val_recall: 0.0940 - val_auc: 0.6396\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 1.1164 - tp: 4384.0000 - fp: 20371.0000 - tn: 204684.0000 - fn: 21435.0000 - accuracy: 0.8334 - precision: 0.1771 - recall: 0.1698 - auc: 0.6140 - val_loss: 0.3613 - val_tp: 353.0000 - val_fp: 1278.0000 - val_tn: 30992.0000 - val_fn: 3295.0000 - val_accuracy: 0.8727 - val_precision: 0.2164 - val_recall: 0.0968 - val_auc: 0.6398\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 1.1118 - tp: 4475.0000 - fp: 20686.0000 - tn: 204369.0000 - fn: 21344.0000 - accuracy: 0.8325 - precision: 0.1779 - recall: 0.1733 - auc: 0.6150 - val_loss: 0.3621 - val_tp: 364.0000 - val_fp: 1327.0000 - val_tn: 30943.0000 - val_fn: 3284.0000 - val_accuracy: 0.8716 - val_precision: 0.2153 - val_recall: 0.0998 - val_auc: 0.6400\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 1.1164 - tp: 4471.0000 - fp: 21374.0000 - tn: 203681.0000 - fn: 21348.0000 - accuracy: 0.8297 - precision: 0.1730 - recall: 0.1732 - auc: 0.6120 - val_loss: 0.3630 - val_tp: 383.0000 - val_fp: 1382.0000 - val_tn: 30888.0000 - val_fn: 3265.0000 - val_accuracy: 0.8706 - val_precision: 0.2170 - val_recall: 0.1050 - val_auc: 0.6402\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1112 - tp: 4565.0000 - fp: 21525.0000 - tn: 203530.0000 - fn: 21254.0000 - accuracy: 0.8295 - precision: 0.1750 - recall: 0.1768 - auc: 0.6131 - val_loss: 0.3638 - val_tp: 392.0000 - val_fp: 1428.0000 - val_tn: 30842.0000 - val_fn: 3256.0000 - val_accuracy: 0.8696 - val_precision: 0.2154 - val_recall: 0.1075 - val_auc: 0.6403\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 2s 72ms/step - loss: 1.1074 - tp: 4600.0000 - fp: 21894.0000 - tn: 203161.0000 - fn: 21219.0000 - accuracy: 0.8281 - precision: 0.1736 - recall: 0.1782 - auc: 0.6138 - val_loss: 0.3646 - val_tp: 401.0000 - val_fp: 1466.0000 - val_tn: 30804.0000 - val_fn: 3247.0000 - val_accuracy: 0.8688 - val_precision: 0.2148 - val_recall: 0.1099 - val_auc: 0.6404\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.1081 - tp: 4637.0000 - fp: 21873.0000 - tn: 203182.0000 - fn: 21182.0000 - accuracy: 0.8284 - precision: 0.1749 - recall: 0.1796 - auc: 0.6127 - val_loss: 0.3653 - val_tp: 411.0000 - val_fp: 1522.0000 - val_tn: 30748.0000 - val_fn: 3237.0000 - val_accuracy: 0.8675 - val_precision: 0.2126 - val_recall: 0.1127 - val_auc: 0.6407\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 1.1027 - tp: 4618.0000 - fp: 22428.0000 - tn: 202627.0000 - fn: 21201.0000 - accuracy: 0.8261 - precision: 0.1707 - recall: 0.1789 - auc: 0.6140 - val_loss: 0.3661 - val_tp: 424.0000 - val_fp: 1564.0000 - val_tn: 30706.0000 - val_fn: 3224.0000 - val_accuracy: 0.8667 - val_precision: 0.2133 - val_recall: 0.1162 - val_auc: 0.6408\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 1.1014 - tp: 4741.0000 - fp: 22792.0000 - tn: 202263.0000 - fn: 21078.0000 - accuracy: 0.8251 - precision: 0.1722 - recall: 0.1836 - auc: 0.6143 - val_loss: 0.3668 - val_tp: 438.0000 - val_fp: 1612.0000 - val_tn: 30658.0000 - val_fn: 3210.0000 - val_accuracy: 0.8657 - val_precision: 0.2137 - val_recall: 0.1201 - val_auc: 0.6410\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 1.1005 - tp: 4815.0000 - fp: 22925.0000 - tn: 202130.0000 - fn: 21004.0000 - accuracy: 0.8249 - precision: 0.1736 - recall: 0.1865 - auc: 0.6143 - val_loss: 0.3676 - val_tp: 447.0000 - val_fp: 1663.0000 - val_tn: 30607.0000 - val_fn: 3201.0000 - val_accuracy: 0.8646 - val_precision: 0.2118 - val_recall: 0.1225 - val_auc: 0.6413\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 2s 88ms/step - loss: 1.0969 - tp: 4941.0000 - fp: 23340.0000 - tn: 201715.0000 - fn: 20878.0000 - accuracy: 0.8237 - precision: 0.1747 - recall: 0.1914 - auc: 0.6150 - val_loss: 0.3685 - val_tp: 466.0000 - val_fp: 1728.0000 - val_tn: 30542.0000 - val_fn: 3182.0000 - val_accuracy: 0.8633 - val_precision: 0.2124 - val_recall: 0.1277 - val_auc: 0.6415\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 35ms/step - loss: 1.0957 - tp: 4907.0000 - fp: 23476.0000 - tn: 201579.0000 - fn: 20912.0000 - accuracy: 0.8231 - precision: 0.1729 - recall: 0.1901 - auc: 0.6149 - val_loss: 0.3694 - val_tp: 478.0000 - val_fp: 1782.0000 - val_tn: 30488.0000 - val_fn: 3170.0000 - val_accuracy: 0.8621 - val_precision: 0.2115 - val_recall: 0.1310 - val_auc: 0.6417\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 1.0897 - tp: 4961.0000 - fp: 23786.0000 - tn: 201269.0000 - fn: 20858.0000 - accuracy: 0.8220 - precision: 0.1726 - recall: 0.1921 - auc: 0.6160 - val_loss: 0.3702 - val_tp: 493.0000 - val_fp: 1855.0000 - val_tn: 30415.0000 - val_fn: 3155.0000 - val_accuracy: 0.8605 - val_precision: 0.2100 - val_recall: 0.1351 - val_auc: 0.6419\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.0911 - tp: 5003.0000 - fp: 24429.0000 - tn: 200626.0000 - fn: 20816.0000 - accuracy: 0.8197 - precision: 0.1700 - recall: 0.1938 - auc: 0.6149 - val_loss: 0.3711 - val_tp: 508.0000 - val_fp: 1917.0000 - val_tn: 30353.0000 - val_fn: 3140.0000 - val_accuracy: 0.8592 - val_precision: 0.2095 - val_recall: 0.1393 - val_auc: 0.6419\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.0843 - tp: 5180.0000 - fp: 24430.0000 - tn: 200625.0000 - fn: 20639.0000 - accuracy: 0.8204 - precision: 0.1749 - recall: 0.2006 - auc: 0.6166 - val_loss: 0.3719 - val_tp: 517.0000 - val_fp: 1963.0000 - val_tn: 30307.0000 - val_fn: 3131.0000 - val_accuracy: 0.8582 - val_precision: 0.2085 - val_recall: 0.1417 - val_auc: 0.6422\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.0905 - tp: 5036.0000 - fp: 24626.0000 - tn: 200429.0000 - fn: 20783.0000 - accuracy: 0.8190 - precision: 0.1698 - recall: 0.1951 - auc: 0.6135 - val_loss: 0.3727 - val_tp: 537.0000 - val_fp: 2005.0000 - val_tn: 30265.0000 - val_fn: 3111.0000 - val_accuracy: 0.8576 - val_precision: 0.2113 - val_recall: 0.1472 - val_auc: 0.6423\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 2s 58ms/step - loss: 1.0834 - tp: 5199.0000 - fp: 25075.0000 - tn: 199980.0000 - fn: 20620.0000 - accuracy: 0.8179 - precision: 0.1717 - recall: 0.2014 - auc: 0.6156 - val_loss: 0.3735 - val_tp: 549.0000 - val_fp: 2060.0000 - val_tn: 30210.0000 - val_fn: 3099.0000 - val_accuracy: 0.8564 - val_precision: 0.2104 - val_recall: 0.1505 - val_auc: 0.6425\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 1.0857 - tp: 5237.0000 - fp: 25282.0000 - tn: 199773.0000 - fn: 20582.0000 - accuracy: 0.8172 - precision: 0.1716 - recall: 0.2028 - auc: 0.6136 - val_loss: 0.3744 - val_tp: 558.0000 - val_fp: 2131.0000 - val_tn: 30139.0000 - val_fn: 3090.0000 - val_accuracy: 0.8546 - val_precision: 0.2075 - val_recall: 0.1530 - val_auc: 0.6427\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 1.0759 - tp: 5379.0000 - fp: 25597.0000 - tn: 199458.0000 - fn: 20440.0000 - accuracy: 0.8165 - precision: 0.1737 - recall: 0.2083 - auc: 0.6162 - val_loss: 0.3752 - val_tp: 570.0000 - val_fp: 2183.0000 - val_tn: 30087.0000 - val_fn: 3078.0000 - val_accuracy: 0.8535 - val_precision: 0.2070 - val_recall: 0.1562 - val_auc: 0.6430\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 1.0810 - tp: 5385.0000 - fp: 25931.0000 - tn: 199124.0000 - fn: 20434.0000 - accuracy: 0.8152 - precision: 0.1720 - recall: 0.2086 - auc: 0.6147 - val_loss: 0.3760 - val_tp: 581.0000 - val_fp: 2234.0000 - val_tn: 30036.0000 - val_fn: 3067.0000 - val_accuracy: 0.8524 - val_precision: 0.2064 - val_recall: 0.1593 - val_auc: 0.6431\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 1s 39ms/step - loss: 1.0758 - tp: 5394.0000 - fp: 26210.0000 - tn: 198845.0000 - fn: 20425.0000 - accuracy: 0.8141 - precision: 0.1707 - recall: 0.2089 - auc: 0.6160 - val_loss: 0.3768 - val_tp: 598.0000 - val_fp: 2282.0000 - val_tn: 29988.0000 - val_fn: 3050.0000 - val_accuracy: 0.8516 - val_precision: 0.2076 - val_recall: 0.1639 - val_auc: 0.6433\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.0744 - tp: 5434.0000 - fp: 26040.0000 - tn: 199015.0000 - fn: 20385.0000 - accuracy: 0.8149 - precision: 0.1727 - recall: 0.2105 - auc: 0.6162 - val_loss: 0.3777 - val_tp: 614.0000 - val_fp: 2334.0000 - val_tn: 29936.0000 - val_fn: 3034.0000 - val_accuracy: 0.8505 - val_precision: 0.2083 - val_recall: 0.1683 - val_auc: 0.6434\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 1.0697 - tp: 5501.0000 - fp: 26472.0000 - tn: 198583.0000 - fn: 20318.0000 - accuracy: 0.8135 - precision: 0.1721 - recall: 0.2131 - auc: 0.6175 - val_loss: 0.3785 - val_tp: 622.0000 - val_fp: 2405.0000 - val_tn: 29865.0000 - val_fn: 3026.0000 - val_accuracy: 0.8488 - val_precision: 0.2055 - val_recall: 0.1705 - val_auc: 0.6436\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 1.0692 - tp: 5590.0000 - fp: 26722.0000 - tn: 198333.0000 - fn: 20229.0000 - accuracy: 0.8129 - precision: 0.1730 - recall: 0.2165 - auc: 0.6168 - val_loss: 0.3794 - val_tp: 632.0000 - val_fp: 2470.0000 - val_tn: 29800.0000 - val_fn: 3016.0000 - val_accuracy: 0.8473 - val_precision: 0.2037 - val_recall: 0.1732 - val_auc: 0.6436\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.0675 - tp: 5650.0000 - fp: 27370.0000 - tn: 197685.0000 - fn: 20169.0000 - accuracy: 0.8105 - precision: 0.1711 - recall: 0.2188 - auc: 0.6166 - val_loss: 0.3803 - val_tp: 645.0000 - val_fp: 2519.0000 - val_tn: 29751.0000 - val_fn: 3003.0000 - val_accuracy: 0.8463 - val_precision: 0.2039 - val_recall: 0.1768 - val_auc: 0.6438\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.0676 - tp: 5577.0000 - fp: 27332.0000 - tn: 197723.0000 - fn: 20242.0000 - accuracy: 0.8104 - precision: 0.1695 - recall: 0.2160 - auc: 0.6161 - val_loss: 0.3812 - val_tp: 657.0000 - val_fp: 2566.0000 - val_tn: 29704.0000 - val_fn: 2991.0000 - val_accuracy: 0.8453 - val_precision: 0.2038 - val_recall: 0.1801 - val_auc: 0.6440\n",
      "Epoch 1/100\n",
      "26/26 [==============================] - 2s 71ms/step - loss: 1.4116 - tp: 979.0000 - fp: 4542.0000 - tn: 252783.0000 - fn: 28488.0000 - accuracy: 0.8848 - precision: 0.1773 - recall: 0.0332 - auc: 0.5772 - val_loss: 0.3395 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 32270.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6082\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.3485 - tp: 563.0000 - fp: 3034.0000 - tn: 222021.0000 - fn: 25256.0000 - accuracy: 0.8872 - precision: 0.1565 - recall: 0.0218 - auc: 0.5842 - val_loss: 0.3378 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 32268.0000 - val_fn: 3648.0000 - val_accuracy: 0.8984 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6175\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 1.3061 - tp: 975.0000 - fp: 4804.0000 - tn: 220251.0000 - fn: 24844.0000 - accuracy: 0.8818 - precision: 0.1687 - recall: 0.0378 - auc: 0.5903 - val_loss: 0.3381 - val_tp: 2.0000 - val_fp: 18.0000 - val_tn: 32252.0000 - val_fn: 3646.0000 - val_accuracy: 0.8980 - val_precision: 0.1000 - val_recall: 5.4825e-04 - val_auc: 0.6246\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.2583 - tp: 1525.0000 - fp: 7321.0000 - tn: 217734.0000 - fn: 24294.0000 - accuracy: 0.8740 - precision: 0.1724 - recall: 0.0591 - auc: 0.5983 - val_loss: 0.3405 - val_tp: 14.0000 - val_fp: 64.0000 - val_tn: 32206.0000 - val_fn: 3634.0000 - val_accuracy: 0.8970 - val_precision: 0.1795 - val_recall: 0.0038 - val_auc: 0.6294\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 1.2189 - tp: 2206.0000 - fp: 10452.0000 - tn: 214603.0000 - fn: 23613.0000 - accuracy: 0.8642 - precision: 0.1743 - recall: 0.0854 - auc: 0.6027 - val_loss: 0.3448 - val_tp: 49.0000 - val_fp: 228.0000 - val_tn: 32042.0000 - val_fn: 3599.0000 - val_accuracy: 0.8935 - val_precision: 0.1769 - val_recall: 0.0134 - val_auc: 0.6330\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 36ms/step - loss: 1.1795 - tp: 2920.0000 - fp: 13756.0000 - tn: 211299.0000 - fn: 22899.0000 - accuracy: 0.8539 - precision: 0.1751 - recall: 0.1131 - auc: 0.6063 - val_loss: 0.3505 - val_tp: 145.0000 - val_fp: 526.0000 - val_tn: 31744.0000 - val_fn: 3503.0000 - val_accuracy: 0.8878 - val_precision: 0.2161 - val_recall: 0.0397 - val_auc: 0.6360\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.1480 - tp: 3670.0000 - fp: 17185.0000 - tn: 207870.0000 - fn: 22149.0000 - accuracy: 0.8432 - precision: 0.1760 - recall: 0.1421 - auc: 0.6103 - val_loss: 0.3574 - val_tp: 284.0000 - val_fp: 981.0000 - val_tn: 31289.0000 - val_fn: 3364.0000 - val_accuracy: 0.8790 - val_precision: 0.2245 - val_recall: 0.0779 - val_auc: 0.6384\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.1175 - tp: 4354.0000 - fp: 20673.0000 - tn: 204382.0000 - fn: 21465.0000 - accuracy: 0.8320 - precision: 0.1740 - recall: 0.1686 - auc: 0.6135 - val_loss: 0.3652 - val_tp: 411.0000 - val_fp: 1507.0000 - val_tn: 30763.0000 - val_fn: 3237.0000 - val_accuracy: 0.8679 - val_precision: 0.2143 - val_recall: 0.1127 - val_auc: 0.6404\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.0945 - tp: 4945.0000 - fp: 23571.0000 - tn: 201484.0000 - fn: 20874.0000 - accuracy: 0.8228 - precision: 0.1734 - recall: 0.1915 - auc: 0.6154 - val_loss: 0.3736 - val_tp: 549.0000 - val_fp: 2061.0000 - val_tn: 30209.0000 - val_fn: 3099.0000 - val_accuracy: 0.8563 - val_precision: 0.2103 - val_recall: 0.1505 - val_auc: 0.6424\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 1.0793 - tp: 5457.0000 - fp: 26338.0000 - tn: 198717.0000 - fn: 20362.0000 - accuracy: 0.8139 - precision: 0.1716 - recall: 0.2114 - auc: 0.6152 - val_loss: 0.3813 - val_tp: 658.0000 - val_fp: 2578.0000 - val_tn: 29692.0000 - val_fn: 2990.0000 - val_accuracy: 0.8450 - val_precision: 0.2033 - val_recall: 0.1804 - val_auc: 0.6437\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 1.0601 - tp: 5857.0000 - fp: 28449.0000 - tn: 196606.0000 - fn: 19962.0000 - accuracy: 0.8070 - precision: 0.1707 - recall: 0.2268 - auc: 0.6156 - val_loss: 0.3885 - val_tp: 763.0000 - val_fp: 3030.0000 - val_tn: 29240.0000 - val_fn: 2885.0000 - val_accuracy: 0.8353 - val_precision: 0.2012 - val_recall: 0.2092 - val_auc: 0.6451\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 1.0418 - tp: 6245.0000 - fp: 30437.0000 - tn: 194618.0000 - fn: 19574.0000 - accuracy: 0.8007 - precision: 0.1702 - recall: 0.2419 - auc: 0.6183 - val_loss: 0.3953 - val_tp: 843.0000 - val_fp: 3386.0000 - val_tn: 28884.0000 - val_fn: 2805.0000 - val_accuracy: 0.8276 - val_precision: 0.1993 - val_recall: 0.2311 - val_auc: 0.6465\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 1.0249 - tp: 6637.0000 - fp: 32076.0000 - tn: 192979.0000 - fn: 19182.0000 - accuracy: 0.7957 - precision: 0.1714 - recall: 0.2571 - auc: 0.6201 - val_loss: 0.4011 - val_tp: 913.0000 - val_fp: 3681.0000 - val_tn: 28589.0000 - val_fn: 2735.0000 - val_accuracy: 0.8214 - val_precision: 0.1987 - val_recall: 0.2503 - val_auc: 0.6479\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 1.0100 - tp: 6929.0000 - fp: 33444.0000 - tn: 191611.0000 - fn: 18890.0000 - accuracy: 0.7914 - precision: 0.1716 - recall: 0.2684 - auc: 0.6217 - val_loss: 0.4063 - val_tp: 955.0000 - val_fp: 3950.0000 - val_tn: 28320.0000 - val_fn: 2693.0000 - val_accuracy: 0.8151 - val_precision: 0.1947 - val_recall: 0.2618 - val_auc: 0.6490\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 1.0012 - tp: 7098.0000 - fp: 35339.0000 - tn: 189716.0000 - fn: 18721.0000 - accuracy: 0.7845 - precision: 0.1673 - recall: 0.2749 - auc: 0.6199 - val_loss: 0.4123 - val_tp: 1007.0000 - val_fp: 4248.0000 - val_tn: 28022.0000 - val_fn: 2641.0000 - val_accuracy: 0.8082 - val_precision: 0.1916 - val_recall: 0.2760 - val_auc: 0.6504\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.9872 - tp: 7279.0000 - fp: 35838.0000 - tn: 189217.0000 - fn: 18540.0000 - accuracy: 0.7832 - precision: 0.1688 - recall: 0.2819 - auc: 0.6221 - val_loss: 0.4157 - val_tp: 1041.0000 - val_fp: 4418.0000 - val_tn: 27852.0000 - val_fn: 2607.0000 - val_accuracy: 0.8044 - val_precision: 0.1907 - val_recall: 0.2854 - val_auc: 0.6515\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9796 - tp: 7395.0000 - fp: 36782.0000 - tn: 188273.0000 - fn: 18424.0000 - accuracy: 0.7799 - precision: 0.1674 - recall: 0.2864 - auc: 0.6208 - val_loss: 0.4194 - val_tp: 1067.0000 - val_fp: 4590.0000 - val_tn: 27680.0000 - val_fn: 2581.0000 - val_accuracy: 0.8004 - val_precision: 0.1886 - val_recall: 0.2925 - val_auc: 0.6527\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.9710 - tp: 7520.0000 - fp: 37816.0000 - tn: 187239.0000 - fn: 18299.0000 - accuracy: 0.7763 - precision: 0.1659 - recall: 0.2913 - auc: 0.6206 - val_loss: 0.4226 - val_tp: 1094.0000 - val_fp: 4716.0000 - val_tn: 27554.0000 - val_fn: 2554.0000 - val_accuracy: 0.7976 - val_precision: 0.1883 - val_recall: 0.2999 - val_auc: 0.6539\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.9591 - tp: 7762.0000 - fp: 38345.0000 - tn: 186710.0000 - fn: 18057.0000 - accuracy: 0.7752 - precision: 0.1683 - recall: 0.3006 - auc: 0.6228 - val_loss: 0.4260 - val_tp: 1120.0000 - val_fp: 4864.0000 - val_tn: 27406.0000 - val_fn: 2528.0000 - val_accuracy: 0.7942 - val_precision: 0.1872 - val_recall: 0.3070 - val_auc: 0.6549\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.9483 - tp: 7829.0000 - fp: 39363.0000 - tn: 185692.0000 - fn: 17990.0000 - accuracy: 0.7714 - precision: 0.1659 - recall: 0.3032 - auc: 0.6228 - val_loss: 0.4280 - val_tp: 1140.0000 - val_fp: 4946.0000 - val_tn: 27324.0000 - val_fn: 2508.0000 - val_accuracy: 0.7925 - val_precision: 0.1873 - val_recall: 0.3125 - val_auc: 0.6559\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.9374 - tp: 7967.0000 - fp: 39610.0000 - tn: 185445.0000 - fn: 17852.0000 - accuracy: 0.7710 - precision: 0.1675 - recall: 0.3086 - auc: 0.6241 - val_loss: 0.4299 - val_tp: 1154.0000 - val_fp: 5028.0000 - val_tn: 27242.0000 - val_fn: 2494.0000 - val_accuracy: 0.7906 - val_precision: 0.1867 - val_recall: 0.3163 - val_auc: 0.6569\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.9263 - tp: 8229.0000 - fp: 40730.0000 - tn: 184325.0000 - fn: 17590.0000 - accuracy: 0.7675 - precision: 0.1681 - recall: 0.3187 - auc: 0.6251 - val_loss: 0.4318 - val_tp: 1173.0000 - val_fp: 5097.0000 - val_tn: 27173.0000 - val_fn: 2475.0000 - val_accuracy: 0.7892 - val_precision: 0.1871 - val_recall: 0.3215 - val_auc: 0.6580\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.9234 - tp: 8167.0000 - fp: 40927.0000 - tn: 184128.0000 - fn: 17652.0000 - accuracy: 0.7665 - precision: 0.1664 - recall: 0.3163 - auc: 0.6229 - val_loss: 0.4329 - val_tp: 1182.0000 - val_fp: 5136.0000 - val_tn: 27134.0000 - val_fn: 2466.0000 - val_accuracy: 0.7884 - val_precision: 0.1871 - val_recall: 0.3240 - val_auc: 0.6590\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.9088 - tp: 8491.0000 - fp: 41263.0000 - tn: 183792.0000 - fn: 17328.0000 - accuracy: 0.7665 - precision: 0.1707 - recall: 0.3289 - auc: 0.6266 - val_loss: 0.4342 - val_tp: 1190.0000 - val_fp: 5186.0000 - val_tn: 27084.0000 - val_fn: 2458.0000 - val_accuracy: 0.7872 - val_precision: 0.1866 - val_recall: 0.3262 - val_auc: 0.6600\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.9075 - tp: 8440.0000 - fp: 41845.0000 - tn: 183210.0000 - fn: 17379.0000 - accuracy: 0.7639 - precision: 0.1678 - recall: 0.3269 - auc: 0.6239 - val_loss: 0.4345 - val_tp: 1199.0000 - val_fp: 5191.0000 - val_tn: 27079.0000 - val_fn: 2449.0000 - val_accuracy: 0.7873 - val_precision: 0.1876 - val_recall: 0.3287 - val_auc: 0.6611\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 55ms/step - loss: 0.8959 - tp: 8629.0000 - fp: 42752.0000 - tn: 182303.0000 - fn: 17190.0000 - accuracy: 0.7611 - precision: 0.1679 - recall: 0.3342 - auc: 0.6263 - val_loss: 0.4359 - val_tp: 1207.0000 - val_fp: 5230.0000 - val_tn: 27040.0000 - val_fn: 2441.0000 - val_accuracy: 0.7864 - val_precision: 0.1875 - val_recall: 0.3309 - val_auc: 0.6619\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 2s 63ms/step - loss: 0.8907 - tp: 8601.0000 - fp: 43395.0000 - tn: 181660.0000 - fn: 17218.0000 - accuracy: 0.7584 - precision: 0.1654 - recall: 0.3331 - auc: 0.6262 - val_loss: 0.4380 - val_tp: 1222.0000 - val_fp: 5308.0000 - val_tn: 26962.0000 - val_fn: 2426.0000 - val_accuracy: 0.7847 - val_precision: 0.1871 - val_recall: 0.3350 - val_auc: 0.6630\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.8830 - tp: 8732.0000 - fp: 43745.0000 - tn: 181310.0000 - fn: 17087.0000 - accuracy: 0.7575 - precision: 0.1664 - recall: 0.3382 - auc: 0.6280 - val_loss: 0.4397 - val_tp: 1243.0000 - val_fp: 5368.0000 - val_tn: 26902.0000 - val_fn: 2405.0000 - val_accuracy: 0.7836 - val_precision: 0.1880 - val_recall: 0.3407 - val_auc: 0.6640\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.8789 - tp: 8695.0000 - fp: 44363.0000 - tn: 180692.0000 - fn: 17124.0000 - accuracy: 0.7549 - precision: 0.1639 - recall: 0.3368 - auc: 0.6265 - val_loss: 0.4400 - val_tp: 1246.0000 - val_fp: 5369.0000 - val_tn: 26901.0000 - val_fn: 2402.0000 - val_accuracy: 0.7836 - val_precision: 0.1884 - val_recall: 0.3416 - val_auc: 0.6649\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 1s 56ms/step - loss: 0.8768 - tp: 8916.0000 - fp: 44802.0000 - tn: 180253.0000 - fn: 16903.0000 - accuracy: 0.7540 - precision: 0.1660 - recall: 0.3453 - auc: 0.6255 - val_loss: 0.4406 - val_tp: 1256.0000 - val_fp: 5389.0000 - val_tn: 26881.0000 - val_fn: 2392.0000 - val_accuracy: 0.7834 - val_precision: 0.1890 - val_recall: 0.3443 - val_auc: 0.6660\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.8687 - tp: 8884.0000 - fp: 45363.0000 - tn: 179692.0000 - fn: 16935.0000 - accuracy: 0.7517 - precision: 0.1638 - recall: 0.3441 - auc: 0.6269 - val_loss: 0.4407 - val_tp: 1257.0000 - val_fp: 5368.0000 - val_tn: 26902.0000 - val_fn: 2391.0000 - val_accuracy: 0.7840 - val_precision: 0.1897 - val_recall: 0.3446 - val_auc: 0.6670\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.8637 - tp: 9088.0000 - fp: 45741.0000 - tn: 179314.0000 - fn: 16731.0000 - accuracy: 0.7510 - precision: 0.1658 - recall: 0.3520 - auc: 0.6282 - val_loss: 0.4411 - val_tp: 1260.0000 - val_fp: 5369.0000 - val_tn: 26901.0000 - val_fn: 2388.0000 - val_accuracy: 0.7840 - val_precision: 0.1901 - val_recall: 0.3454 - val_auc: 0.6681\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.8583 - tp: 9026.0000 - fp: 46014.0000 - tn: 179041.0000 - fn: 16793.0000 - accuracy: 0.7496 - precision: 0.1640 - recall: 0.3496 - auc: 0.6283 - val_loss: 0.4412 - val_tp: 1262.0000 - val_fp: 5361.0000 - val_tn: 26909.0000 - val_fn: 2386.0000 - val_accuracy: 0.7843 - val_precision: 0.1905 - val_recall: 0.3459 - val_auc: 0.6692\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.8512 - tp: 9099.0000 - fp: 46235.0000 - tn: 178820.0000 - fn: 16720.0000 - accuracy: 0.7491 - precision: 0.1644 - recall: 0.3524 - auc: 0.6307 - val_loss: 0.4405 - val_tp: 1259.0000 - val_fp: 5290.0000 - val_tn: 26980.0000 - val_fn: 2389.0000 - val_accuracy: 0.7862 - val_precision: 0.1922 - val_recall: 0.3451 - val_auc: 0.6702\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 0.8463 - tp: 9320.0000 - fp: 46648.0000 - tn: 178407.0000 - fn: 16499.0000 - accuracy: 0.7483 - precision: 0.1665 - recall: 0.3610 - auc: 0.6320 - val_loss: 0.4413 - val_tp: 1264.0000 - val_fp: 5312.0000 - val_tn: 26958.0000 - val_fn: 2384.0000 - val_accuracy: 0.7857 - val_precision: 0.1922 - val_recall: 0.3465 - val_auc: 0.6713\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.8461 - tp: 9272.0000 - fp: 47057.0000 - tn: 177998.0000 - fn: 16547.0000 - accuracy: 0.7465 - precision: 0.1646 - recall: 0.3591 - auc: 0.6298 - val_loss: 0.4420 - val_tp: 1268.0000 - val_fp: 5338.0000 - val_tn: 26932.0000 - val_fn: 2380.0000 - val_accuracy: 0.7851 - val_precision: 0.1919 - val_recall: 0.3476 - val_auc: 0.6724\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.8399 - tp: 9312.0000 - fp: 47105.0000 - tn: 177950.0000 - fn: 16507.0000 - accuracy: 0.7464 - precision: 0.1651 - recall: 0.3607 - auc: 0.6318 - val_loss: 0.4417 - val_tp: 1264.0000 - val_fp: 5309.0000 - val_tn: 26961.0000 - val_fn: 2384.0000 - val_accuracy: 0.7858 - val_precision: 0.1923 - val_recall: 0.3465 - val_auc: 0.6735\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.8352 - tp: 9312.0000 - fp: 47544.0000 - tn: 177511.0000 - fn: 16507.0000 - accuracy: 0.7447 - precision: 0.1638 - recall: 0.3607 - auc: 0.6324 - val_loss: 0.4424 - val_tp: 1277.0000 - val_fp: 5328.0000 - val_tn: 26942.0000 - val_fn: 2371.0000 - val_accuracy: 0.7857 - val_precision: 0.1933 - val_recall: 0.3501 - val_auc: 0.6745\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8333 - tp: 9486.0000 - fp: 47917.0000 - tn: 177138.0000 - fn: 16333.0000 - accuracy: 0.7439 - precision: 0.1653 - recall: 0.3674 - auc: 0.6328 - val_loss: 0.4433 - val_tp: 1279.0000 - val_fp: 5369.0000 - val_tn: 26901.0000 - val_fn: 2369.0000 - val_accuracy: 0.7846 - val_precision: 0.1924 - val_recall: 0.3506 - val_auc: 0.6756\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.8260 - tp: 9519.0000 - fp: 47983.0000 - tn: 177072.0000 - fn: 16300.0000 - accuracy: 0.7438 - precision: 0.1655 - recall: 0.3687 - auc: 0.6353 - val_loss: 0.4434 - val_tp: 1282.0000 - val_fp: 5356.0000 - val_tn: 26914.0000 - val_fn: 2366.0000 - val_accuracy: 0.7850 - val_precision: 0.1931 - val_recall: 0.3514 - val_auc: 0.6766\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 1s 49ms/step - loss: 0.8221 - tp: 9639.0000 - fp: 48331.0000 - tn: 176724.0000 - fn: 16180.0000 - accuracy: 0.7429 - precision: 0.1663 - recall: 0.3733 - auc: 0.6359 - val_loss: 0.4429 - val_tp: 1281.0000 - val_fp: 5322.0000 - val_tn: 26948.0000 - val_fn: 2367.0000 - val_accuracy: 0.7859 - val_precision: 0.1940 - val_recall: 0.3512 - val_auc: 0.6779\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.8235 - tp: 9582.0000 - fp: 48360.0000 - tn: 176695.0000 - fn: 16237.0000 - accuracy: 0.7425 - precision: 0.1654 - recall: 0.3711 - auc: 0.6344 - val_loss: 0.4420 - val_tp: 1271.0000 - val_fp: 5272.0000 - val_tn: 26998.0000 - val_fn: 2377.0000 - val_accuracy: 0.7870 - val_precision: 0.1943 - val_recall: 0.3484 - val_auc: 0.6790\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8175 - tp: 9718.0000 - fp: 48092.0000 - tn: 176963.0000 - fn: 16101.0000 - accuracy: 0.7441 - precision: 0.1681 - recall: 0.3764 - auc: 0.6376 - val_loss: 0.4419 - val_tp: 1273.0000 - val_fp: 5270.0000 - val_tn: 27000.0000 - val_fn: 2375.0000 - val_accuracy: 0.7872 - val_precision: 0.1946 - val_recall: 0.3490 - val_auc: 0.6801\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 1s 46ms/step - loss: 0.8131 - tp: 9725.0000 - fp: 48258.0000 - tn: 176797.0000 - fn: 16094.0000 - accuracy: 0.7435 - precision: 0.1677 - recall: 0.3767 - auc: 0.6384 - val_loss: 0.4412 - val_tp: 1278.0000 - val_fp: 5219.0000 - val_tn: 27051.0000 - val_fn: 2370.0000 - val_accuracy: 0.7887 - val_precision: 0.1967 - val_recall: 0.3503 - val_auc: 0.6811\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.8131 - tp: 9656.0000 - fp: 48695.0000 - tn: 176360.0000 - fn: 16163.0000 - accuracy: 0.7415 - precision: 0.1655 - recall: 0.3740 - auc: 0.6366 - val_loss: 0.4410 - val_tp: 1282.0000 - val_fp: 5206.0000 - val_tn: 27064.0000 - val_fn: 2366.0000 - val_accuracy: 0.7892 - val_precision: 0.1976 - val_recall: 0.3514 - val_auc: 0.6823\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 41ms/step - loss: 0.8115 - tp: 9632.0000 - fp: 48669.0000 - tn: 176386.0000 - fn: 16187.0000 - accuracy: 0.7415 - precision: 0.1652 - recall: 0.3731 - auc: 0.6363 - val_loss: 0.4418 - val_tp: 1293.0000 - val_fp: 5228.0000 - val_tn: 27042.0000 - val_fn: 2355.0000 - val_accuracy: 0.7889 - val_precision: 0.1983 - val_recall: 0.3544 - val_auc: 0.6833\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.8052 - tp: 9767.0000 - fp: 48717.0000 - tn: 176338.0000 - fn: 16052.0000 - accuracy: 0.7418 - precision: 0.1670 - recall: 0.3783 - auc: 0.6395 - val_loss: 0.4427 - val_tp: 1301.0000 - val_fp: 5281.0000 - val_tn: 26989.0000 - val_fn: 2347.0000 - val_accuracy: 0.7876 - val_precision: 0.1977 - val_recall: 0.3566 - val_auc: 0.6843\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.8023 - tp: 9895.0000 - fp: 49212.0000 - tn: 175843.0000 - fn: 15924.0000 - accuracy: 0.7404 - precision: 0.1674 - recall: 0.3832 - auc: 0.6398 - val_loss: 0.4421 - val_tp: 1295.0000 - val_fp: 5242.0000 - val_tn: 27028.0000 - val_fn: 2353.0000 - val_accuracy: 0.7885 - val_precision: 0.1981 - val_recall: 0.3550 - val_auc: 0.6854\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.8018 - tp: 9903.0000 - fp: 49248.0000 - tn: 175807.0000 - fn: 15916.0000 - accuracy: 0.7403 - precision: 0.1674 - recall: 0.3836 - auc: 0.6396 - val_loss: 0.4421 - val_tp: 1301.0000 - val_fp: 5237.0000 - val_tn: 27033.0000 - val_fn: 2347.0000 - val_accuracy: 0.7889 - val_precision: 0.1990 - val_recall: 0.3566 - val_auc: 0.6865\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 1s 55ms/step - loss: 0.7985 - tp: 9957.0000 - fp: 49340.0000 - tn: 175715.0000 - fn: 15862.0000 - accuracy: 0.7401 - precision: 0.1679 - recall: 0.3856 - auc: 0.6406 - val_loss: 0.4423 - val_tp: 1305.0000 - val_fp: 5246.0000 - val_tn: 27024.0000 - val_fn: 2343.0000 - val_accuracy: 0.7887 - val_precision: 0.1992 - val_recall: 0.3577 - val_auc: 0.6875\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7959 - tp: 9987.0000 - fp: 49585.0000 - tn: 175470.0000 - fn: 15832.0000 - accuracy: 0.7392 - precision: 0.1676 - recall: 0.3868 - auc: 0.6419 - val_loss: 0.4426 - val_tp: 1312.0000 - val_fp: 5256.0000 - val_tn: 27014.0000 - val_fn: 2336.0000 - val_accuracy: 0.7886 - val_precision: 0.1998 - val_recall: 0.3596 - val_auc: 0.6884\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 1s 50ms/step - loss: 0.7970 - tp: 9959.0000 - fp: 49818.0000 - tn: 175237.0000 - fn: 15860.0000 - accuracy: 0.7382 - precision: 0.1666 - recall: 0.3857 - auc: 0.6397 - val_loss: 0.4427 - val_tp: 1318.0000 - val_fp: 5248.0000 - val_tn: 27022.0000 - val_fn: 2330.0000 - val_accuracy: 0.7890 - val_precision: 0.2007 - val_recall: 0.3613 - val_auc: 0.6896\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 1s 53ms/step - loss: 0.7936 - tp: 10084.0000 - fp: 50026.0000 - tn: 175029.0000 - fn: 15735.0000 - accuracy: 0.7379 - precision: 0.1678 - recall: 0.3906 - auc: 0.6411 - val_loss: 0.4424 - val_tp: 1324.0000 - val_fp: 5230.0000 - val_tn: 27040.0000 - val_fn: 2324.0000 - val_accuracy: 0.7897 - val_precision: 0.2020 - val_recall: 0.3629 - val_auc: 0.6905\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.7911 - tp: 9987.0000 - fp: 49980.0000 - tn: 175075.0000 - fn: 15832.0000 - accuracy: 0.7377 - precision: 0.1665 - recall: 0.3868 - auc: 0.6415 - val_loss: 0.4419 - val_tp: 1325.0000 - val_fp: 5212.0000 - val_tn: 27058.0000 - val_fn: 2323.0000 - val_accuracy: 0.7902 - val_precision: 0.2027 - val_recall: 0.3632 - val_auc: 0.6917\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7873 - tp: 10128.0000 - fp: 50020.0000 - tn: 175035.0000 - fn: 15691.0000 - accuracy: 0.7381 - precision: 0.1684 - recall: 0.3923 - auc: 0.6434 - val_loss: 0.4423 - val_tp: 1334.0000 - val_fp: 5228.0000 - val_tn: 27042.0000 - val_fn: 2314.0000 - val_accuracy: 0.7900 - val_precision: 0.2033 - val_recall: 0.3657 - val_auc: 0.6926\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 1s 47ms/step - loss: 0.7789 - tp: 10266.0000 - fp: 50005.0000 - tn: 175050.0000 - fn: 15553.0000 - accuracy: 0.7387 - precision: 0.1703 - recall: 0.3976 - auc: 0.6480 - val_loss: 0.4410 - val_tp: 1329.0000 - val_fp: 5164.0000 - val_tn: 27106.0000 - val_fn: 2319.0000 - val_accuracy: 0.7917 - val_precision: 0.2047 - val_recall: 0.3643 - val_auc: 0.6936\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.7809 - tp: 10167.0000 - fp: 49769.0000 - tn: 175286.0000 - fn: 15652.0000 - accuracy: 0.7392 - precision: 0.1696 - recall: 0.3938 - auc: 0.6458 - val_loss: 0.4423 - val_tp: 1334.0000 - val_fp: 5229.0000 - val_tn: 27041.0000 - val_fn: 2314.0000 - val_accuracy: 0.7900 - val_precision: 0.2033 - val_recall: 0.3657 - val_auc: 0.6946\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 1s 51ms/step - loss: 0.7810 - tp: 10253.0000 - fp: 50278.0000 - tn: 174777.0000 - fn: 15566.0000 - accuracy: 0.7375 - precision: 0.1694 - recall: 0.3971 - auc: 0.6448 - val_loss: 0.4423 - val_tp: 1336.0000 - val_fp: 5220.0000 - val_tn: 27050.0000 - val_fn: 2312.0000 - val_accuracy: 0.7903 - val_precision: 0.2038 - val_recall: 0.3662 - val_auc: 0.6955\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 1s 44ms/step - loss: 0.7773 - tp: 10239.0000 - fp: 50304.0000 - tn: 174751.0000 - fn: 15580.0000 - accuracy: 0.7374 - precision: 0.1691 - recall: 0.3966 - auc: 0.6467 - val_loss: 0.4426 - val_tp: 1339.0000 - val_fp: 5230.0000 - val_tn: 27040.0000 - val_fn: 2309.0000 - val_accuracy: 0.7901 - val_precision: 0.2038 - val_recall: 0.3671 - val_auc: 0.6964\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.7743 - tp: 10285.0000 - fp: 50513.0000 - tn: 174542.0000 - fn: 15534.0000 - accuracy: 0.7367 - precision: 0.1692 - recall: 0.3984 - auc: 0.6478 - val_loss: 0.4414 - val_tp: 1323.0000 - val_fp: 5133.0000 - val_tn: 27137.0000 - val_fn: 2325.0000 - val_accuracy: 0.7924 - val_precision: 0.2049 - val_recall: 0.3627 - val_auc: 0.6973\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.7750 - tp: 10285.0000 - fp: 50266.0000 - tn: 174789.0000 - fn: 15534.0000 - accuracy: 0.7377 - precision: 0.1699 - recall: 0.3984 - auc: 0.6467 - val_loss: 0.4417 - val_tp: 1329.0000 - val_fp: 5151.0000 - val_tn: 27119.0000 - val_fn: 2319.0000 - val_accuracy: 0.7920 - val_precision: 0.2051 - val_recall: 0.3643 - val_auc: 0.6983\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.7688 - tp: 10414.0000 - fp: 50738.0000 - tn: 174317.0000 - fn: 15405.0000 - accuracy: 0.7363 - precision: 0.1703 - recall: 0.4033 - auc: 0.6498 - val_loss: 0.4423 - val_tp: 1339.0000 - val_fp: 5194.0000 - val_tn: 27076.0000 - val_fn: 2309.0000 - val_accuracy: 0.7911 - val_precision: 0.2050 - val_recall: 0.3671 - val_auc: 0.6991\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.7715 - tp: 10320.0000 - fp: 50998.0000 - tn: 174057.0000 - fn: 15499.0000 - accuracy: 0.7349 - precision: 0.1683 - recall: 0.3997 - auc: 0.6470 - val_loss: 0.4432 - val_tp: 1349.0000 - val_fp: 5233.0000 - val_tn: 27037.0000 - val_fn: 2299.0000 - val_accuracy: 0.7903 - val_precision: 0.2050 - val_recall: 0.3698 - val_auc: 0.6999\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.7649 - tp: 10521.0000 - fp: 50974.0000 - tn: 174081.0000 - fn: 15298.0000 - accuracy: 0.7358 - precision: 0.1711 - recall: 0.4075 - auc: 0.6518 - val_loss: 0.4430 - val_tp: 1350.0000 - val_fp: 5222.0000 - val_tn: 27048.0000 - val_fn: 2298.0000 - val_accuracy: 0.7906 - val_precision: 0.2054 - val_recall: 0.3701 - val_auc: 0.7007\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.7575 - tp: 10728.0000 - fp: 50985.0000 - tn: 174070.0000 - fn: 15091.0000 - accuracy: 0.7366 - precision: 0.1738 - recall: 0.4155 - auc: 0.6556 - val_loss: 0.4439 - val_tp: 1362.0000 - val_fp: 5258.0000 - val_tn: 27012.0000 - val_fn: 2286.0000 - val_accuracy: 0.7900 - val_precision: 0.2057 - val_recall: 0.3734 - val_auc: 0.7015\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7599 - tp: 10656.0000 - fp: 51062.0000 - tn: 173993.0000 - fn: 15163.0000 - accuracy: 0.7360 - precision: 0.1727 - recall: 0.4127 - auc: 0.6531 - val_loss: 0.4442 - val_tp: 1367.0000 - val_fp: 5267.0000 - val_tn: 27003.0000 - val_fn: 2281.0000 - val_accuracy: 0.7899 - val_precision: 0.2061 - val_recall: 0.3747 - val_auc: 0.7023\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7598 - tp: 10630.0000 - fp: 51395.0000 - tn: 173660.0000 - fn: 15189.0000 - accuracy: 0.7346 - precision: 0.1714 - recall: 0.4117 - auc: 0.6527 - val_loss: 0.4452 - val_tp: 1375.0000 - val_fp: 5307.0000 - val_tn: 26963.0000 - val_fn: 2273.0000 - val_accuracy: 0.7890 - val_precision: 0.2058 - val_recall: 0.3769 - val_auc: 0.7031\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7536 - tp: 10785.0000 - fp: 51352.0000 - tn: 173703.0000 - fn: 15034.0000 - accuracy: 0.7354 - precision: 0.1736 - recall: 0.4177 - auc: 0.6560 - val_loss: 0.4475 - val_tp: 1397.0000 - val_fp: 5448.0000 - val_tn: 26822.0000 - val_fn: 2251.0000 - val_accuracy: 0.7857 - val_precision: 0.2041 - val_recall: 0.3829 - val_auc: 0.7037\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.7505 - tp: 10905.0000 - fp: 51977.0000 - tn: 173078.0000 - fn: 14914.0000 - accuracy: 0.7334 - precision: 0.1734 - recall: 0.4224 - auc: 0.6579 - val_loss: 0.4464 - val_tp: 1391.0000 - val_fp: 5369.0000 - val_tn: 26901.0000 - val_fn: 2257.0000 - val_accuracy: 0.7877 - val_precision: 0.2058 - val_recall: 0.3813 - val_auc: 0.7047\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7520 - tp: 10837.0000 - fp: 52023.0000 - tn: 173032.0000 - fn: 14982.0000 - accuracy: 0.7329 - precision: 0.1724 - recall: 0.4197 - auc: 0.6555 - val_loss: 0.4457 - val_tp: 1390.0000 - val_fp: 5326.0000 - val_tn: 26944.0000 - val_fn: 2258.0000 - val_accuracy: 0.7889 - val_precision: 0.2070 - val_recall: 0.3810 - val_auc: 0.7055\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 1s 35ms/step - loss: 0.7456 - tp: 10920.0000 - fp: 51728.0000 - tn: 173327.0000 - fn: 14899.0000 - accuracy: 0.7344 - precision: 0.1743 - recall: 0.4229 - auc: 0.6597 - val_loss: 0.4467 - val_tp: 1398.0000 - val_fp: 5382.0000 - val_tn: 26888.0000 - val_fn: 2250.0000 - val_accuracy: 0.7875 - val_precision: 0.2062 - val_recall: 0.3832 - val_auc: 0.7063\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 1s 40ms/step - loss: 0.7499 - tp: 10872.0000 - fp: 52262.0000 - tn: 172793.0000 - fn: 14947.0000 - accuracy: 0.7321 - precision: 0.1722 - recall: 0.4211 - auc: 0.6556 - val_loss: 0.4481 - val_tp: 1416.0000 - val_fp: 5452.0000 - val_tn: 26818.0000 - val_fn: 2232.0000 - val_accuracy: 0.7861 - val_precision: 0.2062 - val_recall: 0.3882 - val_auc: 0.7069\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.7456 - tp: 10953.0000 - fp: 52718.0000 - tn: 172337.0000 - fn: 14866.0000 - accuracy: 0.7306 - precision: 0.1720 - recall: 0.4242 - auc: 0.6584 - val_loss: 0.4490 - val_tp: 1427.0000 - val_fp: 5506.0000 - val_tn: 26764.0000 - val_fn: 2221.0000 - val_accuracy: 0.7849 - val_precision: 0.2058 - val_recall: 0.3912 - val_auc: 0.7076\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 1s 38ms/step - loss: 0.7433 - tp: 11019.0000 - fp: 52557.0000 - tn: 172498.0000 - fn: 14800.0000 - accuracy: 0.7315 - precision: 0.1733 - recall: 0.4268 - auc: 0.6588 - val_loss: 0.4488 - val_tp: 1423.0000 - val_fp: 5484.0000 - val_tn: 26786.0000 - val_fn: 2225.0000 - val_accuracy: 0.7854 - val_precision: 0.2060 - val_recall: 0.3901 - val_auc: 0.7084\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7401 - tp: 11133.0000 - fp: 52747.0000 - tn: 172308.0000 - fn: 14686.0000 - accuracy: 0.7312 - precision: 0.1743 - recall: 0.4312 - auc: 0.6608 - val_loss: 0.4495 - val_tp: 1433.0000 - val_fp: 5519.0000 - val_tn: 26751.0000 - val_fn: 2215.0000 - val_accuracy: 0.7847 - val_precision: 0.2061 - val_recall: 0.3928 - val_auc: 0.7091\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7415 - tp: 11044.0000 - fp: 52731.0000 - tn: 172324.0000 - fn: 14775.0000 - accuracy: 0.7309 - precision: 0.1732 - recall: 0.4277 - auc: 0.6595 - val_loss: 0.4497 - val_tp: 1438.0000 - val_fp: 5529.0000 - val_tn: 26741.0000 - val_fn: 2210.0000 - val_accuracy: 0.7845 - val_precision: 0.2064 - val_recall: 0.3942 - val_auc: 0.7098\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.7401 - tp: 11202.0000 - fp: 53081.0000 - tn: 171974.0000 - fn: 14617.0000 - accuracy: 0.7302 - precision: 0.1743 - recall: 0.4339 - auc: 0.6596 - val_loss: 0.4495 - val_tp: 1433.0000 - val_fp: 5523.0000 - val_tn: 26747.0000 - val_fn: 2215.0000 - val_accuracy: 0.7846 - val_precision: 0.2060 - val_recall: 0.3928 - val_auc: 0.7106\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.7340 - tp: 11252.0000 - fp: 52984.0000 - tn: 172071.0000 - fn: 14567.0000 - accuracy: 0.7307 - precision: 0.1752 - recall: 0.4358 - auc: 0.6636 - val_loss: 0.4489 - val_tp: 1434.0000 - val_fp: 5484.0000 - val_tn: 26786.0000 - val_fn: 2214.0000 - val_accuracy: 0.7857 - val_precision: 0.2073 - val_recall: 0.3931 - val_auc: 0.7113\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7354 - tp: 11227.0000 - fp: 53149.0000 - tn: 171906.0000 - fn: 14592.0000 - accuracy: 0.7300 - precision: 0.1744 - recall: 0.4348 - auc: 0.6616 - val_loss: 0.4493 - val_tp: 1444.0000 - val_fp: 5503.0000 - val_tn: 26767.0000 - val_fn: 2204.0000 - val_accuracy: 0.7854 - val_precision: 0.2079 - val_recall: 0.3958 - val_auc: 0.7119\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7334 - tp: 11289.0000 - fp: 53265.0000 - tn: 171790.0000 - fn: 14530.0000 - accuracy: 0.7298 - precision: 0.1749 - recall: 0.4372 - auc: 0.6631 - val_loss: 0.4492 - val_tp: 1442.0000 - val_fp: 5496.0000 - val_tn: 26774.0000 - val_fn: 2206.0000 - val_accuracy: 0.7856 - val_precision: 0.2078 - val_recall: 0.3953 - val_auc: 0.7128\n",
      "Epoch 81/100\n",
      "26/26 [==============================] - 1s 37ms/step - loss: 0.7282 - tp: 11362.0000 - fp: 53440.0000 - tn: 171615.0000 - fn: 14457.0000 - accuracy: 0.7294 - precision: 0.1753 - recall: 0.4401 - auc: 0.6661 - val_loss: 0.4492 - val_tp: 1441.0000 - val_fp: 5503.0000 - val_tn: 26767.0000 - val_fn: 2207.0000 - val_accuracy: 0.7853 - val_precision: 0.2075 - val_recall: 0.3950 - val_auc: 0.7134\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 1s 45ms/step - loss: 0.7264 - tp: 11485.0000 - fp: 53583.0000 - tn: 171472.0000 - fn: 14334.0000 - accuracy: 0.7293 - precision: 0.1765 - recall: 0.4448 - auc: 0.6669 - val_loss: 0.4500 - val_tp: 1452.0000 - val_fp: 5550.0000 - val_tn: 26720.0000 - val_fn: 2196.0000 - val_accuracy: 0.7843 - val_precision: 0.2074 - val_recall: 0.3980 - val_auc: 0.7139\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 1s 42ms/step - loss: 0.7303 - tp: 11354.0000 - fp: 53743.0000 - tn: 171312.0000 - fn: 14465.0000 - accuracy: 0.7281 - precision: 0.1744 - recall: 0.4398 - auc: 0.6639 - val_loss: 0.4507 - val_tp: 1458.0000 - val_fp: 5589.0000 - val_tn: 26681.0000 - val_fn: 2190.0000 - val_accuracy: 0.7834 - val_precision: 0.2069 - val_recall: 0.3997 - val_auc: 0.7145\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7276 - tp: 11311.0000 - fp: 53694.0000 - tn: 171361.0000 - fn: 14508.0000 - accuracy: 0.7281 - precision: 0.1740 - recall: 0.4381 - auc: 0.6650 - val_loss: 0.4492 - val_tp: 1444.0000 - val_fp: 5480.0000 - val_tn: 26790.0000 - val_fn: 2204.0000 - val_accuracy: 0.7861 - val_precision: 0.2085 - val_recall: 0.3958 - val_auc: 0.7154\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7247 - tp: 11523.0000 - fp: 53853.0000 - tn: 171202.0000 - fn: 14296.0000 - accuracy: 0.7284 - precision: 0.1763 - recall: 0.4463 - auc: 0.6670 - val_loss: 0.4493 - val_tp: 1452.0000 - val_fp: 5505.0000 - val_tn: 26765.0000 - val_fn: 2196.0000 - val_accuracy: 0.7856 - val_precision: 0.2087 - val_recall: 0.3980 - val_auc: 0.7159\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 37ms/step - loss: 0.7253 - tp: 11433.0000 - fp: 53643.0000 - tn: 171412.0000 - fn: 14386.0000 - accuracy: 0.7288 - precision: 0.1757 - recall: 0.4428 - auc: 0.6664 - val_loss: 0.4493 - val_tp: 1452.0000 - val_fp: 5505.0000 - val_tn: 26765.0000 - val_fn: 2196.0000 - val_accuracy: 0.7856 - val_precision: 0.2087 - val_recall: 0.3980 - val_auc: 0.7166\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 1s 36ms/step - loss: 0.7218 - tp: 11556.0000 - fp: 53967.0000 - tn: 171088.0000 - fn: 14263.0000 - accuracy: 0.7280 - precision: 0.1764 - recall: 0.4476 - auc: 0.6686 - val_loss: 0.4503 - val_tp: 1465.0000 - val_fp: 5556.0000 - val_tn: 26714.0000 - val_fn: 2183.0000 - val_accuracy: 0.7845 - val_precision: 0.2087 - val_recall: 0.4016 - val_auc: 0.7171\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 1s 43ms/step - loss: 0.7204 - tp: 11671.0000 - fp: 53785.0000 - tn: 171270.0000 - fn: 14148.0000 - accuracy: 0.7292 - precision: 0.1783 - recall: 0.4520 - auc: 0.6694 - val_loss: 0.4488 - val_tp: 1452.0000 - val_fp: 5485.0000 - val_tn: 26785.0000 - val_fn: 2196.0000 - val_accuracy: 0.7862 - val_precision: 0.2093 - val_recall: 0.3980 - val_auc: 0.7179\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 1s 41ms/step - loss: 0.7175 - tp: 11633.0000 - fp: 53737.0000 - tn: 171318.0000 - fn: 14186.0000 - accuracy: 0.7293 - precision: 0.1780 - recall: 0.4506 - auc: 0.6713 - val_loss: 0.4491 - val_tp: 1462.0000 - val_fp: 5516.0000 - val_tn: 26754.0000 - val_fn: 2186.0000 - val_accuracy: 0.7856 - val_precision: 0.2095 - val_recall: 0.4008 - val_auc: 0.7186\n",
      "Epoch 90/100\n",
      " 5/26 [====>.........................] - ETA: 0s - loss: 0.7059 - tp: 2320.0000 - fp: 10741.0000 - tn: 34184.0000 - fn: 2755.0000 - accuracy: 0.7301 - precision: 0.1776 - recall: 0.4571 - auc: 0.6751"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-f7843adeac35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# The class weights go here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         class_weight=class_weight) \n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mval_predictions_weighted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "saved_iterations = {}\n",
    "\n",
    "for i, j, k in every_cart:       \n",
    "    weighted_model = make_model(lr = k)\n",
    "    weighted_model.load_weights(initial_weights)\n",
    "\n",
    "    weighted_history = weighted_model.fit(\n",
    "        train_features,\n",
    "        train_labels,\n",
    "        batch_size=i,\n",
    "        epochs=j,\n",
    "        callbacks = [early_stopping],\n",
    "        validation_data=(val_features, val_labels),\n",
    "        # The class weights go here\n",
    "        class_weight=class_weight) \n",
    "\n",
    "    val_predictions_weighted = weighted_model.predict(val_features, batch_size=i)\n",
    "    AP = average_precision_score(val_labels, val_predictions_weighted)\n",
    "    AUC = AUCcalc(val_labels, val_predictions_weighted)\n",
    "    \n",
    "    saved_iterations[(i, j, k)] = [AP, AUC]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">10000</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">100</th>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.135545</td>\n",
       "      <td>0.608131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.164053</td>\n",
       "      <td>0.644035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000100</th>\n",
       "      <td>0.210697</td>\n",
       "      <td>0.724605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001000</th>\n",
       "      <td>0.236122</td>\n",
       "      <td>0.753916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>0.237031</td>\n",
       "      <td>0.754084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100000</th>\n",
       "      <td>0.237829</td>\n",
       "      <td>0.752204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>0.173901</td>\n",
       "      <td>0.711388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.300000</th>\n",
       "      <td>0.164391</td>\n",
       "      <td>0.696922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.600000</th>\n",
       "      <td>0.153816</td>\n",
       "      <td>0.677249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.900000</th>\n",
       "      <td>0.156337</td>\n",
       "      <td>0.677809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.200000</th>\n",
       "      <td>0.141753</td>\n",
       "      <td>0.651177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.500000</th>\n",
       "      <td>0.142672</td>\n",
       "      <td>0.650289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.800000</th>\n",
       "      <td>0.144499</td>\n",
       "      <td>0.650951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0         1\n",
       "10000 100 0.000001  0.135545  0.608131\n",
       "          0.000010  0.164053  0.644035\n",
       "          0.000100  0.210697  0.724605\n",
       "          0.001000  0.236122  0.753916\n",
       "          0.010000  0.237031  0.754084\n",
       "          0.100000  0.237829  0.752204\n",
       "          1.000000  0.173901  0.711388\n",
       "          1.300000  0.164391  0.696922\n",
       "          1.600000  0.153816  0.677249\n",
       "          1.900000  0.156337  0.677809\n",
       "          2.200000  0.141753  0.651177\n",
       "          2.500000  0.142672  0.650289\n",
       "          2.800000  0.144499  0.650951"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(saved_iterations).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">2000</th>\n",
       "      <th rowspan=\"13\" valign=\"top\">100</th>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.152994</td>\n",
       "      <td>0.631540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.187992</td>\n",
       "      <td>0.687453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000100</th>\n",
       "      <td>0.234234</td>\n",
       "      <td>0.752260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.001000</th>\n",
       "      <td>0.235774</td>\n",
       "      <td>0.752990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.010000</th>\n",
       "      <td>0.234479</td>\n",
       "      <td>0.751226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100000</th>\n",
       "      <td>0.225860</td>\n",
       "      <td>0.746114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>0.158459</td>\n",
       "      <td>0.684522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.300000</th>\n",
       "      <td>0.155608</td>\n",
       "      <td>0.678431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.600000</th>\n",
       "      <td>0.142342</td>\n",
       "      <td>0.649871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.900000</th>\n",
       "      <td>0.132003</td>\n",
       "      <td>0.621726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.200000</th>\n",
       "      <td>0.140701</td>\n",
       "      <td>0.641414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.500000</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.647708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.800000</th>\n",
       "      <td>0.144660</td>\n",
       "      <td>0.656433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10000</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">100</th>\n",
       "      <th>0.000001</th>\n",
       "      <td>0.135538</td>\n",
       "      <td>0.608113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.000010</th>\n",
       "      <td>0.164126</td>\n",
       "      <td>0.644046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0         1\n",
       "2000  100 0.000001  0.152994  0.631540\n",
       "          0.000010  0.187992  0.687453\n",
       "          0.000100  0.234234  0.752260\n",
       "          0.001000  0.235774  0.752990\n",
       "          0.010000  0.234479  0.751226\n",
       "          0.100000  0.225860  0.746114\n",
       "          1.000000  0.158459  0.684522\n",
       "          1.300000  0.155608  0.678431\n",
       "          1.600000  0.142342  0.649871\n",
       "          1.900000  0.132003  0.621726\n",
       "          2.200000  0.140701  0.641414\n",
       "          2.500000  0.142857  0.647708\n",
       "          2.800000  0.144660  0.656433\n",
       "10000 100 0.000001  0.135538  0.608113\n",
       "          0.000010  0.164126  0.644046"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(saved_iterations).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5437993 ],\n",
       "       [0.24689338],\n",
       "       [0.04576439],\n",
       "       ...,\n",
       "       [0.01896614],\n",
       "       [0.02788299],\n",
       "       [0.06111794]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_model = make_model(lr = .1)\n",
    "weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=10000,\n",
    "    epochs=100,\n",
    "    callbacks = [early_stopping],\n",
    "    validation_data=(val_features, val_labels),\n",
    "    # The class weights go here\n",
    "    class_weight=class_weight) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "imbalanced_data.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
